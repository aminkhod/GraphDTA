{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rgo8cLB7Ayqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9019ba19-9acd-45ce-d23b-3d5caf4aceaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_Et0csGA4of",
        "outputId": "faed307b-dfd8-42e4-b94b-27c20c2389c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCJG-aZCA4lg",
        "outputId": "c77fd3c2-19dd-46c6-b6b4-cca2084fb074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive  Othercomputers\n"
          ]
        }
      ],
      "source": [
        "!ls drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqBB0ST7A4i_",
        "outputId": "9b504053-b0a0-4c15-cd84-35d54ee0d533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GraphDTA-new\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/GraphDTA-new'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xsOYH5eqLNn"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3b_OMfravpyX"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jYc3W8E4A4fw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8dd9f6-ddd5-4bfa-e56b-816e1a28eaa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=6d91f3c366a6dd6216c5ac61434b6505fde221ed1b7cf649d67fe0831925ef43\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I6H3tkEBMmf",
        "outputId": "3d29c863-ef5f-499c-9d2d-0acf91ccac50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision numpy pandas scikit-learn tqdm matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SqX64FABMhW",
        "outputId": "3ebca1bd-898b-4666-8d1e-c11c98ad4a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QwFW6ZtGBMdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471ea573-6b1e-49f4-d5b8-0382ab08f4cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.2)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/drive/MyDrive/GraphDTA-new/create_data.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q90AnsOn2XoA",
        "outputId": "83bf6d07-9fc5-40f9-bb25-1752a43b3daa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "convert data from DeepDTA for  kiba\n",
            "\n",
            "dataset: kiba\n",
            "train_fold: 98545\n",
            "test_fold: 19709\n",
            "len(set(drugs)),len(set(prots)): 2068 229\n",
            "convert data from DeepDTA for  davis\n",
            "\n",
            "dataset: davis\n",
            "train_fold: 25046\n",
            "test_fold: 5010\n",
            "len(set(drugs)),len(set(prots)): 68 379\n",
            "data/processed/davis_train.pt  and  data/processed/davis_test.pt  are already created\n",
            "data/processed/kiba_train.pt  and  data/processed/kiba_test.pt  are already created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training.py 0 1 0 ###orggdta with 128,...."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KZzULn7drEG",
        "outputId": "d6204468-463b-4ff1-f4bc-c17a33fd503b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train epoch: 116 [322080/25046 (41%)]\tLoss: 0.116055\n",
            "Train epoch: 116 [408800/25046 (51%)]\tLoss: 0.070534\n",
            "Train epoch: 116 [488760/25046 (61%)]\tLoss: 0.051130\n",
            "Train epoch: 116 [576800/25046 (71%)]\tLoss: 0.045326\n",
            "Train epoch: 116 [659360/25046 (82%)]\tLoss: 0.045166\n",
            "Train epoch: 116 [732060/25046 (92%)]\tLoss: 0.065577\n",
            "Make prediction for 5010 samples...\n",
            "0.23959617 No improvement since epoch  114 ; best_mse,best_ci: 0.23644352 0.889898479699539 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 117 [0/25046 (0%)]\tLoss: 0.077224\n",
            "Train epoch: 117 [82920/25046 (10%)]\tLoss: 0.053367\n",
            "Train epoch: 117 [160080/25046 (20%)]\tLoss: 0.084950\n",
            "Train epoch: 117 [246900/25046 (31%)]\tLoss: 0.088514\n",
            "Train epoch: 117 [334080/25046 (41%)]\tLoss: 0.039982\n",
            "Train epoch: 117 [399700/25046 (51%)]\tLoss: 0.113520\n",
            "Train epoch: 117 [502680/25046 (61%)]\tLoss: 0.053273\n",
            "Train epoch: 117 [582680/25046 (71%)]\tLoss: 0.114747\n",
            "Train epoch: 117 [642400/25046 (82%)]\tLoss: 0.074764\n",
            "Train epoch: 117 [736380/25046 (92%)]\tLoss: 0.063155\n",
            "Make prediction for 5010 samples...\n",
            "0.24611309 No improvement since epoch  114 ; best_mse,best_ci: 0.23644352 0.889898479699539 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 118 [0/25046 (0%)]\tLoss: 0.065942\n",
            "Train epoch: 118 [81200/25046 (10%)]\tLoss: 0.125676\n",
            "Train epoch: 118 [165200/25046 (20%)]\tLoss: 0.077441\n",
            "Train epoch: 118 [243720/25046 (31%)]\tLoss: 0.080575\n",
            "Train epoch: 118 [335360/25046 (41%)]\tLoss: 0.115729\n",
            "Train epoch: 118 [414900/25046 (51%)]\tLoss: 0.060549\n",
            "Train epoch: 118 [502200/25046 (61%)]\tLoss: 0.063310\n",
            "Train epoch: 118 [576940/25046 (71%)]\tLoss: 0.099008\n",
            "Train epoch: 118 [655680/25046 (82%)]\tLoss: 0.065190\n",
            "Train epoch: 118 [736560/25046 (92%)]\tLoss: 0.088570\n",
            "Make prediction for 5010 samples...\n",
            "0.24045031 No improvement since epoch  114 ; best_mse,best_ci: 0.23644352 0.889898479699539 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 119 [0/25046 (0%)]\tLoss: 0.051182\n",
            "Train epoch: 119 [80400/25046 (10%)]\tLoss: 0.099875\n",
            "Train epoch: 119 [170840/25046 (20%)]\tLoss: 0.210397\n",
            "Train epoch: 119 [236580/25046 (31%)]\tLoss: 0.065259\n",
            "Train epoch: 119 [326800/25046 (41%)]\tLoss: 0.056347\n",
            "Train epoch: 119 [415100/25046 (51%)]\tLoss: 0.062297\n",
            "Train epoch: 119 [503280/25046 (61%)]\tLoss: 0.055379\n",
            "Train epoch: 119 [586740/25046 (71%)]\tLoss: 0.087315\n",
            "Train epoch: 119 [639360/25046 (82%)]\tLoss: 0.060455\n",
            "Train epoch: 119 [754380/25046 (92%)]\tLoss: 0.063887\n",
            "Make prediction for 5010 samples...\n",
            "0.23994823 No improvement since epoch  114 ; best_mse,best_ci: 0.23644352 0.889898479699539 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 120 [0/25046 (0%)]\tLoss: 0.053207\n",
            "Train epoch: 120 [81460/25046 (10%)]\tLoss: 0.036406\n",
            "Train epoch: 120 [163320/25046 (20%)]\tLoss: 0.071379\n",
            "Train epoch: 120 [243480/25046 (31%)]\tLoss: 0.048113\n",
            "Train epoch: 120 [332640/25046 (41%)]\tLoss: 0.051702\n",
            "Train epoch: 120 [403600/25046 (51%)]\tLoss: 0.113206\n",
            "Train epoch: 120 [486600/25046 (61%)]\tLoss: 0.056806\n",
            "Train epoch: 120 [574420/25046 (71%)]\tLoss: 0.094631\n",
            "Train epoch: 120 [664320/25046 (82%)]\tLoss: 0.072307\n",
            "Train epoch: 120 [737280/25046 (92%)]\tLoss: 0.048197\n",
            "Make prediction for 5010 samples...\n",
            "0.24297418 No improvement since epoch  114 ; best_mse,best_ci: 0.23644352 0.889898479699539 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 121 [0/25046 (0%)]\tLoss: 0.055005\n",
            "Train epoch: 121 [82420/25046 (10%)]\tLoss: 0.050176\n",
            "Train epoch: 121 [168320/25046 (20%)]\tLoss: 0.077624\n",
            "Train epoch: 121 [247920/25046 (31%)]\tLoss: 0.088717\n",
            "Train epoch: 121 [331920/25046 (41%)]\tLoss: 0.084704\n",
            "Train epoch: 121 [416600/25046 (51%)]\tLoss: 0.074212\n",
            "Train epoch: 121 [489360/25046 (61%)]\tLoss: 0.067569\n",
            "Train epoch: 121 [589680/25046 (71%)]\tLoss: 0.061105\n",
            "Train epoch: 121 [652800/25046 (82%)]\tLoss: 0.061227\n",
            "Train epoch: 121 [741960/25046 (92%)]\tLoss: 0.041469\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  121 ; best_mse,best_ci: 0.23608825 0.8866041660891535 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 122 [0/25046 (0%)]\tLoss: 0.054307\n",
            "Train epoch: 122 [82000/25046 (10%)]\tLoss: 0.104278\n",
            "Train epoch: 122 [164640/25046 (20%)]\tLoss: 0.051684\n",
            "Train epoch: 122 [246720/25046 (31%)]\tLoss: 0.093586\n",
            "Train epoch: 122 [324160/25046 (41%)]\tLoss: 0.042218\n",
            "Train epoch: 122 [417500/25046 (51%)]\tLoss: 0.069310\n",
            "Train epoch: 122 [497160/25046 (61%)]\tLoss: 0.061841\n",
            "Train epoch: 122 [582960/25046 (71%)]\tLoss: 0.054686\n",
            "Train epoch: 122 [656480/25046 (82%)]\tLoss: 0.106012\n",
            "Train epoch: 122 [746820/25046 (92%)]\tLoss: 0.112121\n",
            "Make prediction for 5010 samples...\n",
            "0.24618249 No improvement since epoch  121 ; best_mse,best_ci: 0.23608825 0.8866041660891535 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 123 [0/25046 (0%)]\tLoss: 0.105591\n",
            "Train epoch: 123 [82560/25046 (10%)]\tLoss: 0.062529\n",
            "Train epoch: 123 [163240/25046 (20%)]\tLoss: 0.059793\n",
            "Train epoch: 123 [244740/25046 (31%)]\tLoss: 0.083010\n",
            "Train epoch: 123 [336080/25046 (41%)]\tLoss: 0.091088\n",
            "Train epoch: 123 [402400/25046 (51%)]\tLoss: 0.059373\n",
            "Train epoch: 123 [474360/25046 (61%)]\tLoss: 0.106335\n",
            "Train epoch: 123 [571480/25046 (71%)]\tLoss: 0.066227\n",
            "Train epoch: 123 [649440/25046 (82%)]\tLoss: 0.069469\n",
            "Train epoch: 123 [724320/25046 (92%)]\tLoss: 0.081364\n",
            "Make prediction for 5010 samples...\n",
            "0.23985271 No improvement since epoch  121 ; best_mse,best_ci: 0.23608825 0.8866041660891535 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 124 [0/25046 (0%)]\tLoss: 0.062084\n",
            "Train epoch: 124 [82580/25046 (10%)]\tLoss: 0.055114\n",
            "Train epoch: 124 [164000/25046 (20%)]\tLoss: 0.103332\n",
            "Train epoch: 124 [241020/25046 (31%)]\tLoss: 0.140183\n",
            "Train epoch: 124 [325440/25046 (41%)]\tLoss: 0.068947\n",
            "Train epoch: 124 [417600/25046 (51%)]\tLoss: 0.075906\n",
            "Train epoch: 124 [497400/25046 (61%)]\tLoss: 0.130203\n",
            "Train epoch: 124 [579740/25046 (71%)]\tLoss: 0.071023\n",
            "Train epoch: 124 [656800/25046 (82%)]\tLoss: 0.054815\n",
            "Train epoch: 124 [743040/25046 (92%)]\tLoss: 0.048246\n",
            "Make prediction for 5010 samples...\n",
            "0.24626167 No improvement since epoch  121 ; best_mse,best_ci: 0.23608825 0.8866041660891535 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 125 [0/25046 (0%)]\tLoss: 0.052757\n",
            "Train epoch: 125 [83720/25046 (10%)]\tLoss: 0.074638\n",
            "Train epoch: 125 [165160/25046 (20%)]\tLoss: 0.059863\n",
            "Train epoch: 125 [249660/25046 (31%)]\tLoss: 0.049013\n",
            "Train epoch: 125 [326080/25046 (41%)]\tLoss: 0.057262\n",
            "Train epoch: 125 [417700/25046 (51%)]\tLoss: 0.059345\n",
            "Train epoch: 125 [504600/25046 (61%)]\tLoss: 0.074281\n",
            "Train epoch: 125 [559300/25046 (71%)]\tLoss: 0.088773\n",
            "Train epoch: 125 [654240/25046 (82%)]\tLoss: 0.135295\n",
            "Train epoch: 125 [753300/25046 (92%)]\tLoss: 0.041354\n",
            "Make prediction for 5010 samples...\n",
            "0.2405852 No improvement since epoch  121 ; best_mse,best_ci: 0.23608825 0.8866041660891535 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 126 [0/25046 (0%)]\tLoss: 0.049824\n",
            "Train epoch: 126 [82440/25046 (10%)]\tLoss: 0.093881\n",
            "Train epoch: 126 [162080/25046 (20%)]\tLoss: 0.100799\n",
            "Train epoch: 126 [250140/25046 (31%)]\tLoss: 0.056374\n",
            "Train epoch: 126 [316960/25046 (41%)]\tLoss: 0.061628\n",
            "Train epoch: 126 [403900/25046 (51%)]\tLoss: 0.069803\n",
            "Train epoch: 126 [497640/25046 (61%)]\tLoss: 0.039514\n",
            "Train epoch: 126 [562800/25046 (71%)]\tLoss: 0.085315\n",
            "Train epoch: 126 [651680/25046 (82%)]\tLoss: 0.067771\n",
            "Train epoch: 126 [741600/25046 (92%)]\tLoss: 0.055862\n",
            "Make prediction for 5010 samples...\n",
            "0.24326454 No improvement since epoch  121 ; best_mse,best_ci: 0.23608825 0.8866041660891535 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 127 [0/25046 (0%)]\tLoss: 0.067236\n",
            "Train epoch: 127 [82700/25046 (10%)]\tLoss: 0.091911\n",
            "Train epoch: 127 [161080/25046 (20%)]\tLoss: 0.073358\n",
            "Train epoch: 127 [246720/25046 (31%)]\tLoss: 0.143029\n",
            "Train epoch: 127 [330480/25046 (41%)]\tLoss: 0.129654\n",
            "Train epoch: 127 [410700/25046 (51%)]\tLoss: 0.065355\n",
            "Train epoch: 127 [490320/25046 (61%)]\tLoss: 0.075166\n",
            "Train epoch: 127 [582260/25046 (71%)]\tLoss: 0.049457\n",
            "Train epoch: 127 [646400/25046 (82%)]\tLoss: 0.049726\n",
            "Train epoch: 127 [737640/25046 (92%)]\tLoss: 0.038503\n",
            "Make prediction for 5010 samples...\n",
            "0.23694558 No improvement since epoch  121 ; best_mse,best_ci: 0.23608825 0.8866041660891535 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 128 [0/25046 (0%)]\tLoss: 0.030061\n",
            "Train epoch: 128 [80560/25046 (10%)]\tLoss: 0.066039\n",
            "Train epoch: 128 [168360/25046 (20%)]\tLoss: 0.049221\n",
            "Train epoch: 128 [248400/25046 (31%)]\tLoss: 0.065518\n",
            "Train epoch: 128 [328160/25046 (41%)]\tLoss: 0.056176\n",
            "Train epoch: 128 [409300/25046 (51%)]\tLoss: 0.047947\n",
            "Train epoch: 128 [515640/25046 (61%)]\tLoss: 0.095519\n",
            "Train epoch: 128 [567840/25046 (71%)]\tLoss: 0.047675\n",
            "Train epoch: 128 [663040/25046 (82%)]\tLoss: 0.088370\n",
            "Train epoch: 128 [730440/25046 (92%)]\tLoss: 0.070195\n",
            "Make prediction for 5010 samples...\n",
            "0.23935695 No improvement since epoch  121 ; best_mse,best_ci: 0.23608825 0.8866041660891535 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 129 [0/25046 (0%)]\tLoss: 0.083768\n",
            "Train epoch: 129 [80160/25046 (10%)]\tLoss: 0.066969\n",
            "Train epoch: 129 [163160/25046 (20%)]\tLoss: 0.048392\n",
            "Train epoch: 129 [249240/25046 (31%)]\tLoss: 0.089224\n",
            "Train epoch: 129 [320640/25046 (41%)]\tLoss: 0.054680\n",
            "Train epoch: 129 [418400/25046 (51%)]\tLoss: 0.058205\n",
            "Train epoch: 129 [494520/25046 (61%)]\tLoss: 0.054121\n",
            "Train epoch: 129 [574420/25046 (71%)]\tLoss: 0.077265\n",
            "Train epoch: 129 [667040/25046 (82%)]\tLoss: 0.133972\n",
            "Train epoch: 129 [746100/25046 (92%)]\tLoss: 0.046554\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 130 [0/25046 (0%)]\tLoss: 0.043558\n",
            "Train epoch: 130 [81240/25046 (10%)]\tLoss: 0.047683\n",
            "Train epoch: 130 [166920/25046 (20%)]\tLoss: 0.103414\n",
            "Train epoch: 130 [244920/25046 (31%)]\tLoss: 0.047114\n",
            "Train epoch: 130 [321040/25046 (41%)]\tLoss: 0.113323\n",
            "Train epoch: 130 [409000/25046 (51%)]\tLoss: 0.063763\n",
            "Train epoch: 130 [485880/25046 (61%)]\tLoss: 0.132155\n",
            "Train epoch: 130 [582400/25046 (71%)]\tLoss: 0.097798\n",
            "Train epoch: 130 [653600/25046 (82%)]\tLoss: 0.097985\n",
            "Train epoch: 130 [760140/25046 (92%)]\tLoss: 0.074199\n",
            "Make prediction for 5010 samples...\n",
            "0.25664753 No improvement since epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 131 [0/25046 (0%)]\tLoss: 0.078578\n",
            "Train epoch: 131 [81460/25046 (10%)]\tLoss: 0.106638\n",
            "Train epoch: 131 [165920/25046 (20%)]\tLoss: 0.057659\n",
            "Train epoch: 131 [246540/25046 (31%)]\tLoss: 0.034551\n",
            "Train epoch: 131 [326640/25046 (41%)]\tLoss: 0.061218\n",
            "Train epoch: 131 [407000/25046 (51%)]\tLoss: 0.104611\n",
            "Train epoch: 131 [511800/25046 (61%)]\tLoss: 0.072500\n",
            "Train epoch: 131 [582400/25046 (71%)]\tLoss: 0.063669\n",
            "Train epoch: 131 [659200/25046 (82%)]\tLoss: 0.065025\n",
            "Train epoch: 131 [733320/25046 (92%)]\tLoss: 0.095158\n",
            "Make prediction for 5010 samples...\n",
            "0.23930787 No improvement since epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 132 [0/25046 (0%)]\tLoss: 0.059095\n",
            "Train epoch: 132 [78860/25046 (10%)]\tLoss: 0.044456\n",
            "Train epoch: 132 [160680/25046 (20%)]\tLoss: 0.091606\n",
            "Train epoch: 132 [243720/25046 (31%)]\tLoss: 0.056174\n",
            "Train epoch: 132 [325840/25046 (41%)]\tLoss: 0.135087\n",
            "Train epoch: 132 [411900/25046 (51%)]\tLoss: 0.101384\n",
            "Train epoch: 132 [494880/25046 (61%)]\tLoss: 0.084717\n",
            "Train epoch: 132 [597380/25046 (71%)]\tLoss: 0.077432\n",
            "Train epoch: 132 [654720/25046 (82%)]\tLoss: 0.068510\n",
            "Train epoch: 132 [742860/25046 (92%)]\tLoss: 0.145574\n",
            "Make prediction for 5010 samples...\n",
            "0.23647022 No improvement since epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 133 [0/25046 (0%)]\tLoss: 0.093632\n",
            "Train epoch: 133 [82020/25046 (10%)]\tLoss: 0.095029\n",
            "Train epoch: 133 [159160/25046 (20%)]\tLoss: 0.080357\n",
            "Train epoch: 133 [247140/25046 (31%)]\tLoss: 0.059174\n",
            "Train epoch: 133 [335200/25046 (41%)]\tLoss: 0.047051\n",
            "Train epoch: 133 [426300/25046 (51%)]\tLoss: 0.058678\n",
            "Train epoch: 133 [490800/25046 (61%)]\tLoss: 0.076227\n",
            "Train epoch: 133 [593600/25046 (71%)]\tLoss: 0.118984\n",
            "Train epoch: 133 [652320/25046 (82%)]\tLoss: 0.075792\n",
            "Train epoch: 133 [730980/25046 (92%)]\tLoss: 0.050797\n",
            "Make prediction for 5010 samples...\n",
            "0.24240172 No improvement since epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 134 [0/25046 (0%)]\tLoss: 0.074863\n",
            "Train epoch: 134 [82020/25046 (10%)]\tLoss: 0.073895\n",
            "Train epoch: 134 [162800/25046 (20%)]\tLoss: 0.063698\n",
            "Train epoch: 134 [236820/25046 (31%)]\tLoss: 0.063724\n",
            "Train epoch: 134 [330560/25046 (41%)]\tLoss: 0.132597\n",
            "Train epoch: 134 [401200/25046 (51%)]\tLoss: 0.039528\n",
            "Train epoch: 134 [502200/25046 (61%)]\tLoss: 0.100361\n",
            "Train epoch: 134 [573580/25046 (71%)]\tLoss: 0.059174\n",
            "Train epoch: 134 [662720/25046 (82%)]\tLoss: 0.057568\n",
            "Train epoch: 134 [735660/25046 (92%)]\tLoss: 0.070814\n",
            "Make prediction for 5010 samples...\n",
            "0.25009057 No improvement since epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 135 [0/25046 (0%)]\tLoss: 0.065975\n",
            "Train epoch: 135 [84500/25046 (10%)]\tLoss: 0.059303\n",
            "Train epoch: 135 [162720/25046 (20%)]\tLoss: 0.112969\n",
            "Train epoch: 135 [242340/25046 (31%)]\tLoss: 0.105632\n",
            "Train epoch: 135 [332400/25046 (41%)]\tLoss: 0.084065\n",
            "Train epoch: 135 [406700/25046 (51%)]\tLoss: 0.102550\n",
            "Train epoch: 135 [476280/25046 (61%)]\tLoss: 0.043252\n",
            "Train epoch: 135 [561960/25046 (71%)]\tLoss: 0.091858\n",
            "Train epoch: 135 [663520/25046 (82%)]\tLoss: 0.047607\n",
            "Train epoch: 135 [736740/25046 (92%)]\tLoss: 0.041985\n",
            "Make prediction for 5010 samples...\n",
            "0.2380223 No improvement since epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 136 [0/25046 (0%)]\tLoss: 0.064765\n",
            "Train epoch: 136 [84420/25046 (10%)]\tLoss: 0.097387\n",
            "Train epoch: 136 [163440/25046 (20%)]\tLoss: 0.059570\n",
            "Train epoch: 136 [240600/25046 (31%)]\tLoss: 0.064921\n",
            "Train epoch: 136 [324400/25046 (41%)]\tLoss: 0.060306\n",
            "Train epoch: 136 [408400/25046 (51%)]\tLoss: 0.070078\n",
            "Train epoch: 136 [502800/25046 (61%)]\tLoss: 0.068292\n",
            "Train epoch: 136 [571620/25046 (71%)]\tLoss: 0.045680\n",
            "Train epoch: 136 [640320/25046 (82%)]\tLoss: 0.074692\n",
            "Train epoch: 136 [732060/25046 (92%)]\tLoss: 0.056856\n",
            "Make prediction for 5010 samples...\n",
            "0.23463395 No improvement since epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 137 [0/25046 (0%)]\tLoss: 0.200975\n",
            "Train epoch: 137 [82480/25046 (10%)]\tLoss: 0.061103\n",
            "Train epoch: 137 [161080/25046 (20%)]\tLoss: 0.064640\n",
            "Train epoch: 137 [247920/25046 (31%)]\tLoss: 0.050333\n",
            "Train epoch: 137 [332960/25046 (41%)]\tLoss: 0.108470\n",
            "Train epoch: 137 [407900/25046 (51%)]\tLoss: 0.116110\n",
            "Train epoch: 137 [496200/25046 (61%)]\tLoss: 0.054576\n",
            "Train epoch: 137 [561400/25046 (71%)]\tLoss: 0.063798\n",
            "Train epoch: 137 [663200/25046 (82%)]\tLoss: 0.065060\n",
            "Train epoch: 137 [722700/25046 (92%)]\tLoss: 0.073411\n",
            "Make prediction for 5010 samples...\n",
            "0.23864166 No improvement since epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 138 [0/25046 (0%)]\tLoss: 0.058304\n",
            "Train epoch: 138 [83100/25046 (10%)]\tLoss: 0.121245\n",
            "Train epoch: 138 [170080/25046 (20%)]\tLoss: 0.072491\n",
            "Train epoch: 138 [240360/25046 (31%)]\tLoss: 0.069385\n",
            "Train epoch: 138 [325120/25046 (41%)]\tLoss: 0.086327\n",
            "Train epoch: 138 [415200/25046 (51%)]\tLoss: 0.073514\n",
            "Train epoch: 138 [505200/25046 (61%)]\tLoss: 0.068872\n",
            "Train epoch: 138 [564480/25046 (71%)]\tLoss: 0.080231\n",
            "Train epoch: 138 [676640/25046 (82%)]\tLoss: 0.086709\n",
            "Train epoch: 138 [744660/25046 (92%)]\tLoss: 0.061334\n",
            "Make prediction for 5010 samples...\n",
            "0.23817004 No improvement since epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 139 [0/25046 (0%)]\tLoss: 0.087632\n",
            "Train epoch: 139 [80640/25046 (10%)]\tLoss: 0.080538\n",
            "Train epoch: 139 [166320/25046 (20%)]\tLoss: 0.045882\n",
            "Train epoch: 139 [251040/25046 (31%)]\tLoss: 0.099793\n",
            "Train epoch: 139 [333680/25046 (41%)]\tLoss: 0.092875\n",
            "Train epoch: 139 [419100/25046 (51%)]\tLoss: 0.061688\n",
            "Train epoch: 139 [505920/25046 (61%)]\tLoss: 0.128724\n",
            "Train epoch: 139 [580020/25046 (71%)]\tLoss: 0.107433\n",
            "Train epoch: 139 [655360/25046 (82%)]\tLoss: 0.051434\n",
            "Train epoch: 139 [738360/25046 (92%)]\tLoss: 0.052345\n",
            "Make prediction for 5010 samples...\n",
            "0.23873363 No improvement since epoch  129 ; best_mse,best_ci: 0.23404178 0.8912007367255319 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 140 [0/25046 (0%)]\tLoss: 0.068160\n",
            "Train epoch: 140 [85420/25046 (10%)]\tLoss: 0.058283\n",
            "Train epoch: 140 [163400/25046 (20%)]\tLoss: 0.049598\n",
            "Train epoch: 140 [249900/25046 (31%)]\tLoss: 0.037811\n",
            "Train epoch: 140 [328800/25046 (41%)]\tLoss: 0.067938\n",
            "Train epoch: 140 [415600/25046 (51%)]\tLoss: 0.072042\n",
            "Train epoch: 140 [491760/25046 (61%)]\tLoss: 0.063030\n",
            "Train epoch: 140 [571200/25046 (71%)]\tLoss: 0.091254\n",
            "Train epoch: 140 [659520/25046 (82%)]\tLoss: 0.053302\n",
            "Train epoch: 140 [756360/25046 (92%)]\tLoss: 0.128824\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  140 ; best_mse,best_ci: 0.23347329 0.8873474925004974 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 141 [0/25046 (0%)]\tLoss: 0.064003\n",
            "Train epoch: 141 [82060/25046 (10%)]\tLoss: 0.059593\n",
            "Train epoch: 141 [166720/25046 (20%)]\tLoss: 0.181232\n",
            "Train epoch: 141 [244380/25046 (31%)]\tLoss: 0.055276\n",
            "Train epoch: 141 [326480/25046 (41%)]\tLoss: 0.088106\n",
            "Train epoch: 141 [417900/25046 (51%)]\tLoss: 0.060315\n",
            "Train epoch: 141 [487080/25046 (61%)]\tLoss: 0.082616\n",
            "Train epoch: 141 [579040/25046 (71%)]\tLoss: 0.059569\n",
            "Train epoch: 141 [644800/25046 (82%)]\tLoss: 0.055847\n",
            "Train epoch: 141 [745380/25046 (92%)]\tLoss: 0.087862\n",
            "Make prediction for 5010 samples...\n",
            "0.23630154 No improvement since epoch  140 ; best_mse,best_ci: 0.23347329 0.8873474925004974 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 142 [0/25046 (0%)]\tLoss: 0.097527\n",
            "Train epoch: 142 [83920/25046 (10%)]\tLoss: 0.047084\n",
            "Train epoch: 142 [163320/25046 (20%)]\tLoss: 0.083186\n",
            "Train epoch: 142 [243840/25046 (31%)]\tLoss: 0.043388\n",
            "Train epoch: 142 [327920/25046 (41%)]\tLoss: 0.035697\n",
            "Train epoch: 142 [404000/25046 (51%)]\tLoss: 0.049282\n",
            "Train epoch: 142 [500640/25046 (61%)]\tLoss: 0.069537\n",
            "Train epoch: 142 [578060/25046 (71%)]\tLoss: 0.108495\n",
            "Train epoch: 142 [640800/25046 (82%)]\tLoss: 0.045145\n",
            "Train epoch: 142 [733680/25046 (92%)]\tLoss: 0.069293\n",
            "Make prediction for 5010 samples...\n",
            "0.2338103 No improvement since epoch  140 ; best_mse,best_ci: 0.23347329 0.8873474925004974 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 143 [0/25046 (0%)]\tLoss: 0.048068\n",
            "Train epoch: 143 [81900/25046 (10%)]\tLoss: 0.067601\n",
            "Train epoch: 143 [167640/25046 (20%)]\tLoss: 0.174366\n",
            "Train epoch: 143 [248400/25046 (31%)]\tLoss: 0.052866\n",
            "Train epoch: 143 [322160/25046 (41%)]\tLoss: 0.062738\n",
            "Train epoch: 143 [411500/25046 (51%)]\tLoss: 0.127719\n",
            "Train epoch: 143 [498480/25046 (61%)]\tLoss: 0.042467\n",
            "Train epoch: 143 [565180/25046 (71%)]\tLoss: 0.048413\n",
            "Train epoch: 143 [651200/25046 (82%)]\tLoss: 0.041100\n",
            "Train epoch: 143 [761040/25046 (92%)]\tLoss: 0.067070\n",
            "Make prediction for 5010 samples...\n",
            "0.23764116 No improvement since epoch  140 ; best_mse,best_ci: 0.23347329 0.8873474925004974 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 144 [0/25046 (0%)]\tLoss: 0.062630\n",
            "Train epoch: 144 [80900/25046 (10%)]\tLoss: 0.082233\n",
            "Train epoch: 144 [165680/25046 (20%)]\tLoss: 0.068366\n",
            "Train epoch: 144 [242820/25046 (31%)]\tLoss: 0.047427\n",
            "Train epoch: 144 [333040/25046 (41%)]\tLoss: 0.061985\n",
            "Train epoch: 144 [401900/25046 (51%)]\tLoss: 0.062026\n",
            "Train epoch: 144 [486120/25046 (61%)]\tLoss: 0.094530\n",
            "Train epoch: 144 [574560/25046 (71%)]\tLoss: 0.064991\n",
            "Train epoch: 144 [681120/25046 (82%)]\tLoss: 0.045993\n",
            "Train epoch: 144 [748080/25046 (92%)]\tLoss: 0.054120\n",
            "Make prediction for 5010 samples...\n",
            "0.24321903 No improvement since epoch  140 ; best_mse,best_ci: 0.23347329 0.8873474925004974 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 145 [0/25046 (0%)]\tLoss: 0.051457\n",
            "Train epoch: 145 [81640/25046 (10%)]\tLoss: 0.062694\n",
            "Train epoch: 145 [166640/25046 (20%)]\tLoss: 0.083447\n",
            "Train epoch: 145 [238500/25046 (31%)]\tLoss: 0.042263\n",
            "Train epoch: 145 [337440/25046 (41%)]\tLoss: 0.040234\n",
            "Train epoch: 145 [406200/25046 (51%)]\tLoss: 0.034460\n",
            "Train epoch: 145 [483360/25046 (61%)]\tLoss: 0.044697\n",
            "Train epoch: 145 [566020/25046 (71%)]\tLoss: 0.115671\n",
            "Train epoch: 145 [653760/25046 (82%)]\tLoss: 0.042774\n",
            "Train epoch: 145 [727740/25046 (92%)]\tLoss: 0.118607\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  145 ; best_mse,best_ci: 0.23135248 0.8896273229237516 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 146 [0/25046 (0%)]\tLoss: 0.107800\n",
            "Train epoch: 146 [81580/25046 (10%)]\tLoss: 0.030669\n",
            "Train epoch: 146 [166480/25046 (20%)]\tLoss: 0.040009\n",
            "Train epoch: 146 [250200/25046 (31%)]\tLoss: 0.038982\n",
            "Train epoch: 146 [334400/25046 (41%)]\tLoss: 0.063653\n",
            "Train epoch: 146 [399100/25046 (51%)]\tLoss: 0.044020\n",
            "Train epoch: 146 [493080/25046 (61%)]\tLoss: 0.050295\n",
            "Train epoch: 146 [582960/25046 (71%)]\tLoss: 0.088995\n",
            "Train epoch: 146 [668640/25046 (82%)]\tLoss: 0.093699\n",
            "Train epoch: 146 [738540/25046 (92%)]\tLoss: 0.080136\n",
            "Make prediction for 5010 samples...\n",
            "0.25314683 No improvement since epoch  145 ; best_mse,best_ci: 0.23135248 0.8896273229237516 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 147 [0/25046 (0%)]\tLoss: 0.090478\n",
            "Train epoch: 147 [83380/25046 (10%)]\tLoss: 0.074531\n",
            "Train epoch: 147 [169320/25046 (20%)]\tLoss: 0.035626\n",
            "Train epoch: 147 [251100/25046 (31%)]\tLoss: 0.087469\n",
            "Train epoch: 147 [330720/25046 (41%)]\tLoss: 0.072159\n",
            "Train epoch: 147 [417800/25046 (51%)]\tLoss: 0.170469\n",
            "Train epoch: 147 [469920/25046 (61%)]\tLoss: 0.063274\n",
            "Train epoch: 147 [586040/25046 (71%)]\tLoss: 0.166974\n",
            "Train epoch: 147 [643840/25046 (82%)]\tLoss: 0.036117\n",
            "Train epoch: 147 [738180/25046 (92%)]\tLoss: 0.051819\n",
            "Make prediction for 5010 samples...\n",
            "0.23369156 No improvement since epoch  145 ; best_mse,best_ci: 0.23135248 0.8896273229237516 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 148 [0/25046 (0%)]\tLoss: 0.080167\n",
            "Train epoch: 148 [81880/25046 (10%)]\tLoss: 0.089794\n",
            "Train epoch: 148 [166240/25046 (20%)]\tLoss: 0.031843\n",
            "Train epoch: 148 [250380/25046 (31%)]\tLoss: 0.077959\n",
            "Train epoch: 148 [325200/25046 (41%)]\tLoss: 0.084182\n",
            "Train epoch: 148 [407900/25046 (51%)]\tLoss: 0.060312\n",
            "Train epoch: 148 [477120/25046 (61%)]\tLoss: 0.058690\n",
            "Train epoch: 148 [596680/25046 (71%)]\tLoss: 0.115803\n",
            "Train epoch: 148 [662720/25046 (82%)]\tLoss: 0.036140\n",
            "Train epoch: 148 [728280/25046 (92%)]\tLoss: 0.057072\n",
            "Make prediction for 5010 samples...\n",
            "0.2386971 No improvement since epoch  145 ; best_mse,best_ci: 0.23135248 0.8896273229237516 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 149 [0/25046 (0%)]\tLoss: 0.059561\n",
            "Train epoch: 149 [80160/25046 (10%)]\tLoss: 0.044421\n",
            "Train epoch: 149 [162080/25046 (20%)]\tLoss: 0.068539\n",
            "Train epoch: 149 [249300/25046 (31%)]\tLoss: 0.050723\n",
            "Train epoch: 149 [321040/25046 (41%)]\tLoss: 0.073491\n",
            "Train epoch: 149 [408300/25046 (51%)]\tLoss: 0.076637\n",
            "Train epoch: 149 [478800/25046 (61%)]\tLoss: 0.062005\n",
            "Train epoch: 149 [572880/25046 (71%)]\tLoss: 0.068038\n",
            "Train epoch: 149 [649120/25046 (82%)]\tLoss: 0.044980\n",
            "Train epoch: 149 [743040/25046 (92%)]\tLoss: 0.114419\n",
            "Make prediction for 5010 samples...\n",
            "0.23490378 No improvement since epoch  145 ; best_mse,best_ci: 0.23135248 0.8896273229237516 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 150 [0/25046 (0%)]\tLoss: 0.082552\n",
            "Train epoch: 150 [82100/25046 (10%)]\tLoss: 0.070240\n",
            "Train epoch: 150 [162720/25046 (20%)]\tLoss: 0.081590\n",
            "Train epoch: 150 [246120/25046 (31%)]\tLoss: 0.059495\n",
            "Train epoch: 150 [336560/25046 (41%)]\tLoss: 0.091255\n",
            "Train epoch: 150 [405200/25046 (51%)]\tLoss: 0.047589\n",
            "Train epoch: 150 [479040/25046 (61%)]\tLoss: 0.077142\n",
            "Train epoch: 150 [582960/25046 (71%)]\tLoss: 0.043923\n",
            "Train epoch: 150 [656160/25046 (82%)]\tLoss: 0.045033\n",
            "Train epoch: 150 [739080/25046 (92%)]\tLoss: 0.048370\n",
            "Make prediction for 5010 samples...\n",
            "0.24074912 No improvement since epoch  145 ; best_mse,best_ci: 0.23135248 0.8896273229237516 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 151 [0/25046 (0%)]\tLoss: 0.082078\n",
            "Train epoch: 151 [82800/25046 (10%)]\tLoss: 0.070815\n",
            "Train epoch: 151 [169520/25046 (20%)]\tLoss: 0.046821\n",
            "Train epoch: 151 [248940/25046 (31%)]\tLoss: 0.052852\n",
            "Train epoch: 151 [331600/25046 (41%)]\tLoss: 0.077632\n",
            "Train epoch: 151 [408800/25046 (51%)]\tLoss: 0.051075\n",
            "Train epoch: 151 [483960/25046 (61%)]\tLoss: 0.056753\n",
            "Train epoch: 151 [573860/25046 (71%)]\tLoss: 0.064436\n",
            "Train epoch: 151 [639360/25046 (82%)]\tLoss: 0.107689\n",
            "Train epoch: 151 [740700/25046 (92%)]\tLoss: 0.081557\n",
            "Make prediction for 5010 samples...\n",
            "0.23541375 No improvement since epoch  145 ; best_mse,best_ci: 0.23135248 0.8896273229237516 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 152 [0/25046 (0%)]\tLoss: 0.072651\n",
            "Train epoch: 152 [84020/25046 (10%)]\tLoss: 0.053728\n",
            "Train epoch: 152 [165200/25046 (20%)]\tLoss: 0.102171\n",
            "Train epoch: 152 [249480/25046 (31%)]\tLoss: 0.092893\n",
            "Train epoch: 152 [327920/25046 (41%)]\tLoss: 0.061805\n",
            "Train epoch: 152 [415500/25046 (51%)]\tLoss: 0.099766\n",
            "Train epoch: 152 [482640/25046 (61%)]\tLoss: 0.067053\n",
            "Train epoch: 152 [574560/25046 (71%)]\tLoss: 0.027961\n",
            "Train epoch: 152 [665760/25046 (82%)]\tLoss: 0.069189\n",
            "Train epoch: 152 [743220/25046 (92%)]\tLoss: 0.037668\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 153 [0/25046 (0%)]\tLoss: 0.064787\n",
            "Train epoch: 153 [82140/25046 (10%)]\tLoss: 0.068888\n",
            "Train epoch: 153 [168320/25046 (20%)]\tLoss: 0.045288\n",
            "Train epoch: 153 [241440/25046 (31%)]\tLoss: 0.064012\n",
            "Train epoch: 153 [327840/25046 (41%)]\tLoss: 0.055423\n",
            "Train epoch: 153 [411200/25046 (51%)]\tLoss: 0.033801\n",
            "Train epoch: 153 [491040/25046 (61%)]\tLoss: 0.041530\n",
            "Train epoch: 153 [585340/25046 (71%)]\tLoss: 0.056186\n",
            "Train epoch: 153 [655520/25046 (82%)]\tLoss: 0.043674\n",
            "Train epoch: 153 [736920/25046 (92%)]\tLoss: 0.067492\n",
            "Make prediction for 5010 samples...\n",
            "0.22945766 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 154 [0/25046 (0%)]\tLoss: 0.043148\n",
            "Train epoch: 154 [81440/25046 (10%)]\tLoss: 0.117593\n",
            "Train epoch: 154 [166960/25046 (20%)]\tLoss: 0.070163\n",
            "Train epoch: 154 [243420/25046 (31%)]\tLoss: 0.047804\n",
            "Train epoch: 154 [334560/25046 (41%)]\tLoss: 0.091046\n",
            "Train epoch: 154 [410100/25046 (51%)]\tLoss: 0.053922\n",
            "Train epoch: 154 [492840/25046 (61%)]\tLoss: 0.040867\n",
            "Train epoch: 154 [574420/25046 (71%)]\tLoss: 0.117846\n",
            "Train epoch: 154 [658720/25046 (82%)]\tLoss: 0.099633\n",
            "Train epoch: 154 [734760/25046 (92%)]\tLoss: 0.048019\n",
            "Make prediction for 5010 samples...\n",
            "0.23453717 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 155 [0/25046 (0%)]\tLoss: 0.069035\n",
            "Train epoch: 155 [81360/25046 (10%)]\tLoss: 0.043461\n",
            "Train epoch: 155 [168800/25046 (20%)]\tLoss: 0.047688\n",
            "Train epoch: 155 [247620/25046 (31%)]\tLoss: 0.051139\n",
            "Train epoch: 155 [329520/25046 (41%)]\tLoss: 0.071864\n",
            "Train epoch: 155 [418400/25046 (51%)]\tLoss: 0.056248\n",
            "Train epoch: 155 [494160/25046 (61%)]\tLoss: 0.044151\n",
            "Train epoch: 155 [603820/25046 (71%)]\tLoss: 0.040014\n",
            "Train epoch: 155 [653120/25046 (82%)]\tLoss: 0.053994\n",
            "Train epoch: 155 [740160/25046 (92%)]\tLoss: 0.062358\n",
            "Make prediction for 5010 samples...\n",
            "0.23687467 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 156 [0/25046 (0%)]\tLoss: 0.093664\n",
            "Train epoch: 156 [81800/25046 (10%)]\tLoss: 0.057875\n",
            "Train epoch: 156 [165000/25046 (20%)]\tLoss: 0.045318\n",
            "Train epoch: 156 [244860/25046 (31%)]\tLoss: 0.065826\n",
            "Train epoch: 156 [335600/25046 (41%)]\tLoss: 0.075237\n",
            "Train epoch: 156 [399000/25046 (51%)]\tLoss: 0.116066\n",
            "Train epoch: 156 [486360/25046 (61%)]\tLoss: 0.056591\n",
            "Train epoch: 156 [577920/25046 (71%)]\tLoss: 0.076531\n",
            "Train epoch: 156 [668640/25046 (82%)]\tLoss: 0.038638\n",
            "Train epoch: 156 [724680/25046 (92%)]\tLoss: 0.129730\n",
            "Make prediction for 5010 samples...\n",
            "0.23817 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 157 [0/25046 (0%)]\tLoss: 0.078607\n",
            "Train epoch: 157 [81920/25046 (10%)]\tLoss: 0.072939\n",
            "Train epoch: 157 [161200/25046 (20%)]\tLoss: 0.055801\n",
            "Train epoch: 157 [249660/25046 (31%)]\tLoss: 0.065578\n",
            "Train epoch: 157 [324160/25046 (41%)]\tLoss: 0.071504\n",
            "Train epoch: 157 [414600/25046 (51%)]\tLoss: 0.110716\n",
            "Train epoch: 157 [483960/25046 (61%)]\tLoss: 0.079050\n",
            "Train epoch: 157 [570640/25046 (71%)]\tLoss: 0.053513\n",
            "Train epoch: 157 [649760/25046 (82%)]\tLoss: 0.091987\n",
            "Train epoch: 157 [739080/25046 (92%)]\tLoss: 0.061828\n",
            "Make prediction for 5010 samples...\n",
            "0.23230472 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 158 [0/25046 (0%)]\tLoss: 0.038042\n",
            "Train epoch: 158 [83640/25046 (10%)]\tLoss: 0.058324\n",
            "Train epoch: 158 [163720/25046 (20%)]\tLoss: 0.034667\n",
            "Train epoch: 158 [249600/25046 (31%)]\tLoss: 0.070901\n",
            "Train epoch: 158 [332000/25046 (41%)]\tLoss: 0.048652\n",
            "Train epoch: 158 [402300/25046 (51%)]\tLoss: 0.039706\n",
            "Train epoch: 158 [493560/25046 (61%)]\tLoss: 0.157797\n",
            "Train epoch: 158 [573300/25046 (71%)]\tLoss: 0.032040\n",
            "Train epoch: 158 [623040/25046 (82%)]\tLoss: 0.075044\n",
            "Train epoch: 158 [747900/25046 (92%)]\tLoss: 0.112427\n",
            "Make prediction for 5010 samples...\n",
            "0.23299363 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 159 [0/25046 (0%)]\tLoss: 0.060371\n",
            "Train epoch: 159 [80980/25046 (10%)]\tLoss: 0.043661\n",
            "Train epoch: 159 [165520/25046 (20%)]\tLoss: 0.053972\n",
            "Train epoch: 159 [244740/25046 (31%)]\tLoss: 0.083106\n",
            "Train epoch: 159 [319840/25046 (41%)]\tLoss: 0.059077\n",
            "Train epoch: 159 [415400/25046 (51%)]\tLoss: 0.063941\n",
            "Train epoch: 159 [497640/25046 (61%)]\tLoss: 0.044295\n",
            "Train epoch: 159 [587160/25046 (71%)]\tLoss: 0.061430\n",
            "Train epoch: 159 [658720/25046 (82%)]\tLoss: 0.045267\n",
            "Train epoch: 159 [744840/25046 (92%)]\tLoss: 0.081178\n",
            "Make prediction for 5010 samples...\n",
            "0.23245019 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 160 [0/25046 (0%)]\tLoss: 0.098467\n",
            "Train epoch: 160 [83740/25046 (10%)]\tLoss: 0.056917\n",
            "Train epoch: 160 [160840/25046 (20%)]\tLoss: 0.068832\n",
            "Train epoch: 160 [243120/25046 (31%)]\tLoss: 0.042642\n",
            "Train epoch: 160 [321200/25046 (41%)]\tLoss: 0.081682\n",
            "Train epoch: 160 [420800/25046 (51%)]\tLoss: 0.035881\n",
            "Train epoch: 160 [501840/25046 (61%)]\tLoss: 0.053550\n",
            "Train epoch: 160 [572600/25046 (71%)]\tLoss: 0.063389\n",
            "Train epoch: 160 [654240/25046 (82%)]\tLoss: 0.044919\n",
            "Train epoch: 160 [747000/25046 (92%)]\tLoss: 0.166862\n",
            "Make prediction for 5010 samples...\n",
            "0.23219727 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 161 [0/25046 (0%)]\tLoss: 0.041240\n",
            "Train epoch: 161 [81380/25046 (10%)]\tLoss: 0.053880\n",
            "Train epoch: 161 [168120/25046 (20%)]\tLoss: 0.045222\n",
            "Train epoch: 161 [238560/25046 (31%)]\tLoss: 0.053236\n",
            "Train epoch: 161 [333120/25046 (41%)]\tLoss: 0.036420\n",
            "Train epoch: 161 [399000/25046 (51%)]\tLoss: 0.053596\n",
            "Train epoch: 161 [495960/25046 (61%)]\tLoss: 0.050266\n",
            "Train epoch: 161 [563080/25046 (71%)]\tLoss: 0.049242\n",
            "Train epoch: 161 [668000/25046 (82%)]\tLoss: 0.060431\n",
            "Train epoch: 161 [741060/25046 (92%)]\tLoss: 0.077477\n",
            "Make prediction for 5010 samples...\n",
            "0.23402552 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 162 [0/25046 (0%)]\tLoss: 0.041891\n",
            "Train epoch: 162 [81820/25046 (10%)]\tLoss: 0.050696\n",
            "Train epoch: 162 [161040/25046 (20%)]\tLoss: 0.059493\n",
            "Train epoch: 162 [242700/25046 (31%)]\tLoss: 0.059697\n",
            "Train epoch: 162 [329840/25046 (41%)]\tLoss: 0.043077\n",
            "Train epoch: 162 [427800/25046 (51%)]\tLoss: 0.076768\n",
            "Train epoch: 162 [507240/25046 (61%)]\tLoss: 0.076397\n",
            "Train epoch: 162 [577220/25046 (71%)]\tLoss: 0.050096\n",
            "Train epoch: 162 [638720/25046 (82%)]\tLoss: 0.048611\n",
            "Train epoch: 162 [717300/25046 (92%)]\tLoss: 0.042998\n",
            "Make prediction for 5010 samples...\n",
            "0.2374581 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 163 [0/25046 (0%)]\tLoss: 0.048129\n",
            "Train epoch: 163 [82020/25046 (10%)]\tLoss: 0.080525\n",
            "Train epoch: 163 [173040/25046 (20%)]\tLoss: 0.090553\n",
            "Train epoch: 163 [243960/25046 (31%)]\tLoss: 0.064709\n",
            "Train epoch: 163 [318320/25046 (41%)]\tLoss: 0.053616\n",
            "Train epoch: 163 [399400/25046 (51%)]\tLoss: 0.064893\n",
            "Train epoch: 163 [497160/25046 (61%)]\tLoss: 0.050019\n",
            "Train epoch: 163 [562240/25046 (71%)]\tLoss: 0.049273\n",
            "Train epoch: 163 [644960/25046 (82%)]\tLoss: 0.119003\n",
            "Train epoch: 163 [764280/25046 (92%)]\tLoss: 0.023480\n",
            "Make prediction for 5010 samples...\n",
            "0.2489454 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 164 [0/25046 (0%)]\tLoss: 0.037253\n",
            "Train epoch: 164 [84300/25046 (10%)]\tLoss: 0.086923\n",
            "Train epoch: 164 [165880/25046 (20%)]\tLoss: 0.082188\n",
            "Train epoch: 164 [244740/25046 (31%)]\tLoss: 0.066508\n",
            "Train epoch: 164 [332720/25046 (41%)]\tLoss: 0.057061\n",
            "Train epoch: 164 [406100/25046 (51%)]\tLoss: 0.042350\n",
            "Train epoch: 164 [500880/25046 (61%)]\tLoss: 0.079905\n",
            "Train epoch: 164 [576800/25046 (71%)]\tLoss: 0.061484\n",
            "Train epoch: 164 [656000/25046 (82%)]\tLoss: 0.053219\n",
            "Train epoch: 164 [737460/25046 (92%)]\tLoss: 0.065904\n",
            "Make prediction for 5010 samples...\n",
            "0.23765291 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 165 [0/25046 (0%)]\tLoss: 0.057842\n",
            "Train epoch: 165 [80340/25046 (10%)]\tLoss: 0.048504\n",
            "Train epoch: 165 [162320/25046 (20%)]\tLoss: 0.043021\n",
            "Train epoch: 165 [247020/25046 (31%)]\tLoss: 0.065466\n",
            "Train epoch: 165 [333520/25046 (41%)]\tLoss: 0.066908\n",
            "Train epoch: 165 [404400/25046 (51%)]\tLoss: 0.050301\n",
            "Train epoch: 165 [507960/25046 (61%)]\tLoss: 0.048500\n",
            "Train epoch: 165 [568540/25046 (71%)]\tLoss: 0.049048\n",
            "Train epoch: 165 [653120/25046 (82%)]\tLoss: 0.121780\n",
            "Train epoch: 165 [730620/25046 (92%)]\tLoss: 0.036661\n",
            "Make prediction for 5010 samples...\n",
            "0.23454492 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 166 [0/25046 (0%)]\tLoss: 0.068017\n",
            "Train epoch: 166 [82920/25046 (10%)]\tLoss: 0.074847\n",
            "Train epoch: 166 [167840/25046 (20%)]\tLoss: 0.060074\n",
            "Train epoch: 166 [243900/25046 (31%)]\tLoss: 0.032232\n",
            "Train epoch: 166 [328960/25046 (41%)]\tLoss: 0.047672\n",
            "Train epoch: 166 [402800/25046 (51%)]\tLoss: 0.037238\n",
            "Train epoch: 166 [500400/25046 (61%)]\tLoss: 0.066997\n",
            "Train epoch: 166 [571200/25046 (71%)]\tLoss: 0.073048\n",
            "Train epoch: 166 [641600/25046 (82%)]\tLoss: 0.097016\n",
            "Train epoch: 166 [739980/25046 (92%)]\tLoss: 0.168416\n",
            "Make prediction for 5010 samples...\n",
            "0.2386226 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 167 [0/25046 (0%)]\tLoss: 0.050942\n",
            "Train epoch: 167 [82340/25046 (10%)]\tLoss: 0.063979\n",
            "Train epoch: 167 [163440/25046 (20%)]\tLoss: 0.037940\n",
            "Train epoch: 167 [248460/25046 (31%)]\tLoss: 0.043233\n",
            "Train epoch: 167 [323360/25046 (41%)]\tLoss: 0.068566\n",
            "Train epoch: 167 [413000/25046 (51%)]\tLoss: 0.064693\n",
            "Train epoch: 167 [489000/25046 (61%)]\tLoss: 0.037118\n",
            "Train epoch: 167 [560420/25046 (71%)]\tLoss: 0.078266\n",
            "Train epoch: 167 [653760/25046 (82%)]\tLoss: 0.033814\n",
            "Train epoch: 167 [742860/25046 (92%)]\tLoss: 0.044513\n",
            "Make prediction for 5010 samples...\n",
            "0.2368646 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 168 [0/25046 (0%)]\tLoss: 0.043749\n",
            "Train epoch: 168 [81040/25046 (10%)]\tLoss: 0.107781\n",
            "Train epoch: 168 [165760/25046 (20%)]\tLoss: 0.053020\n",
            "Train epoch: 168 [246600/25046 (31%)]\tLoss: 0.046251\n",
            "Train epoch: 168 [328880/25046 (41%)]\tLoss: 0.037221\n",
            "Train epoch: 168 [414400/25046 (51%)]\tLoss: 0.038848\n",
            "Train epoch: 168 [480240/25046 (61%)]\tLoss: 0.045205\n",
            "Train epoch: 168 [580580/25046 (71%)]\tLoss: 0.098554\n",
            "Train epoch: 168 [641920/25046 (82%)]\tLoss: 0.085441\n",
            "Train epoch: 168 [733320/25046 (92%)]\tLoss: 0.071070\n",
            "Make prediction for 5010 samples...\n",
            "0.2377265 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 169 [0/25046 (0%)]\tLoss: 0.037848\n",
            "Train epoch: 169 [83560/25046 (10%)]\tLoss: 0.074759\n",
            "Train epoch: 169 [168800/25046 (20%)]\tLoss: 0.062978\n",
            "Train epoch: 169 [243840/25046 (31%)]\tLoss: 0.114404\n",
            "Train epoch: 169 [330880/25046 (41%)]\tLoss: 0.090108\n",
            "Train epoch: 169 [411800/25046 (51%)]\tLoss: 0.058041\n",
            "Train epoch: 169 [491400/25046 (61%)]\tLoss: 0.102679\n",
            "Train epoch: 169 [582540/25046 (71%)]\tLoss: 0.053313\n",
            "Train epoch: 169 [666880/25046 (82%)]\tLoss: 0.057095\n",
            "Train epoch: 169 [739800/25046 (92%)]\tLoss: 0.060089\n",
            "Make prediction for 5010 samples...\n",
            "0.23318782 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 170 [0/25046 (0%)]\tLoss: 0.060452\n",
            "Train epoch: 170 [81720/25046 (10%)]\tLoss: 0.057323\n",
            "Train epoch: 170 [164920/25046 (20%)]\tLoss: 0.045701\n",
            "Train epoch: 170 [249360/25046 (31%)]\tLoss: 0.106941\n",
            "Train epoch: 170 [323840/25046 (41%)]\tLoss: 0.092768\n",
            "Train epoch: 170 [404700/25046 (51%)]\tLoss: 0.118363\n",
            "Train epoch: 170 [493080/25046 (61%)]\tLoss: 0.116057\n",
            "Train epoch: 170 [584640/25046 (71%)]\tLoss: 0.105986\n",
            "Train epoch: 170 [669440/25046 (82%)]\tLoss: 0.081623\n",
            "Train epoch: 170 [726120/25046 (92%)]\tLoss: 0.041759\n",
            "Make prediction for 5010 samples...\n",
            "0.23960407 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 171 [0/25046 (0%)]\tLoss: 0.124641\n",
            "Train epoch: 171 [83180/25046 (10%)]\tLoss: 0.033191\n",
            "Train epoch: 171 [165160/25046 (20%)]\tLoss: 0.046333\n",
            "Train epoch: 171 [243900/25046 (31%)]\tLoss: 0.031444\n",
            "Train epoch: 171 [334800/25046 (41%)]\tLoss: 0.059606\n",
            "Train epoch: 171 [409000/25046 (51%)]\tLoss: 0.036650\n",
            "Train epoch: 171 [490440/25046 (61%)]\tLoss: 0.035328\n",
            "Train epoch: 171 [568400/25046 (71%)]\tLoss: 0.064566\n",
            "Train epoch: 171 [651840/25046 (82%)]\tLoss: 0.045243\n",
            "Train epoch: 171 [734580/25046 (92%)]\tLoss: 0.033338\n",
            "Make prediction for 5010 samples...\n",
            "0.23632535 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 172 [0/25046 (0%)]\tLoss: 0.084184\n",
            "Train epoch: 172 [81860/25046 (10%)]\tLoss: 0.085133\n",
            "Train epoch: 172 [164920/25046 (20%)]\tLoss: 0.036140\n",
            "Train epoch: 172 [245040/25046 (31%)]\tLoss: 0.042805\n",
            "Train epoch: 172 [324640/25046 (41%)]\tLoss: 0.064902\n",
            "Train epoch: 172 [415300/25046 (51%)]\tLoss: 0.030555\n",
            "Train epoch: 172 [509400/25046 (61%)]\tLoss: 0.062794\n",
            "Train epoch: 172 [577080/25046 (71%)]\tLoss: 0.068125\n",
            "Train epoch: 172 [656320/25046 (82%)]\tLoss: 0.065125\n",
            "Train epoch: 172 [754020/25046 (92%)]\tLoss: 0.079521\n",
            "Make prediction for 5010 samples...\n",
            "0.23394027 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 173 [0/25046 (0%)]\tLoss: 0.044882\n",
            "Train epoch: 173 [83680/25046 (10%)]\tLoss: 0.037257\n",
            "Train epoch: 173 [159160/25046 (20%)]\tLoss: 0.036371\n",
            "Train epoch: 173 [250260/25046 (31%)]\tLoss: 0.066718\n",
            "Train epoch: 173 [326000/25046 (41%)]\tLoss: 0.045606\n",
            "Train epoch: 173 [424900/25046 (51%)]\tLoss: 0.042050\n",
            "Train epoch: 173 [492600/25046 (61%)]\tLoss: 0.120393\n",
            "Train epoch: 173 [573020/25046 (71%)]\tLoss: 0.072173\n",
            "Train epoch: 173 [634560/25046 (82%)]\tLoss: 0.043728\n",
            "Train epoch: 173 [727740/25046 (92%)]\tLoss: 0.046444\n",
            "Make prediction for 5010 samples...\n",
            "0.2306552 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 174 [0/25046 (0%)]\tLoss: 0.079289\n",
            "Train epoch: 174 [80740/25046 (10%)]\tLoss: 0.046546\n",
            "Train epoch: 174 [164200/25046 (20%)]\tLoss: 0.175737\n",
            "Train epoch: 174 [244200/25046 (31%)]\tLoss: 0.036700\n",
            "Train epoch: 174 [333200/25046 (41%)]\tLoss: 0.070678\n",
            "Train epoch: 174 [413000/25046 (51%)]\tLoss: 0.038788\n",
            "Train epoch: 174 [495480/25046 (61%)]\tLoss: 0.045409\n",
            "Train epoch: 174 [578200/25046 (71%)]\tLoss: 0.081346\n",
            "Train epoch: 174 [668000/25046 (82%)]\tLoss: 0.088292\n",
            "Train epoch: 174 [740340/25046 (92%)]\tLoss: 0.104654\n",
            "Make prediction for 5010 samples...\n",
            "0.22979537 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 175 [0/25046 (0%)]\tLoss: 0.074568\n",
            "Train epoch: 175 [84320/25046 (10%)]\tLoss: 0.056390\n",
            "Train epoch: 175 [166080/25046 (20%)]\tLoss: 0.060502\n",
            "Train epoch: 175 [249660/25046 (31%)]\tLoss: 0.055229\n",
            "Train epoch: 175 [330960/25046 (41%)]\tLoss: 0.070540\n",
            "Train epoch: 175 [420100/25046 (51%)]\tLoss: 0.075735\n",
            "Train epoch: 175 [505320/25046 (61%)]\tLoss: 0.041756\n",
            "Train epoch: 175 [561120/25046 (71%)]\tLoss: 0.042265\n",
            "Train epoch: 175 [665280/25046 (82%)]\tLoss: 0.119050\n",
            "Train epoch: 175 [725940/25046 (92%)]\tLoss: 0.106917\n",
            "Make prediction for 5010 samples...\n",
            "0.2330028 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 176 [0/25046 (0%)]\tLoss: 0.051750\n",
            "Train epoch: 176 [84240/25046 (10%)]\tLoss: 0.122367\n",
            "Train epoch: 176 [160440/25046 (20%)]\tLoss: 0.044603\n",
            "Train epoch: 176 [249060/25046 (31%)]\tLoss: 0.080990\n",
            "Train epoch: 176 [330160/25046 (41%)]\tLoss: 0.077235\n",
            "Train epoch: 176 [420500/25046 (51%)]\tLoss: 0.069168\n",
            "Train epoch: 176 [490920/25046 (61%)]\tLoss: 0.080909\n",
            "Train epoch: 176 [576240/25046 (71%)]\tLoss: 0.042477\n",
            "Train epoch: 176 [652160/25046 (82%)]\tLoss: 0.068154\n",
            "Train epoch: 176 [718740/25046 (92%)]\tLoss: 0.063620\n",
            "Make prediction for 5010 samples...\n",
            "0.23992743 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 177 [0/25046 (0%)]\tLoss: 0.037679\n",
            "Train epoch: 177 [84080/25046 (10%)]\tLoss: 0.082948\n",
            "Train epoch: 177 [161840/25046 (20%)]\tLoss: 0.045224\n",
            "Train epoch: 177 [241740/25046 (31%)]\tLoss: 0.060934\n",
            "Train epoch: 177 [324400/25046 (41%)]\tLoss: 0.033606\n",
            "Train epoch: 177 [414900/25046 (51%)]\tLoss: 0.045031\n",
            "Train epoch: 177 [490800/25046 (61%)]\tLoss: 0.060164\n",
            "Train epoch: 177 [587720/25046 (71%)]\tLoss: 0.056301\n",
            "Train epoch: 177 [628800/25046 (82%)]\tLoss: 0.074918\n",
            "Train epoch: 177 [726480/25046 (92%)]\tLoss: 0.042793\n",
            "Make prediction for 5010 samples...\n",
            "0.24477 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 178 [0/25046 (0%)]\tLoss: 0.106600\n",
            "Train epoch: 178 [81420/25046 (10%)]\tLoss: 0.055754\n",
            "Train epoch: 178 [164280/25046 (20%)]\tLoss: 0.084941\n",
            "Train epoch: 178 [246720/25046 (31%)]\tLoss: 0.054799\n",
            "Train epoch: 178 [323360/25046 (41%)]\tLoss: 0.041809\n",
            "Train epoch: 178 [410000/25046 (51%)]\tLoss: 0.054793\n",
            "Train epoch: 178 [497760/25046 (61%)]\tLoss: 0.047510\n",
            "Train epoch: 178 [567560/25046 (71%)]\tLoss: 0.080850\n",
            "Train epoch: 178 [672320/25046 (82%)]\tLoss: 0.038965\n",
            "Train epoch: 178 [716760/25046 (92%)]\tLoss: 0.040919\n",
            "Make prediction for 5010 samples...\n",
            "0.24013409 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 179 [0/25046 (0%)]\tLoss: 0.063867\n",
            "Train epoch: 179 [82520/25046 (10%)]\tLoss: 0.041177\n",
            "Train epoch: 179 [164600/25046 (20%)]\tLoss: 0.071812\n",
            "Train epoch: 179 [240000/25046 (31%)]\tLoss: 0.047238\n",
            "Train epoch: 179 [329760/25046 (41%)]\tLoss: 0.042378\n",
            "Train epoch: 179 [417100/25046 (51%)]\tLoss: 0.079045\n",
            "Train epoch: 179 [483720/25046 (61%)]\tLoss: 0.061323\n",
            "Train epoch: 179 [566860/25046 (71%)]\tLoss: 0.130450\n",
            "Train epoch: 179 [664000/25046 (82%)]\tLoss: 0.035981\n",
            "Train epoch: 179 [725940/25046 (92%)]\tLoss: 0.059798\n",
            "Make prediction for 5010 samples...\n",
            "0.23391514 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 180 [0/25046 (0%)]\tLoss: 0.117992\n",
            "Train epoch: 180 [80540/25046 (10%)]\tLoss: 0.030421\n",
            "Train epoch: 180 [161800/25046 (20%)]\tLoss: 0.071720\n",
            "Train epoch: 180 [251700/25046 (31%)]\tLoss: 0.052164\n",
            "Train epoch: 180 [322960/25046 (41%)]\tLoss: 0.060138\n",
            "Train epoch: 180 [411500/25046 (51%)]\tLoss: 0.051214\n",
            "Train epoch: 180 [491520/25046 (61%)]\tLoss: 0.037523\n",
            "Train epoch: 180 [591780/25046 (71%)]\tLoss: 0.158836\n",
            "Train epoch: 180 [660960/25046 (82%)]\tLoss: 0.052723\n",
            "Train epoch: 180 [745200/25046 (92%)]\tLoss: 0.065580\n",
            "Make prediction for 5010 samples...\n",
            "0.23062554 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 181 [0/25046 (0%)]\tLoss: 0.048818\n",
            "Train epoch: 181 [83640/25046 (10%)]\tLoss: 0.048643\n",
            "Train epoch: 181 [168560/25046 (20%)]\tLoss: 0.046162\n",
            "Train epoch: 181 [245160/25046 (31%)]\tLoss: 0.048048\n",
            "Train epoch: 181 [322960/25046 (41%)]\tLoss: 0.055481\n",
            "Train epoch: 181 [410200/25046 (51%)]\tLoss: 0.051519\n",
            "Train epoch: 181 [490800/25046 (61%)]\tLoss: 0.125578\n",
            "Train epoch: 181 [566440/25046 (71%)]\tLoss: 0.075515\n",
            "Train epoch: 181 [657920/25046 (82%)]\tLoss: 0.048319\n",
            "Train epoch: 181 [714420/25046 (92%)]\tLoss: 0.076398\n",
            "Make prediction for 5010 samples...\n",
            "0.23782913 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 182 [0/25046 (0%)]\tLoss: 0.099081\n",
            "Train epoch: 182 [82060/25046 (10%)]\tLoss: 0.080852\n",
            "Train epoch: 182 [165480/25046 (20%)]\tLoss: 0.068571\n",
            "Train epoch: 182 [249060/25046 (31%)]\tLoss: 0.064494\n",
            "Train epoch: 182 [329760/25046 (41%)]\tLoss: 0.060501\n",
            "Train epoch: 182 [408500/25046 (51%)]\tLoss: 0.028156\n",
            "Train epoch: 182 [487320/25046 (61%)]\tLoss: 0.041173\n",
            "Train epoch: 182 [568820/25046 (71%)]\tLoss: 0.052411\n",
            "Train epoch: 182 [673120/25046 (82%)]\tLoss: 0.033976\n",
            "Train epoch: 182 [744660/25046 (92%)]\tLoss: 0.052874\n",
            "Make prediction for 5010 samples...\n",
            "0.23820388 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 183 [0/25046 (0%)]\tLoss: 0.069762\n",
            "Train epoch: 183 [82280/25046 (10%)]\tLoss: 0.040134\n",
            "Train epoch: 183 [165200/25046 (20%)]\tLoss: 0.041405\n",
            "Train epoch: 183 [247680/25046 (31%)]\tLoss: 0.037993\n",
            "Train epoch: 183 [322560/25046 (41%)]\tLoss: 0.071073\n",
            "Train epoch: 183 [408500/25046 (51%)]\tLoss: 0.158163\n",
            "Train epoch: 183 [486960/25046 (61%)]\tLoss: 0.084356\n",
            "Train epoch: 183 [574980/25046 (71%)]\tLoss: 0.040157\n",
            "Train epoch: 183 [664000/25046 (82%)]\tLoss: 0.059699\n",
            "Train epoch: 183 [729000/25046 (92%)]\tLoss: 0.090219\n",
            "Make prediction for 5010 samples...\n",
            "0.2327731 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 184 [0/25046 (0%)]\tLoss: 0.079806\n",
            "Train epoch: 184 [82100/25046 (10%)]\tLoss: 0.073517\n",
            "Train epoch: 184 [161160/25046 (20%)]\tLoss: 0.048663\n",
            "Train epoch: 184 [236880/25046 (31%)]\tLoss: 0.104242\n",
            "Train epoch: 184 [312800/25046 (41%)]\tLoss: 0.045499\n",
            "Train epoch: 184 [407500/25046 (51%)]\tLoss: 0.040734\n",
            "Train epoch: 184 [488040/25046 (61%)]\tLoss: 0.074873\n",
            "Train epoch: 184 [573300/25046 (71%)]\tLoss: 0.066528\n",
            "Train epoch: 184 [648480/25046 (82%)]\tLoss: 0.062655\n",
            "Train epoch: 184 [734580/25046 (92%)]\tLoss: 0.041441\n",
            "Make prediction for 5010 samples...\n",
            "0.23828505 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 185 [0/25046 (0%)]\tLoss: 0.048210\n",
            "Train epoch: 185 [80820/25046 (10%)]\tLoss: 0.052720\n",
            "Train epoch: 185 [165120/25046 (20%)]\tLoss: 0.064107\n",
            "Train epoch: 185 [243900/25046 (31%)]\tLoss: 0.070469\n",
            "Train epoch: 185 [331600/25046 (41%)]\tLoss: 0.054184\n",
            "Train epoch: 185 [395900/25046 (51%)]\tLoss: 0.048001\n",
            "Train epoch: 185 [489120/25046 (61%)]\tLoss: 0.080322\n",
            "Train epoch: 185 [562240/25046 (71%)]\tLoss: 0.045126\n",
            "Train epoch: 185 [675360/25046 (82%)]\tLoss: 0.102626\n",
            "Train epoch: 185 [738540/25046 (92%)]\tLoss: 0.110818\n",
            "Make prediction for 5010 samples...\n",
            "0.2364139 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 186 [0/25046 (0%)]\tLoss: 0.078657\n",
            "Train epoch: 186 [83080/25046 (10%)]\tLoss: 0.039293\n",
            "Train epoch: 186 [158480/25046 (20%)]\tLoss: 0.075397\n",
            "Train epoch: 186 [242760/25046 (31%)]\tLoss: 0.092862\n",
            "Train epoch: 186 [330720/25046 (41%)]\tLoss: 0.132506\n",
            "Train epoch: 186 [406900/25046 (51%)]\tLoss: 0.109261\n",
            "Train epoch: 186 [499080/25046 (61%)]\tLoss: 0.090940\n",
            "Train epoch: 186 [576380/25046 (71%)]\tLoss: 0.074305\n",
            "Train epoch: 186 [668320/25046 (82%)]\tLoss: 0.068778\n",
            "Train epoch: 186 [739080/25046 (92%)]\tLoss: 0.093659\n",
            "Make prediction for 5010 samples...\n",
            "0.24384554 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 187 [0/25046 (0%)]\tLoss: 0.047001\n",
            "Train epoch: 187 [82060/25046 (10%)]\tLoss: 0.085424\n",
            "Train epoch: 187 [162520/25046 (20%)]\tLoss: 0.046916\n",
            "Train epoch: 187 [242520/25046 (31%)]\tLoss: 0.075452\n",
            "Train epoch: 187 [338000/25046 (41%)]\tLoss: 0.082065\n",
            "Train epoch: 187 [408300/25046 (51%)]\tLoss: 0.067304\n",
            "Train epoch: 187 [503040/25046 (61%)]\tLoss: 0.047200\n",
            "Train epoch: 187 [568680/25046 (71%)]\tLoss: 0.063327\n",
            "Train epoch: 187 [681120/25046 (82%)]\tLoss: 0.030462\n",
            "Train epoch: 187 [742680/25046 (92%)]\tLoss: 0.053486\n",
            "Make prediction for 5010 samples...\n",
            "0.24222732 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 188 [0/25046 (0%)]\tLoss: 0.057883\n",
            "Train epoch: 188 [80620/25046 (10%)]\tLoss: 0.033706\n",
            "Train epoch: 188 [170960/25046 (20%)]\tLoss: 0.066528\n",
            "Train epoch: 188 [246660/25046 (31%)]\tLoss: 0.067549\n",
            "Train epoch: 188 [326640/25046 (41%)]\tLoss: 0.041896\n",
            "Train epoch: 188 [406700/25046 (51%)]\tLoss: 0.046892\n",
            "Train epoch: 188 [483840/25046 (61%)]\tLoss: 0.043203\n",
            "Train epoch: 188 [595980/25046 (71%)]\tLoss: 0.055076\n",
            "Train epoch: 188 [661920/25046 (82%)]\tLoss: 0.036029\n",
            "Train epoch: 188 [753660/25046 (92%)]\tLoss: 0.066127\n",
            "Make prediction for 5010 samples...\n",
            "0.23350225 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 189 [0/25046 (0%)]\tLoss: 0.027936\n",
            "Train epoch: 189 [80420/25046 (10%)]\tLoss: 0.035548\n",
            "Train epoch: 189 [159720/25046 (20%)]\tLoss: 0.074175\n",
            "Train epoch: 189 [246360/25046 (31%)]\tLoss: 0.042762\n",
            "Train epoch: 189 [318320/25046 (41%)]\tLoss: 0.053862\n",
            "Train epoch: 189 [408200/25046 (51%)]\tLoss: 0.033484\n",
            "Train epoch: 189 [506040/25046 (61%)]\tLoss: 0.060166\n",
            "Train epoch: 189 [577360/25046 (71%)]\tLoss: 0.162667\n",
            "Train epoch: 189 [676960/25046 (82%)]\tLoss: 0.064352\n",
            "Train epoch: 189 [741960/25046 (92%)]\tLoss: 0.040407\n",
            "Make prediction for 5010 samples...\n",
            "0.2351675 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 190 [0/25046 (0%)]\tLoss: 0.059741\n",
            "Train epoch: 190 [82500/25046 (10%)]\tLoss: 0.057541\n",
            "Train epoch: 190 [164040/25046 (20%)]\tLoss: 0.045433\n",
            "Train epoch: 190 [238680/25046 (31%)]\tLoss: 0.050997\n",
            "Train epoch: 190 [337360/25046 (41%)]\tLoss: 0.034685\n",
            "Train epoch: 190 [401400/25046 (51%)]\tLoss: 0.072098\n",
            "Train epoch: 190 [500040/25046 (61%)]\tLoss: 0.148365\n",
            "Train epoch: 190 [580300/25046 (71%)]\tLoss: 0.069664\n",
            "Train epoch: 190 [645440/25046 (82%)]\tLoss: 0.066778\n",
            "Train epoch: 190 [746280/25046 (92%)]\tLoss: 0.029979\n",
            "Make prediction for 5010 samples...\n",
            "0.23978525 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 191 [0/25046 (0%)]\tLoss: 0.041678\n",
            "Train epoch: 191 [82220/25046 (10%)]\tLoss: 0.073627\n",
            "Train epoch: 191 [165720/25046 (20%)]\tLoss: 0.061208\n",
            "Train epoch: 191 [247260/25046 (31%)]\tLoss: 0.041651\n",
            "Train epoch: 191 [318080/25046 (41%)]\tLoss: 0.064747\n",
            "Train epoch: 191 [419900/25046 (51%)]\tLoss: 0.034205\n",
            "Train epoch: 191 [504480/25046 (61%)]\tLoss: 0.081873\n",
            "Train epoch: 191 [570360/25046 (71%)]\tLoss: 0.100125\n",
            "Train epoch: 191 [659680/25046 (82%)]\tLoss: 0.022375\n",
            "Train epoch: 191 [731160/25046 (92%)]\tLoss: 0.049774\n",
            "Make prediction for 5010 samples...\n",
            "0.27977327 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 192 [0/25046 (0%)]\tLoss: 0.084347\n",
            "Train epoch: 192 [81400/25046 (10%)]\tLoss: 0.141399\n",
            "Train epoch: 192 [161480/25046 (20%)]\tLoss: 0.069470\n",
            "Train epoch: 192 [254040/25046 (31%)]\tLoss: 0.031740\n",
            "Train epoch: 192 [329360/25046 (41%)]\tLoss: 0.051827\n",
            "Train epoch: 192 [405500/25046 (51%)]\tLoss: 0.094064\n",
            "Train epoch: 192 [493440/25046 (61%)]\tLoss: 0.082760\n",
            "Train epoch: 192 [573580/25046 (71%)]\tLoss: 0.086253\n",
            "Train epoch: 192 [658720/25046 (82%)]\tLoss: 0.050344\n",
            "Train epoch: 192 [741420/25046 (92%)]\tLoss: 0.108492\n",
            "Make prediction for 5010 samples...\n",
            "0.23423098 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 193 [0/25046 (0%)]\tLoss: 0.053484\n",
            "Train epoch: 193 [83520/25046 (10%)]\tLoss: 0.051057\n",
            "Train epoch: 193 [165080/25046 (20%)]\tLoss: 0.156257\n",
            "Train epoch: 193 [244260/25046 (31%)]\tLoss: 0.063562\n",
            "Train epoch: 193 [324800/25046 (41%)]\tLoss: 0.052608\n",
            "Train epoch: 193 [413400/25046 (51%)]\tLoss: 0.090917\n",
            "Train epoch: 193 [488400/25046 (61%)]\tLoss: 0.044218\n",
            "Train epoch: 193 [560000/25046 (71%)]\tLoss: 0.117947\n",
            "Train epoch: 193 [654400/25046 (82%)]\tLoss: 0.048249\n",
            "Train epoch: 193 [737820/25046 (92%)]\tLoss: 0.037051\n",
            "Make prediction for 5010 samples...\n",
            "0.23846439 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 194 [0/25046 (0%)]\tLoss: 0.041106\n",
            "Train epoch: 194 [83960/25046 (10%)]\tLoss: 0.064315\n",
            "Train epoch: 194 [164480/25046 (20%)]\tLoss: 0.055553\n",
            "Train epoch: 194 [245100/25046 (31%)]\tLoss: 0.046423\n",
            "Train epoch: 194 [329760/25046 (41%)]\tLoss: 0.037022\n",
            "Train epoch: 194 [407200/25046 (51%)]\tLoss: 0.068761\n",
            "Train epoch: 194 [490680/25046 (61%)]\tLoss: 0.032407\n",
            "Train epoch: 194 [581840/25046 (71%)]\tLoss: 0.074594\n",
            "Train epoch: 194 [646240/25046 (82%)]\tLoss: 0.049343\n",
            "Train epoch: 194 [732420/25046 (92%)]\tLoss: 0.061768\n",
            "Make prediction for 5010 samples...\n",
            "0.22844316 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 195 [0/25046 (0%)]\tLoss: 0.076681\n",
            "Train epoch: 195 [82620/25046 (10%)]\tLoss: 0.059996\n",
            "Train epoch: 195 [157840/25046 (20%)]\tLoss: 0.057380\n",
            "Train epoch: 195 [246780/25046 (31%)]\tLoss: 0.097680\n",
            "Train epoch: 195 [327200/25046 (41%)]\tLoss: 0.053280\n",
            "Train epoch: 195 [411700/25046 (51%)]\tLoss: 0.030320\n",
            "Train epoch: 195 [493920/25046 (61%)]\tLoss: 0.066097\n",
            "Train epoch: 195 [553280/25046 (71%)]\tLoss: 0.106296\n",
            "Train epoch: 195 [680480/25046 (82%)]\tLoss: 0.034246\n",
            "Train epoch: 195 [720720/25046 (92%)]\tLoss: 0.095734\n",
            "Make prediction for 5010 samples...\n",
            "0.23569678 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 196 [0/25046 (0%)]\tLoss: 0.050297\n",
            "Train epoch: 196 [81260/25046 (10%)]\tLoss: 0.041207\n",
            "Train epoch: 196 [160880/25046 (20%)]\tLoss: 0.045551\n",
            "Train epoch: 196 [243840/25046 (31%)]\tLoss: 0.045620\n",
            "Train epoch: 196 [331040/25046 (41%)]\tLoss: 0.073308\n",
            "Train epoch: 196 [417100/25046 (51%)]\tLoss: 0.040392\n",
            "Train epoch: 196 [498720/25046 (61%)]\tLoss: 0.044900\n",
            "Train epoch: 196 [584360/25046 (71%)]\tLoss: 0.027336\n",
            "Train epoch: 196 [667360/25046 (82%)]\tLoss: 0.057305\n",
            "Train epoch: 196 [743760/25046 (92%)]\tLoss: 0.131335\n",
            "Make prediction for 5010 samples...\n",
            "0.23441477 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 197 [0/25046 (0%)]\tLoss: 0.048594\n",
            "Train epoch: 197 [80360/25046 (10%)]\tLoss: 0.037935\n",
            "Train epoch: 197 [163040/25046 (20%)]\tLoss: 0.105901\n",
            "Train epoch: 197 [238140/25046 (31%)]\tLoss: 0.046816\n",
            "Train epoch: 197 [334400/25046 (41%)]\tLoss: 0.045611\n",
            "Train epoch: 197 [410800/25046 (51%)]\tLoss: 0.068850\n",
            "Train epoch: 197 [488640/25046 (61%)]\tLoss: 0.047455\n",
            "Train epoch: 197 [571200/25046 (71%)]\tLoss: 0.062410\n",
            "Train epoch: 197 [663200/25046 (82%)]\tLoss: 0.037924\n",
            "Train epoch: 197 [739080/25046 (92%)]\tLoss: 0.058902\n",
            "Make prediction for 5010 samples...\n",
            "0.23111801 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 198 [0/25046 (0%)]\tLoss: 0.050017\n",
            "Train epoch: 198 [82680/25046 (10%)]\tLoss: 0.052479\n",
            "Train epoch: 198 [168440/25046 (20%)]\tLoss: 0.029853\n",
            "Train epoch: 198 [246600/25046 (31%)]\tLoss: 0.042529\n",
            "Train epoch: 198 [325760/25046 (41%)]\tLoss: 0.038992\n",
            "Train epoch: 198 [417500/25046 (51%)]\tLoss: 0.050998\n",
            "Train epoch: 198 [480720/25046 (61%)]\tLoss: 0.037910\n",
            "Train epoch: 198 [579740/25046 (71%)]\tLoss: 0.108430\n",
            "Train epoch: 198 [664000/25046 (82%)]\tLoss: 0.091213\n",
            "Train epoch: 198 [743400/25046 (92%)]\tLoss: 0.065278\n",
            "Make prediction for 5010 samples...\n",
            "0.23008254 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 199 [0/25046 (0%)]\tLoss: 0.054151\n",
            "Train epoch: 199 [81600/25046 (10%)]\tLoss: 0.042350\n",
            "Train epoch: 199 [165640/25046 (20%)]\tLoss: 0.058353\n",
            "Train epoch: 199 [249600/25046 (31%)]\tLoss: 0.059518\n",
            "Train epoch: 199 [331600/25046 (41%)]\tLoss: 0.074105\n",
            "Train epoch: 199 [415400/25046 (51%)]\tLoss: 0.044867\n",
            "Train epoch: 199 [499560/25046 (61%)]\tLoss: 0.066984\n",
            "Train epoch: 199 [577080/25046 (71%)]\tLoss: 0.090648\n",
            "Train epoch: 199 [645760/25046 (82%)]\tLoss: 0.062179\n",
            "Train epoch: 199 [753120/25046 (92%)]\tLoss: 0.044198\n",
            "Make prediction for 5010 samples...\n",
            "0.23724568 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 200 [0/25046 (0%)]\tLoss: 0.059914\n",
            "Train epoch: 200 [78640/25046 (10%)]\tLoss: 0.066874\n",
            "Train epoch: 200 [163840/25046 (20%)]\tLoss: 0.040442\n",
            "Train epoch: 200 [250680/25046 (31%)]\tLoss: 0.122847\n",
            "Train epoch: 200 [323360/25046 (41%)]\tLoss: 0.066765\n",
            "Train epoch: 200 [422800/25046 (51%)]\tLoss: 0.090465\n",
            "Train epoch: 200 [500640/25046 (61%)]\tLoss: 0.043961\n",
            "Train epoch: 200 [569660/25046 (71%)]\tLoss: 0.059753\n",
            "Train epoch: 200 [643360/25046 (82%)]\tLoss: 0.060909\n",
            "Train epoch: 200 [729720/25046 (92%)]\tLoss: 0.040542\n",
            "Make prediction for 5010 samples...\n",
            "0.23317671 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 201 [0/25046 (0%)]\tLoss: 0.081438\n",
            "Train epoch: 201 [82040/25046 (10%)]\tLoss: 0.040137\n",
            "Train epoch: 201 [162040/25046 (20%)]\tLoss: 0.070010\n",
            "Train epoch: 201 [248940/25046 (31%)]\tLoss: 0.046036\n",
            "Train epoch: 201 [333920/25046 (41%)]\tLoss: 0.062514\n",
            "Train epoch: 201 [410700/25046 (51%)]\tLoss: 0.045695\n",
            "Train epoch: 201 [484680/25046 (61%)]\tLoss: 0.095681\n",
            "Train epoch: 201 [576240/25046 (71%)]\tLoss: 0.039222\n",
            "Train epoch: 201 [660160/25046 (82%)]\tLoss: 0.036767\n",
            "Train epoch: 201 [727740/25046 (92%)]\tLoss: 0.126298\n",
            "Make prediction for 5010 samples...\n",
            "0.233404 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 202 [0/25046 (0%)]\tLoss: 0.074427\n",
            "Train epoch: 202 [82300/25046 (10%)]\tLoss: 0.052098\n",
            "Train epoch: 202 [162040/25046 (20%)]\tLoss: 0.037160\n",
            "Train epoch: 202 [249420/25046 (31%)]\tLoss: 0.045866\n",
            "Train epoch: 202 [331040/25046 (41%)]\tLoss: 0.058602\n",
            "Train epoch: 202 [408900/25046 (51%)]\tLoss: 0.028924\n",
            "Train epoch: 202 [498480/25046 (61%)]\tLoss: 0.079657\n",
            "Train epoch: 202 [582820/25046 (71%)]\tLoss: 0.060553\n",
            "Train epoch: 202 [657120/25046 (82%)]\tLoss: 0.062697\n",
            "Train epoch: 202 [717660/25046 (92%)]\tLoss: 0.068470\n",
            "Make prediction for 5010 samples...\n",
            "0.23623334 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 203 [0/25046 (0%)]\tLoss: 0.059843\n",
            "Train epoch: 203 [81800/25046 (10%)]\tLoss: 0.051455\n",
            "Train epoch: 203 [159320/25046 (20%)]\tLoss: 0.080235\n",
            "Train epoch: 203 [244920/25046 (31%)]\tLoss: 0.053274\n",
            "Train epoch: 203 [327840/25046 (41%)]\tLoss: 0.037621\n",
            "Train epoch: 203 [399500/25046 (51%)]\tLoss: 0.076156\n",
            "Train epoch: 203 [485520/25046 (61%)]\tLoss: 0.063459\n",
            "Train epoch: 203 [570640/25046 (71%)]\tLoss: 0.068583\n",
            "Train epoch: 203 [652160/25046 (82%)]\tLoss: 0.061579\n",
            "Train epoch: 203 [733140/25046 (92%)]\tLoss: 0.054055\n",
            "Make prediction for 5010 samples...\n",
            "0.23671958 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 204 [0/25046 (0%)]\tLoss: 0.052639\n",
            "Train epoch: 204 [81280/25046 (10%)]\tLoss: 0.073731\n",
            "Train epoch: 204 [165680/25046 (20%)]\tLoss: 0.065641\n",
            "Train epoch: 204 [244860/25046 (31%)]\tLoss: 0.045688\n",
            "Train epoch: 204 [330160/25046 (41%)]\tLoss: 0.062193\n",
            "Train epoch: 204 [420300/25046 (51%)]\tLoss: 0.047613\n",
            "Train epoch: 204 [483720/25046 (61%)]\tLoss: 0.056288\n",
            "Train epoch: 204 [580160/25046 (71%)]\tLoss: 0.082286\n",
            "Train epoch: 204 [644320/25046 (82%)]\tLoss: 0.090146\n",
            "Train epoch: 204 [730620/25046 (92%)]\tLoss: 0.033526\n",
            "Make prediction for 5010 samples...\n",
            "0.24299155 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 205 [0/25046 (0%)]\tLoss: 0.049832\n",
            "Train epoch: 205 [84700/25046 (10%)]\tLoss: 0.046853\n",
            "Train epoch: 205 [163960/25046 (20%)]\tLoss: 0.063117\n",
            "Train epoch: 205 [252180/25046 (31%)]\tLoss: 0.107513\n",
            "Train epoch: 205 [328000/25046 (41%)]\tLoss: 0.033317\n",
            "Train epoch: 205 [416800/25046 (51%)]\tLoss: 0.074809\n",
            "Train epoch: 205 [496200/25046 (61%)]\tLoss: 0.097503\n",
            "Train epoch: 205 [568260/25046 (71%)]\tLoss: 0.075005\n",
            "Train epoch: 205 [662400/25046 (82%)]\tLoss: 0.069208\n",
            "Train epoch: 205 [739440/25046 (92%)]\tLoss: 0.066072\n",
            "Make prediction for 5010 samples...\n",
            "0.23928401 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 206 [0/25046 (0%)]\tLoss: 0.046351\n",
            "Train epoch: 206 [81840/25046 (10%)]\tLoss: 0.040626\n",
            "Train epoch: 206 [161040/25046 (20%)]\tLoss: 0.064956\n",
            "Train epoch: 206 [247380/25046 (31%)]\tLoss: 0.064789\n",
            "Train epoch: 206 [332640/25046 (41%)]\tLoss: 0.081828\n",
            "Train epoch: 206 [413200/25046 (51%)]\tLoss: 0.148366\n",
            "Train epoch: 206 [506400/25046 (61%)]\tLoss: 0.056660\n",
            "Train epoch: 206 [580720/25046 (71%)]\tLoss: 0.051086\n",
            "Train epoch: 206 [660000/25046 (82%)]\tLoss: 0.047767\n",
            "Train epoch: 206 [738180/25046 (92%)]\tLoss: 0.039592\n",
            "Make prediction for 5010 samples...\n",
            "0.22847892 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 207 [0/25046 (0%)]\tLoss: 0.065870\n",
            "Train epoch: 207 [79420/25046 (10%)]\tLoss: 0.065067\n",
            "Train epoch: 207 [164480/25046 (20%)]\tLoss: 0.047534\n",
            "Train epoch: 207 [242880/25046 (31%)]\tLoss: 0.099685\n",
            "Train epoch: 207 [324080/25046 (41%)]\tLoss: 0.047236\n",
            "Train epoch: 207 [413400/25046 (51%)]\tLoss: 0.045532\n",
            "Train epoch: 207 [487080/25046 (61%)]\tLoss: 0.049706\n",
            "Train epoch: 207 [573720/25046 (71%)]\tLoss: 0.045656\n",
            "Train epoch: 207 [652160/25046 (82%)]\tLoss: 0.080882\n",
            "Train epoch: 207 [739620/25046 (92%)]\tLoss: 0.089294\n",
            "Make prediction for 5010 samples...\n",
            "0.23664756 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 208 [0/25046 (0%)]\tLoss: 0.054067\n",
            "Train epoch: 208 [81680/25046 (10%)]\tLoss: 0.056692\n",
            "Train epoch: 208 [161640/25046 (20%)]\tLoss: 0.038677\n",
            "Train epoch: 208 [245580/25046 (31%)]\tLoss: 0.045169\n",
            "Train epoch: 208 [337120/25046 (41%)]\tLoss: 0.059360\n",
            "Train epoch: 208 [405700/25046 (51%)]\tLoss: 0.090073\n",
            "Train epoch: 208 [480000/25046 (61%)]\tLoss: 0.170931\n",
            "Train epoch: 208 [572740/25046 (71%)]\tLoss: 0.044565\n",
            "Train epoch: 208 [659520/25046 (82%)]\tLoss: 0.037650\n",
            "Train epoch: 208 [759420/25046 (92%)]\tLoss: 0.065254\n",
            "Make prediction for 5010 samples...\n",
            "0.23355906 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 209 [0/25046 (0%)]\tLoss: 0.088543\n",
            "Train epoch: 209 [82200/25046 (10%)]\tLoss: 0.070116\n",
            "Train epoch: 209 [157040/25046 (20%)]\tLoss: 0.058114\n",
            "Train epoch: 209 [249060/25046 (31%)]\tLoss: 0.067282\n",
            "Train epoch: 209 [324480/25046 (41%)]\tLoss: 0.070716\n",
            "Train epoch: 209 [415800/25046 (51%)]\tLoss: 0.051791\n",
            "Train epoch: 209 [509040/25046 (61%)]\tLoss: 0.046126\n",
            "Train epoch: 209 [583520/25046 (71%)]\tLoss: 0.092732\n",
            "Train epoch: 209 [666880/25046 (82%)]\tLoss: 0.063501\n",
            "Train epoch: 209 [746280/25046 (92%)]\tLoss: 0.071538\n",
            "Make prediction for 5010 samples...\n",
            "0.23577237 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 210 [0/25046 (0%)]\tLoss: 0.052210\n",
            "Train epoch: 210 [81960/25046 (10%)]\tLoss: 0.042721\n",
            "Train epoch: 210 [163480/25046 (20%)]\tLoss: 0.047676\n",
            "Train epoch: 210 [244020/25046 (31%)]\tLoss: 0.071860\n",
            "Train epoch: 210 [322960/25046 (41%)]\tLoss: 0.078977\n",
            "Train epoch: 210 [410600/25046 (51%)]\tLoss: 0.041861\n",
            "Train epoch: 210 [492600/25046 (61%)]\tLoss: 0.076723\n",
            "Train epoch: 210 [558600/25046 (71%)]\tLoss: 0.074111\n",
            "Train epoch: 210 [667200/25046 (82%)]\tLoss: 0.112501\n",
            "Train epoch: 210 [714060/25046 (92%)]\tLoss: 0.074213\n",
            "Make prediction for 5010 samples...\n",
            "0.22996175 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 211 [0/25046 (0%)]\tLoss: 0.091423\n",
            "Train epoch: 211 [82400/25046 (10%)]\tLoss: 0.059875\n",
            "Train epoch: 211 [165440/25046 (20%)]\tLoss: 0.035287\n",
            "Train epoch: 211 [240060/25046 (31%)]\tLoss: 0.067392\n",
            "Train epoch: 211 [328720/25046 (41%)]\tLoss: 0.075880\n",
            "Train epoch: 211 [421100/25046 (51%)]\tLoss: 0.123365\n",
            "Train epoch: 211 [479280/25046 (61%)]\tLoss: 0.040212\n",
            "Train epoch: 211 [565320/25046 (71%)]\tLoss: 0.052749\n",
            "Train epoch: 211 [674880/25046 (82%)]\tLoss: 0.049984\n",
            "Train epoch: 211 [733680/25046 (92%)]\tLoss: 0.035649\n",
            "Make prediction for 5010 samples...\n",
            "0.23702621 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 212 [0/25046 (0%)]\tLoss: 0.034241\n",
            "Train epoch: 212 [82620/25046 (10%)]\tLoss: 0.086923\n",
            "Train epoch: 212 [165360/25046 (20%)]\tLoss: 0.121094\n",
            "Train epoch: 212 [244500/25046 (31%)]\tLoss: 0.052366\n",
            "Train epoch: 212 [332560/25046 (41%)]\tLoss: 0.067755\n",
            "Train epoch: 212 [413900/25046 (51%)]\tLoss: 0.058927\n",
            "Train epoch: 212 [496440/25046 (61%)]\tLoss: 0.042190\n",
            "Train epoch: 212 [591220/25046 (71%)]\tLoss: 0.048244\n",
            "Train epoch: 212 [665920/25046 (82%)]\tLoss: 0.063043\n",
            "Train epoch: 212 [740880/25046 (92%)]\tLoss: 0.063431\n",
            "Make prediction for 5010 samples...\n",
            "0.22919752 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 213 [0/25046 (0%)]\tLoss: 0.041045\n",
            "Train epoch: 213 [81480/25046 (10%)]\tLoss: 0.095633\n",
            "Train epoch: 213 [164440/25046 (20%)]\tLoss: 0.046657\n",
            "Train epoch: 213 [249240/25046 (31%)]\tLoss: 0.058274\n",
            "Train epoch: 213 [324400/25046 (41%)]\tLoss: 0.062986\n",
            "Train epoch: 213 [418300/25046 (51%)]\tLoss: 0.053539\n",
            "Train epoch: 213 [498840/25046 (61%)]\tLoss: 0.099532\n",
            "Train epoch: 213 [559300/25046 (71%)]\tLoss: 0.051027\n",
            "Train epoch: 213 [660160/25046 (82%)]\tLoss: 0.060168\n",
            "Train epoch: 213 [733320/25046 (92%)]\tLoss: 0.102119\n",
            "Make prediction for 5010 samples...\n",
            "0.23018992 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 214 [0/25046 (0%)]\tLoss: 0.054834\n",
            "Train epoch: 214 [80920/25046 (10%)]\tLoss: 0.076249\n",
            "Train epoch: 214 [157960/25046 (20%)]\tLoss: 0.068284\n",
            "Train epoch: 214 [237600/25046 (31%)]\tLoss: 0.052009\n",
            "Train epoch: 214 [334880/25046 (41%)]\tLoss: 0.094515\n",
            "Train epoch: 214 [415800/25046 (51%)]\tLoss: 0.078367\n",
            "Train epoch: 214 [490920/25046 (61%)]\tLoss: 0.067417\n",
            "Train epoch: 214 [570500/25046 (71%)]\tLoss: 0.040712\n",
            "Train epoch: 214 [663520/25046 (82%)]\tLoss: 0.063719\n",
            "Train epoch: 214 [728640/25046 (92%)]\tLoss: 0.069937\n",
            "Make prediction for 5010 samples...\n",
            "0.2393848 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 215 [0/25046 (0%)]\tLoss: 0.043828\n",
            "Train epoch: 215 [81540/25046 (10%)]\tLoss: 0.034969\n",
            "Train epoch: 215 [163000/25046 (20%)]\tLoss: 0.035794\n",
            "Train epoch: 215 [241500/25046 (31%)]\tLoss: 0.041996\n",
            "Train epoch: 215 [321760/25046 (41%)]\tLoss: 0.069024\n",
            "Train epoch: 215 [400300/25046 (51%)]\tLoss: 0.049606\n",
            "Train epoch: 215 [478680/25046 (61%)]\tLoss: 0.052661\n",
            "Train epoch: 215 [580020/25046 (71%)]\tLoss: 0.072583\n",
            "Train epoch: 215 [638240/25046 (82%)]\tLoss: 0.031217\n",
            "Train epoch: 215 [720000/25046 (92%)]\tLoss: 0.082492\n",
            "Make prediction for 5010 samples...\n",
            "0.23446652 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 216 [0/25046 (0%)]\tLoss: 0.040582\n",
            "Train epoch: 216 [81260/25046 (10%)]\tLoss: 0.043370\n",
            "Train epoch: 216 [165160/25046 (20%)]\tLoss: 0.041692\n",
            "Train epoch: 216 [238920/25046 (31%)]\tLoss: 0.081561\n",
            "Train epoch: 216 [328160/25046 (41%)]\tLoss: 0.085558\n",
            "Train epoch: 216 [410300/25046 (51%)]\tLoss: 0.084199\n",
            "Train epoch: 216 [498600/25046 (61%)]\tLoss: 0.064937\n",
            "Train epoch: 216 [581980/25046 (71%)]\tLoss: 0.099818\n",
            "Train epoch: 216 [668640/25046 (82%)]\tLoss: 0.100340\n",
            "Train epoch: 216 [749160/25046 (92%)]\tLoss: 0.041765\n",
            "Make prediction for 5010 samples...\n",
            "0.23265657 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 217 [0/25046 (0%)]\tLoss: 0.036733\n",
            "Train epoch: 217 [82260/25046 (10%)]\tLoss: 0.064983\n",
            "Train epoch: 217 [167840/25046 (20%)]\tLoss: 0.058787\n",
            "Train epoch: 217 [250860/25046 (31%)]\tLoss: 0.063718\n",
            "Train epoch: 217 [334480/25046 (41%)]\tLoss: 0.058851\n",
            "Train epoch: 217 [411700/25046 (51%)]\tLoss: 0.034151\n",
            "Train epoch: 217 [491520/25046 (61%)]\tLoss: 0.042681\n",
            "Train epoch: 217 [573720/25046 (71%)]\tLoss: 0.049176\n",
            "Train epoch: 217 [647680/25046 (82%)]\tLoss: 0.079859\n",
            "Train epoch: 217 [722700/25046 (92%)]\tLoss: 0.063688\n",
            "Make prediction for 5010 samples...\n",
            "0.23401536 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 218 [0/25046 (0%)]\tLoss: 0.032261\n",
            "Train epoch: 218 [81180/25046 (10%)]\tLoss: 0.042210\n",
            "Train epoch: 218 [162920/25046 (20%)]\tLoss: 0.038244\n",
            "Train epoch: 218 [252480/25046 (31%)]\tLoss: 0.029075\n",
            "Train epoch: 218 [326080/25046 (41%)]\tLoss: 0.058929\n",
            "Train epoch: 218 [411100/25046 (51%)]\tLoss: 0.046869\n",
            "Train epoch: 218 [503160/25046 (61%)]\tLoss: 0.197142\n",
            "Train epoch: 218 [578200/25046 (71%)]\tLoss: 0.037738\n",
            "Train epoch: 218 [645280/25046 (82%)]\tLoss: 0.078653\n",
            "Train epoch: 218 [761760/25046 (92%)]\tLoss: 0.052307\n",
            "Make prediction for 5010 samples...\n",
            "0.23983541 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 219 [0/25046 (0%)]\tLoss: 0.032891\n",
            "Train epoch: 219 [80120/25046 (10%)]\tLoss: 0.076465\n",
            "Train epoch: 219 [161720/25046 (20%)]\tLoss: 0.038135\n",
            "Train epoch: 219 [246480/25046 (31%)]\tLoss: 0.053750\n",
            "Train epoch: 219 [322640/25046 (41%)]\tLoss: 0.027048\n",
            "Train epoch: 219 [407800/25046 (51%)]\tLoss: 0.056740\n",
            "Train epoch: 219 [499440/25046 (61%)]\tLoss: 0.056625\n",
            "Train epoch: 219 [580720/25046 (71%)]\tLoss: 0.052445\n",
            "Train epoch: 219 [663520/25046 (82%)]\tLoss: 0.042068\n",
            "Train epoch: 219 [744480/25046 (92%)]\tLoss: 0.043308\n",
            "Make prediction for 5010 samples...\n",
            "0.23588741 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 220 [0/25046 (0%)]\tLoss: 0.049862\n",
            "Train epoch: 220 [82900/25046 (10%)]\tLoss: 0.077633\n",
            "Train epoch: 220 [171760/25046 (20%)]\tLoss: 0.049209\n",
            "Train epoch: 220 [241140/25046 (31%)]\tLoss: 0.028333\n",
            "Train epoch: 220 [320320/25046 (41%)]\tLoss: 0.048756\n",
            "Train epoch: 220 [408500/25046 (51%)]\tLoss: 0.055277\n",
            "Train epoch: 220 [490680/25046 (61%)]\tLoss: 0.029262\n",
            "Train epoch: 220 [590800/25046 (71%)]\tLoss: 0.073472\n",
            "Train epoch: 220 [666720/25046 (82%)]\tLoss: 0.020170\n",
            "Train epoch: 220 [742500/25046 (92%)]\tLoss: 0.040102\n",
            "Make prediction for 5010 samples...\n",
            "0.23044366 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 221 [0/25046 (0%)]\tLoss: 0.087627\n",
            "Train epoch: 221 [84860/25046 (10%)]\tLoss: 0.044919\n",
            "Train epoch: 221 [163080/25046 (20%)]\tLoss: 0.109597\n",
            "Train epoch: 221 [240420/25046 (31%)]\tLoss: 0.031972\n",
            "Train epoch: 221 [330480/25046 (41%)]\tLoss: 0.070677\n",
            "Train epoch: 221 [404200/25046 (51%)]\tLoss: 0.127051\n",
            "Train epoch: 221 [485280/25046 (61%)]\tLoss: 0.047826\n",
            "Train epoch: 221 [576100/25046 (71%)]\tLoss: 0.053865\n",
            "Train epoch: 221 [675680/25046 (82%)]\tLoss: 0.151870\n",
            "Train epoch: 221 [745200/25046 (92%)]\tLoss: 0.073828\n",
            "Make prediction for 5010 samples...\n",
            "0.23476258 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 222 [0/25046 (0%)]\tLoss: 0.045508\n",
            "Train epoch: 222 [82580/25046 (10%)]\tLoss: 0.055235\n",
            "Train epoch: 222 [162160/25046 (20%)]\tLoss: 0.033963\n",
            "Train epoch: 222 [244140/25046 (31%)]\tLoss: 0.063406\n",
            "Train epoch: 222 [325360/25046 (41%)]\tLoss: 0.057452\n",
            "Train epoch: 222 [398000/25046 (51%)]\tLoss: 0.046213\n",
            "Train epoch: 222 [491160/25046 (61%)]\tLoss: 0.037914\n",
            "Train epoch: 222 [579180/25046 (71%)]\tLoss: 0.072502\n",
            "Train epoch: 222 [674560/25046 (82%)]\tLoss: 0.058241\n",
            "Train epoch: 222 [757260/25046 (92%)]\tLoss: 0.062621\n",
            "Make prediction for 5010 samples...\n",
            "0.24106674 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 223 [0/25046 (0%)]\tLoss: 0.040914\n",
            "Train epoch: 223 [80620/25046 (10%)]\tLoss: 0.062364\n",
            "Train epoch: 223 [163240/25046 (20%)]\tLoss: 0.038159\n",
            "Train epoch: 223 [252300/25046 (31%)]\tLoss: 0.065572\n",
            "Train epoch: 223 [323040/25046 (41%)]\tLoss: 0.079701\n",
            "Train epoch: 223 [408500/25046 (51%)]\tLoss: 0.060361\n",
            "Train epoch: 223 [501480/25046 (61%)]\tLoss: 0.054135\n",
            "Train epoch: 223 [584640/25046 (71%)]\tLoss: 0.055141\n",
            "Train epoch: 223 [676480/25046 (82%)]\tLoss: 0.053866\n",
            "Train epoch: 223 [733320/25046 (92%)]\tLoss: 0.059531\n",
            "Make prediction for 5010 samples...\n",
            "0.237815 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 224 [0/25046 (0%)]\tLoss: 0.032801\n",
            "Train epoch: 224 [81000/25046 (10%)]\tLoss: 0.050894\n",
            "Train epoch: 224 [164520/25046 (20%)]\tLoss: 0.033478\n",
            "Train epoch: 224 [245220/25046 (31%)]\tLoss: 0.084506\n",
            "Train epoch: 224 [333440/25046 (41%)]\tLoss: 0.032940\n",
            "Train epoch: 224 [407700/25046 (51%)]\tLoss: 0.058096\n",
            "Train epoch: 224 [495360/25046 (61%)]\tLoss: 0.067750\n",
            "Train epoch: 224 [564340/25046 (71%)]\tLoss: 0.049982\n",
            "Train epoch: 224 [664160/25046 (82%)]\tLoss: 0.055300\n",
            "Train epoch: 224 [752760/25046 (92%)]\tLoss: 0.039231\n",
            "Make prediction for 5010 samples...\n",
            "0.24193859 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 225 [0/25046 (0%)]\tLoss: 0.037464\n",
            "Train epoch: 225 [81380/25046 (10%)]\tLoss: 0.053735\n",
            "Train epoch: 225 [167760/25046 (20%)]\tLoss: 0.132575\n",
            "Train epoch: 225 [243780/25046 (31%)]\tLoss: 0.052895\n",
            "Train epoch: 225 [319280/25046 (41%)]\tLoss: 0.070008\n",
            "Train epoch: 225 [404000/25046 (51%)]\tLoss: 0.087419\n",
            "Train epoch: 225 [487320/25046 (61%)]\tLoss: 0.079757\n",
            "Train epoch: 225 [568820/25046 (71%)]\tLoss: 0.044027\n",
            "Train epoch: 225 [654880/25046 (82%)]\tLoss: 0.062653\n",
            "Train epoch: 225 [726660/25046 (92%)]\tLoss: 0.057996\n",
            "Make prediction for 5010 samples...\n",
            "0.23967728 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 226 [0/25046 (0%)]\tLoss: 0.027367\n",
            "Train epoch: 226 [82780/25046 (10%)]\tLoss: 0.059523\n",
            "Train epoch: 226 [166240/25046 (20%)]\tLoss: 0.059579\n",
            "Train epoch: 226 [237120/25046 (31%)]\tLoss: 0.041670\n",
            "Train epoch: 226 [337840/25046 (41%)]\tLoss: 0.088018\n",
            "Train epoch: 226 [404700/25046 (51%)]\tLoss: 0.034275\n",
            "Train epoch: 226 [483720/25046 (61%)]\tLoss: 0.037019\n",
            "Train epoch: 226 [573440/25046 (71%)]\tLoss: 0.079287\n",
            "Train epoch: 226 [640480/25046 (82%)]\tLoss: 0.062306\n",
            "Train epoch: 226 [744300/25046 (92%)]\tLoss: 0.074521\n",
            "Make prediction for 5010 samples...\n",
            "0.23641019 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 227 [0/25046 (0%)]\tLoss: 0.041149\n",
            "Train epoch: 227 [85140/25046 (10%)]\tLoss: 0.036230\n",
            "Train epoch: 227 [167840/25046 (20%)]\tLoss: 0.071897\n",
            "Train epoch: 227 [249660/25046 (31%)]\tLoss: 0.040767\n",
            "Train epoch: 227 [318960/25046 (41%)]\tLoss: 0.094978\n",
            "Train epoch: 227 [414100/25046 (51%)]\tLoss: 0.061720\n",
            "Train epoch: 227 [492960/25046 (61%)]\tLoss: 0.034868\n",
            "Train epoch: 227 [594020/25046 (71%)]\tLoss: 0.076933\n",
            "Train epoch: 227 [670400/25046 (82%)]\tLoss: 0.035595\n",
            "Train epoch: 227 [739080/25046 (92%)]\tLoss: 0.062910\n",
            "Make prediction for 5010 samples...\n",
            "0.24010164 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 228 [0/25046 (0%)]\tLoss: 0.042540\n",
            "Train epoch: 228 [78720/25046 (10%)]\tLoss: 0.130950\n",
            "Train epoch: 228 [164640/25046 (20%)]\tLoss: 0.068758\n",
            "Train epoch: 228 [248880/25046 (31%)]\tLoss: 0.058022\n",
            "Train epoch: 228 [339040/25046 (41%)]\tLoss: 0.035533\n",
            "Train epoch: 228 [409900/25046 (51%)]\tLoss: 0.039300\n",
            "Train epoch: 228 [498720/25046 (61%)]\tLoss: 0.053615\n",
            "Train epoch: 228 [570500/25046 (71%)]\tLoss: 0.111710\n",
            "Train epoch: 228 [660480/25046 (82%)]\tLoss: 0.067212\n",
            "Train epoch: 228 [774180/25046 (92%)]\tLoss: 0.084393\n",
            "Make prediction for 5010 samples...\n",
            "0.24103989 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 229 [0/25046 (0%)]\tLoss: 0.053363\n",
            "Train epoch: 229 [79380/25046 (10%)]\tLoss: 0.035764\n",
            "Train epoch: 229 [161560/25046 (20%)]\tLoss: 0.021755\n",
            "Train epoch: 229 [248100/25046 (31%)]\tLoss: 0.070741\n",
            "Train epoch: 229 [321520/25046 (41%)]\tLoss: 0.054865\n",
            "Train epoch: 229 [416000/25046 (51%)]\tLoss: 0.064217\n",
            "Train epoch: 229 [495120/25046 (61%)]\tLoss: 0.043974\n",
            "Train epoch: 229 [574840/25046 (71%)]\tLoss: 0.096875\n",
            "Train epoch: 229 [641920/25046 (82%)]\tLoss: 0.035563\n",
            "Train epoch: 229 [749340/25046 (92%)]\tLoss: 0.043918\n",
            "Make prediction for 5010 samples...\n",
            "0.24216041 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 230 [0/25046 (0%)]\tLoss: 0.049025\n",
            "Train epoch: 230 [83940/25046 (10%)]\tLoss: 0.059089\n",
            "Train epoch: 230 [165400/25046 (20%)]\tLoss: 0.066186\n",
            "Train epoch: 230 [250020/25046 (31%)]\tLoss: 0.132132\n",
            "Train epoch: 230 [330080/25046 (41%)]\tLoss: 0.065684\n",
            "Train epoch: 230 [412500/25046 (51%)]\tLoss: 0.041388\n",
            "Train epoch: 230 [500040/25046 (61%)]\tLoss: 0.055132\n",
            "Train epoch: 230 [559720/25046 (71%)]\tLoss: 0.046476\n",
            "Train epoch: 230 [655680/25046 (82%)]\tLoss: 0.024508\n",
            "Train epoch: 230 [735120/25046 (92%)]\tLoss: 0.052572\n",
            "Make prediction for 5010 samples...\n",
            "0.23693073 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 231 [0/25046 (0%)]\tLoss: 0.066021\n",
            "Train epoch: 231 [82820/25046 (10%)]\tLoss: 0.063104\n",
            "Train epoch: 231 [161000/25046 (20%)]\tLoss: 0.020525\n",
            "Train epoch: 231 [250140/25046 (31%)]\tLoss: 0.038341\n",
            "Train epoch: 231 [325280/25046 (41%)]\tLoss: 0.032850\n",
            "Train epoch: 231 [406200/25046 (51%)]\tLoss: 0.031699\n",
            "Train epoch: 231 [495960/25046 (61%)]\tLoss: 0.055976\n",
            "Train epoch: 231 [566440/25046 (71%)]\tLoss: 0.035011\n",
            "Train epoch: 231 [645920/25046 (82%)]\tLoss: 0.055358\n",
            "Train epoch: 231 [718560/25046 (92%)]\tLoss: 0.163798\n",
            "Make prediction for 5010 samples...\n",
            "0.23423406 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 232 [0/25046 (0%)]\tLoss: 0.082465\n",
            "Train epoch: 232 [81720/25046 (10%)]\tLoss: 0.075762\n",
            "Train epoch: 232 [166040/25046 (20%)]\tLoss: 0.035960\n",
            "Train epoch: 232 [248220/25046 (31%)]\tLoss: 0.042407\n",
            "Train epoch: 232 [334880/25046 (41%)]\tLoss: 0.041241\n",
            "Train epoch: 232 [412500/25046 (51%)]\tLoss: 0.057949\n",
            "Train epoch: 232 [488160/25046 (61%)]\tLoss: 0.035372\n",
            "Train epoch: 232 [575400/25046 (71%)]\tLoss: 0.059057\n",
            "Train epoch: 232 [641760/25046 (82%)]\tLoss: 0.035828\n",
            "Train epoch: 232 [697680/25046 (92%)]\tLoss: 0.041608\n",
            "Make prediction for 5010 samples...\n",
            "0.24162683 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 233 [0/25046 (0%)]\tLoss: 0.033358\n",
            "Train epoch: 233 [84040/25046 (10%)]\tLoss: 0.039013\n",
            "Train epoch: 233 [164840/25046 (20%)]\tLoss: 0.026482\n",
            "Train epoch: 233 [244140/25046 (31%)]\tLoss: 0.062326\n",
            "Train epoch: 233 [331760/25046 (41%)]\tLoss: 0.041192\n",
            "Train epoch: 233 [414600/25046 (51%)]\tLoss: 0.076507\n",
            "Train epoch: 233 [495360/25046 (61%)]\tLoss: 0.064349\n",
            "Train epoch: 233 [594580/25046 (71%)]\tLoss: 0.050149\n",
            "Train epoch: 233 [652640/25046 (82%)]\tLoss: 0.062804\n",
            "Train epoch: 233 [745560/25046 (92%)]\tLoss: 0.034822\n",
            "Make prediction for 5010 samples...\n",
            "0.24046578 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 234 [0/25046 (0%)]\tLoss: 0.056114\n",
            "Train epoch: 234 [82440/25046 (10%)]\tLoss: 0.055173\n",
            "Train epoch: 234 [160480/25046 (20%)]\tLoss: 0.054703\n",
            "Train epoch: 234 [238320/25046 (31%)]\tLoss: 0.084251\n",
            "Train epoch: 234 [332240/25046 (41%)]\tLoss: 0.050142\n",
            "Train epoch: 234 [422900/25046 (51%)]\tLoss: 0.028433\n",
            "Train epoch: 234 [487080/25046 (61%)]\tLoss: 0.031572\n",
            "Train epoch: 234 [575400/25046 (71%)]\tLoss: 0.032195\n",
            "Train epoch: 234 [635360/25046 (82%)]\tLoss: 0.109834\n",
            "Train epoch: 234 [756900/25046 (92%)]\tLoss: 0.044140\n",
            "Make prediction for 5010 samples...\n",
            "0.23569852 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 235 [0/25046 (0%)]\tLoss: 0.058263\n",
            "Train epoch: 235 [83520/25046 (10%)]\tLoss: 0.033024\n",
            "Train epoch: 235 [163240/25046 (20%)]\tLoss: 0.052834\n",
            "Train epoch: 235 [242400/25046 (31%)]\tLoss: 0.098777\n",
            "Train epoch: 235 [335840/25046 (41%)]\tLoss: 0.043713\n",
            "Train epoch: 235 [405600/25046 (51%)]\tLoss: 0.021176\n",
            "Train epoch: 235 [499800/25046 (61%)]\tLoss: 0.072717\n",
            "Train epoch: 235 [575820/25046 (71%)]\tLoss: 0.025510\n",
            "Train epoch: 235 [652320/25046 (82%)]\tLoss: 0.051868\n",
            "Train epoch: 235 [725940/25046 (92%)]\tLoss: 0.037825\n",
            "Make prediction for 5010 samples...\n",
            "0.23698592 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 236 [0/25046 (0%)]\tLoss: 0.068294\n",
            "Train epoch: 236 [83540/25046 (10%)]\tLoss: 0.045410\n",
            "Train epoch: 236 [163880/25046 (20%)]\tLoss: 0.056395\n",
            "Train epoch: 236 [247620/25046 (31%)]\tLoss: 0.045748\n",
            "Train epoch: 236 [323040/25046 (41%)]\tLoss: 0.046507\n",
            "Train epoch: 236 [402600/25046 (51%)]\tLoss: 0.048966\n",
            "Train epoch: 236 [497520/25046 (61%)]\tLoss: 0.044951\n",
            "Train epoch: 236 [570920/25046 (71%)]\tLoss: 0.063722\n",
            "Train epoch: 236 [670400/25046 (82%)]\tLoss: 0.048218\n",
            "Train epoch: 236 [734760/25046 (92%)]\tLoss: 0.052666\n",
            "Make prediction for 5010 samples...\n",
            "0.24122125 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 237 [0/25046 (0%)]\tLoss: 0.051368\n",
            "Train epoch: 237 [81500/25046 (10%)]\tLoss: 0.044373\n",
            "Train epoch: 237 [163920/25046 (20%)]\tLoss: 0.055340\n",
            "Train epoch: 237 [244440/25046 (31%)]\tLoss: 0.038176\n",
            "Train epoch: 237 [324160/25046 (41%)]\tLoss: 0.054366\n",
            "Train epoch: 237 [411200/25046 (51%)]\tLoss: 0.054555\n",
            "Train epoch: 237 [493320/25046 (61%)]\tLoss: 0.250958\n",
            "Train epoch: 237 [572040/25046 (71%)]\tLoss: 0.092183\n",
            "Train epoch: 237 [640480/25046 (82%)]\tLoss: 0.055362\n",
            "Train epoch: 237 [750960/25046 (92%)]\tLoss: 0.093137\n",
            "Make prediction for 5010 samples...\n",
            "0.24163261 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 238 [0/25046 (0%)]\tLoss: 0.035343\n",
            "Train epoch: 238 [83660/25046 (10%)]\tLoss: 0.147256\n",
            "Train epoch: 238 [163560/25046 (20%)]\tLoss: 0.140941\n",
            "Train epoch: 238 [245160/25046 (31%)]\tLoss: 0.089980\n",
            "Train epoch: 238 [328400/25046 (41%)]\tLoss: 0.099351\n",
            "Train epoch: 238 [409100/25046 (51%)]\tLoss: 0.040925\n",
            "Train epoch: 238 [479160/25046 (61%)]\tLoss: 0.052097\n",
            "Train epoch: 238 [567700/25046 (71%)]\tLoss: 0.053789\n",
            "Train epoch: 238 [675040/25046 (82%)]\tLoss: 0.104011\n",
            "Train epoch: 238 [743220/25046 (92%)]\tLoss: 0.040207\n",
            "Make prediction for 5010 samples...\n",
            "0.24956742 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 239 [0/25046 (0%)]\tLoss: 0.080036\n",
            "Train epoch: 239 [80120/25046 (10%)]\tLoss: 0.043219\n",
            "Train epoch: 239 [166800/25046 (20%)]\tLoss: 0.065834\n",
            "Train epoch: 239 [242640/25046 (31%)]\tLoss: 0.067053\n",
            "Train epoch: 239 [320160/25046 (41%)]\tLoss: 0.049462\n",
            "Train epoch: 239 [406700/25046 (51%)]\tLoss: 0.062566\n",
            "Train epoch: 239 [485160/25046 (61%)]\tLoss: 0.058672\n",
            "Train epoch: 239 [557620/25046 (71%)]\tLoss: 0.055449\n",
            "Train epoch: 239 [659840/25046 (82%)]\tLoss: 0.132014\n",
            "Train epoch: 239 [730440/25046 (92%)]\tLoss: 0.029678\n",
            "Make prediction for 5010 samples...\n",
            "0.25580058 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 240 [0/25046 (0%)]\tLoss: 0.065262\n",
            "Train epoch: 240 [80340/25046 (10%)]\tLoss: 0.059170\n",
            "Train epoch: 240 [165240/25046 (20%)]\tLoss: 0.128428\n",
            "Train epoch: 240 [248520/25046 (31%)]\tLoss: 0.039545\n",
            "Train epoch: 240 [323680/25046 (41%)]\tLoss: 0.111685\n",
            "Train epoch: 240 [405700/25046 (51%)]\tLoss: 0.066480\n",
            "Train epoch: 240 [502200/25046 (61%)]\tLoss: 0.028941\n",
            "Train epoch: 240 [595140/25046 (71%)]\tLoss: 0.039686\n",
            "Train epoch: 240 [672320/25046 (82%)]\tLoss: 0.040049\n",
            "Train epoch: 240 [749520/25046 (92%)]\tLoss: 0.029072\n",
            "Make prediction for 5010 samples...\n",
            "0.24442574 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 241 [0/25046 (0%)]\tLoss: 0.037882\n",
            "Train epoch: 241 [81940/25046 (10%)]\tLoss: 0.049590\n",
            "Train epoch: 241 [162920/25046 (20%)]\tLoss: 0.032678\n",
            "Train epoch: 241 [247800/25046 (31%)]\tLoss: 0.027093\n",
            "Train epoch: 241 [333120/25046 (41%)]\tLoss: 0.059725\n",
            "Train epoch: 241 [419200/25046 (51%)]\tLoss: 0.028722\n",
            "Train epoch: 241 [468600/25046 (61%)]\tLoss: 0.059484\n",
            "Train epoch: 241 [567140/25046 (71%)]\tLoss: 0.029265\n",
            "Train epoch: 241 [685280/25046 (82%)]\tLoss: 0.052162\n",
            "Train epoch: 241 [738900/25046 (92%)]\tLoss: 0.030993\n",
            "Make prediction for 5010 samples...\n",
            "0.24236351 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 242 [0/25046 (0%)]\tLoss: 0.068477\n",
            "Train epoch: 242 [83100/25046 (10%)]\tLoss: 0.059513\n",
            "Train epoch: 242 [163360/25046 (20%)]\tLoss: 0.053947\n",
            "Train epoch: 242 [246840/25046 (31%)]\tLoss: 0.073608\n",
            "Train epoch: 242 [324640/25046 (41%)]\tLoss: 0.189289\n",
            "Train epoch: 242 [407700/25046 (51%)]\tLoss: 0.067020\n",
            "Train epoch: 242 [491160/25046 (61%)]\tLoss: 0.046464\n",
            "Train epoch: 242 [588420/25046 (71%)]\tLoss: 0.070489\n",
            "Train epoch: 242 [657600/25046 (82%)]\tLoss: 0.031635\n",
            "Train epoch: 242 [719640/25046 (92%)]\tLoss: 0.090433\n",
            "Make prediction for 5010 samples...\n",
            "0.23505706 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 243 [0/25046 (0%)]\tLoss: 0.032859\n",
            "Train epoch: 243 [83460/25046 (10%)]\tLoss: 0.062989\n",
            "Train epoch: 243 [164680/25046 (20%)]\tLoss: 0.037631\n",
            "Train epoch: 243 [247020/25046 (31%)]\tLoss: 0.027331\n",
            "Train epoch: 243 [336000/25046 (41%)]\tLoss: 0.076169\n",
            "Train epoch: 243 [405400/25046 (51%)]\tLoss: 0.081791\n",
            "Train epoch: 243 [478800/25046 (61%)]\tLoss: 0.037205\n",
            "Train epoch: 243 [578480/25046 (71%)]\tLoss: 0.064533\n",
            "Train epoch: 243 [661920/25046 (82%)]\tLoss: 0.064384\n",
            "Train epoch: 243 [745020/25046 (92%)]\tLoss: 0.029742\n",
            "Make prediction for 5010 samples...\n",
            "0.23673297 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 244 [0/25046 (0%)]\tLoss: 0.059228\n",
            "Train epoch: 244 [82280/25046 (10%)]\tLoss: 0.036376\n",
            "Train epoch: 244 [165760/25046 (20%)]\tLoss: 0.102924\n",
            "Train epoch: 244 [247740/25046 (31%)]\tLoss: 0.033082\n",
            "Train epoch: 244 [323600/25046 (41%)]\tLoss: 0.042321\n",
            "Train epoch: 244 [402900/25046 (51%)]\tLoss: 0.076264\n",
            "Train epoch: 244 [490680/25046 (61%)]\tLoss: 0.071392\n",
            "Train epoch: 244 [564060/25046 (71%)]\tLoss: 0.082516\n",
            "Train epoch: 244 [657440/25046 (82%)]\tLoss: 0.069314\n",
            "Train epoch: 244 [725760/25046 (92%)]\tLoss: 0.078661\n",
            "Make prediction for 5010 samples...\n",
            "0.23669189 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 245 [0/25046 (0%)]\tLoss: 0.042464\n",
            "Train epoch: 245 [83100/25046 (10%)]\tLoss: 0.022880\n",
            "Train epoch: 245 [164520/25046 (20%)]\tLoss: 0.035654\n",
            "Train epoch: 245 [242220/25046 (31%)]\tLoss: 0.041577\n",
            "Train epoch: 245 [325840/25046 (41%)]\tLoss: 0.039892\n",
            "Train epoch: 245 [417900/25046 (51%)]\tLoss: 0.045051\n",
            "Train epoch: 245 [485160/25046 (61%)]\tLoss: 0.043280\n",
            "Train epoch: 245 [580160/25046 (71%)]\tLoss: 0.056421\n",
            "Train epoch: 245 [636640/25046 (82%)]\tLoss: 0.049150\n",
            "Train epoch: 245 [748620/25046 (92%)]\tLoss: 0.045450\n",
            "Make prediction for 5010 samples...\n",
            "0.23623425 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 246 [0/25046 (0%)]\tLoss: 0.034197\n",
            "Train epoch: 246 [82980/25046 (10%)]\tLoss: 0.038224\n",
            "Train epoch: 246 [163920/25046 (20%)]\tLoss: 0.089983\n",
            "Train epoch: 246 [252180/25046 (31%)]\tLoss: 0.170364\n",
            "Train epoch: 246 [331280/25046 (41%)]\tLoss: 0.036640\n",
            "Train epoch: 246 [406600/25046 (51%)]\tLoss: 0.032080\n",
            "Train epoch: 246 [495000/25046 (61%)]\tLoss: 0.025402\n",
            "Train epoch: 246 [574980/25046 (71%)]\tLoss: 0.088355\n",
            "Train epoch: 246 [669280/25046 (82%)]\tLoss: 0.034488\n",
            "Train epoch: 246 [728640/25046 (92%)]\tLoss: 0.057188\n",
            "Make prediction for 5010 samples...\n",
            "0.24294199 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 247 [0/25046 (0%)]\tLoss: 0.040160\n",
            "Train epoch: 247 [81660/25046 (10%)]\tLoss: 0.072317\n",
            "Train epoch: 247 [162760/25046 (20%)]\tLoss: 0.037151\n",
            "Train epoch: 247 [243240/25046 (31%)]\tLoss: 0.062354\n",
            "Train epoch: 247 [328080/25046 (41%)]\tLoss: 0.028054\n",
            "Train epoch: 247 [412000/25046 (51%)]\tLoss: 0.073369\n",
            "Train epoch: 247 [484560/25046 (61%)]\tLoss: 0.058338\n",
            "Train epoch: 247 [574840/25046 (71%)]\tLoss: 0.078580\n",
            "Train epoch: 247 [648640/25046 (82%)]\tLoss: 0.094201\n",
            "Train epoch: 247 [736560/25046 (92%)]\tLoss: 0.079928\n",
            "Make prediction for 5010 samples...\n",
            "0.2431644 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 248 [0/25046 (0%)]\tLoss: 0.035907\n",
            "Train epoch: 248 [83380/25046 (10%)]\tLoss: 0.088885\n",
            "Train epoch: 248 [163360/25046 (20%)]\tLoss: 0.063332\n",
            "Train epoch: 248 [243180/25046 (31%)]\tLoss: 0.067429\n",
            "Train epoch: 248 [332320/25046 (41%)]\tLoss: 0.114663\n",
            "Train epoch: 248 [413600/25046 (51%)]\tLoss: 0.038659\n",
            "Train epoch: 248 [496440/25046 (61%)]\tLoss: 0.029985\n",
            "Train epoch: 248 [577080/25046 (71%)]\tLoss: 0.036831\n",
            "Train epoch: 248 [653760/25046 (82%)]\tLoss: 0.037513\n",
            "Train epoch: 248 [746100/25046 (92%)]\tLoss: 0.059663\n",
            "Make prediction for 5010 samples...\n",
            "0.2411683 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 249 [0/25046 (0%)]\tLoss: 0.022432\n",
            "Train epoch: 249 [81020/25046 (10%)]\tLoss: 0.101137\n",
            "Train epoch: 249 [163120/25046 (20%)]\tLoss: 0.123559\n",
            "Train epoch: 249 [241440/25046 (31%)]\tLoss: 0.031374\n",
            "Train epoch: 249 [315440/25046 (41%)]\tLoss: 0.047731\n",
            "Train epoch: 249 [400300/25046 (51%)]\tLoss: 0.060495\n",
            "Train epoch: 249 [492600/25046 (61%)]\tLoss: 0.035380\n",
            "Train epoch: 249 [557200/25046 (71%)]\tLoss: 0.057172\n",
            "Train epoch: 249 [646400/25046 (82%)]\tLoss: 0.030987\n",
            "Train epoch: 249 [742320/25046 (92%)]\tLoss: 0.054064\n",
            "Make prediction for 5010 samples...\n",
            "0.23963554 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 250 [0/25046 (0%)]\tLoss: 0.054026\n",
            "Train epoch: 250 [82700/25046 (10%)]\tLoss: 0.045867\n",
            "Train epoch: 250 [165960/25046 (20%)]\tLoss: 0.069578\n",
            "Train epoch: 250 [248400/25046 (31%)]\tLoss: 0.036529\n",
            "Train epoch: 250 [325040/25046 (41%)]\tLoss: 0.061223\n",
            "Train epoch: 250 [412300/25046 (51%)]\tLoss: 0.040438\n",
            "Train epoch: 250 [492960/25046 (61%)]\tLoss: 0.101758\n",
            "Train epoch: 250 [563500/25046 (71%)]\tLoss: 0.054188\n",
            "Train epoch: 250 [644480/25046 (82%)]\tLoss: 0.143413\n",
            "Train epoch: 250 [736200/25046 (92%)]\tLoss: 0.037048\n",
            "Make prediction for 5010 samples...\n",
            "0.24424437 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 251 [0/25046 (0%)]\tLoss: 0.096759\n",
            "Train epoch: 251 [81600/25046 (10%)]\tLoss: 0.041494\n",
            "Train epoch: 251 [170720/25046 (20%)]\tLoss: 0.045952\n",
            "Train epoch: 251 [248100/25046 (31%)]\tLoss: 0.053674\n",
            "Train epoch: 251 [315920/25046 (41%)]\tLoss: 0.034278\n",
            "Train epoch: 251 [413600/25046 (51%)]\tLoss: 0.077827\n",
            "Train epoch: 251 [491760/25046 (61%)]\tLoss: 0.088113\n",
            "Train epoch: 251 [562660/25046 (71%)]\tLoss: 0.048237\n",
            "Train epoch: 251 [646560/25046 (82%)]\tLoss: 0.091806\n",
            "Train epoch: 251 [739800/25046 (92%)]\tLoss: 0.138147\n",
            "Make prediction for 5010 samples...\n",
            "0.23904443 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 252 [0/25046 (0%)]\tLoss: 0.053008\n",
            "Train epoch: 252 [81880/25046 (10%)]\tLoss: 0.037790\n",
            "Train epoch: 252 [160040/25046 (20%)]\tLoss: 0.044448\n",
            "Train epoch: 252 [243360/25046 (31%)]\tLoss: 0.056586\n",
            "Train epoch: 252 [321440/25046 (41%)]\tLoss: 0.034970\n",
            "Train epoch: 252 [412300/25046 (51%)]\tLoss: 0.046525\n",
            "Train epoch: 252 [510960/25046 (61%)]\tLoss: 0.060774\n",
            "Train epoch: 252 [562800/25046 (71%)]\tLoss: 0.044469\n",
            "Train epoch: 252 [673440/25046 (82%)]\tLoss: 0.070572\n",
            "Train epoch: 252 [736920/25046 (92%)]\tLoss: 0.043335\n",
            "Make prediction for 5010 samples...\n",
            "0.23610185 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 253 [0/25046 (0%)]\tLoss: 0.037572\n",
            "Train epoch: 253 [82240/25046 (10%)]\tLoss: 0.054035\n",
            "Train epoch: 253 [161960/25046 (20%)]\tLoss: 0.044062\n",
            "Train epoch: 253 [246000/25046 (31%)]\tLoss: 0.054965\n",
            "Train epoch: 253 [320320/25046 (41%)]\tLoss: 0.024303\n",
            "Train epoch: 253 [399400/25046 (51%)]\tLoss: 0.062594\n",
            "Train epoch: 253 [502320/25046 (61%)]\tLoss: 0.050641\n",
            "Train epoch: 253 [568820/25046 (71%)]\tLoss: 0.032065\n",
            "Train epoch: 253 [653440/25046 (82%)]\tLoss: 0.041070\n",
            "Train epoch: 253 [745740/25046 (92%)]\tLoss: 0.035726\n",
            "Make prediction for 5010 samples...\n",
            "0.24170828 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 254 [0/25046 (0%)]\tLoss: 0.029265\n",
            "Train epoch: 254 [82740/25046 (10%)]\tLoss: 0.045458\n",
            "Train epoch: 254 [166320/25046 (20%)]\tLoss: 0.056994\n",
            "Train epoch: 254 [249780/25046 (31%)]\tLoss: 0.033319\n",
            "Train epoch: 254 [335440/25046 (41%)]\tLoss: 0.044842\n",
            "Train epoch: 254 [407100/25046 (51%)]\tLoss: 0.049845\n",
            "Train epoch: 254 [512880/25046 (61%)]\tLoss: 0.074556\n",
            "Train epoch: 254 [578900/25046 (71%)]\tLoss: 0.085891\n",
            "Train epoch: 254 [652960/25046 (82%)]\tLoss: 0.052952\n",
            "Train epoch: 254 [736380/25046 (92%)]\tLoss: 0.039180\n",
            "Make prediction for 5010 samples...\n",
            "0.23934753 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 255 [0/25046 (0%)]\tLoss: 0.069323\n",
            "Train epoch: 255 [79800/25046 (10%)]\tLoss: 0.076804\n",
            "Train epoch: 255 [167920/25046 (20%)]\tLoss: 0.032602\n",
            "Train epoch: 255 [248160/25046 (31%)]\tLoss: 0.048765\n",
            "Train epoch: 255 [335920/25046 (41%)]\tLoss: 0.045871\n",
            "Train epoch: 255 [410300/25046 (51%)]\tLoss: 0.033700\n",
            "Train epoch: 255 [489240/25046 (61%)]\tLoss: 0.045261\n",
            "Train epoch: 255 [582260/25046 (71%)]\tLoss: 0.032671\n",
            "Train epoch: 255 [652320/25046 (82%)]\tLoss: 0.082066\n",
            "Train epoch: 255 [726480/25046 (92%)]\tLoss: 0.027504\n",
            "Make prediction for 5010 samples...\n",
            "0.23994172 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 256 [0/25046 (0%)]\tLoss: 0.024462\n",
            "Train epoch: 256 [81380/25046 (10%)]\tLoss: 0.071902\n",
            "Train epoch: 256 [167800/25046 (20%)]\tLoss: 0.035449\n",
            "Train epoch: 256 [244980/25046 (31%)]\tLoss: 0.057889\n",
            "Train epoch: 256 [330560/25046 (41%)]\tLoss: 0.026672\n",
            "Train epoch: 256 [391700/25046 (51%)]\tLoss: 0.052062\n",
            "Train epoch: 256 [492240/25046 (61%)]\tLoss: 0.076151\n",
            "Train epoch: 256 [584640/25046 (71%)]\tLoss: 0.041090\n",
            "Train epoch: 256 [643680/25046 (82%)]\tLoss: 0.056110\n",
            "Train epoch: 256 [727740/25046 (92%)]\tLoss: 0.078737\n",
            "Make prediction for 5010 samples...\n",
            "0.23636226 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 257 [0/25046 (0%)]\tLoss: 0.056419\n",
            "Train epoch: 257 [82760/25046 (10%)]\tLoss: 0.062010\n",
            "Train epoch: 257 [163680/25046 (20%)]\tLoss: 0.036969\n",
            "Train epoch: 257 [251580/25046 (31%)]\tLoss: 0.065227\n",
            "Train epoch: 257 [332080/25046 (41%)]\tLoss: 0.037805\n",
            "Train epoch: 257 [411500/25046 (51%)]\tLoss: 0.024225\n",
            "Train epoch: 257 [491040/25046 (61%)]\tLoss: 0.096050\n",
            "Train epoch: 257 [587300/25046 (71%)]\tLoss: 0.053109\n",
            "Train epoch: 257 [645920/25046 (82%)]\tLoss: 0.029558\n",
            "Train epoch: 257 [736200/25046 (92%)]\tLoss: 0.055898\n",
            "Make prediction for 5010 samples...\n",
            "0.23687387 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 258 [0/25046 (0%)]\tLoss: 0.029535\n",
            "Train epoch: 258 [82460/25046 (10%)]\tLoss: 0.061546\n",
            "Train epoch: 258 [167480/25046 (20%)]\tLoss: 0.073564\n",
            "Train epoch: 258 [249720/25046 (31%)]\tLoss: 0.044242\n",
            "Train epoch: 258 [325840/25046 (41%)]\tLoss: 0.045332\n",
            "Train epoch: 258 [421700/25046 (51%)]\tLoss: 0.031358\n",
            "Train epoch: 258 [516480/25046 (61%)]\tLoss: 0.060866\n",
            "Train epoch: 258 [571900/25046 (71%)]\tLoss: 0.041538\n",
            "Train epoch: 258 [646240/25046 (82%)]\tLoss: 0.051338\n",
            "Train epoch: 258 [734760/25046 (92%)]\tLoss: 0.097420\n",
            "Make prediction for 5010 samples...\n",
            "0.23823515 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 259 [0/25046 (0%)]\tLoss: 0.034013\n",
            "Train epoch: 259 [81900/25046 (10%)]\tLoss: 0.074020\n",
            "Train epoch: 259 [163160/25046 (20%)]\tLoss: 0.065212\n",
            "Train epoch: 259 [245700/25046 (31%)]\tLoss: 0.071658\n",
            "Train epoch: 259 [324480/25046 (41%)]\tLoss: 0.073625\n",
            "Train epoch: 259 [410500/25046 (51%)]\tLoss: 0.031333\n",
            "Train epoch: 259 [482760/25046 (61%)]\tLoss: 0.034898\n",
            "Train epoch: 259 [565880/25046 (71%)]\tLoss: 0.078173\n",
            "Train epoch: 259 [660160/25046 (82%)]\tLoss: 0.044133\n",
            "Train epoch: 259 [739260/25046 (92%)]\tLoss: 0.072826\n",
            "Make prediction for 5010 samples...\n",
            "0.24036707 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 260 [0/25046 (0%)]\tLoss: 0.026429\n",
            "Train epoch: 260 [80640/25046 (10%)]\tLoss: 0.073455\n",
            "Train epoch: 260 [164960/25046 (20%)]\tLoss: 0.069230\n",
            "Train epoch: 260 [244260/25046 (31%)]\tLoss: 0.035316\n",
            "Train epoch: 260 [337440/25046 (41%)]\tLoss: 0.046203\n",
            "Train epoch: 260 [417200/25046 (51%)]\tLoss: 0.092571\n",
            "Train epoch: 260 [497280/25046 (61%)]\tLoss: 0.060476\n",
            "Train epoch: 260 [582540/25046 (71%)]\tLoss: 0.093513\n",
            "Train epoch: 260 [656480/25046 (82%)]\tLoss: 0.039095\n",
            "Train epoch: 260 [736920/25046 (92%)]\tLoss: 0.068252\n",
            "Make prediction for 5010 samples...\n",
            "0.23605879 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 261 [0/25046 (0%)]\tLoss: 0.047263\n",
            "Train epoch: 261 [81020/25046 (10%)]\tLoss: 0.052494\n",
            "Train epoch: 261 [165120/25046 (20%)]\tLoss: 0.026147\n",
            "Train epoch: 261 [243420/25046 (31%)]\tLoss: 0.051841\n",
            "Train epoch: 261 [327760/25046 (41%)]\tLoss: 0.048275\n",
            "Train epoch: 261 [405600/25046 (51%)]\tLoss: 0.051469\n",
            "Train epoch: 261 [484560/25046 (61%)]\tLoss: 0.066074\n",
            "Train epoch: 261 [582400/25046 (71%)]\tLoss: 0.070140\n",
            "Train epoch: 261 [644160/25046 (82%)]\tLoss: 0.042084\n",
            "Train epoch: 261 [732600/25046 (92%)]\tLoss: 0.034928\n",
            "Make prediction for 5010 samples...\n",
            "0.24187528 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 262 [0/25046 (0%)]\tLoss: 0.095224\n",
            "Train epoch: 262 [83380/25046 (10%)]\tLoss: 0.045915\n",
            "Train epoch: 262 [164480/25046 (20%)]\tLoss: 0.047025\n",
            "Train epoch: 262 [246780/25046 (31%)]\tLoss: 0.052402\n",
            "Train epoch: 262 [337200/25046 (41%)]\tLoss: 0.043840\n",
            "Train epoch: 262 [408000/25046 (51%)]\tLoss: 0.087381\n",
            "Train epoch: 262 [486960/25046 (61%)]\tLoss: 0.021357\n",
            "Train epoch: 262 [579040/25046 (71%)]\tLoss: 0.055911\n",
            "Train epoch: 262 [658400/25046 (82%)]\tLoss: 0.032907\n",
            "Train epoch: 262 [765720/25046 (92%)]\tLoss: 0.080661\n",
            "Make prediction for 5010 samples...\n",
            "0.24461117 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 263 [0/25046 (0%)]\tLoss: 0.028048\n",
            "Train epoch: 263 [83160/25046 (10%)]\tLoss: 0.065079\n",
            "Train epoch: 263 [159960/25046 (20%)]\tLoss: 0.058934\n",
            "Train epoch: 263 [250200/25046 (31%)]\tLoss: 0.032192\n",
            "Train epoch: 263 [324240/25046 (41%)]\tLoss: 0.043336\n",
            "Train epoch: 263 [414300/25046 (51%)]\tLoss: 0.084644\n",
            "Train epoch: 263 [496560/25046 (61%)]\tLoss: 0.051758\n",
            "Train epoch: 263 [565600/25046 (71%)]\tLoss: 0.057322\n",
            "Train epoch: 263 [661120/25046 (82%)]\tLoss: 0.039542\n",
            "Train epoch: 263 [748620/25046 (92%)]\tLoss: 0.083803\n",
            "Make prediction for 5010 samples...\n",
            "0.24546736 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 264 [0/25046 (0%)]\tLoss: 0.034810\n",
            "Train epoch: 264 [82220/25046 (10%)]\tLoss: 0.044751\n",
            "Train epoch: 264 [162840/25046 (20%)]\tLoss: 0.042982\n",
            "Train epoch: 264 [239940/25046 (31%)]\tLoss: 0.049802\n",
            "Train epoch: 264 [322560/25046 (41%)]\tLoss: 0.068167\n",
            "Train epoch: 264 [414200/25046 (51%)]\tLoss: 0.041556\n",
            "Train epoch: 264 [504480/25046 (61%)]\tLoss: 0.074779\n",
            "Train epoch: 264 [574840/25046 (71%)]\tLoss: 0.028557\n",
            "Train epoch: 264 [649280/25046 (82%)]\tLoss: 0.136582\n",
            "Train epoch: 264 [726660/25046 (92%)]\tLoss: 0.073377\n",
            "Make prediction for 5010 samples...\n",
            "0.24525487 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 265 [0/25046 (0%)]\tLoss: 0.044011\n",
            "Train epoch: 265 [80820/25046 (10%)]\tLoss: 0.102439\n",
            "Train epoch: 265 [161760/25046 (20%)]\tLoss: 0.036217\n",
            "Train epoch: 265 [247020/25046 (31%)]\tLoss: 0.058482\n",
            "Train epoch: 265 [325520/25046 (41%)]\tLoss: 0.052238\n",
            "Train epoch: 265 [409700/25046 (51%)]\tLoss: 0.087667\n",
            "Train epoch: 265 [492720/25046 (61%)]\tLoss: 0.057616\n",
            "Train epoch: 265 [578620/25046 (71%)]\tLoss: 0.051863\n",
            "Train epoch: 265 [646560/25046 (82%)]\tLoss: 0.044882\n",
            "Train epoch: 265 [754920/25046 (92%)]\tLoss: 0.043801\n",
            "Make prediction for 5010 samples...\n",
            "0.24908443 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 266 [0/25046 (0%)]\tLoss: 0.030913\n",
            "Train epoch: 266 [82600/25046 (10%)]\tLoss: 0.028087\n",
            "Train epoch: 266 [163640/25046 (20%)]\tLoss: 0.095620\n",
            "Train epoch: 266 [245340/25046 (31%)]\tLoss: 0.027901\n",
            "Train epoch: 266 [335920/25046 (41%)]\tLoss: 0.043612\n",
            "Train epoch: 266 [405500/25046 (51%)]\tLoss: 0.031972\n",
            "Train epoch: 266 [473640/25046 (61%)]\tLoss: 0.035527\n",
            "Train epoch: 266 [582680/25046 (71%)]\tLoss: 0.045077\n",
            "Train epoch: 266 [664640/25046 (82%)]\tLoss: 0.096928\n",
            "Train epoch: 266 [735120/25046 (92%)]\tLoss: 0.057331\n",
            "Make prediction for 5010 samples...\n",
            "0.24259038 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 267 [0/25046 (0%)]\tLoss: 0.027361\n",
            "Train epoch: 267 [82360/25046 (10%)]\tLoss: 0.069407\n",
            "Train epoch: 267 [164200/25046 (20%)]\tLoss: 0.048568\n",
            "Train epoch: 267 [247740/25046 (31%)]\tLoss: 0.053695\n",
            "Train epoch: 267 [332800/25046 (41%)]\tLoss: 0.028887\n",
            "Train epoch: 267 [411700/25046 (51%)]\tLoss: 0.029512\n",
            "Train epoch: 267 [503160/25046 (61%)]\tLoss: 0.055552\n",
            "Train epoch: 267 [573160/25046 (71%)]\tLoss: 0.034591\n",
            "Train epoch: 267 [646080/25046 (82%)]\tLoss: 0.131863\n",
            "Train epoch: 267 [718380/25046 (92%)]\tLoss: 0.087178\n",
            "Make prediction for 5010 samples...\n",
            "0.23995954 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 268 [0/25046 (0%)]\tLoss: 0.059199\n",
            "Train epoch: 268 [84800/25046 (10%)]\tLoss: 0.073143\n",
            "Train epoch: 268 [164080/25046 (20%)]\tLoss: 0.045284\n",
            "Train epoch: 268 [246540/25046 (31%)]\tLoss: 0.054716\n",
            "Train epoch: 268 [335200/25046 (41%)]\tLoss: 0.049194\n",
            "Train epoch: 268 [419500/25046 (51%)]\tLoss: 0.042038\n",
            "Train epoch: 268 [493800/25046 (61%)]\tLoss: 0.059852\n",
            "Train epoch: 268 [561260/25046 (71%)]\tLoss: 0.059836\n",
            "Train epoch: 268 [666880/25046 (82%)]\tLoss: 0.056118\n",
            "Train epoch: 268 [754560/25046 (92%)]\tLoss: 0.048453\n",
            "Make prediction for 5010 samples...\n",
            "0.23964742 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 269 [0/25046 (0%)]\tLoss: 0.028284\n",
            "Train epoch: 269 [84480/25046 (10%)]\tLoss: 0.051262\n",
            "Train epoch: 269 [164160/25046 (20%)]\tLoss: 0.031545\n",
            "Train epoch: 269 [250740/25046 (31%)]\tLoss: 0.078166\n",
            "Train epoch: 269 [332320/25046 (41%)]\tLoss: 0.065519\n",
            "Train epoch: 269 [411900/25046 (51%)]\tLoss: 0.097300\n",
            "Train epoch: 269 [484200/25046 (61%)]\tLoss: 0.039978\n",
            "Train epoch: 269 [573860/25046 (71%)]\tLoss: 0.084141\n",
            "Train epoch: 269 [660160/25046 (82%)]\tLoss: 0.062681\n",
            "Train epoch: 269 [730260/25046 (92%)]\tLoss: 0.050314\n",
            "Make prediction for 5010 samples...\n",
            "0.24288985 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 270 [0/25046 (0%)]\tLoss: 0.038607\n",
            "Train epoch: 270 [82500/25046 (10%)]\tLoss: 0.047754\n",
            "Train epoch: 270 [163880/25046 (20%)]\tLoss: 0.067409\n",
            "Train epoch: 270 [250920/25046 (31%)]\tLoss: 0.081053\n",
            "Train epoch: 270 [333440/25046 (41%)]\tLoss: 0.036201\n",
            "Train epoch: 270 [415700/25046 (51%)]\tLoss: 0.077562\n",
            "Train epoch: 270 [493800/25046 (61%)]\tLoss: 0.076129\n",
            "Train epoch: 270 [569380/25046 (71%)]\tLoss: 0.041545\n",
            "Train epoch: 270 [675360/25046 (82%)]\tLoss: 0.059454\n",
            "Train epoch: 270 [724680/25046 (92%)]\tLoss: 0.067626\n",
            "Make prediction for 5010 samples...\n",
            "0.24178846 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 271 [0/25046 (0%)]\tLoss: 0.041415\n",
            "Train epoch: 271 [80980/25046 (10%)]\tLoss: 0.033631\n",
            "Train epoch: 271 [166920/25046 (20%)]\tLoss: 0.084777\n",
            "Train epoch: 271 [245220/25046 (31%)]\tLoss: 0.102269\n",
            "Train epoch: 271 [326080/25046 (41%)]\tLoss: 0.025390\n",
            "Train epoch: 271 [413900/25046 (51%)]\tLoss: 0.045091\n",
            "Train epoch: 271 [503640/25046 (61%)]\tLoss: 0.025484\n",
            "Train epoch: 271 [573580/25046 (71%)]\tLoss: 0.021847\n",
            "Train epoch: 271 [642720/25046 (82%)]\tLoss: 0.070042\n",
            "Train epoch: 271 [729540/25046 (92%)]\tLoss: 0.100862\n",
            "Make prediction for 5010 samples...\n",
            "0.24161601 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 272 [0/25046 (0%)]\tLoss: 0.034507\n",
            "Train epoch: 272 [80120/25046 (10%)]\tLoss: 0.025766\n",
            "Train epoch: 272 [163240/25046 (20%)]\tLoss: 0.021060\n",
            "Train epoch: 272 [247080/25046 (31%)]\tLoss: 0.036968\n",
            "Train epoch: 272 [320720/25046 (41%)]\tLoss: 0.053814\n",
            "Train epoch: 272 [404300/25046 (51%)]\tLoss: 0.048407\n",
            "Train epoch: 272 [502080/25046 (61%)]\tLoss: 0.051018\n",
            "Train epoch: 272 [585900/25046 (71%)]\tLoss: 0.032220\n",
            "Train epoch: 272 [642880/25046 (82%)]\tLoss: 0.050171\n",
            "Train epoch: 272 [737640/25046 (92%)]\tLoss: 0.071689\n",
            "Make prediction for 5010 samples...\n",
            "0.23997404 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 273 [0/25046 (0%)]\tLoss: 0.072624\n",
            "Train epoch: 273 [83640/25046 (10%)]\tLoss: 0.110955\n",
            "Train epoch: 273 [161840/25046 (20%)]\tLoss: 0.036199\n",
            "Train epoch: 273 [249780/25046 (31%)]\tLoss: 0.112499\n",
            "Train epoch: 273 [332560/25046 (41%)]\tLoss: 0.032579\n",
            "Train epoch: 273 [410200/25046 (51%)]\tLoss: 0.042420\n",
            "Train epoch: 273 [484680/25046 (61%)]\tLoss: 0.076853\n",
            "Train epoch: 273 [577500/25046 (71%)]\tLoss: 0.068002\n",
            "Train epoch: 273 [655680/25046 (82%)]\tLoss: 0.040225\n",
            "Train epoch: 273 [752400/25046 (92%)]\tLoss: 0.051089\n",
            "Make prediction for 5010 samples...\n",
            "0.24072614 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 274 [0/25046 (0%)]\tLoss: 0.098771\n",
            "Train epoch: 274 [81860/25046 (10%)]\tLoss: 0.081788\n",
            "Train epoch: 274 [164240/25046 (20%)]\tLoss: 0.139419\n",
            "Train epoch: 274 [243360/25046 (31%)]\tLoss: 0.048763\n",
            "Train epoch: 274 [327280/25046 (41%)]\tLoss: 0.049099\n",
            "Train epoch: 274 [403900/25046 (51%)]\tLoss: 0.043194\n",
            "Train epoch: 274 [478320/25046 (61%)]\tLoss: 0.113388\n",
            "Train epoch: 274 [583380/25046 (71%)]\tLoss: 0.042780\n",
            "Train epoch: 274 [668960/25046 (82%)]\tLoss: 0.047685\n",
            "Train epoch: 274 [753480/25046 (92%)]\tLoss: 0.062175\n",
            "Make prediction for 5010 samples...\n",
            "0.24021296 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 275 [0/25046 (0%)]\tLoss: 0.045044\n",
            "Train epoch: 275 [84140/25046 (10%)]\tLoss: 0.093104\n",
            "Train epoch: 275 [170680/25046 (20%)]\tLoss: 0.060321\n",
            "Train epoch: 275 [244920/25046 (31%)]\tLoss: 0.052865\n",
            "Train epoch: 275 [334560/25046 (41%)]\tLoss: 0.073159\n",
            "Train epoch: 275 [404900/25046 (51%)]\tLoss: 0.052415\n",
            "Train epoch: 275 [489840/25046 (61%)]\tLoss: 0.040357\n",
            "Train epoch: 275 [564900/25046 (71%)]\tLoss: 0.023880\n",
            "Train epoch: 275 [652800/25046 (82%)]\tLoss: 0.082225\n",
            "Train epoch: 275 [736200/25046 (92%)]\tLoss: 0.045513\n",
            "Make prediction for 5010 samples...\n",
            "0.23806258 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 276 [0/25046 (0%)]\tLoss: 0.033964\n",
            "Train epoch: 276 [82440/25046 (10%)]\tLoss: 0.037442\n",
            "Train epoch: 276 [161800/25046 (20%)]\tLoss: 0.036788\n",
            "Train epoch: 276 [250620/25046 (31%)]\tLoss: 0.059477\n",
            "Train epoch: 276 [335120/25046 (41%)]\tLoss: 0.089582\n",
            "Train epoch: 276 [418000/25046 (51%)]\tLoss: 0.027960\n",
            "Train epoch: 276 [492480/25046 (61%)]\tLoss: 0.056130\n",
            "Train epoch: 276 [576520/25046 (71%)]\tLoss: 0.041061\n",
            "Train epoch: 276 [648960/25046 (82%)]\tLoss: 0.041859\n",
            "Train epoch: 276 [734940/25046 (92%)]\tLoss: 0.043803\n",
            "Make prediction for 5010 samples...\n",
            "0.25208074 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 277 [0/25046 (0%)]\tLoss: 0.060287\n",
            "Train epoch: 277 [81660/25046 (10%)]\tLoss: 0.049451\n",
            "Train epoch: 277 [163440/25046 (20%)]\tLoss: 0.034891\n",
            "Train epoch: 277 [246000/25046 (31%)]\tLoss: 0.042361\n",
            "Train epoch: 277 [331760/25046 (41%)]\tLoss: 0.084022\n",
            "Train epoch: 277 [418100/25046 (51%)]\tLoss: 0.025829\n",
            "Train epoch: 277 [501120/25046 (61%)]\tLoss: 0.036225\n",
            "Train epoch: 277 [567140/25046 (71%)]\tLoss: 0.032398\n",
            "Train epoch: 277 [651840/25046 (82%)]\tLoss: 0.064374\n",
            "Train epoch: 277 [744120/25046 (92%)]\tLoss: 0.032859\n",
            "Make prediction for 5010 samples...\n",
            "0.23558277 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 278 [0/25046 (0%)]\tLoss: 0.067587\n",
            "Train epoch: 278 [82940/25046 (10%)]\tLoss: 0.027434\n",
            "Train epoch: 278 [164720/25046 (20%)]\tLoss: 0.045086\n",
            "Train epoch: 278 [250980/25046 (31%)]\tLoss: 0.020251\n",
            "Train epoch: 278 [329200/25046 (41%)]\tLoss: 0.062743\n",
            "Train epoch: 278 [401000/25046 (51%)]\tLoss: 0.041703\n",
            "Train epoch: 278 [495120/25046 (61%)]\tLoss: 0.058236\n",
            "Train epoch: 278 [569800/25046 (71%)]\tLoss: 0.025154\n",
            "Train epoch: 278 [672960/25046 (82%)]\tLoss: 0.043234\n",
            "Train epoch: 278 [756900/25046 (92%)]\tLoss: 0.033582\n",
            "Make prediction for 5010 samples...\n",
            "0.2412501 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 279 [0/25046 (0%)]\tLoss: 0.041326\n",
            "Train epoch: 279 [80860/25046 (10%)]\tLoss: 0.054871\n",
            "Train epoch: 279 [162320/25046 (20%)]\tLoss: 0.079363\n",
            "Train epoch: 279 [241740/25046 (31%)]\tLoss: 0.046058\n",
            "Train epoch: 279 [334480/25046 (41%)]\tLoss: 0.029905\n",
            "Train epoch: 279 [412900/25046 (51%)]\tLoss: 0.058156\n",
            "Train epoch: 279 [494760/25046 (61%)]\tLoss: 0.057657\n",
            "Train epoch: 279 [563360/25046 (71%)]\tLoss: 0.098316\n",
            "Train epoch: 279 [641920/25046 (82%)]\tLoss: 0.024350\n",
            "Train epoch: 279 [748620/25046 (92%)]\tLoss: 0.058926\n",
            "Make prediction for 5010 samples...\n",
            "0.24022602 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 280 [0/25046 (0%)]\tLoss: 0.107982\n",
            "Train epoch: 280 [83660/25046 (10%)]\tLoss: 0.091779\n",
            "Train epoch: 280 [160720/25046 (20%)]\tLoss: 0.040091\n",
            "Train epoch: 280 [239400/25046 (31%)]\tLoss: 0.084454\n",
            "Train epoch: 280 [318960/25046 (41%)]\tLoss: 0.060816\n",
            "Train epoch: 280 [414300/25046 (51%)]\tLoss: 0.035156\n",
            "Train epoch: 280 [493680/25046 (61%)]\tLoss: 0.032335\n",
            "Train epoch: 280 [570080/25046 (71%)]\tLoss: 0.032885\n",
            "Train epoch: 280 [659360/25046 (82%)]\tLoss: 0.035913\n",
            "Train epoch: 280 [730980/25046 (92%)]\tLoss: 0.063293\n",
            "Make prediction for 5010 samples...\n",
            "0.24137658 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 281 [0/25046 (0%)]\tLoss: 0.024931\n",
            "Train epoch: 281 [78720/25046 (10%)]\tLoss: 0.081362\n",
            "Train epoch: 281 [163000/25046 (20%)]\tLoss: 0.054372\n",
            "Train epoch: 281 [249420/25046 (31%)]\tLoss: 0.037953\n",
            "Train epoch: 281 [327680/25046 (41%)]\tLoss: 0.085503\n",
            "Train epoch: 281 [413000/25046 (51%)]\tLoss: 0.057936\n",
            "Train epoch: 281 [492360/25046 (61%)]\tLoss: 0.137465\n",
            "Train epoch: 281 [554120/25046 (71%)]\tLoss: 0.031710\n",
            "Train epoch: 281 [658560/25046 (82%)]\tLoss: 0.033106\n",
            "Train epoch: 281 [741060/25046 (92%)]\tLoss: 0.063841\n",
            "Make prediction for 5010 samples...\n",
            "0.24535324 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 282 [0/25046 (0%)]\tLoss: 0.029956\n",
            "Train epoch: 282 [83600/25046 (10%)]\tLoss: 0.035807\n",
            "Train epoch: 282 [163840/25046 (20%)]\tLoss: 0.057197\n",
            "Train epoch: 282 [242820/25046 (31%)]\tLoss: 0.060141\n",
            "Train epoch: 282 [334320/25046 (41%)]\tLoss: 0.046509\n",
            "Train epoch: 282 [421200/25046 (51%)]\tLoss: 0.049907\n",
            "Train epoch: 282 [490440/25046 (61%)]\tLoss: 0.025561\n",
            "Train epoch: 282 [564900/25046 (71%)]\tLoss: 0.042358\n",
            "Train epoch: 282 [658240/25046 (82%)]\tLoss: 0.081880\n",
            "Train epoch: 282 [727920/25046 (92%)]\tLoss: 0.047805\n",
            "Make prediction for 5010 samples...\n",
            "0.24140805 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 283 [0/25046 (0%)]\tLoss: 0.032540\n",
            "Train epoch: 283 [81500/25046 (10%)]\tLoss: 0.056688\n",
            "Train epoch: 283 [165480/25046 (20%)]\tLoss: 0.027854\n",
            "Train epoch: 283 [243300/25046 (31%)]\tLoss: 0.052979\n",
            "Train epoch: 283 [324160/25046 (41%)]\tLoss: 0.035379\n",
            "Train epoch: 283 [411200/25046 (51%)]\tLoss: 0.110449\n",
            "Train epoch: 283 [507120/25046 (61%)]\tLoss: 0.033968\n",
            "Train epoch: 283 [600880/25046 (71%)]\tLoss: 0.034683\n",
            "Train epoch: 283 [657760/25046 (82%)]\tLoss: 0.053455\n",
            "Train epoch: 283 [722520/25046 (92%)]\tLoss: 0.062120\n",
            "Make prediction for 5010 samples...\n",
            "0.237078 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 284 [0/25046 (0%)]\tLoss: 0.068121\n",
            "Train epoch: 284 [82580/25046 (10%)]\tLoss: 0.041330\n",
            "Train epoch: 284 [163440/25046 (20%)]\tLoss: 0.024497\n",
            "Train epoch: 284 [245880/25046 (31%)]\tLoss: 0.034856\n",
            "Train epoch: 284 [322000/25046 (41%)]\tLoss: 0.039170\n",
            "Train epoch: 284 [414700/25046 (51%)]\tLoss: 0.063536\n",
            "Train epoch: 284 [500760/25046 (61%)]\tLoss: 0.049178\n",
            "Train epoch: 284 [560280/25046 (71%)]\tLoss: 0.038112\n",
            "Train epoch: 284 [645760/25046 (82%)]\tLoss: 0.110873\n",
            "Train epoch: 284 [748440/25046 (92%)]\tLoss: 0.044501\n",
            "Make prediction for 5010 samples...\n",
            "0.2481747 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 285 [0/25046 (0%)]\tLoss: 0.027217\n",
            "Train epoch: 285 [81340/25046 (10%)]\tLoss: 0.041110\n",
            "Train epoch: 285 [162800/25046 (20%)]\tLoss: 0.071845\n",
            "Train epoch: 285 [243180/25046 (31%)]\tLoss: 0.061544\n",
            "Train epoch: 285 [326800/25046 (41%)]\tLoss: 0.025055\n",
            "Train epoch: 285 [408000/25046 (51%)]\tLoss: 0.056080\n",
            "Train epoch: 285 [484080/25046 (61%)]\tLoss: 0.056850\n",
            "Train epoch: 285 [568120/25046 (71%)]\tLoss: 0.042340\n",
            "Train epoch: 285 [643520/25046 (82%)]\tLoss: 0.082320\n",
            "Train epoch: 285 [730800/25046 (92%)]\tLoss: 0.079575\n",
            "Make prediction for 5010 samples...\n",
            "0.24440752 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 286 [0/25046 (0%)]\tLoss: 0.061765\n",
            "Train epoch: 286 [83620/25046 (10%)]\tLoss: 0.064992\n",
            "Train epoch: 286 [162160/25046 (20%)]\tLoss: 0.043239\n",
            "Train epoch: 286 [240720/25046 (31%)]\tLoss: 0.067686\n",
            "Train epoch: 286 [325680/25046 (41%)]\tLoss: 0.063646\n",
            "Train epoch: 286 [409400/25046 (51%)]\tLoss: 0.042186\n",
            "Train epoch: 286 [495480/25046 (61%)]\tLoss: 0.028659\n",
            "Train epoch: 286 [562100/25046 (71%)]\tLoss: 0.030755\n",
            "Train epoch: 286 [649120/25046 (82%)]\tLoss: 0.026307\n",
            "Train epoch: 286 [739980/25046 (92%)]\tLoss: 0.036551\n",
            "Make prediction for 5010 samples...\n",
            "0.24651602 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 287 [0/25046 (0%)]\tLoss: 0.094882\n",
            "Train epoch: 287 [82300/25046 (10%)]\tLoss: 0.082644\n",
            "Train epoch: 287 [171560/25046 (20%)]\tLoss: 0.079296\n",
            "Train epoch: 287 [246840/25046 (31%)]\tLoss: 0.035095\n",
            "Train epoch: 287 [326160/25046 (41%)]\tLoss: 0.055840\n",
            "Train epoch: 287 [406200/25046 (51%)]\tLoss: 0.044856\n",
            "Train epoch: 287 [494880/25046 (61%)]\tLoss: 0.051906\n",
            "Train epoch: 287 [572880/25046 (71%)]\tLoss: 0.078918\n",
            "Train epoch: 287 [667040/25046 (82%)]\tLoss: 0.074895\n",
            "Train epoch: 287 [738900/25046 (92%)]\tLoss: 0.053278\n",
            "Make prediction for 5010 samples...\n",
            "0.24191236 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 288 [0/25046 (0%)]\tLoss: 0.049986\n",
            "Train epoch: 288 [82300/25046 (10%)]\tLoss: 0.058674\n",
            "Train epoch: 288 [159960/25046 (20%)]\tLoss: 0.108984\n",
            "Train epoch: 288 [249120/25046 (31%)]\tLoss: 0.039718\n",
            "Train epoch: 288 [325040/25046 (41%)]\tLoss: 0.054567\n",
            "Train epoch: 288 [402500/25046 (51%)]\tLoss: 0.047432\n",
            "Train epoch: 288 [482520/25046 (61%)]\tLoss: 0.072938\n",
            "Train epoch: 288 [570080/25046 (71%)]\tLoss: 0.040642\n",
            "Train epoch: 288 [668960/25046 (82%)]\tLoss: 0.060456\n",
            "Train epoch: 288 [737640/25046 (92%)]\tLoss: 0.050433\n",
            "Make prediction for 5010 samples...\n",
            "0.24408972 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 289 [0/25046 (0%)]\tLoss: 0.020081\n",
            "Train epoch: 289 [82320/25046 (10%)]\tLoss: 0.043946\n",
            "Train epoch: 289 [165960/25046 (20%)]\tLoss: 0.049464\n",
            "Train epoch: 289 [241800/25046 (31%)]\tLoss: 0.067363\n",
            "Train epoch: 289 [330560/25046 (41%)]\tLoss: 0.045394\n",
            "Train epoch: 289 [408300/25046 (51%)]\tLoss: 0.044937\n",
            "Train epoch: 289 [487920/25046 (61%)]\tLoss: 0.025179\n",
            "Train epoch: 289 [564480/25046 (71%)]\tLoss: 0.049718\n",
            "Train epoch: 289 [657440/25046 (82%)]\tLoss: 0.074085\n",
            "Train epoch: 289 [736020/25046 (92%)]\tLoss: 0.039732\n",
            "Make prediction for 5010 samples...\n",
            "0.24682875 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 290 [0/25046 (0%)]\tLoss: 0.063995\n",
            "Train epoch: 290 [83600/25046 (10%)]\tLoss: 0.033052\n",
            "Train epoch: 290 [169440/25046 (20%)]\tLoss: 0.021762\n",
            "Train epoch: 290 [249360/25046 (31%)]\tLoss: 0.041828\n",
            "Train epoch: 290 [326080/25046 (41%)]\tLoss: 0.083467\n",
            "Train epoch: 290 [402700/25046 (51%)]\tLoss: 0.030426\n",
            "Train epoch: 290 [487680/25046 (61%)]\tLoss: 0.065713\n",
            "Train epoch: 290 [567840/25046 (71%)]\tLoss: 0.071202\n",
            "Train epoch: 290 [656800/25046 (82%)]\tLoss: 0.085552\n",
            "Train epoch: 290 [744660/25046 (92%)]\tLoss: 0.044277\n",
            "Make prediction for 5010 samples...\n",
            "0.24649572 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 291 [0/25046 (0%)]\tLoss: 0.200922\n",
            "Train epoch: 291 [78580/25046 (10%)]\tLoss: 0.064219\n",
            "Train epoch: 291 [162200/25046 (20%)]\tLoss: 0.038415\n",
            "Train epoch: 291 [245580/25046 (31%)]\tLoss: 0.070900\n",
            "Train epoch: 291 [331760/25046 (41%)]\tLoss: 0.027052\n",
            "Train epoch: 291 [406600/25046 (51%)]\tLoss: 0.093446\n",
            "Train epoch: 291 [485880/25046 (61%)]\tLoss: 0.051537\n",
            "Train epoch: 291 [588140/25046 (71%)]\tLoss: 0.087572\n",
            "Train epoch: 291 [649120/25046 (82%)]\tLoss: 0.064504\n",
            "Train epoch: 291 [719640/25046 (92%)]\tLoss: 0.070548\n",
            "Make prediction for 5010 samples...\n",
            "0.23788975 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 292 [0/25046 (0%)]\tLoss: 0.040620\n",
            "Train epoch: 292 [82900/25046 (10%)]\tLoss: 0.044674\n",
            "Train epoch: 292 [166520/25046 (20%)]\tLoss: 0.026874\n",
            "Train epoch: 292 [256140/25046 (31%)]\tLoss: 0.054237\n",
            "Train epoch: 292 [331200/25046 (41%)]\tLoss: 0.087127\n",
            "Train epoch: 292 [400000/25046 (51%)]\tLoss: 0.082120\n",
            "Train epoch: 292 [498840/25046 (61%)]\tLoss: 0.062804\n",
            "Train epoch: 292 [567000/25046 (71%)]\tLoss: 0.030173\n",
            "Train epoch: 292 [649440/25046 (82%)]\tLoss: 0.058134\n",
            "Train epoch: 292 [753300/25046 (92%)]\tLoss: 0.089348\n",
            "Make prediction for 5010 samples...\n",
            "0.23921758 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 293 [0/25046 (0%)]\tLoss: 0.044929\n",
            "Train epoch: 293 [84040/25046 (10%)]\tLoss: 0.024078\n",
            "Train epoch: 293 [165040/25046 (20%)]\tLoss: 0.057548\n",
            "Train epoch: 293 [242460/25046 (31%)]\tLoss: 0.034409\n",
            "Train epoch: 293 [328480/25046 (41%)]\tLoss: 0.044474\n",
            "Train epoch: 293 [413400/25046 (51%)]\tLoss: 0.067005\n",
            "Train epoch: 293 [491400/25046 (61%)]\tLoss: 0.042951\n",
            "Train epoch: 293 [563080/25046 (71%)]\tLoss: 0.054086\n",
            "Train epoch: 293 [651200/25046 (82%)]\tLoss: 0.032063\n",
            "Train epoch: 293 [752940/25046 (92%)]\tLoss: 0.067928\n",
            "Make prediction for 5010 samples...\n",
            "0.23981047 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 294 [0/25046 (0%)]\tLoss: 0.041455\n",
            "Train epoch: 294 [82480/25046 (10%)]\tLoss: 0.064236\n",
            "Train epoch: 294 [169040/25046 (20%)]\tLoss: 0.033340\n",
            "Train epoch: 294 [247560/25046 (31%)]\tLoss: 0.041875\n",
            "Train epoch: 294 [331600/25046 (41%)]\tLoss: 0.196479\n",
            "Train epoch: 294 [401100/25046 (51%)]\tLoss: 0.033062\n",
            "Train epoch: 294 [494400/25046 (61%)]\tLoss: 0.037899\n",
            "Train epoch: 294 [587860/25046 (71%)]\tLoss: 0.046270\n",
            "Train epoch: 294 [666560/25046 (82%)]\tLoss: 0.044764\n",
            "Train epoch: 294 [755640/25046 (92%)]\tLoss: 0.079422\n",
            "Make prediction for 5010 samples...\n",
            "0.2396683 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 295 [0/25046 (0%)]\tLoss: 0.043029\n",
            "Train epoch: 295 [83180/25046 (10%)]\tLoss: 0.036182\n",
            "Train epoch: 295 [161440/25046 (20%)]\tLoss: 0.036989\n",
            "Train epoch: 295 [255720/25046 (31%)]\tLoss: 0.036114\n",
            "Train epoch: 295 [339600/25046 (41%)]\tLoss: 0.038202\n",
            "Train epoch: 295 [420100/25046 (51%)]\tLoss: 0.061809\n",
            "Train epoch: 295 [500040/25046 (61%)]\tLoss: 0.061385\n",
            "Train epoch: 295 [584920/25046 (71%)]\tLoss: 0.039817\n",
            "Train epoch: 295 [653440/25046 (82%)]\tLoss: 0.020940\n",
            "Train epoch: 295 [754020/25046 (92%)]\tLoss: 0.146548\n",
            "Make prediction for 5010 samples...\n",
            "0.23681192 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 296 [0/25046 (0%)]\tLoss: 0.052336\n",
            "Train epoch: 296 [81980/25046 (10%)]\tLoss: 0.077825\n",
            "Train epoch: 296 [163160/25046 (20%)]\tLoss: 0.042667\n",
            "Train epoch: 296 [244740/25046 (31%)]\tLoss: 0.050580\n",
            "Train epoch: 296 [332080/25046 (41%)]\tLoss: 0.065162\n",
            "Train epoch: 296 [409200/25046 (51%)]\tLoss: 0.076428\n",
            "Train epoch: 296 [480240/25046 (61%)]\tLoss: 0.046876\n",
            "Train epoch: 296 [573160/25046 (71%)]\tLoss: 0.062576\n",
            "Train epoch: 296 [642240/25046 (82%)]\tLoss: 0.053152\n",
            "Train epoch: 296 [752940/25046 (92%)]\tLoss: 0.058437\n",
            "Make prediction for 5010 samples...\n",
            "0.23899828 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 297 [0/25046 (0%)]\tLoss: 0.037577\n",
            "Train epoch: 297 [81300/25046 (10%)]\tLoss: 0.019905\n",
            "Train epoch: 297 [165240/25046 (20%)]\tLoss: 0.127561\n",
            "Train epoch: 297 [246240/25046 (31%)]\tLoss: 0.026331\n",
            "Train epoch: 297 [331680/25046 (41%)]\tLoss: 0.039910\n",
            "Train epoch: 297 [413200/25046 (51%)]\tLoss: 0.063018\n",
            "Train epoch: 297 [490320/25046 (61%)]\tLoss: 0.037059\n",
            "Train epoch: 297 [578760/25046 (71%)]\tLoss: 0.046328\n",
            "Train epoch: 297 [653600/25046 (82%)]\tLoss: 0.069324\n",
            "Train epoch: 297 [727380/25046 (92%)]\tLoss: 0.046514\n",
            "Make prediction for 5010 samples...\n",
            "0.23732854 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 298 [0/25046 (0%)]\tLoss: 0.058754\n",
            "Train epoch: 298 [85680/25046 (10%)]\tLoss: 0.062552\n",
            "Train epoch: 298 [160040/25046 (20%)]\tLoss: 0.038780\n",
            "Train epoch: 298 [246720/25046 (31%)]\tLoss: 0.033186\n",
            "Train epoch: 298 [332960/25046 (41%)]\tLoss: 0.078072\n",
            "Train epoch: 298 [418000/25046 (51%)]\tLoss: 0.152832\n",
            "Train epoch: 298 [495960/25046 (61%)]\tLoss: 0.063295\n",
            "Train epoch: 298 [565600/25046 (71%)]\tLoss: 0.057139\n",
            "Train epoch: 298 [687200/25046 (82%)]\tLoss: 0.065285\n",
            "Train epoch: 298 [740160/25046 (92%)]\tLoss: 0.027130\n",
            "Make prediction for 5010 samples...\n",
            "0.24278267 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 299 [0/25046 (0%)]\tLoss: 0.035623\n",
            "Train epoch: 299 [83660/25046 (10%)]\tLoss: 0.035306\n",
            "Train epoch: 299 [166600/25046 (20%)]\tLoss: 0.055078\n",
            "Train epoch: 299 [246060/25046 (31%)]\tLoss: 0.102674\n",
            "Train epoch: 299 [349440/25046 (41%)]\tLoss: 0.048407\n",
            "Train epoch: 299 [414700/25046 (51%)]\tLoss: 0.145152\n",
            "Train epoch: 299 [489000/25046 (61%)]\tLoss: 0.068590\n",
            "Train epoch: 299 [579180/25046 (71%)]\tLoss: 0.035125\n",
            "Train epoch: 299 [645440/25046 (82%)]\tLoss: 0.080352\n",
            "Train epoch: 299 [735840/25046 (92%)]\tLoss: 0.054589\n",
            "Make prediction for 5010 samples...\n",
            "0.24683349 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 300 [0/25046 (0%)]\tLoss: 0.038485\n",
            "Train epoch: 300 [83480/25046 (10%)]\tLoss: 0.066308\n",
            "Train epoch: 300 [161480/25046 (20%)]\tLoss: 0.036226\n",
            "Train epoch: 300 [249900/25046 (31%)]\tLoss: 0.047541\n",
            "Train epoch: 300 [322240/25046 (41%)]\tLoss: 0.041247\n",
            "Train epoch: 300 [415200/25046 (51%)]\tLoss: 0.036334\n",
            "Train epoch: 300 [500160/25046 (61%)]\tLoss: 0.027838\n",
            "Train epoch: 300 [581700/25046 (71%)]\tLoss: 0.108071\n",
            "Train epoch: 300 [663360/25046 (82%)]\tLoss: 0.021724\n",
            "Train epoch: 300 [723780/25046 (92%)]\tLoss: 0.055860\n",
            "Make prediction for 5010 samples...\n",
            "0.24611242 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 301 [0/25046 (0%)]\tLoss: 0.041618\n",
            "Train epoch: 301 [83520/25046 (10%)]\tLoss: 0.049094\n",
            "Train epoch: 301 [162520/25046 (20%)]\tLoss: 0.078553\n",
            "Train epoch: 301 [247260/25046 (31%)]\tLoss: 0.078164\n",
            "Train epoch: 301 [334400/25046 (41%)]\tLoss: 0.073238\n",
            "Train epoch: 301 [409100/25046 (51%)]\tLoss: 0.050376\n",
            "Train epoch: 301 [498360/25046 (61%)]\tLoss: 0.027314\n",
            "Train epoch: 301 [563360/25046 (71%)]\tLoss: 0.048356\n",
            "Train epoch: 301 [655840/25046 (82%)]\tLoss: 0.053313\n",
            "Train epoch: 301 [753120/25046 (92%)]\tLoss: 0.026508\n",
            "Make prediction for 5010 samples...\n",
            "0.24238028 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 302 [0/25046 (0%)]\tLoss: 0.036731\n",
            "Train epoch: 302 [78720/25046 (10%)]\tLoss: 0.064763\n",
            "Train epoch: 302 [164640/25046 (20%)]\tLoss: 0.080116\n",
            "Train epoch: 302 [241740/25046 (31%)]\tLoss: 0.036125\n",
            "Train epoch: 302 [330080/25046 (41%)]\tLoss: 0.034447\n",
            "Train epoch: 302 [408900/25046 (51%)]\tLoss: 0.037978\n",
            "Train epoch: 302 [487320/25046 (61%)]\tLoss: 0.026886\n",
            "Train epoch: 302 [567000/25046 (71%)]\tLoss: 0.065189\n",
            "Train epoch: 302 [665600/25046 (82%)]\tLoss: 0.149824\n",
            "Train epoch: 302 [768960/25046 (92%)]\tLoss: 0.035113\n",
            "Make prediction for 5010 samples...\n",
            "0.23862018 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 303 [0/25046 (0%)]\tLoss: 0.052188\n",
            "Train epoch: 303 [83040/25046 (10%)]\tLoss: 0.067122\n",
            "Train epoch: 303 [162040/25046 (20%)]\tLoss: 0.050038\n",
            "Train epoch: 303 [252360/25046 (31%)]\tLoss: 0.023621\n",
            "Train epoch: 303 [329360/25046 (41%)]\tLoss: 0.028988\n",
            "Train epoch: 303 [400100/25046 (51%)]\tLoss: 0.062887\n",
            "Train epoch: 303 [485400/25046 (61%)]\tLoss: 0.086458\n",
            "Train epoch: 303 [559020/25046 (71%)]\tLoss: 0.050225\n",
            "Train epoch: 303 [656480/25046 (82%)]\tLoss: 0.048955\n",
            "Train epoch: 303 [731520/25046 (92%)]\tLoss: 0.060009\n",
            "Make prediction for 5010 samples...\n",
            "0.24027492 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 304 [0/25046 (0%)]\tLoss: 0.058779\n",
            "Train epoch: 304 [83820/25046 (10%)]\tLoss: 0.018477\n",
            "Train epoch: 304 [165840/25046 (20%)]\tLoss: 0.036717\n",
            "Train epoch: 304 [244260/25046 (31%)]\tLoss: 0.038024\n",
            "Train epoch: 304 [327600/25046 (41%)]\tLoss: 0.027064\n",
            "Train epoch: 304 [397600/25046 (51%)]\tLoss: 0.083485\n",
            "Train epoch: 304 [476040/25046 (61%)]\tLoss: 0.043079\n",
            "Train epoch: 304 [572320/25046 (71%)]\tLoss: 0.041750\n",
            "Train epoch: 304 [665920/25046 (82%)]\tLoss: 0.042039\n",
            "Train epoch: 304 [752580/25046 (92%)]\tLoss: 0.033890\n",
            "Make prediction for 5010 samples...\n",
            "0.23672226 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 305 [0/25046 (0%)]\tLoss: 0.062266\n",
            "Train epoch: 305 [83760/25046 (10%)]\tLoss: 0.036413\n",
            "Train epoch: 305 [165880/25046 (20%)]\tLoss: 0.057842\n",
            "Train epoch: 305 [240360/25046 (31%)]\tLoss: 0.059336\n",
            "Train epoch: 305 [324000/25046 (41%)]\tLoss: 0.037139\n",
            "Train epoch: 305 [400500/25046 (51%)]\tLoss: 0.034998\n",
            "Train epoch: 305 [498120/25046 (61%)]\tLoss: 0.144536\n",
            "Train epoch: 305 [575120/25046 (71%)]\tLoss: 0.078651\n",
            "Train epoch: 305 [633440/25046 (82%)]\tLoss: 0.043344\n",
            "Train epoch: 305 [758520/25046 (92%)]\tLoss: 0.059131\n",
            "Make prediction for 5010 samples...\n",
            "0.23518841 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 306 [0/25046 (0%)]\tLoss: 0.051732\n",
            "Train epoch: 306 [81760/25046 (10%)]\tLoss: 0.036420\n",
            "Train epoch: 306 [163960/25046 (20%)]\tLoss: 0.035959\n",
            "Train epoch: 306 [253440/25046 (31%)]\tLoss: 0.074375\n",
            "Train epoch: 306 [332640/25046 (41%)]\tLoss: 0.029841\n",
            "Train epoch: 306 [417800/25046 (51%)]\tLoss: 0.074186\n",
            "Train epoch: 306 [477720/25046 (61%)]\tLoss: 0.020688\n",
            "Train epoch: 306 [567000/25046 (71%)]\tLoss: 0.033617\n",
            "Train epoch: 306 [660800/25046 (82%)]\tLoss: 0.056489\n",
            "Train epoch: 306 [736560/25046 (92%)]\tLoss: 0.027918\n",
            "Make prediction for 5010 samples...\n",
            "0.24349543 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 307 [0/25046 (0%)]\tLoss: 0.033341\n",
            "Train epoch: 307 [82780/25046 (10%)]\tLoss: 0.031749\n",
            "Train epoch: 307 [165400/25046 (20%)]\tLoss: 0.046424\n",
            "Train epoch: 307 [247620/25046 (31%)]\tLoss: 0.036764\n",
            "Train epoch: 307 [319120/25046 (41%)]\tLoss: 0.045481\n",
            "Train epoch: 307 [408300/25046 (51%)]\tLoss: 0.073668\n",
            "Train epoch: 307 [484680/25046 (61%)]\tLoss: 0.034832\n",
            "Train epoch: 307 [586460/25046 (71%)]\tLoss: 0.065714\n",
            "Train epoch: 307 [640160/25046 (82%)]\tLoss: 0.060458\n",
            "Train epoch: 307 [737820/25046 (92%)]\tLoss: 0.046689\n",
            "Make prediction for 5010 samples...\n",
            "0.23468295 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 308 [0/25046 (0%)]\tLoss: 0.022480\n",
            "Train epoch: 308 [83500/25046 (10%)]\tLoss: 0.025314\n",
            "Train epoch: 308 [163800/25046 (20%)]\tLoss: 0.078259\n",
            "Train epoch: 308 [238860/25046 (31%)]\tLoss: 0.059770\n",
            "Train epoch: 308 [330240/25046 (41%)]\tLoss: 0.036336\n",
            "Train epoch: 308 [403300/25046 (51%)]\tLoss: 0.037909\n",
            "Train epoch: 308 [480000/25046 (61%)]\tLoss: 0.033559\n",
            "Train epoch: 308 [573020/25046 (71%)]\tLoss: 0.028956\n",
            "Train epoch: 308 [645760/25046 (82%)]\tLoss: 0.060366\n",
            "Train epoch: 308 [726840/25046 (92%)]\tLoss: 0.053817\n",
            "Make prediction for 5010 samples...\n",
            "0.23970526 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 309 [0/25046 (0%)]\tLoss: 0.062272\n",
            "Train epoch: 309 [81020/25046 (10%)]\tLoss: 0.033005\n",
            "Train epoch: 309 [164720/25046 (20%)]\tLoss: 0.048341\n",
            "Train epoch: 309 [244140/25046 (31%)]\tLoss: 0.026073\n",
            "Train epoch: 309 [318960/25046 (41%)]\tLoss: 0.042208\n",
            "Train epoch: 309 [414700/25046 (51%)]\tLoss: 0.029029\n",
            "Train epoch: 309 [486360/25046 (61%)]\tLoss: 0.069127\n",
            "Train epoch: 309 [566300/25046 (71%)]\tLoss: 0.031835\n",
            "Train epoch: 309 [664960/25046 (82%)]\tLoss: 0.053907\n",
            "Train epoch: 309 [747360/25046 (92%)]\tLoss: 0.031686\n",
            "Make prediction for 5010 samples...\n",
            "0.2407995 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 310 [0/25046 (0%)]\tLoss: 0.065293\n",
            "Train epoch: 310 [82760/25046 (10%)]\tLoss: 0.054436\n",
            "Train epoch: 310 [168960/25046 (20%)]\tLoss: 0.050730\n",
            "Train epoch: 310 [245040/25046 (31%)]\tLoss: 0.107656\n",
            "Train epoch: 310 [330080/25046 (41%)]\tLoss: 0.027196\n",
            "Train epoch: 310 [417100/25046 (51%)]\tLoss: 0.019597\n",
            "Train epoch: 310 [490680/25046 (61%)]\tLoss: 0.042581\n",
            "Train epoch: 310 [583660/25046 (71%)]\tLoss: 0.027364\n",
            "Train epoch: 310 [647360/25046 (82%)]\tLoss: 0.051800\n",
            "Train epoch: 310 [733680/25046 (92%)]\tLoss: 0.073090\n",
            "Make prediction for 5010 samples...\n",
            "0.23764834 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 311 [0/25046 (0%)]\tLoss: 0.055627\n",
            "Train epoch: 311 [82540/25046 (10%)]\tLoss: 0.018028\n",
            "Train epoch: 311 [164480/25046 (20%)]\tLoss: 0.042949\n",
            "Train epoch: 311 [249360/25046 (31%)]\tLoss: 0.046045\n",
            "Train epoch: 311 [328880/25046 (41%)]\tLoss: 0.096381\n",
            "Train epoch: 311 [416600/25046 (51%)]\tLoss: 0.057817\n",
            "Train epoch: 311 [476760/25046 (61%)]\tLoss: 0.026913\n",
            "Train epoch: 311 [585340/25046 (71%)]\tLoss: 0.036235\n",
            "Train epoch: 311 [666400/25046 (82%)]\tLoss: 0.040470\n",
            "Train epoch: 311 [723420/25046 (92%)]\tLoss: 0.054699\n",
            "Make prediction for 5010 samples...\n",
            "0.24117553 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 312 [0/25046 (0%)]\tLoss: 0.102532\n",
            "Train epoch: 312 [82080/25046 (10%)]\tLoss: 0.043319\n",
            "Train epoch: 312 [164160/25046 (20%)]\tLoss: 0.023355\n",
            "Train epoch: 312 [251640/25046 (31%)]\tLoss: 0.031186\n",
            "Train epoch: 312 [325760/25046 (41%)]\tLoss: 0.080801\n",
            "Train epoch: 312 [417800/25046 (51%)]\tLoss: 0.022891\n",
            "Train epoch: 312 [487320/25046 (61%)]\tLoss: 0.101868\n",
            "Train epoch: 312 [588560/25046 (71%)]\tLoss: 0.060519\n",
            "Train epoch: 312 [646080/25046 (82%)]\tLoss: 0.052592\n",
            "Train epoch: 312 [740520/25046 (92%)]\tLoss: 0.100368\n",
            "Make prediction for 5010 samples...\n",
            "0.2422012 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 313 [0/25046 (0%)]\tLoss: 0.025854\n",
            "Train epoch: 313 [83380/25046 (10%)]\tLoss: 0.028915\n",
            "Train epoch: 313 [164240/25046 (20%)]\tLoss: 0.036597\n",
            "Train epoch: 313 [252240/25046 (31%)]\tLoss: 0.056116\n",
            "Train epoch: 313 [332400/25046 (41%)]\tLoss: 0.060994\n",
            "Train epoch: 313 [412000/25046 (51%)]\tLoss: 0.087421\n",
            "Train epoch: 313 [495960/25046 (61%)]\tLoss: 0.081216\n",
            "Train epoch: 313 [572880/25046 (71%)]\tLoss: 0.050032\n",
            "Train epoch: 313 [655200/25046 (82%)]\tLoss: 0.027073\n",
            "Train epoch: 313 [733140/25046 (92%)]\tLoss: 0.059437\n",
            "Make prediction for 5010 samples...\n",
            "0.24011628 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 314 [0/25046 (0%)]\tLoss: 0.029352\n",
            "Train epoch: 314 [83700/25046 (10%)]\tLoss: 0.065740\n",
            "Train epoch: 314 [164240/25046 (20%)]\tLoss: 0.153880\n",
            "Train epoch: 314 [249240/25046 (31%)]\tLoss: 0.032058\n",
            "Train epoch: 314 [312800/25046 (41%)]\tLoss: 0.035877\n",
            "Train epoch: 314 [406200/25046 (51%)]\tLoss: 0.048333\n",
            "Train epoch: 314 [496680/25046 (61%)]\tLoss: 0.063216\n",
            "Train epoch: 314 [579320/25046 (71%)]\tLoss: 0.075011\n",
            "Train epoch: 314 [650560/25046 (82%)]\tLoss: 0.026860\n",
            "Train epoch: 314 [748260/25046 (92%)]\tLoss: 0.031602\n",
            "Make prediction for 5010 samples...\n",
            "0.24007295 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 315 [0/25046 (0%)]\tLoss: 0.033263\n",
            "Train epoch: 315 [83120/25046 (10%)]\tLoss: 0.047965\n",
            "Train epoch: 315 [164240/25046 (20%)]\tLoss: 0.024481\n",
            "Train epoch: 315 [243900/25046 (31%)]\tLoss: 0.072030\n",
            "Train epoch: 315 [322400/25046 (41%)]\tLoss: 0.025296\n",
            "Train epoch: 315 [407200/25046 (51%)]\tLoss: 0.049953\n",
            "Train epoch: 315 [495600/25046 (61%)]\tLoss: 0.027882\n",
            "Train epoch: 315 [597800/25046 (71%)]\tLoss: 0.049333\n",
            "Train epoch: 315 [646240/25046 (82%)]\tLoss: 0.028486\n",
            "Train epoch: 315 [740160/25046 (92%)]\tLoss: 0.027874\n",
            "Make prediction for 5010 samples...\n",
            "0.23688638 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 316 [0/25046 (0%)]\tLoss: 0.083203\n",
            "Train epoch: 316 [82540/25046 (10%)]\tLoss: 0.037544\n",
            "Train epoch: 316 [162320/25046 (20%)]\tLoss: 0.056497\n",
            "Train epoch: 316 [243780/25046 (31%)]\tLoss: 0.041201\n",
            "Train epoch: 316 [329680/25046 (41%)]\tLoss: 0.059466\n",
            "Train epoch: 316 [409100/25046 (51%)]\tLoss: 0.045239\n",
            "Train epoch: 316 [500040/25046 (61%)]\tLoss: 0.096286\n",
            "Train epoch: 316 [558040/25046 (71%)]\tLoss: 0.047556\n",
            "Train epoch: 316 [664640/25046 (82%)]\tLoss: 0.042644\n",
            "Train epoch: 316 [741420/25046 (92%)]\tLoss: 0.019105\n",
            "Make prediction for 5010 samples...\n",
            "0.245127 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 317 [0/25046 (0%)]\tLoss: 0.026849\n",
            "Train epoch: 317 [80960/25046 (10%)]\tLoss: 0.056434\n",
            "Train epoch: 317 [168040/25046 (20%)]\tLoss: 0.052156\n",
            "Train epoch: 317 [233940/25046 (31%)]\tLoss: 0.040033\n",
            "Train epoch: 317 [341440/25046 (41%)]\tLoss: 0.066996\n",
            "Train epoch: 317 [422600/25046 (51%)]\tLoss: 0.046113\n",
            "Train epoch: 317 [493080/25046 (61%)]\tLoss: 0.049082\n",
            "Train epoch: 317 [573160/25046 (71%)]\tLoss: 0.050090\n",
            "Train epoch: 317 [654560/25046 (82%)]\tLoss: 0.026427\n",
            "Train epoch: 317 [722160/25046 (92%)]\tLoss: 0.035651\n",
            "Make prediction for 5010 samples...\n",
            "0.24418974 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 318 [0/25046 (0%)]\tLoss: 0.042282\n",
            "Train epoch: 318 [82880/25046 (10%)]\tLoss: 0.027687\n",
            "Train epoch: 318 [166120/25046 (20%)]\tLoss: 0.054719\n",
            "Train epoch: 318 [238620/25046 (31%)]\tLoss: 0.075565\n",
            "Train epoch: 318 [321120/25046 (41%)]\tLoss: 0.037702\n",
            "Train epoch: 318 [414300/25046 (51%)]\tLoss: 0.070671\n",
            "Train epoch: 318 [491640/25046 (61%)]\tLoss: 0.039196\n",
            "Train epoch: 318 [569240/25046 (71%)]\tLoss: 0.063221\n",
            "Train epoch: 318 [667520/25046 (82%)]\tLoss: 0.061273\n",
            "Train epoch: 318 [728280/25046 (92%)]\tLoss: 0.036135\n",
            "Make prediction for 5010 samples...\n",
            "0.24120726 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 319 [0/25046 (0%)]\tLoss: 0.029671\n",
            "Train epoch: 319 [81780/25046 (10%)]\tLoss: 0.050932\n",
            "Train epoch: 319 [163440/25046 (20%)]\tLoss: 0.033545\n",
            "Train epoch: 319 [242640/25046 (31%)]\tLoss: 0.052111\n",
            "Train epoch: 319 [323760/25046 (41%)]\tLoss: 0.065288\n",
            "Train epoch: 319 [415500/25046 (51%)]\tLoss: 0.094527\n",
            "Train epoch: 319 [486960/25046 (61%)]\tLoss: 0.033700\n",
            "Train epoch: 319 [563640/25046 (71%)]\tLoss: 0.065276\n",
            "Train epoch: 319 [668000/25046 (82%)]\tLoss: 0.050532\n",
            "Train epoch: 319 [750780/25046 (92%)]\tLoss: 0.042656\n",
            "Make prediction for 5010 samples...\n",
            "0.24534748 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 320 [0/25046 (0%)]\tLoss: 0.040638\n",
            "Train epoch: 320 [85320/25046 (10%)]\tLoss: 0.027792\n",
            "Train epoch: 320 [164400/25046 (20%)]\tLoss: 0.056656\n",
            "Train epoch: 320 [250380/25046 (31%)]\tLoss: 0.023163\n",
            "Train epoch: 320 [319440/25046 (41%)]\tLoss: 0.037894\n",
            "Train epoch: 320 [405000/25046 (51%)]\tLoss: 0.030874\n",
            "Train epoch: 320 [508200/25046 (61%)]\tLoss: 0.119752\n",
            "Train epoch: 320 [566860/25046 (71%)]\tLoss: 0.075926\n",
            "Train epoch: 320 [643840/25046 (82%)]\tLoss: 0.038607\n",
            "Train epoch: 320 [719280/25046 (92%)]\tLoss: 0.071472\n",
            "Make prediction for 5010 samples...\n",
            "0.2509329 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 321 [0/25046 (0%)]\tLoss: 0.031036\n",
            "Train epoch: 321 [80780/25046 (10%)]\tLoss: 0.045202\n",
            "Train epoch: 321 [168280/25046 (20%)]\tLoss: 0.019394\n",
            "Train epoch: 321 [250680/25046 (31%)]\tLoss: 0.046608\n",
            "Train epoch: 321 [330800/25046 (41%)]\tLoss: 0.068302\n",
            "Train epoch: 321 [418500/25046 (51%)]\tLoss: 0.054863\n",
            "Train epoch: 321 [490800/25046 (61%)]\tLoss: 0.070930\n",
            "Train epoch: 321 [558040/25046 (71%)]\tLoss: 0.049152\n",
            "Train epoch: 321 [677600/25046 (82%)]\tLoss: 0.038342\n",
            "Train epoch: 321 [734400/25046 (92%)]\tLoss: 0.036968\n",
            "Make prediction for 5010 samples...\n",
            "0.24685939 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 322 [0/25046 (0%)]\tLoss: 0.045134\n",
            "Train epoch: 322 [81900/25046 (10%)]\tLoss: 0.047630\n",
            "Train epoch: 322 [165880/25046 (20%)]\tLoss: 0.073118\n",
            "Train epoch: 322 [249360/25046 (31%)]\tLoss: 0.032257\n",
            "Train epoch: 322 [333920/25046 (41%)]\tLoss: 0.038463\n",
            "Train epoch: 322 [401000/25046 (51%)]\tLoss: 0.027831\n",
            "Train epoch: 322 [496200/25046 (61%)]\tLoss: 0.074601\n",
            "Train epoch: 322 [582540/25046 (71%)]\tLoss: 0.017367\n",
            "Train epoch: 322 [667680/25046 (82%)]\tLoss: 0.041127\n",
            "Train epoch: 322 [757980/25046 (92%)]\tLoss: 0.062978\n",
            "Make prediction for 5010 samples...\n",
            "0.24133243 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 323 [0/25046 (0%)]\tLoss: 0.031019\n",
            "Train epoch: 323 [83360/25046 (10%)]\tLoss: 0.118154\n",
            "Train epoch: 323 [165720/25046 (20%)]\tLoss: 0.023788\n",
            "Train epoch: 323 [243900/25046 (31%)]\tLoss: 0.075545\n",
            "Train epoch: 323 [321600/25046 (41%)]\tLoss: 0.075198\n",
            "Train epoch: 323 [404000/25046 (51%)]\tLoss: 0.069786\n",
            "Train epoch: 323 [491520/25046 (61%)]\tLoss: 0.040503\n",
            "Train epoch: 323 [578200/25046 (71%)]\tLoss: 0.051274\n",
            "Train epoch: 323 [684160/25046 (82%)]\tLoss: 0.042311\n",
            "Train epoch: 323 [754740/25046 (92%)]\tLoss: 0.030893\n",
            "Make prediction for 5010 samples...\n",
            "0.24433692 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 324 [0/25046 (0%)]\tLoss: 0.028927\n",
            "Train epoch: 324 [79380/25046 (10%)]\tLoss: 0.025126\n",
            "Train epoch: 324 [166520/25046 (20%)]\tLoss: 0.094210\n",
            "Train epoch: 324 [248160/25046 (31%)]\tLoss: 0.032203\n",
            "Train epoch: 324 [328480/25046 (41%)]\tLoss: 0.035522\n",
            "Train epoch: 324 [409400/25046 (51%)]\tLoss: 0.034687\n",
            "Train epoch: 324 [488640/25046 (61%)]\tLoss: 0.028403\n",
            "Train epoch: 324 [597100/25046 (71%)]\tLoss: 0.048021\n",
            "Train epoch: 324 [625120/25046 (82%)]\tLoss: 0.074806\n",
            "Train epoch: 324 [758340/25046 (92%)]\tLoss: 0.069394\n",
            "Make prediction for 5010 samples...\n",
            "0.24252732 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 325 [0/25046 (0%)]\tLoss: 0.042371\n",
            "Train epoch: 325 [82100/25046 (10%)]\tLoss: 0.055362\n",
            "Train epoch: 325 [166000/25046 (20%)]\tLoss: 0.054153\n",
            "Train epoch: 325 [248940/25046 (31%)]\tLoss: 0.075967\n",
            "Train epoch: 325 [329680/25046 (41%)]\tLoss: 0.072284\n",
            "Train epoch: 325 [413500/25046 (51%)]\tLoss: 0.079548\n",
            "Train epoch: 325 [487320/25046 (61%)]\tLoss: 0.046672\n",
            "Train epoch: 325 [574560/25046 (71%)]\tLoss: 0.025642\n",
            "Train epoch: 325 [659040/25046 (82%)]\tLoss: 0.159961\n",
            "Train epoch: 325 [742860/25046 (92%)]\tLoss: 0.030820\n",
            "Make prediction for 5010 samples...\n",
            "0.24512157 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 326 [0/25046 (0%)]\tLoss: 0.023376\n",
            "Train epoch: 326 [81700/25046 (10%)]\tLoss: 0.043419\n",
            "Train epoch: 326 [164120/25046 (20%)]\tLoss: 0.069854\n",
            "Train epoch: 326 [237120/25046 (31%)]\tLoss: 0.111906\n",
            "Train epoch: 326 [334640/25046 (41%)]\tLoss: 0.088701\n",
            "Train epoch: 326 [404200/25046 (51%)]\tLoss: 0.065212\n",
            "Train epoch: 326 [491160/25046 (61%)]\tLoss: 0.038869\n",
            "Train epoch: 326 [583380/25046 (71%)]\tLoss: 0.027605\n",
            "Train epoch: 326 [664160/25046 (82%)]\tLoss: 0.127739\n",
            "Train epoch: 326 [730800/25046 (92%)]\tLoss: 0.045210\n",
            "Make prediction for 5010 samples...\n",
            "0.24157807 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 327 [0/25046 (0%)]\tLoss: 0.048158\n",
            "Train epoch: 327 [80500/25046 (10%)]\tLoss: 0.040005\n",
            "Train epoch: 327 [167920/25046 (20%)]\tLoss: 0.139157\n",
            "Train epoch: 327 [247440/25046 (31%)]\tLoss: 0.024765\n",
            "Train epoch: 327 [328240/25046 (41%)]\tLoss: 0.022428\n",
            "Train epoch: 327 [408400/25046 (51%)]\tLoss: 0.028846\n",
            "Train epoch: 327 [486000/25046 (61%)]\tLoss: 0.052596\n",
            "Train epoch: 327 [580300/25046 (71%)]\tLoss: 0.057229\n",
            "Train epoch: 327 [652320/25046 (82%)]\tLoss: 0.038212\n",
            "Train epoch: 327 [746640/25046 (92%)]\tLoss: 0.045640\n",
            "Make prediction for 5010 samples...\n",
            "0.24339996 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 328 [0/25046 (0%)]\tLoss: 0.051011\n",
            "Train epoch: 328 [85020/25046 (10%)]\tLoss: 0.068328\n",
            "Train epoch: 328 [161400/25046 (20%)]\tLoss: 0.033374\n",
            "Train epoch: 328 [249780/25046 (31%)]\tLoss: 0.036427\n",
            "Train epoch: 328 [327680/25046 (41%)]\tLoss: 0.041734\n",
            "Train epoch: 328 [402200/25046 (51%)]\tLoss: 0.093291\n",
            "Train epoch: 328 [505320/25046 (61%)]\tLoss: 0.045803\n",
            "Train epoch: 328 [582960/25046 (71%)]\tLoss: 0.040979\n",
            "Train epoch: 328 [685600/25046 (82%)]\tLoss: 0.036211\n",
            "Train epoch: 328 [736380/25046 (92%)]\tLoss: 0.071188\n",
            "Make prediction for 5010 samples...\n",
            "0.24149562 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 329 [0/25046 (0%)]\tLoss: 0.034831\n",
            "Train epoch: 329 [82560/25046 (10%)]\tLoss: 0.050391\n",
            "Train epoch: 329 [163880/25046 (20%)]\tLoss: 0.036202\n",
            "Train epoch: 329 [234420/25046 (31%)]\tLoss: 0.047224\n",
            "Train epoch: 329 [328240/25046 (41%)]\tLoss: 0.050857\n",
            "Train epoch: 329 [410800/25046 (51%)]\tLoss: 0.034886\n",
            "Train epoch: 329 [498120/25046 (61%)]\tLoss: 0.044485\n",
            "Train epoch: 329 [568680/25046 (71%)]\tLoss: 0.040031\n",
            "Train epoch: 329 [642240/25046 (82%)]\tLoss: 0.031094\n",
            "Train epoch: 329 [772020/25046 (92%)]\tLoss: 0.053290\n",
            "Make prediction for 5010 samples...\n",
            "0.24271096 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 330 [0/25046 (0%)]\tLoss: 0.021027\n",
            "Train epoch: 330 [83200/25046 (10%)]\tLoss: 0.046748\n",
            "Train epoch: 330 [165280/25046 (20%)]\tLoss: 0.040577\n",
            "Train epoch: 330 [247440/25046 (31%)]\tLoss: 0.061652\n",
            "Train epoch: 330 [317120/25046 (41%)]\tLoss: 0.044730\n",
            "Train epoch: 330 [409500/25046 (51%)]\tLoss: 0.155669\n",
            "Train epoch: 330 [506280/25046 (61%)]\tLoss: 0.068641\n",
            "Train epoch: 330 [566720/25046 (71%)]\tLoss: 0.088509\n",
            "Train epoch: 330 [644640/25046 (82%)]\tLoss: 0.037233\n",
            "Train epoch: 330 [754200/25046 (92%)]\tLoss: 0.055437\n",
            "Make prediction for 5010 samples...\n",
            "0.23979421 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 331 [0/25046 (0%)]\tLoss: 0.021528\n",
            "Train epoch: 331 [79040/25046 (10%)]\tLoss: 0.050473\n",
            "Train epoch: 331 [170280/25046 (20%)]\tLoss: 0.043729\n",
            "Train epoch: 331 [252900/25046 (31%)]\tLoss: 0.109734\n",
            "Train epoch: 331 [333040/25046 (41%)]\tLoss: 0.071842\n",
            "Train epoch: 331 [409100/25046 (51%)]\tLoss: 0.036653\n",
            "Train epoch: 331 [491880/25046 (61%)]\tLoss: 0.035883\n",
            "Train epoch: 331 [576100/25046 (71%)]\tLoss: 0.059154\n",
            "Train epoch: 331 [665280/25046 (82%)]\tLoss: 0.121113\n",
            "Train epoch: 331 [752400/25046 (92%)]\tLoss: 0.128236\n",
            "Make prediction for 5010 samples...\n",
            "0.2419704 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 332 [0/25046 (0%)]\tLoss: 0.027426\n",
            "Train epoch: 332 [80640/25046 (10%)]\tLoss: 0.055082\n",
            "Train epoch: 332 [161480/25046 (20%)]\tLoss: 0.050812\n",
            "Train epoch: 332 [246540/25046 (31%)]\tLoss: 0.036466\n",
            "Train epoch: 332 [338320/25046 (41%)]\tLoss: 0.036732\n",
            "Train epoch: 332 [413500/25046 (51%)]\tLoss: 0.045017\n",
            "Train epoch: 332 [497880/25046 (61%)]\tLoss: 0.047619\n",
            "Train epoch: 332 [571200/25046 (71%)]\tLoss: 0.070272\n",
            "Train epoch: 332 [653440/25046 (82%)]\tLoss: 0.108405\n",
            "Train epoch: 332 [741600/25046 (92%)]\tLoss: 0.086714\n",
            "Make prediction for 5010 samples...\n",
            "0.23870048 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 333 [0/25046 (0%)]\tLoss: 0.072316\n",
            "Train epoch: 333 [85700/25046 (10%)]\tLoss: 0.035127\n",
            "Train epoch: 333 [164240/25046 (20%)]\tLoss: 0.121899\n",
            "Train epoch: 333 [243960/25046 (31%)]\tLoss: 0.165119\n",
            "Train epoch: 333 [330480/25046 (41%)]\tLoss: 0.037344\n",
            "Train epoch: 333 [410900/25046 (51%)]\tLoss: 0.045581\n",
            "Train epoch: 333 [506520/25046 (61%)]\tLoss: 0.020776\n",
            "Train epoch: 333 [567280/25046 (71%)]\tLoss: 0.092205\n",
            "Train epoch: 333 [648320/25046 (82%)]\tLoss: 0.029871\n",
            "Train epoch: 333 [730620/25046 (92%)]\tLoss: 0.024608\n",
            "Make prediction for 5010 samples...\n",
            "0.2488912 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 334 [0/25046 (0%)]\tLoss: 0.034328\n",
            "Train epoch: 334 [81660/25046 (10%)]\tLoss: 0.042686\n",
            "Train epoch: 334 [165080/25046 (20%)]\tLoss: 0.058972\n",
            "Train epoch: 334 [245760/25046 (31%)]\tLoss: 0.037453\n",
            "Train epoch: 334 [330640/25046 (41%)]\tLoss: 0.091750\n",
            "Train epoch: 334 [412700/25046 (51%)]\tLoss: 0.026749\n",
            "Train epoch: 334 [492480/25046 (61%)]\tLoss: 0.028833\n",
            "Train epoch: 334 [585760/25046 (71%)]\tLoss: 0.161116\n",
            "Train epoch: 334 [666240/25046 (82%)]\tLoss: 0.078208\n",
            "Train epoch: 334 [728820/25046 (92%)]\tLoss: 0.071630\n",
            "Make prediction for 5010 samples...\n",
            "0.24918371 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 335 [0/25046 (0%)]\tLoss: 0.041184\n",
            "Train epoch: 335 [82760/25046 (10%)]\tLoss: 0.060276\n",
            "Train epoch: 335 [161840/25046 (20%)]\tLoss: 0.021349\n",
            "Train epoch: 335 [246840/25046 (31%)]\tLoss: 0.043137\n",
            "Train epoch: 335 [317920/25046 (41%)]\tLoss: 0.022192\n",
            "Train epoch: 335 [402300/25046 (51%)]\tLoss: 0.053264\n",
            "Train epoch: 335 [484920/25046 (61%)]\tLoss: 0.047078\n",
            "Train epoch: 335 [570780/25046 (71%)]\tLoss: 0.136012\n",
            "Train epoch: 335 [669600/25046 (82%)]\tLoss: 0.048148\n",
            "Train epoch: 335 [744660/25046 (92%)]\tLoss: 0.105842\n",
            "Make prediction for 5010 samples...\n",
            "0.24507709 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 336 [0/25046 (0%)]\tLoss: 0.063556\n",
            "Train epoch: 336 [79960/25046 (10%)]\tLoss: 0.034114\n",
            "Train epoch: 336 [165280/25046 (20%)]\tLoss: 0.069201\n",
            "Train epoch: 336 [250980/25046 (31%)]\tLoss: 0.040464\n",
            "Train epoch: 336 [320400/25046 (41%)]\tLoss: 0.071971\n",
            "Train epoch: 336 [412100/25046 (51%)]\tLoss: 0.051773\n",
            "Train epoch: 336 [497640/25046 (61%)]\tLoss: 0.045339\n",
            "Train epoch: 336 [562940/25046 (71%)]\tLoss: 0.045872\n",
            "Train epoch: 336 [649440/25046 (82%)]\tLoss: 0.032890\n",
            "Train epoch: 336 [759780/25046 (92%)]\tLoss: 0.042857\n",
            "Make prediction for 5010 samples...\n",
            "0.2555246 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 337 [0/25046 (0%)]\tLoss: 0.090170\n",
            "Train epoch: 337 [83580/25046 (10%)]\tLoss: 0.027206\n",
            "Train epoch: 337 [158520/25046 (20%)]\tLoss: 0.030786\n",
            "Train epoch: 337 [246840/25046 (31%)]\tLoss: 0.073679\n",
            "Train epoch: 337 [336640/25046 (41%)]\tLoss: 0.054809\n",
            "Train epoch: 337 [397900/25046 (51%)]\tLoss: 0.059378\n",
            "Train epoch: 337 [498720/25046 (61%)]\tLoss: 0.063632\n",
            "Train epoch: 337 [579320/25046 (71%)]\tLoss: 0.045868\n",
            "Train epoch: 337 [665920/25046 (82%)]\tLoss: 0.094128\n",
            "Train epoch: 337 [731700/25046 (92%)]\tLoss: 0.038303\n",
            "Make prediction for 5010 samples...\n",
            "0.2481792 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 338 [0/25046 (0%)]\tLoss: 0.031584\n",
            "Train epoch: 338 [81200/25046 (10%)]\tLoss: 0.027103\n",
            "Train epoch: 338 [163400/25046 (20%)]\tLoss: 0.035733\n",
            "Train epoch: 338 [240720/25046 (31%)]\tLoss: 0.039811\n",
            "Train epoch: 338 [320560/25046 (41%)]\tLoss: 0.041877\n",
            "Train epoch: 338 [407600/25046 (51%)]\tLoss: 0.060224\n",
            "Train epoch: 338 [497160/25046 (61%)]\tLoss: 0.060690\n",
            "Train epoch: 338 [574420/25046 (71%)]\tLoss: 0.066194\n",
            "Train epoch: 338 [663520/25046 (82%)]\tLoss: 0.049233\n",
            "Train epoch: 338 [720720/25046 (92%)]\tLoss: 0.114173\n",
            "Make prediction for 5010 samples...\n",
            "0.25310853 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 339 [0/25046 (0%)]\tLoss: 0.076151\n",
            "Train epoch: 339 [82680/25046 (10%)]\tLoss: 0.042774\n",
            "Train epoch: 339 [165280/25046 (20%)]\tLoss: 0.080543\n",
            "Train epoch: 339 [245100/25046 (31%)]\tLoss: 0.079434\n",
            "Train epoch: 339 [331840/25046 (41%)]\tLoss: 0.033063\n",
            "Train epoch: 339 [404700/25046 (51%)]\tLoss: 0.041926\n",
            "Train epoch: 339 [490920/25046 (61%)]\tLoss: 0.053071\n",
            "Train epoch: 339 [565880/25046 (71%)]\tLoss: 0.033176\n",
            "Train epoch: 339 [667840/25046 (82%)]\tLoss: 0.035468\n",
            "Train epoch: 339 [739080/25046 (92%)]\tLoss: 0.068382\n",
            "Make prediction for 5010 samples...\n",
            "0.24695668 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 340 [0/25046 (0%)]\tLoss: 0.055559\n",
            "Train epoch: 340 [82000/25046 (10%)]\tLoss: 0.036690\n",
            "Train epoch: 340 [162960/25046 (20%)]\tLoss: 0.090162\n",
            "Train epoch: 340 [244380/25046 (31%)]\tLoss: 0.035768\n",
            "Train epoch: 340 [326240/25046 (41%)]\tLoss: 0.044580\n",
            "Train epoch: 340 [407400/25046 (51%)]\tLoss: 0.039705\n",
            "Train epoch: 340 [492360/25046 (61%)]\tLoss: 0.026893\n",
            "Train epoch: 340 [580440/25046 (71%)]\tLoss: 0.055632\n",
            "Train epoch: 340 [659040/25046 (82%)]\tLoss: 0.049009\n",
            "Train epoch: 340 [741240/25046 (92%)]\tLoss: 0.064339\n",
            "Make prediction for 5010 samples...\n",
            "0.2458597 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 341 [0/25046 (0%)]\tLoss: 0.064924\n",
            "Train epoch: 341 [80880/25046 (10%)]\tLoss: 0.033003\n",
            "Train epoch: 341 [171320/25046 (20%)]\tLoss: 0.064978\n",
            "Train epoch: 341 [247560/25046 (31%)]\tLoss: 0.037516\n",
            "Train epoch: 341 [332800/25046 (41%)]\tLoss: 0.046447\n",
            "Train epoch: 341 [414400/25046 (51%)]\tLoss: 0.079119\n",
            "Train epoch: 341 [485400/25046 (61%)]\tLoss: 0.048340\n",
            "Train epoch: 341 [569660/25046 (71%)]\tLoss: 0.034428\n",
            "Train epoch: 341 [666240/25046 (82%)]\tLoss: 0.060738\n",
            "Train epoch: 341 [738720/25046 (92%)]\tLoss: 0.036400\n",
            "Make prediction for 5010 samples...\n",
            "0.24690627 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 342 [0/25046 (0%)]\tLoss: 0.053256\n",
            "Train epoch: 342 [82340/25046 (10%)]\tLoss: 0.055394\n",
            "Train epoch: 342 [162840/25046 (20%)]\tLoss: 0.027396\n",
            "Train epoch: 342 [248640/25046 (31%)]\tLoss: 0.055679\n",
            "Train epoch: 342 [324080/25046 (41%)]\tLoss: 0.055964\n",
            "Train epoch: 342 [409000/25046 (51%)]\tLoss: 0.049540\n",
            "Train epoch: 342 [500160/25046 (61%)]\tLoss: 0.097655\n",
            "Train epoch: 342 [571200/25046 (71%)]\tLoss: 0.052569\n",
            "Train epoch: 342 [664160/25046 (82%)]\tLoss: 0.070298\n",
            "Train epoch: 342 [739980/25046 (92%)]\tLoss: 0.030991\n",
            "Make prediction for 5010 samples...\n",
            "0.25218293 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 343 [0/25046 (0%)]\tLoss: 0.103726\n",
            "Train epoch: 343 [82020/25046 (10%)]\tLoss: 0.036370\n",
            "Train epoch: 343 [160680/25046 (20%)]\tLoss: 0.021791\n",
            "Train epoch: 343 [251040/25046 (31%)]\tLoss: 0.028894\n",
            "Train epoch: 343 [333440/25046 (41%)]\tLoss: 0.054168\n",
            "Train epoch: 343 [410700/25046 (51%)]\tLoss: 0.064069\n",
            "Train epoch: 343 [492840/25046 (61%)]\tLoss: 0.047750\n",
            "Train epoch: 343 [574840/25046 (71%)]\tLoss: 0.028907\n",
            "Train epoch: 343 [652160/25046 (82%)]\tLoss: 0.036313\n",
            "Train epoch: 343 [739620/25046 (92%)]\tLoss: 0.041027\n",
            "Make prediction for 5010 samples...\n",
            "0.24738187 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 344 [0/25046 (0%)]\tLoss: 0.030746\n",
            "Train epoch: 344 [83880/25046 (10%)]\tLoss: 0.048089\n",
            "Train epoch: 344 [169320/25046 (20%)]\tLoss: 0.066639\n",
            "Train epoch: 344 [244200/25046 (31%)]\tLoss: 0.076332\n",
            "Train epoch: 344 [328960/25046 (41%)]\tLoss: 0.086709\n",
            "Train epoch: 344 [411600/25046 (51%)]\tLoss: 0.054922\n",
            "Train epoch: 344 [478560/25046 (61%)]\tLoss: 0.028372\n",
            "Train epoch: 344 [579040/25046 (71%)]\tLoss: 0.044858\n",
            "Train epoch: 344 [646240/25046 (82%)]\tLoss: 0.022328\n",
            "Train epoch: 344 [724860/25046 (92%)]\tLoss: 0.026683\n",
            "Make prediction for 5010 samples...\n",
            "0.24922995 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 345 [0/25046 (0%)]\tLoss: 0.041115\n",
            "Train epoch: 345 [82820/25046 (10%)]\tLoss: 0.068737\n",
            "Train epoch: 345 [168520/25046 (20%)]\tLoss: 0.037663\n",
            "Train epoch: 345 [247560/25046 (31%)]\tLoss: 0.051661\n",
            "Train epoch: 345 [336160/25046 (41%)]\tLoss: 0.034811\n",
            "Train epoch: 345 [404600/25046 (51%)]\tLoss: 0.057797\n",
            "Train epoch: 345 [494520/25046 (61%)]\tLoss: 0.028530\n",
            "Train epoch: 345 [573580/25046 (71%)]\tLoss: 0.043469\n",
            "Train epoch: 345 [667680/25046 (82%)]\tLoss: 0.078278\n",
            "Train epoch: 345 [749520/25046 (92%)]\tLoss: 0.042952\n",
            "Make prediction for 5010 samples...\n",
            "0.24306151 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 346 [0/25046 (0%)]\tLoss: 0.023417\n",
            "Train epoch: 346 [80060/25046 (10%)]\tLoss: 0.042358\n",
            "Train epoch: 346 [166120/25046 (20%)]\tLoss: 0.069079\n",
            "Train epoch: 346 [245280/25046 (31%)]\tLoss: 0.034529\n",
            "Train epoch: 346 [326160/25046 (41%)]\tLoss: 0.123002\n",
            "Train epoch: 346 [415600/25046 (51%)]\tLoss: 0.060390\n",
            "Train epoch: 346 [489840/25046 (61%)]\tLoss: 0.051963\n",
            "Train epoch: 346 [563640/25046 (71%)]\tLoss: 0.045458\n",
            "Train epoch: 346 [651040/25046 (82%)]\tLoss: 0.048006\n",
            "Train epoch: 346 [748440/25046 (92%)]\tLoss: 0.053741\n",
            "Make prediction for 5010 samples...\n",
            "0.24206214 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 347 [0/25046 (0%)]\tLoss: 0.033361\n",
            "Train epoch: 347 [82400/25046 (10%)]\tLoss: 0.060900\n",
            "Train epoch: 347 [158120/25046 (20%)]\tLoss: 0.028217\n",
            "Train epoch: 347 [240060/25046 (31%)]\tLoss: 0.099532\n",
            "Train epoch: 347 [330800/25046 (41%)]\tLoss: 0.023002\n",
            "Train epoch: 347 [408900/25046 (51%)]\tLoss: 0.039590\n",
            "Train epoch: 347 [499080/25046 (61%)]\tLoss: 0.072997\n",
            "Train epoch: 347 [573580/25046 (71%)]\tLoss: 0.032459\n",
            "Train epoch: 347 [670080/25046 (82%)]\tLoss: 0.044929\n",
            "Train epoch: 347 [774000/25046 (92%)]\tLoss: 0.040836\n",
            "Make prediction for 5010 samples...\n",
            "0.24928454 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 348 [0/25046 (0%)]\tLoss: 0.039865\n",
            "Train epoch: 348 [82500/25046 (10%)]\tLoss: 0.106120\n",
            "Train epoch: 348 [165080/25046 (20%)]\tLoss: 0.033832\n",
            "Train epoch: 348 [239280/25046 (31%)]\tLoss: 0.044912\n",
            "Train epoch: 348 [318160/25046 (41%)]\tLoss: 0.070675\n",
            "Train epoch: 348 [409200/25046 (51%)]\tLoss: 0.038706\n",
            "Train epoch: 348 [500640/25046 (61%)]\tLoss: 0.025093\n",
            "Train epoch: 348 [586320/25046 (71%)]\tLoss: 0.101877\n",
            "Train epoch: 348 [651520/25046 (82%)]\tLoss: 0.037626\n",
            "Train epoch: 348 [744660/25046 (92%)]\tLoss: 0.068189\n",
            "Make prediction for 5010 samples...\n",
            "0.25667575 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 349 [0/25046 (0%)]\tLoss: 0.025410\n",
            "Train epoch: 349 [79420/25046 (10%)]\tLoss: 0.037702\n",
            "Train epoch: 349 [165320/25046 (20%)]\tLoss: 0.042398\n",
            "Train epoch: 349 [247920/25046 (31%)]\tLoss: 0.049695\n",
            "Train epoch: 349 [321600/25046 (41%)]\tLoss: 0.045554\n",
            "Train epoch: 349 [413900/25046 (51%)]\tLoss: 0.089719\n",
            "Train epoch: 349 [499920/25046 (61%)]\tLoss: 0.035802\n",
            "Train epoch: 349 [580020/25046 (71%)]\tLoss: 0.063871\n",
            "Train epoch: 349 [666400/25046 (82%)]\tLoss: 0.099550\n",
            "Train epoch: 349 [740340/25046 (92%)]\tLoss: 0.041290\n",
            "Make prediction for 5010 samples...\n",
            "0.24941167 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 350 [0/25046 (0%)]\tLoss: 0.105541\n",
            "Train epoch: 350 [83220/25046 (10%)]\tLoss: 0.078955\n",
            "Train epoch: 350 [164480/25046 (20%)]\tLoss: 0.025266\n",
            "Train epoch: 350 [252240/25046 (31%)]\tLoss: 0.037384\n",
            "Train epoch: 350 [318400/25046 (41%)]\tLoss: 0.058530\n",
            "Train epoch: 350 [407500/25046 (51%)]\tLoss: 0.041721\n",
            "Train epoch: 350 [495360/25046 (61%)]\tLoss: 0.056160\n",
            "Train epoch: 350 [584220/25046 (71%)]\tLoss: 0.054535\n",
            "Train epoch: 350 [671840/25046 (82%)]\tLoss: 0.028946\n",
            "Train epoch: 350 [744660/25046 (92%)]\tLoss: 0.068226\n",
            "Make prediction for 5010 samples...\n",
            "0.25122836 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 351 [0/25046 (0%)]\tLoss: 0.047231\n",
            "Train epoch: 351 [82480/25046 (10%)]\tLoss: 0.032673\n",
            "Train epoch: 351 [166080/25046 (20%)]\tLoss: 0.032631\n",
            "Train epoch: 351 [248760/25046 (31%)]\tLoss: 0.052418\n",
            "Train epoch: 351 [321120/25046 (41%)]\tLoss: 0.050281\n",
            "Train epoch: 351 [415800/25046 (51%)]\tLoss: 0.032967\n",
            "Train epoch: 351 [495360/25046 (61%)]\tLoss: 0.063895\n",
            "Train epoch: 351 [583520/25046 (71%)]\tLoss: 0.055438\n",
            "Train epoch: 351 [665280/25046 (82%)]\tLoss: 0.085689\n",
            "Train epoch: 351 [752220/25046 (92%)]\tLoss: 0.073449\n",
            "Make prediction for 5010 samples...\n",
            "0.24937734 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 352 [0/25046 (0%)]\tLoss: 0.030502\n",
            "Train epoch: 352 [82080/25046 (10%)]\tLoss: 0.039838\n",
            "Train epoch: 352 [162960/25046 (20%)]\tLoss: 0.026830\n",
            "Train epoch: 352 [246660/25046 (31%)]\tLoss: 0.036270\n",
            "Train epoch: 352 [318720/25046 (41%)]\tLoss: 0.019154\n",
            "Train epoch: 352 [402100/25046 (51%)]\tLoss: 0.053146\n",
            "Train epoch: 352 [490200/25046 (61%)]\tLoss: 0.043510\n",
            "Train epoch: 352 [581000/25046 (71%)]\tLoss: 0.071397\n",
            "Train epoch: 352 [672640/25046 (82%)]\tLoss: 0.101950\n",
            "Train epoch: 352 [724320/25046 (92%)]\tLoss: 0.051640\n",
            "Make prediction for 5010 samples...\n",
            "0.24972057 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 353 [0/25046 (0%)]\tLoss: 0.033868\n",
            "Train epoch: 353 [81240/25046 (10%)]\tLoss: 0.075979\n",
            "Train epoch: 353 [168200/25046 (20%)]\tLoss: 0.024239\n",
            "Train epoch: 353 [248700/25046 (31%)]\tLoss: 0.047879\n",
            "Train epoch: 353 [324080/25046 (41%)]\tLoss: 0.023769\n",
            "Train epoch: 353 [409100/25046 (51%)]\tLoss: 0.056846\n",
            "Train epoch: 353 [486480/25046 (61%)]\tLoss: 0.029817\n",
            "Train epoch: 353 [580020/25046 (71%)]\tLoss: 0.043659\n",
            "Train epoch: 353 [660960/25046 (82%)]\tLoss: 0.033112\n",
            "Train epoch: 353 [752040/25046 (92%)]\tLoss: 0.046750\n",
            "Make prediction for 5010 samples...\n",
            "0.25582072 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 354 [0/25046 (0%)]\tLoss: 0.026281\n",
            "Train epoch: 354 [83680/25046 (10%)]\tLoss: 0.045049\n",
            "Train epoch: 354 [163240/25046 (20%)]\tLoss: 0.026386\n",
            "Train epoch: 354 [246120/25046 (31%)]\tLoss: 0.050709\n",
            "Train epoch: 354 [325840/25046 (41%)]\tLoss: 0.088257\n",
            "Train epoch: 354 [409400/25046 (51%)]\tLoss: 0.022519\n",
            "Train epoch: 354 [496080/25046 (61%)]\tLoss: 0.035462\n",
            "Train epoch: 354 [587440/25046 (71%)]\tLoss: 0.035663\n",
            "Train epoch: 354 [670080/25046 (82%)]\tLoss: 0.024839\n",
            "Train epoch: 354 [722160/25046 (92%)]\tLoss: 0.020912\n",
            "Make prediction for 5010 samples...\n",
            "0.25185597 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 355 [0/25046 (0%)]\tLoss: 0.046400\n",
            "Train epoch: 355 [84220/25046 (10%)]\tLoss: 0.036311\n",
            "Train epoch: 355 [161920/25046 (20%)]\tLoss: 0.039344\n",
            "Train epoch: 355 [253500/25046 (31%)]\tLoss: 0.134669\n",
            "Train epoch: 355 [336400/25046 (41%)]\tLoss: 0.049972\n",
            "Train epoch: 355 [406200/25046 (51%)]\tLoss: 0.047051\n",
            "Train epoch: 355 [492960/25046 (61%)]\tLoss: 0.038322\n",
            "Train epoch: 355 [571620/25046 (71%)]\tLoss: 0.067595\n",
            "Train epoch: 355 [655680/25046 (82%)]\tLoss: 0.057441\n",
            "Train epoch: 355 [743940/25046 (92%)]\tLoss: 0.072488\n",
            "Make prediction for 5010 samples...\n",
            "0.24704477 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 356 [0/25046 (0%)]\tLoss: 0.061718\n",
            "Train epoch: 356 [81600/25046 (10%)]\tLoss: 0.067805\n",
            "Train epoch: 356 [162600/25046 (20%)]\tLoss: 0.055749\n",
            "Train epoch: 356 [247560/25046 (31%)]\tLoss: 0.024071\n",
            "Train epoch: 356 [327600/25046 (41%)]\tLoss: 0.033526\n",
            "Train epoch: 356 [419900/25046 (51%)]\tLoss: 0.065633\n",
            "Train epoch: 356 [486240/25046 (61%)]\tLoss: 0.040166\n",
            "Train epoch: 356 [568540/25046 (71%)]\tLoss: 0.030578\n",
            "Train epoch: 356 [662400/25046 (82%)]\tLoss: 0.068922\n",
            "Train epoch: 356 [732240/25046 (92%)]\tLoss: 0.055928\n",
            "Make prediction for 5010 samples...\n",
            "0.2520937 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 357 [0/25046 (0%)]\tLoss: 0.039039\n",
            "Train epoch: 357 [82300/25046 (10%)]\tLoss: 0.035642\n",
            "Train epoch: 357 [163360/25046 (20%)]\tLoss: 0.107610\n",
            "Train epoch: 357 [249540/25046 (31%)]\tLoss: 0.080580\n",
            "Train epoch: 357 [335840/25046 (41%)]\tLoss: 0.043010\n",
            "Train epoch: 357 [417700/25046 (51%)]\tLoss: 0.140573\n",
            "Train epoch: 357 [496680/25046 (61%)]\tLoss: 0.055062\n",
            "Train epoch: 357 [567560/25046 (71%)]\tLoss: 0.033419\n",
            "Train epoch: 357 [673600/25046 (82%)]\tLoss: 0.050375\n",
            "Train epoch: 357 [759060/25046 (92%)]\tLoss: 0.073714\n",
            "Make prediction for 5010 samples...\n",
            "0.24851513 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 358 [0/25046 (0%)]\tLoss: 0.086962\n",
            "Train epoch: 358 [80460/25046 (10%)]\tLoss: 0.047549\n",
            "Train epoch: 358 [164840/25046 (20%)]\tLoss: 0.039484\n",
            "Train epoch: 358 [244920/25046 (31%)]\tLoss: 0.104744\n",
            "Train epoch: 358 [328240/25046 (41%)]\tLoss: 0.090063\n",
            "Train epoch: 358 [422000/25046 (51%)]\tLoss: 0.047450\n",
            "Train epoch: 358 [494760/25046 (61%)]\tLoss: 0.026765\n",
            "Train epoch: 358 [569240/25046 (71%)]\tLoss: 0.042966\n",
            "Train epoch: 358 [669120/25046 (82%)]\tLoss: 0.154246\n",
            "Train epoch: 358 [726840/25046 (92%)]\tLoss: 0.043797\n",
            "Make prediction for 5010 samples...\n",
            "0.24921475 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 359 [0/25046 (0%)]\tLoss: 0.055913\n",
            "Train epoch: 359 [83020/25046 (10%)]\tLoss: 0.093803\n",
            "Train epoch: 359 [160520/25046 (20%)]\tLoss: 0.050372\n",
            "Train epoch: 359 [245940/25046 (31%)]\tLoss: 0.034249\n",
            "Train epoch: 359 [343280/25046 (41%)]\tLoss: 0.076822\n",
            "Train epoch: 359 [421700/25046 (51%)]\tLoss: 0.026254\n",
            "Train epoch: 359 [487320/25046 (61%)]\tLoss: 0.047319\n",
            "Train epoch: 359 [584360/25046 (71%)]\tLoss: 0.033010\n",
            "Train epoch: 359 [641920/25046 (82%)]\tLoss: 0.060658\n",
            "Train epoch: 359 [724680/25046 (92%)]\tLoss: 0.028246\n",
            "Make prediction for 5010 samples...\n",
            "0.25318065 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 360 [0/25046 (0%)]\tLoss: 0.082487\n",
            "Train epoch: 360 [83280/25046 (10%)]\tLoss: 0.038642\n",
            "Train epoch: 360 [163080/25046 (20%)]\tLoss: 0.031969\n",
            "Train epoch: 360 [249720/25046 (31%)]\tLoss: 0.040326\n",
            "Train epoch: 360 [325120/25046 (41%)]\tLoss: 0.023292\n",
            "Train epoch: 360 [415800/25046 (51%)]\tLoss: 0.020920\n",
            "Train epoch: 360 [503520/25046 (61%)]\tLoss: 0.039667\n",
            "Train epoch: 360 [576100/25046 (71%)]\tLoss: 0.048377\n",
            "Train epoch: 360 [647360/25046 (82%)]\tLoss: 0.081559\n",
            "Train epoch: 360 [723600/25046 (92%)]\tLoss: 0.133785\n",
            "Make prediction for 5010 samples...\n",
            "0.24820013 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 361 [0/25046 (0%)]\tLoss: 0.045367\n",
            "Train epoch: 361 [80860/25046 (10%)]\tLoss: 0.048185\n",
            "Train epoch: 361 [162800/25046 (20%)]\tLoss: 0.040159\n",
            "Train epoch: 361 [248280/25046 (31%)]\tLoss: 0.026069\n",
            "Train epoch: 361 [322320/25046 (41%)]\tLoss: 0.041137\n",
            "Train epoch: 361 [398600/25046 (51%)]\tLoss: 0.090001\n",
            "Train epoch: 361 [483600/25046 (61%)]\tLoss: 0.041586\n",
            "Train epoch: 361 [573860/25046 (71%)]\tLoss: 0.042563\n",
            "Train epoch: 361 [655040/25046 (82%)]\tLoss: 0.079543\n",
            "Train epoch: 361 [756180/25046 (92%)]\tLoss: 0.025089\n",
            "Make prediction for 5010 samples...\n",
            "0.24720584 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 362 [0/25046 (0%)]\tLoss: 0.101544\n",
            "Train epoch: 362 [83360/25046 (10%)]\tLoss: 0.057394\n",
            "Train epoch: 362 [163840/25046 (20%)]\tLoss: 0.035421\n",
            "Train epoch: 362 [247260/25046 (31%)]\tLoss: 0.030362\n",
            "Train epoch: 362 [328960/25046 (41%)]\tLoss: 0.109770\n",
            "Train epoch: 362 [417000/25046 (51%)]\tLoss: 0.043945\n",
            "Train epoch: 362 [496560/25046 (61%)]\tLoss: 0.069891\n",
            "Train epoch: 362 [581560/25046 (71%)]\tLoss: 0.089563\n",
            "Train epoch: 362 [645920/25046 (82%)]\tLoss: 0.066335\n",
            "Train epoch: 362 [730800/25046 (92%)]\tLoss: 0.037836\n",
            "Make prediction for 5010 samples...\n",
            "0.24701929 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 363 [0/25046 (0%)]\tLoss: 0.058976\n",
            "Train epoch: 363 [83660/25046 (10%)]\tLoss: 0.029803\n",
            "Train epoch: 363 [162080/25046 (20%)]\tLoss: 0.058194\n",
            "Train epoch: 363 [241260/25046 (31%)]\tLoss: 0.086792\n",
            "Train epoch: 363 [334160/25046 (41%)]\tLoss: 0.043143\n",
            "Train epoch: 363 [409800/25046 (51%)]\tLoss: 0.024378\n",
            "Train epoch: 363 [485160/25046 (61%)]\tLoss: 0.098370\n",
            "Train epoch: 363 [582820/25046 (71%)]\tLoss: 0.038009\n",
            "Train epoch: 363 [663360/25046 (82%)]\tLoss: 0.058710\n",
            "Train epoch: 363 [722340/25046 (92%)]\tLoss: 0.030948\n",
            "Make prediction for 5010 samples...\n",
            "0.24619284 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 364 [0/25046 (0%)]\tLoss: 0.045620\n",
            "Train epoch: 364 [86140/25046 (10%)]\tLoss: 0.037481\n",
            "Train epoch: 364 [166360/25046 (20%)]\tLoss: 0.051181\n",
            "Train epoch: 364 [246840/25046 (31%)]\tLoss: 0.030354\n",
            "Train epoch: 364 [328400/25046 (41%)]\tLoss: 0.062172\n",
            "Train epoch: 364 [407600/25046 (51%)]\tLoss: 0.047063\n",
            "Train epoch: 364 [501360/25046 (61%)]\tLoss: 0.034888\n",
            "Train epoch: 364 [575820/25046 (71%)]\tLoss: 0.106250\n",
            "Train epoch: 364 [645920/25046 (82%)]\tLoss: 0.027067\n",
            "Train epoch: 364 [754200/25046 (92%)]\tLoss: 0.040729\n",
            "Make prediction for 5010 samples...\n",
            "0.25073987 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 365 [0/25046 (0%)]\tLoss: 0.048240\n",
            "Train epoch: 365 [84460/25046 (10%)]\tLoss: 0.085810\n",
            "Train epoch: 365 [164760/25046 (20%)]\tLoss: 0.057607\n",
            "Train epoch: 365 [241620/25046 (31%)]\tLoss: 0.053216\n",
            "Train epoch: 365 [337360/25046 (41%)]\tLoss: 0.031865\n",
            "Train epoch: 365 [396100/25046 (51%)]\tLoss: 0.046069\n",
            "Train epoch: 365 [503160/25046 (61%)]\tLoss: 0.056057\n",
            "Train epoch: 365 [586180/25046 (71%)]\tLoss: 0.059032\n",
            "Train epoch: 365 [670400/25046 (82%)]\tLoss: 0.047440\n",
            "Train epoch: 365 [738000/25046 (92%)]\tLoss: 0.086069\n",
            "Make prediction for 5010 samples...\n",
            "0.24717425 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 366 [0/25046 (0%)]\tLoss: 0.071475\n",
            "Train epoch: 366 [81920/25046 (10%)]\tLoss: 0.031469\n",
            "Train epoch: 366 [165080/25046 (20%)]\tLoss: 0.058772\n",
            "Train epoch: 366 [249540/25046 (31%)]\tLoss: 0.044136\n",
            "Train epoch: 366 [325200/25046 (41%)]\tLoss: 0.122857\n",
            "Train epoch: 366 [420100/25046 (51%)]\tLoss: 0.038133\n",
            "Train epoch: 366 [493680/25046 (61%)]\tLoss: 0.050075\n",
            "Train epoch: 366 [562940/25046 (71%)]\tLoss: 0.050475\n",
            "Train epoch: 366 [641440/25046 (82%)]\tLoss: 0.074409\n",
            "Train epoch: 366 [746280/25046 (92%)]\tLoss: 0.041357\n",
            "Make prediction for 5010 samples...\n",
            "0.24485575 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 367 [0/25046 (0%)]\tLoss: 0.017652\n",
            "Train epoch: 367 [81520/25046 (10%)]\tLoss: 0.050419\n",
            "Train epoch: 367 [164720/25046 (20%)]\tLoss: 0.044980\n",
            "Train epoch: 367 [248640/25046 (31%)]\tLoss: 0.048378\n",
            "Train epoch: 367 [328560/25046 (41%)]\tLoss: 0.032907\n",
            "Train epoch: 367 [398800/25046 (51%)]\tLoss: 0.060785\n",
            "Train epoch: 367 [502680/25046 (61%)]\tLoss: 0.031640\n",
            "Train epoch: 367 [589820/25046 (71%)]\tLoss: 0.055564\n",
            "Train epoch: 367 [648640/25046 (82%)]\tLoss: 0.032038\n",
            "Train epoch: 367 [731160/25046 (92%)]\tLoss: 0.037567\n",
            "Make prediction for 5010 samples...\n",
            "0.24326676 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 368 [0/25046 (0%)]\tLoss: 0.069942\n",
            "Train epoch: 368 [81020/25046 (10%)]\tLoss: 0.042245\n",
            "Train epoch: 368 [165480/25046 (20%)]\tLoss: 0.031203\n",
            "Train epoch: 368 [248220/25046 (31%)]\tLoss: 0.048668\n",
            "Train epoch: 368 [321040/25046 (41%)]\tLoss: 0.060201\n",
            "Train epoch: 368 [424000/25046 (51%)]\tLoss: 0.033482\n",
            "Train epoch: 368 [499320/25046 (61%)]\tLoss: 0.038642\n",
            "Train epoch: 368 [576380/25046 (71%)]\tLoss: 0.075989\n",
            "Train epoch: 368 [649600/25046 (82%)]\tLoss: 0.152258\n",
            "Train epoch: 368 [730800/25046 (92%)]\tLoss: 0.076527\n",
            "Make prediction for 5010 samples...\n",
            "0.2442843 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 369 [0/25046 (0%)]\tLoss: 0.038627\n",
            "Train epoch: 369 [82340/25046 (10%)]\tLoss: 0.029314\n",
            "Train epoch: 369 [163200/25046 (20%)]\tLoss: 0.031197\n",
            "Train epoch: 369 [243900/25046 (31%)]\tLoss: 0.026547\n",
            "Train epoch: 369 [336080/25046 (41%)]\tLoss: 0.040024\n",
            "Train epoch: 369 [409300/25046 (51%)]\tLoss: 0.040073\n",
            "Train epoch: 369 [491760/25046 (61%)]\tLoss: 0.137475\n",
            "Train epoch: 369 [569940/25046 (71%)]\tLoss: 0.014943\n",
            "Train epoch: 369 [661920/25046 (82%)]\tLoss: 0.024896\n",
            "Train epoch: 369 [748800/25046 (92%)]\tLoss: 0.049154\n",
            "Make prediction for 5010 samples...\n",
            "0.24555 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 370 [0/25046 (0%)]\tLoss: 0.061174\n",
            "Train epoch: 370 [80380/25046 (10%)]\tLoss: 0.058244\n",
            "Train epoch: 370 [170720/25046 (20%)]\tLoss: 0.060111\n",
            "Train epoch: 370 [250620/25046 (31%)]\tLoss: 0.033775\n",
            "Train epoch: 370 [339520/25046 (41%)]\tLoss: 0.027463\n",
            "Train epoch: 370 [404700/25046 (51%)]\tLoss: 0.051664\n",
            "Train epoch: 370 [476280/25046 (61%)]\tLoss: 0.053965\n",
            "Train epoch: 370 [588420/25046 (71%)]\tLoss: 0.037324\n",
            "Train epoch: 370 [650880/25046 (82%)]\tLoss: 0.034311\n",
            "Train epoch: 370 [737280/25046 (92%)]\tLoss: 0.088255\n",
            "Make prediction for 5010 samples...\n",
            "0.2511669 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 371 [0/25046 (0%)]\tLoss: 0.025815\n",
            "Train epoch: 371 [82560/25046 (10%)]\tLoss: 0.042730\n",
            "Train epoch: 371 [164680/25046 (20%)]\tLoss: 0.027081\n",
            "Train epoch: 371 [247320/25046 (31%)]\tLoss: 0.066867\n",
            "Train epoch: 371 [331520/25046 (41%)]\tLoss: 0.188633\n",
            "Train epoch: 371 [407400/25046 (51%)]\tLoss: 0.062858\n",
            "Train epoch: 371 [473280/25046 (61%)]\tLoss: 0.027457\n",
            "Train epoch: 371 [573160/25046 (71%)]\tLoss: 0.039513\n",
            "Train epoch: 371 [666560/25046 (82%)]\tLoss: 0.032713\n",
            "Train epoch: 371 [757800/25046 (92%)]\tLoss: 0.061471\n",
            "Make prediction for 5010 samples...\n",
            "0.24593592 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 372 [0/25046 (0%)]\tLoss: 0.031580\n",
            "Train epoch: 372 [83240/25046 (10%)]\tLoss: 0.043262\n",
            "Train epoch: 372 [167040/25046 (20%)]\tLoss: 0.043735\n",
            "Train epoch: 372 [247740/25046 (31%)]\tLoss: 0.080213\n",
            "Train epoch: 372 [325840/25046 (41%)]\tLoss: 0.035251\n",
            "Train epoch: 372 [415800/25046 (51%)]\tLoss: 0.030243\n",
            "Train epoch: 372 [498360/25046 (61%)]\tLoss: 0.032324\n",
            "Train epoch: 372 [572460/25046 (71%)]\tLoss: 0.049427\n",
            "Train epoch: 372 [652000/25046 (82%)]\tLoss: 0.042935\n",
            "Train epoch: 372 [748800/25046 (92%)]\tLoss: 0.049171\n",
            "Make prediction for 5010 samples...\n",
            "0.24748905 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 373 [0/25046 (0%)]\tLoss: 0.027472\n",
            "Train epoch: 373 [82580/25046 (10%)]\tLoss: 0.041483\n",
            "Train epoch: 373 [163600/25046 (20%)]\tLoss: 0.024860\n",
            "Train epoch: 373 [239940/25046 (31%)]\tLoss: 0.049641\n",
            "Train epoch: 373 [332480/25046 (41%)]\tLoss: 0.023979\n",
            "Train epoch: 373 [408600/25046 (51%)]\tLoss: 0.049887\n",
            "Train epoch: 373 [497760/25046 (61%)]\tLoss: 0.052420\n",
            "Train epoch: 373 [567560/25046 (71%)]\tLoss: 0.066624\n",
            "Train epoch: 373 [634880/25046 (82%)]\tLoss: 0.135704\n",
            "Train epoch: 373 [721620/25046 (92%)]\tLoss: 0.067562\n",
            "Make prediction for 5010 samples...\n",
            "0.24388464 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 374 [0/25046 (0%)]\tLoss: 0.062880\n",
            "Train epoch: 374 [80260/25046 (10%)]\tLoss: 0.097529\n",
            "Train epoch: 374 [162920/25046 (20%)]\tLoss: 0.072270\n",
            "Train epoch: 374 [250140/25046 (31%)]\tLoss: 0.040938\n",
            "Train epoch: 374 [330320/25046 (41%)]\tLoss: 0.041279\n",
            "Train epoch: 374 [412900/25046 (51%)]\tLoss: 0.081632\n",
            "Train epoch: 374 [479160/25046 (61%)]\tLoss: 0.031473\n",
            "Train epoch: 374 [578480/25046 (71%)]\tLoss: 0.028392\n",
            "Train epoch: 374 [667360/25046 (82%)]\tLoss: 0.122086\n",
            "Train epoch: 374 [753660/25046 (92%)]\tLoss: 0.035504\n",
            "Make prediction for 5010 samples...\n",
            "0.24643253 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 375 [0/25046 (0%)]\tLoss: 0.048989\n",
            "Train epoch: 375 [81600/25046 (10%)]\tLoss: 0.059894\n",
            "Train epoch: 375 [165400/25046 (20%)]\tLoss: 0.024588\n",
            "Train epoch: 375 [246360/25046 (31%)]\tLoss: 0.054387\n",
            "Train epoch: 375 [320960/25046 (41%)]\tLoss: 0.031788\n",
            "Train epoch: 375 [397100/25046 (51%)]\tLoss: 0.053042\n",
            "Train epoch: 375 [491760/25046 (61%)]\tLoss: 0.024585\n",
            "Train epoch: 375 [573720/25046 (71%)]\tLoss: 0.038072\n",
            "Train epoch: 375 [669920/25046 (82%)]\tLoss: 0.041146\n",
            "Train epoch: 375 [751320/25046 (92%)]\tLoss: 0.036979\n",
            "Make prediction for 5010 samples...\n",
            "0.24929777 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 376 [0/25046 (0%)]\tLoss: 0.046755\n",
            "Train epoch: 376 [80900/25046 (10%)]\tLoss: 0.043240\n",
            "Train epoch: 376 [161480/25046 (20%)]\tLoss: 0.035010\n",
            "Train epoch: 376 [250500/25046 (31%)]\tLoss: 0.033850\n",
            "Train epoch: 376 [331360/25046 (41%)]\tLoss: 0.046287\n",
            "Train epoch: 376 [413500/25046 (51%)]\tLoss: 0.037130\n",
            "Train epoch: 376 [495840/25046 (61%)]\tLoss: 0.057332\n",
            "Train epoch: 376 [564760/25046 (71%)]\tLoss: 0.036959\n",
            "Train epoch: 376 [652160/25046 (82%)]\tLoss: 0.053492\n",
            "Train epoch: 376 [745560/25046 (92%)]\tLoss: 0.029658\n",
            "Make prediction for 5010 samples...\n",
            "0.2485965 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 377 [0/25046 (0%)]\tLoss: 0.052500\n",
            "Train epoch: 377 [80400/25046 (10%)]\tLoss: 0.038070\n",
            "Train epoch: 377 [165840/25046 (20%)]\tLoss: 0.045096\n",
            "Train epoch: 377 [249420/25046 (31%)]\tLoss: 0.066074\n",
            "Train epoch: 377 [329200/25046 (41%)]\tLoss: 0.076275\n",
            "Train epoch: 377 [416000/25046 (51%)]\tLoss: 0.050528\n",
            "Train epoch: 377 [490560/25046 (61%)]\tLoss: 0.027843\n",
            "Train epoch: 377 [561960/25046 (71%)]\tLoss: 0.028805\n",
            "Train epoch: 377 [645440/25046 (82%)]\tLoss: 0.055736\n",
            "Train epoch: 377 [748080/25046 (92%)]\tLoss: 0.070216\n",
            "Make prediction for 5010 samples...\n",
            "0.2519964 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 378 [0/25046 (0%)]\tLoss: 0.044404\n",
            "Train epoch: 378 [82200/25046 (10%)]\tLoss: 0.085681\n",
            "Train epoch: 378 [162400/25046 (20%)]\tLoss: 0.023201\n",
            "Train epoch: 378 [244380/25046 (31%)]\tLoss: 0.042321\n",
            "Train epoch: 378 [331120/25046 (41%)]\tLoss: 0.045620\n",
            "Train epoch: 378 [419100/25046 (51%)]\tLoss: 0.025294\n",
            "Train epoch: 378 [509760/25046 (61%)]\tLoss: 0.075301\n",
            "Train epoch: 378 [572320/25046 (71%)]\tLoss: 0.051995\n",
            "Train epoch: 378 [633280/25046 (82%)]\tLoss: 0.019085\n",
            "Train epoch: 378 [731520/25046 (92%)]\tLoss: 0.082551\n",
            "Make prediction for 5010 samples...\n",
            "0.25320703 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 379 [0/25046 (0%)]\tLoss: 0.046488\n",
            "Train epoch: 379 [83540/25046 (10%)]\tLoss: 0.041617\n",
            "Train epoch: 379 [162760/25046 (20%)]\tLoss: 0.043115\n",
            "Train epoch: 379 [248640/25046 (31%)]\tLoss: 0.147029\n",
            "Train epoch: 379 [322400/25046 (41%)]\tLoss: 0.051680\n",
            "Train epoch: 379 [395900/25046 (51%)]\tLoss: 0.074877\n",
            "Train epoch: 379 [496920/25046 (61%)]\tLoss: 0.034203\n",
            "Train epoch: 379 [567140/25046 (71%)]\tLoss: 0.119500\n",
            "Train epoch: 379 [674880/25046 (82%)]\tLoss: 0.070330\n",
            "Train epoch: 379 [746460/25046 (92%)]\tLoss: 0.021411\n",
            "Make prediction for 5010 samples...\n",
            "0.26105958 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 380 [0/25046 (0%)]\tLoss: 0.051398\n",
            "Train epoch: 380 [80780/25046 (10%)]\tLoss: 0.041529\n",
            "Train epoch: 380 [169840/25046 (20%)]\tLoss: 0.025612\n",
            "Train epoch: 380 [249540/25046 (31%)]\tLoss: 0.050233\n",
            "Train epoch: 380 [324800/25046 (41%)]\tLoss: 0.057995\n",
            "Train epoch: 380 [397800/25046 (51%)]\tLoss: 0.044604\n",
            "Train epoch: 380 [489360/25046 (61%)]\tLoss: 0.040935\n",
            "Train epoch: 380 [559160/25046 (71%)]\tLoss: 0.111034\n",
            "Train epoch: 380 [652640/25046 (82%)]\tLoss: 0.035233\n",
            "Train epoch: 380 [745200/25046 (92%)]\tLoss: 0.039562\n",
            "Make prediction for 5010 samples...\n",
            "0.2541055 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 381 [0/25046 (0%)]\tLoss: 0.037134\n",
            "Train epoch: 381 [79940/25046 (10%)]\tLoss: 0.032756\n",
            "Train epoch: 381 [162880/25046 (20%)]\tLoss: 0.036134\n",
            "Train epoch: 381 [250200/25046 (31%)]\tLoss: 0.036165\n",
            "Train epoch: 381 [327600/25046 (41%)]\tLoss: 0.024431\n",
            "Train epoch: 381 [408300/25046 (51%)]\tLoss: 0.021347\n",
            "Train epoch: 381 [492480/25046 (61%)]\tLoss: 0.076762\n",
            "Train epoch: 381 [577360/25046 (71%)]\tLoss: 0.096630\n",
            "Train epoch: 381 [653920/25046 (82%)]\tLoss: 0.033474\n",
            "Train epoch: 381 [749700/25046 (92%)]\tLoss: 0.135207\n",
            "Make prediction for 5010 samples...\n",
            "0.24935754 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 382 [0/25046 (0%)]\tLoss: 0.038312\n",
            "Train epoch: 382 [80900/25046 (10%)]\tLoss: 0.019968\n",
            "Train epoch: 382 [164000/25046 (20%)]\tLoss: 0.057662\n",
            "Train epoch: 382 [237960/25046 (31%)]\tLoss: 0.096229\n",
            "Train epoch: 382 [330480/25046 (41%)]\tLoss: 0.034101\n",
            "Train epoch: 382 [416600/25046 (51%)]\tLoss: 0.022006\n",
            "Train epoch: 382 [503040/25046 (61%)]\tLoss: 0.028321\n",
            "Train epoch: 382 [579320/25046 (71%)]\tLoss: 0.023019\n",
            "Train epoch: 382 [655360/25046 (82%)]\tLoss: 0.040022\n",
            "Train epoch: 382 [756180/25046 (92%)]\tLoss: 0.050477\n",
            "Make prediction for 5010 samples...\n",
            "0.24791303 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 383 [0/25046 (0%)]\tLoss: 0.034722\n",
            "Train epoch: 383 [82280/25046 (10%)]\tLoss: 0.029685\n",
            "Train epoch: 383 [166120/25046 (20%)]\tLoss: 0.089767\n",
            "Train epoch: 383 [247320/25046 (31%)]\tLoss: 0.028428\n",
            "Train epoch: 383 [330000/25046 (41%)]\tLoss: 0.052709\n",
            "Train epoch: 383 [417900/25046 (51%)]\tLoss: 0.058664\n",
            "Train epoch: 383 [490440/25046 (61%)]\tLoss: 0.016278\n",
            "Train epoch: 383 [563500/25046 (71%)]\tLoss: 0.043341\n",
            "Train epoch: 383 [671360/25046 (82%)]\tLoss: 0.033478\n",
            "Train epoch: 383 [738720/25046 (92%)]\tLoss: 0.054047\n",
            "Make prediction for 5010 samples...\n",
            "0.24684697 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 384 [0/25046 (0%)]\tLoss: 0.039803\n",
            "Train epoch: 384 [82020/25046 (10%)]\tLoss: 0.042781\n",
            "Train epoch: 384 [162200/25046 (20%)]\tLoss: 0.043650\n",
            "Train epoch: 384 [238980/25046 (31%)]\tLoss: 0.089248\n",
            "Train epoch: 384 [328880/25046 (41%)]\tLoss: 0.051079\n",
            "Train epoch: 384 [400000/25046 (51%)]\tLoss: 0.063387\n",
            "Train epoch: 384 [498960/25046 (61%)]\tLoss: 0.060719\n",
            "Train epoch: 384 [582400/25046 (71%)]\tLoss: 0.041862\n",
            "Train epoch: 384 [657600/25046 (82%)]\tLoss: 0.053032\n",
            "Train epoch: 384 [752220/25046 (92%)]\tLoss: 0.026882\n",
            "Make prediction for 5010 samples...\n",
            "0.24856523 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 385 [0/25046 (0%)]\tLoss: 0.086503\n",
            "Train epoch: 385 [82340/25046 (10%)]\tLoss: 0.072663\n",
            "Train epoch: 385 [164920/25046 (20%)]\tLoss: 0.032290\n",
            "Train epoch: 385 [248400/25046 (31%)]\tLoss: 0.032500\n",
            "Train epoch: 385 [325280/25046 (41%)]\tLoss: 0.047617\n",
            "Train epoch: 385 [410900/25046 (51%)]\tLoss: 0.049231\n",
            "Train epoch: 385 [501600/25046 (61%)]\tLoss: 0.148436\n",
            "Train epoch: 385 [588700/25046 (71%)]\tLoss: 0.037233\n",
            "Train epoch: 385 [646240/25046 (82%)]\tLoss: 0.066819\n",
            "Train epoch: 385 [741420/25046 (92%)]\tLoss: 0.045532\n",
            "Make prediction for 5010 samples...\n",
            "0.24665411 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 386 [0/25046 (0%)]\tLoss: 0.065038\n",
            "Train epoch: 386 [83300/25046 (10%)]\tLoss: 0.040776\n",
            "Train epoch: 386 [163640/25046 (20%)]\tLoss: 0.143398\n",
            "Train epoch: 386 [249060/25046 (31%)]\tLoss: 0.081904\n",
            "Train epoch: 386 [330160/25046 (41%)]\tLoss: 0.028884\n",
            "Train epoch: 386 [412200/25046 (51%)]\tLoss: 0.074130\n",
            "Train epoch: 386 [500160/25046 (61%)]\tLoss: 0.028918\n",
            "Train epoch: 386 [580860/25046 (71%)]\tLoss: 0.040569\n",
            "Train epoch: 386 [656960/25046 (82%)]\tLoss: 0.028568\n",
            "Train epoch: 386 [728640/25046 (92%)]\tLoss: 0.046574\n",
            "Make prediction for 5010 samples...\n",
            "0.24626006 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 387 [0/25046 (0%)]\tLoss: 0.040490\n",
            "Train epoch: 387 [82820/25046 (10%)]\tLoss: 0.059047\n",
            "Train epoch: 387 [164880/25046 (20%)]\tLoss: 0.040794\n",
            "Train epoch: 387 [247620/25046 (31%)]\tLoss: 0.034126\n",
            "Train epoch: 387 [324000/25046 (41%)]\tLoss: 0.042300\n",
            "Train epoch: 387 [414500/25046 (51%)]\tLoss: 0.072074\n",
            "Train epoch: 387 [483240/25046 (61%)]\tLoss: 0.045676\n",
            "Train epoch: 387 [575960/25046 (71%)]\tLoss: 0.050492\n",
            "Train epoch: 387 [656640/25046 (82%)]\tLoss: 0.056344\n",
            "Train epoch: 387 [752580/25046 (92%)]\tLoss: 0.025644\n",
            "Make prediction for 5010 samples...\n",
            "0.25156283 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 388 [0/25046 (0%)]\tLoss: 0.032087\n",
            "Train epoch: 388 [82760/25046 (10%)]\tLoss: 0.022242\n",
            "Train epoch: 388 [166200/25046 (20%)]\tLoss: 0.023465\n",
            "Train epoch: 388 [241140/25046 (31%)]\tLoss: 0.081038\n",
            "Train epoch: 388 [323280/25046 (41%)]\tLoss: 0.063771\n",
            "Train epoch: 388 [406200/25046 (51%)]\tLoss: 0.023629\n",
            "Train epoch: 388 [481320/25046 (61%)]\tLoss: 0.061095\n",
            "Train epoch: 388 [574140/25046 (71%)]\tLoss: 0.042739\n",
            "Train epoch: 388 [647200/25046 (82%)]\tLoss: 0.102968\n",
            "Train epoch: 388 [727920/25046 (92%)]\tLoss: 0.053884\n",
            "Make prediction for 5010 samples...\n",
            "0.2513955 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 389 [0/25046 (0%)]\tLoss: 0.038649\n",
            "Train epoch: 389 [82320/25046 (10%)]\tLoss: 0.030823\n",
            "Train epoch: 389 [163920/25046 (20%)]\tLoss: 0.035956\n",
            "Train epoch: 389 [255180/25046 (31%)]\tLoss: 0.026112\n",
            "Train epoch: 389 [332800/25046 (41%)]\tLoss: 0.032926\n",
            "Train epoch: 389 [403500/25046 (51%)]\tLoss: 0.059078\n",
            "Train epoch: 389 [493800/25046 (61%)]\tLoss: 0.022813\n",
            "Train epoch: 389 [572320/25046 (71%)]\tLoss: 0.040375\n",
            "Train epoch: 389 [650240/25046 (82%)]\tLoss: 0.102658\n",
            "Train epoch: 389 [732600/25046 (92%)]\tLoss: 0.061282\n",
            "Make prediction for 5010 samples...\n",
            "0.25090963 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 390 [0/25046 (0%)]\tLoss: 0.054492\n",
            "Train epoch: 390 [85760/25046 (10%)]\tLoss: 0.042580\n",
            "Train epoch: 390 [170400/25046 (20%)]\tLoss: 0.027772\n",
            "Train epoch: 390 [247020/25046 (31%)]\tLoss: 0.029218\n",
            "Train epoch: 390 [328960/25046 (41%)]\tLoss: 0.047344\n",
            "Train epoch: 390 [422200/25046 (51%)]\tLoss: 0.041016\n",
            "Train epoch: 390 [499200/25046 (61%)]\tLoss: 0.057650\n",
            "Train epoch: 390 [571620/25046 (71%)]\tLoss: 0.042431\n",
            "Train epoch: 390 [665280/25046 (82%)]\tLoss: 0.081246\n",
            "Train epoch: 390 [749160/25046 (92%)]\tLoss: 0.041009\n",
            "Make prediction for 5010 samples...\n",
            "0.25042745 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 391 [0/25046 (0%)]\tLoss: 0.048287\n",
            "Train epoch: 391 [82300/25046 (10%)]\tLoss: 0.085221\n",
            "Train epoch: 391 [160920/25046 (20%)]\tLoss: 0.056284\n",
            "Train epoch: 391 [245160/25046 (31%)]\tLoss: 0.052132\n",
            "Train epoch: 391 [327840/25046 (41%)]\tLoss: 0.056714\n",
            "Train epoch: 391 [415800/25046 (51%)]\tLoss: 0.029365\n",
            "Train epoch: 391 [507240/25046 (61%)]\tLoss: 0.050982\n",
            "Train epoch: 391 [567840/25046 (71%)]\tLoss: 0.030255\n",
            "Train epoch: 391 [654080/25046 (82%)]\tLoss: 0.026722\n",
            "Train epoch: 391 [728640/25046 (92%)]\tLoss: 0.035751\n",
            "Make prediction for 5010 samples...\n",
            "0.24993187 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 392 [0/25046 (0%)]\tLoss: 0.023842\n",
            "Train epoch: 392 [81480/25046 (10%)]\tLoss: 0.027606\n",
            "Train epoch: 392 [164200/25046 (20%)]\tLoss: 0.049790\n",
            "Train epoch: 392 [248580/25046 (31%)]\tLoss: 0.056320\n",
            "Train epoch: 392 [336720/25046 (41%)]\tLoss: 0.018701\n",
            "Train epoch: 392 [408000/25046 (51%)]\tLoss: 0.046342\n",
            "Train epoch: 392 [489000/25046 (61%)]\tLoss: 0.028286\n",
            "Train epoch: 392 [574420/25046 (71%)]\tLoss: 0.109487\n",
            "Train epoch: 392 [646560/25046 (82%)]\tLoss: 0.205689\n",
            "Train epoch: 392 [768240/25046 (92%)]\tLoss: 0.040219\n",
            "Make prediction for 5010 samples...\n",
            "0.25497252 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 393 [0/25046 (0%)]\tLoss: 0.019945\n",
            "Train epoch: 393 [79780/25046 (10%)]\tLoss: 0.090951\n",
            "Train epoch: 393 [165360/25046 (20%)]\tLoss: 0.082381\n",
            "Train epoch: 393 [245220/25046 (31%)]\tLoss: 0.071805\n",
            "Train epoch: 393 [330480/25046 (41%)]\tLoss: 0.053972\n",
            "Train epoch: 393 [409300/25046 (51%)]\tLoss: 0.031488\n",
            "Train epoch: 393 [497280/25046 (61%)]\tLoss: 0.038707\n",
            "Train epoch: 393 [586040/25046 (71%)]\tLoss: 0.041456\n",
            "Train epoch: 393 [681760/25046 (82%)]\tLoss: 0.070136\n",
            "Train epoch: 393 [733680/25046 (92%)]\tLoss: 0.043048\n",
            "Make prediction for 5010 samples...\n",
            "0.25141627 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 394 [0/25046 (0%)]\tLoss: 0.127143\n",
            "Train epoch: 394 [80520/25046 (10%)]\tLoss: 0.021254\n",
            "Train epoch: 394 [166920/25046 (20%)]\tLoss: 0.043597\n",
            "Train epoch: 394 [239760/25046 (31%)]\tLoss: 0.042360\n",
            "Train epoch: 394 [336480/25046 (41%)]\tLoss: 0.030861\n",
            "Train epoch: 394 [410800/25046 (51%)]\tLoss: 0.028869\n",
            "Train epoch: 394 [497760/25046 (61%)]\tLoss: 0.034698\n",
            "Train epoch: 394 [573720/25046 (71%)]\tLoss: 0.079015\n",
            "Train epoch: 394 [633120/25046 (82%)]\tLoss: 0.037932\n",
            "Train epoch: 394 [728640/25046 (92%)]\tLoss: 0.080856\n",
            "Make prediction for 5010 samples...\n",
            "0.25651285 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 395 [0/25046 (0%)]\tLoss: 0.029461\n",
            "Train epoch: 395 [81100/25046 (10%)]\tLoss: 0.050283\n",
            "Train epoch: 395 [168120/25046 (20%)]\tLoss: 0.062188\n",
            "Train epoch: 395 [245460/25046 (31%)]\tLoss: 0.042825\n",
            "Train epoch: 395 [322560/25046 (41%)]\tLoss: 0.036748\n",
            "Train epoch: 395 [410600/25046 (51%)]\tLoss: 0.035903\n",
            "Train epoch: 395 [500640/25046 (61%)]\tLoss: 0.058338\n",
            "Train epoch: 395 [587440/25046 (71%)]\tLoss: 0.066306\n",
            "Train epoch: 395 [659680/25046 (82%)]\tLoss: 0.026028\n",
            "Train epoch: 395 [723600/25046 (92%)]\tLoss: 0.027167\n",
            "Make prediction for 5010 samples...\n",
            "0.2505837 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 396 [0/25046 (0%)]\tLoss: 0.030566\n",
            "Train epoch: 396 [82920/25046 (10%)]\tLoss: 0.091449\n",
            "Train epoch: 396 [162400/25046 (20%)]\tLoss: 0.067519\n",
            "Train epoch: 396 [250200/25046 (31%)]\tLoss: 0.035907\n",
            "Train epoch: 396 [327920/25046 (41%)]\tLoss: 0.017529\n",
            "Train epoch: 396 [418300/25046 (51%)]\tLoss: 0.054409\n",
            "Train epoch: 396 [494400/25046 (61%)]\tLoss: 0.100201\n",
            "Train epoch: 396 [589680/25046 (71%)]\tLoss: 0.038129\n",
            "Train epoch: 396 [651520/25046 (82%)]\tLoss: 0.034189\n",
            "Train epoch: 396 [773280/25046 (92%)]\tLoss: 0.022094\n",
            "Make prediction for 5010 samples...\n",
            "0.24891947 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 397 [0/25046 (0%)]\tLoss: 0.053281\n",
            "Train epoch: 397 [83740/25046 (10%)]\tLoss: 0.042288\n",
            "Train epoch: 397 [163960/25046 (20%)]\tLoss: 0.049014\n",
            "Train epoch: 397 [249480/25046 (31%)]\tLoss: 0.037400\n",
            "Train epoch: 397 [322640/25046 (41%)]\tLoss: 0.027927\n",
            "Train epoch: 397 [410100/25046 (51%)]\tLoss: 0.021914\n",
            "Train epoch: 397 [496320/25046 (61%)]\tLoss: 0.025904\n",
            "Train epoch: 397 [579320/25046 (71%)]\tLoss: 0.070260\n",
            "Train epoch: 397 [652160/25046 (82%)]\tLoss: 0.017263\n",
            "Train epoch: 397 [735660/25046 (92%)]\tLoss: 0.071635\n",
            "Make prediction for 5010 samples...\n",
            "0.25797307 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 398 [0/25046 (0%)]\tLoss: 0.030458\n",
            "Train epoch: 398 [79860/25046 (10%)]\tLoss: 0.055255\n",
            "Train epoch: 398 [162800/25046 (20%)]\tLoss: 0.064700\n",
            "Train epoch: 398 [248580/25046 (31%)]\tLoss: 0.058473\n",
            "Train epoch: 398 [320080/25046 (41%)]\tLoss: 0.103725\n",
            "Train epoch: 398 [409900/25046 (51%)]\tLoss: 0.059789\n",
            "Train epoch: 398 [495480/25046 (61%)]\tLoss: 0.023246\n",
            "Train epoch: 398 [580300/25046 (71%)]\tLoss: 0.054329\n",
            "Train epoch: 398 [654880/25046 (82%)]\tLoss: 0.027217\n",
            "Train epoch: 398 [733680/25046 (92%)]\tLoss: 0.086485\n",
            "Make prediction for 5010 samples...\n",
            "0.24678466 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 399 [0/25046 (0%)]\tLoss: 0.067948\n",
            "Train epoch: 399 [80500/25046 (10%)]\tLoss: 0.029383\n",
            "Train epoch: 399 [161000/25046 (20%)]\tLoss: 0.094093\n",
            "Train epoch: 399 [249660/25046 (31%)]\tLoss: 0.065701\n",
            "Train epoch: 399 [328240/25046 (41%)]\tLoss: 0.034434\n",
            "Train epoch: 399 [399200/25046 (51%)]\tLoss: 0.037332\n",
            "Train epoch: 399 [490800/25046 (61%)]\tLoss: 0.062847\n",
            "Train epoch: 399 [576240/25046 (71%)]\tLoss: 0.051255\n",
            "Train epoch: 399 [651200/25046 (82%)]\tLoss: 0.039639\n",
            "Train epoch: 399 [743400/25046 (92%)]\tLoss: 0.030561\n",
            "Make prediction for 5010 samples...\n",
            "0.2495596 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 400 [0/25046 (0%)]\tLoss: 0.038666\n",
            "Train epoch: 400 [82220/25046 (10%)]\tLoss: 0.029200\n",
            "Train epoch: 400 [167400/25046 (20%)]\tLoss: 0.030159\n",
            "Train epoch: 400 [245460/25046 (31%)]\tLoss: 0.038927\n",
            "Train epoch: 400 [326160/25046 (41%)]\tLoss: 0.051135\n",
            "Train epoch: 400 [411200/25046 (51%)]\tLoss: 0.019714\n",
            "Train epoch: 400 [487680/25046 (61%)]\tLoss: 0.037585\n",
            "Train epoch: 400 [570920/25046 (71%)]\tLoss: 0.049105\n",
            "Train epoch: 400 [656320/25046 (82%)]\tLoss: 0.065164\n",
            "Train epoch: 400 [749160/25046 (92%)]\tLoss: 0.077868\n",
            "Make prediction for 5010 samples...\n",
            "0.25395226 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 401 [0/25046 (0%)]\tLoss: 0.083879\n",
            "Train epoch: 401 [81300/25046 (10%)]\tLoss: 0.028089\n",
            "Train epoch: 401 [163000/25046 (20%)]\tLoss: 0.050977\n",
            "Train epoch: 401 [243960/25046 (31%)]\tLoss: 0.044746\n",
            "Train epoch: 401 [323360/25046 (41%)]\tLoss: 0.074267\n",
            "Train epoch: 401 [413300/25046 (51%)]\tLoss: 0.035489\n",
            "Train epoch: 401 [490560/25046 (61%)]\tLoss: 0.038100\n",
            "Train epoch: 401 [574980/25046 (71%)]\tLoss: 0.093951\n",
            "Train epoch: 401 [651840/25046 (82%)]\tLoss: 0.045540\n",
            "Train epoch: 401 [722520/25046 (92%)]\tLoss: 0.224053\n",
            "Make prediction for 5010 samples...\n",
            "0.25007948 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 402 [0/25046 (0%)]\tLoss: 0.049684\n",
            "Train epoch: 402 [81620/25046 (10%)]\tLoss: 0.035312\n",
            "Train epoch: 402 [164240/25046 (20%)]\tLoss: 0.034679\n",
            "Train epoch: 402 [247500/25046 (31%)]\tLoss: 0.016974\n",
            "Train epoch: 402 [320560/25046 (41%)]\tLoss: 0.030912\n",
            "Train epoch: 402 [417000/25046 (51%)]\tLoss: 0.033921\n",
            "Train epoch: 402 [486720/25046 (61%)]\tLoss: 0.069762\n",
            "Train epoch: 402 [575820/25046 (71%)]\tLoss: 0.069272\n",
            "Train epoch: 402 [664000/25046 (82%)]\tLoss: 0.041389\n",
            "Train epoch: 402 [753840/25046 (92%)]\tLoss: 0.109484\n",
            "Make prediction for 5010 samples...\n",
            "0.2543604 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 403 [0/25046 (0%)]\tLoss: 0.030262\n",
            "Train epoch: 403 [80940/25046 (10%)]\tLoss: 0.059731\n",
            "Train epoch: 403 [164320/25046 (20%)]\tLoss: 0.072557\n",
            "Train epoch: 403 [241440/25046 (31%)]\tLoss: 0.073490\n",
            "Train epoch: 403 [326160/25046 (41%)]\tLoss: 0.088800\n",
            "Train epoch: 403 [414800/25046 (51%)]\tLoss: 0.038793\n",
            "Train epoch: 403 [497400/25046 (61%)]\tLoss: 0.032466\n",
            "Train epoch: 403 [564480/25046 (71%)]\tLoss: 0.081452\n",
            "Train epoch: 403 [645760/25046 (82%)]\tLoss: 0.051026\n",
            "Train epoch: 403 [746100/25046 (92%)]\tLoss: 0.048321\n",
            "Make prediction for 5010 samples...\n",
            "0.24754874 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 404 [0/25046 (0%)]\tLoss: 0.048890\n",
            "Train epoch: 404 [81020/25046 (10%)]\tLoss: 0.071450\n",
            "Train epoch: 404 [166160/25046 (20%)]\tLoss: 0.028684\n",
            "Train epoch: 404 [240300/25046 (31%)]\tLoss: 0.095392\n",
            "Train epoch: 404 [336480/25046 (41%)]\tLoss: 0.026429\n",
            "Train epoch: 404 [419400/25046 (51%)]\tLoss: 0.072235\n",
            "Train epoch: 404 [474480/25046 (61%)]\tLoss: 0.023566\n",
            "Train epoch: 404 [576660/25046 (71%)]\tLoss: 0.026628\n",
            "Train epoch: 404 [667520/25046 (82%)]\tLoss: 0.161232\n",
            "Train epoch: 404 [733140/25046 (92%)]\tLoss: 0.070650\n",
            "Make prediction for 5010 samples...\n",
            "0.2492023 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 405 [0/25046 (0%)]\tLoss: 0.043002\n",
            "Train epoch: 405 [81900/25046 (10%)]\tLoss: 0.046992\n",
            "Train epoch: 405 [160280/25046 (20%)]\tLoss: 0.032996\n",
            "Train epoch: 405 [249660/25046 (31%)]\tLoss: 0.103446\n",
            "Train epoch: 405 [320160/25046 (41%)]\tLoss: 0.062554\n",
            "Train epoch: 405 [408800/25046 (51%)]\tLoss: 0.048697\n",
            "Train epoch: 405 [478080/25046 (61%)]\tLoss: 0.090623\n",
            "Train epoch: 405 [581840/25046 (71%)]\tLoss: 0.028514\n",
            "Train epoch: 405 [662720/25046 (82%)]\tLoss: 0.090613\n",
            "Train epoch: 405 [747720/25046 (92%)]\tLoss: 0.029671\n",
            "Make prediction for 5010 samples...\n",
            "0.25175947 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 406 [0/25046 (0%)]\tLoss: 0.022673\n",
            "Train epoch: 406 [82720/25046 (10%)]\tLoss: 0.029474\n",
            "Train epoch: 406 [161760/25046 (20%)]\tLoss: 0.060488\n",
            "Train epoch: 406 [242940/25046 (31%)]\tLoss: 0.058357\n",
            "Train epoch: 406 [330160/25046 (41%)]\tLoss: 0.030529\n",
            "Train epoch: 406 [414700/25046 (51%)]\tLoss: 0.047465\n",
            "Train epoch: 406 [492360/25046 (61%)]\tLoss: 0.030297\n",
            "Train epoch: 406 [580860/25046 (71%)]\tLoss: 0.054058\n",
            "Train epoch: 406 [653120/25046 (82%)]\tLoss: 0.024921\n",
            "Train epoch: 406 [752220/25046 (92%)]\tLoss: 0.028152\n",
            "Make prediction for 5010 samples...\n",
            "0.25378567 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 407 [0/25046 (0%)]\tLoss: 0.028650\n",
            "Train epoch: 407 [83660/25046 (10%)]\tLoss: 0.037226\n",
            "Train epoch: 407 [161840/25046 (20%)]\tLoss: 0.018687\n",
            "Train epoch: 407 [250260/25046 (31%)]\tLoss: 0.028071\n",
            "Train epoch: 407 [330560/25046 (41%)]\tLoss: 0.043982\n",
            "Train epoch: 407 [399800/25046 (51%)]\tLoss: 0.148399\n",
            "Train epoch: 407 [493200/25046 (61%)]\tLoss: 0.040127\n",
            "Train epoch: 407 [603820/25046 (71%)]\tLoss: 0.074396\n",
            "Train epoch: 407 [660480/25046 (82%)]\tLoss: 0.029204\n",
            "Train epoch: 407 [720180/25046 (92%)]\tLoss: 0.030768\n",
            "Make prediction for 5010 samples...\n",
            "0.25190035 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 408 [0/25046 (0%)]\tLoss: 0.054896\n",
            "Train epoch: 408 [80360/25046 (10%)]\tLoss: 0.056813\n",
            "Train epoch: 408 [163400/25046 (20%)]\tLoss: 0.054456\n",
            "Train epoch: 408 [240300/25046 (31%)]\tLoss: 0.089259\n",
            "Train epoch: 408 [331520/25046 (41%)]\tLoss: 0.033505\n",
            "Train epoch: 408 [416200/25046 (51%)]\tLoss: 0.045308\n",
            "Train epoch: 408 [495720/25046 (61%)]\tLoss: 0.050506\n",
            "Train epoch: 408 [587020/25046 (71%)]\tLoss: 0.136280\n",
            "Train epoch: 408 [654400/25046 (82%)]\tLoss: 0.095150\n",
            "Train epoch: 408 [729360/25046 (92%)]\tLoss: 0.058373\n",
            "Make prediction for 5010 samples...\n",
            "0.2627141 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 409 [0/25046 (0%)]\tLoss: 0.051758\n",
            "Train epoch: 409 [81920/25046 (10%)]\tLoss: 0.031318\n",
            "Train epoch: 409 [162440/25046 (20%)]\tLoss: 0.075227\n",
            "Train epoch: 409 [257040/25046 (31%)]\tLoss: 0.022757\n",
            "Train epoch: 409 [324640/25046 (41%)]\tLoss: 0.040092\n",
            "Train epoch: 409 [404700/25046 (51%)]\tLoss: 0.061950\n",
            "Train epoch: 409 [496440/25046 (61%)]\tLoss: 0.049035\n",
            "Train epoch: 409 [577080/25046 (71%)]\tLoss: 0.019385\n",
            "Train epoch: 409 [649920/25046 (82%)]\tLoss: 0.023089\n",
            "Train epoch: 409 [734760/25046 (92%)]\tLoss: 0.108966\n",
            "Make prediction for 5010 samples...\n",
            "0.2472777 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 410 [0/25046 (0%)]\tLoss: 0.031260\n",
            "Train epoch: 410 [82520/25046 (10%)]\tLoss: 0.026328\n",
            "Train epoch: 410 [164640/25046 (20%)]\tLoss: 0.032196\n",
            "Train epoch: 410 [249720/25046 (31%)]\tLoss: 0.082110\n",
            "Train epoch: 410 [335840/25046 (41%)]\tLoss: 0.032001\n",
            "Train epoch: 410 [414600/25046 (51%)]\tLoss: 0.032079\n",
            "Train epoch: 410 [495480/25046 (61%)]\tLoss: 0.102138\n",
            "Train epoch: 410 [566720/25046 (71%)]\tLoss: 0.083503\n",
            "Train epoch: 410 [655680/25046 (82%)]\tLoss: 0.057341\n",
            "Train epoch: 410 [736380/25046 (92%)]\tLoss: 0.090962\n",
            "Make prediction for 5010 samples...\n",
            "0.24426292 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 411 [0/25046 (0%)]\tLoss: 0.069276\n",
            "Train epoch: 411 [82560/25046 (10%)]\tLoss: 0.084136\n",
            "Train epoch: 411 [164520/25046 (20%)]\tLoss: 0.035357\n",
            "Train epoch: 411 [247680/25046 (31%)]\tLoss: 0.050769\n",
            "Train epoch: 411 [314240/25046 (41%)]\tLoss: 0.019790\n",
            "Train epoch: 411 [407000/25046 (51%)]\tLoss: 0.069402\n",
            "Train epoch: 411 [480240/25046 (61%)]\tLoss: 0.047604\n",
            "Train epoch: 411 [555240/25046 (71%)]\tLoss: 0.019686\n",
            "Train epoch: 411 [660160/25046 (82%)]\tLoss: 0.053802\n",
            "Train epoch: 411 [739080/25046 (92%)]\tLoss: 0.030306\n",
            "Make prediction for 5010 samples...\n",
            "0.2494951 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 412 [0/25046 (0%)]\tLoss: 0.058111\n",
            "Train epoch: 412 [81760/25046 (10%)]\tLoss: 0.076284\n",
            "Train epoch: 412 [159760/25046 (20%)]\tLoss: 0.025893\n",
            "Train epoch: 412 [238980/25046 (31%)]\tLoss: 0.048774\n",
            "Train epoch: 412 [328720/25046 (41%)]\tLoss: 0.104959\n",
            "Train epoch: 412 [408800/25046 (51%)]\tLoss: 0.053370\n",
            "Train epoch: 412 [508440/25046 (61%)]\tLoss: 0.083040\n",
            "Train epoch: 412 [574280/25046 (71%)]\tLoss: 0.071345\n",
            "Train epoch: 412 [667680/25046 (82%)]\tLoss: 0.062726\n",
            "Train epoch: 412 [741780/25046 (92%)]\tLoss: 0.077594\n",
            "Make prediction for 5010 samples...\n",
            "0.27003866 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 413 [0/25046 (0%)]\tLoss: 0.028901\n",
            "Train epoch: 413 [82140/25046 (10%)]\tLoss: 0.077317\n",
            "Train epoch: 413 [168680/25046 (20%)]\tLoss: 0.017160\n",
            "Train epoch: 413 [249780/25046 (31%)]\tLoss: 0.031792\n",
            "Train epoch: 413 [330320/25046 (41%)]\tLoss: 0.055035\n",
            "Train epoch: 413 [411700/25046 (51%)]\tLoss: 0.044921\n",
            "Train epoch: 413 [488640/25046 (61%)]\tLoss: 0.023610\n",
            "Train epoch: 413 [567840/25046 (71%)]\tLoss: 0.058131\n",
            "Train epoch: 413 [671840/25046 (82%)]\tLoss: 0.079393\n",
            "Train epoch: 413 [712080/25046 (92%)]\tLoss: 0.067039\n",
            "Make prediction for 5010 samples...\n",
            "0.24852951 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 414 [0/25046 (0%)]\tLoss: 0.039820\n",
            "Train epoch: 414 [82220/25046 (10%)]\tLoss: 0.022902\n",
            "Train epoch: 414 [169000/25046 (20%)]\tLoss: 0.083450\n",
            "Train epoch: 414 [242100/25046 (31%)]\tLoss: 0.020418\n",
            "Train epoch: 414 [335280/25046 (41%)]\tLoss: 0.047622\n",
            "Train epoch: 414 [408600/25046 (51%)]\tLoss: 0.035084\n",
            "Train epoch: 414 [494040/25046 (61%)]\tLoss: 0.050080\n",
            "Train epoch: 414 [578900/25046 (71%)]\tLoss: 0.041576\n",
            "Train epoch: 414 [658720/25046 (82%)]\tLoss: 0.038007\n",
            "Train epoch: 414 [737640/25046 (92%)]\tLoss: 0.070294\n",
            "Make prediction for 5010 samples...\n",
            "0.25157842 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 415 [0/25046 (0%)]\tLoss: 0.050884\n",
            "Train epoch: 415 [84120/25046 (10%)]\tLoss: 0.070941\n",
            "Train epoch: 415 [166280/25046 (20%)]\tLoss: 0.038765\n",
            "Train epoch: 415 [235440/25046 (31%)]\tLoss: 0.038249\n",
            "Train epoch: 415 [336160/25046 (41%)]\tLoss: 0.065983\n",
            "Train epoch: 415 [403400/25046 (51%)]\tLoss: 0.023223\n",
            "Train epoch: 415 [504360/25046 (61%)]\tLoss: 0.060173\n",
            "Train epoch: 415 [575260/25046 (71%)]\tLoss: 0.029567\n",
            "Train epoch: 415 [653440/25046 (82%)]\tLoss: 0.070095\n",
            "Train epoch: 415 [752940/25046 (92%)]\tLoss: 0.058203\n",
            "Make prediction for 5010 samples...\n",
            "0.26401207 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 416 [0/25046 (0%)]\tLoss: 0.029574\n",
            "Train epoch: 416 [81900/25046 (10%)]\tLoss: 0.041253\n",
            "Train epoch: 416 [162200/25046 (20%)]\tLoss: 0.043352\n",
            "Train epoch: 416 [251640/25046 (31%)]\tLoss: 0.060411\n",
            "Train epoch: 416 [346480/25046 (41%)]\tLoss: 0.043619\n",
            "Train epoch: 416 [418700/25046 (51%)]\tLoss: 0.023312\n",
            "Train epoch: 416 [468960/25046 (61%)]\tLoss: 0.058707\n",
            "Train epoch: 416 [581420/25046 (71%)]\tLoss: 0.036280\n",
            "Train epoch: 416 [654560/25046 (82%)]\tLoss: 0.066459\n",
            "Train epoch: 416 [708480/25046 (92%)]\tLoss: 0.051243\n",
            "Make prediction for 5010 samples...\n",
            "0.2561907 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 417 [0/25046 (0%)]\tLoss: 0.086573\n",
            "Train epoch: 417 [82640/25046 (10%)]\tLoss: 0.043799\n",
            "Train epoch: 417 [162400/25046 (20%)]\tLoss: 0.032722\n",
            "Train epoch: 417 [243540/25046 (31%)]\tLoss: 0.081995\n",
            "Train epoch: 417 [321680/25046 (41%)]\tLoss: 0.049641\n",
            "Train epoch: 417 [416300/25046 (51%)]\tLoss: 0.036633\n",
            "Train epoch: 417 [491520/25046 (61%)]\tLoss: 0.044254\n",
            "Train epoch: 417 [563080/25046 (71%)]\tLoss: 0.075398\n",
            "Train epoch: 417 [647040/25046 (82%)]\tLoss: 0.052595\n",
            "Train epoch: 417 [736020/25046 (92%)]\tLoss: 0.026301\n",
            "Make prediction for 5010 samples...\n",
            "0.252121 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 418 [0/25046 (0%)]\tLoss: 0.041306\n",
            "Train epoch: 418 [81380/25046 (10%)]\tLoss: 0.038616\n",
            "Train epoch: 418 [166760/25046 (20%)]\tLoss: 0.028381\n",
            "Train epoch: 418 [245040/25046 (31%)]\tLoss: 0.027238\n",
            "Train epoch: 418 [332800/25046 (41%)]\tLoss: 0.042130\n",
            "Train epoch: 418 [408400/25046 (51%)]\tLoss: 0.065724\n",
            "Train epoch: 418 [489360/25046 (61%)]\tLoss: 0.067333\n",
            "Train epoch: 418 [564200/25046 (71%)]\tLoss: 0.029919\n",
            "Train epoch: 418 [642080/25046 (82%)]\tLoss: 0.060164\n",
            "Train epoch: 418 [733680/25046 (92%)]\tLoss: 0.027121\n",
            "Make prediction for 5010 samples...\n",
            "0.25145623 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 419 [0/25046 (0%)]\tLoss: 0.108403\n",
            "Train epoch: 419 [81700/25046 (10%)]\tLoss: 0.089173\n",
            "Train epoch: 419 [166280/25046 (20%)]\tLoss: 0.025773\n",
            "Train epoch: 419 [247260/25046 (31%)]\tLoss: 0.030877\n",
            "Train epoch: 419 [334560/25046 (41%)]\tLoss: 0.047941\n",
            "Train epoch: 419 [413500/25046 (51%)]\tLoss: 0.024082\n",
            "Train epoch: 419 [488520/25046 (61%)]\tLoss: 0.019215\n",
            "Train epoch: 419 [556920/25046 (71%)]\tLoss: 0.012420\n",
            "Train epoch: 419 [671040/25046 (82%)]\tLoss: 0.109613\n",
            "Train epoch: 419 [740700/25046 (92%)]\tLoss: 0.076526\n",
            "Make prediction for 5010 samples...\n",
            "0.25519848 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 420 [0/25046 (0%)]\tLoss: 0.028430\n",
            "Train epoch: 420 [81600/25046 (10%)]\tLoss: 0.024608\n",
            "Train epoch: 420 [167360/25046 (20%)]\tLoss: 0.035240\n",
            "Train epoch: 420 [245400/25046 (31%)]\tLoss: 0.030317\n",
            "Train epoch: 420 [333040/25046 (41%)]\tLoss: 0.036858\n",
            "Train epoch: 420 [398400/25046 (51%)]\tLoss: 0.091249\n",
            "Train epoch: 420 [495240/25046 (61%)]\tLoss: 0.055260\n",
            "Train epoch: 420 [566720/25046 (71%)]\tLoss: 0.116868\n",
            "Train epoch: 420 [656160/25046 (82%)]\tLoss: 0.075276\n",
            "Train epoch: 420 [733680/25046 (92%)]\tLoss: 0.040679\n",
            "Make prediction for 5010 samples...\n",
            "0.25123936 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 421 [0/25046 (0%)]\tLoss: 0.017518\n",
            "Train epoch: 421 [82400/25046 (10%)]\tLoss: 0.055934\n",
            "Train epoch: 421 [168440/25046 (20%)]\tLoss: 0.037433\n",
            "Train epoch: 421 [236580/25046 (31%)]\tLoss: 0.046146\n",
            "Train epoch: 421 [325280/25046 (41%)]\tLoss: 0.054845\n",
            "Train epoch: 421 [414000/25046 (51%)]\tLoss: 0.092607\n",
            "Train epoch: 421 [487680/25046 (61%)]\tLoss: 0.043708\n",
            "Train epoch: 421 [563780/25046 (71%)]\tLoss: 0.029064\n",
            "Train epoch: 421 [653760/25046 (82%)]\tLoss: 0.030866\n",
            "Train epoch: 421 [717480/25046 (92%)]\tLoss: 0.019823\n",
            "Make prediction for 5010 samples...\n",
            "0.25437096 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 422 [0/25046 (0%)]\tLoss: 0.068962\n",
            "Train epoch: 422 [82240/25046 (10%)]\tLoss: 0.024538\n",
            "Train epoch: 422 [163800/25046 (20%)]\tLoss: 0.111740\n",
            "Train epoch: 422 [247500/25046 (31%)]\tLoss: 0.024633\n",
            "Train epoch: 422 [329120/25046 (41%)]\tLoss: 0.040868\n",
            "Train epoch: 422 [412000/25046 (51%)]\tLoss: 0.019008\n",
            "Train epoch: 422 [496440/25046 (61%)]\tLoss: 0.053471\n",
            "Train epoch: 422 [584080/25046 (71%)]\tLoss: 0.025148\n",
            "Train epoch: 422 [643200/25046 (82%)]\tLoss: 0.050837\n",
            "Train epoch: 422 [736740/25046 (92%)]\tLoss: 0.033985\n",
            "Make prediction for 5010 samples...\n",
            "0.24965869 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 423 [0/25046 (0%)]\tLoss: 0.039281\n",
            "Train epoch: 423 [80700/25046 (10%)]\tLoss: 0.048513\n",
            "Train epoch: 423 [160800/25046 (20%)]\tLoss: 0.034677\n",
            "Train epoch: 423 [241260/25046 (31%)]\tLoss: 0.028120\n",
            "Train epoch: 423 [330000/25046 (41%)]\tLoss: 0.043782\n",
            "Train epoch: 423 [418400/25046 (51%)]\tLoss: 0.041633\n",
            "Train epoch: 423 [488400/25046 (61%)]\tLoss: 0.022973\n",
            "Train epoch: 423 [583940/25046 (71%)]\tLoss: 0.034707\n",
            "Train epoch: 423 [647040/25046 (82%)]\tLoss: 0.036467\n",
            "Train epoch: 423 [747360/25046 (92%)]\tLoss: 0.039614\n",
            "Make prediction for 5010 samples...\n",
            "0.24894288 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 424 [0/25046 (0%)]\tLoss: 0.043278\n",
            "Train epoch: 424 [82420/25046 (10%)]\tLoss: 0.090385\n",
            "Train epoch: 424 [168760/25046 (20%)]\tLoss: 0.045221\n",
            "Train epoch: 424 [246900/25046 (31%)]\tLoss: 0.053208\n",
            "Train epoch: 424 [329600/25046 (41%)]\tLoss: 0.042922\n",
            "Train epoch: 424 [401700/25046 (51%)]\tLoss: 0.035662\n",
            "Train epoch: 424 [482280/25046 (61%)]\tLoss: 0.057058\n",
            "Train epoch: 424 [584220/25046 (71%)]\tLoss: 0.033898\n",
            "Train epoch: 424 [661920/25046 (82%)]\tLoss: 0.037371\n",
            "Train epoch: 424 [742140/25046 (92%)]\tLoss: 0.035765\n",
            "Make prediction for 5010 samples...\n",
            "0.24903157 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 425 [0/25046 (0%)]\tLoss: 0.028032\n",
            "Train epoch: 425 [81080/25046 (10%)]\tLoss: 0.021306\n",
            "Train epoch: 425 [165040/25046 (20%)]\tLoss: 0.041054\n",
            "Train epoch: 425 [245340/25046 (31%)]\tLoss: 0.013757\n",
            "Train epoch: 425 [321520/25046 (41%)]\tLoss: 0.024443\n",
            "Train epoch: 425 [403700/25046 (51%)]\tLoss: 0.019440\n",
            "Train epoch: 425 [494040/25046 (61%)]\tLoss: 0.026206\n",
            "Train epoch: 425 [570780/25046 (71%)]\tLoss: 0.051218\n",
            "Train epoch: 425 [681440/25046 (82%)]\tLoss: 0.035384\n",
            "Train epoch: 425 [747180/25046 (92%)]\tLoss: 0.025686\n",
            "Make prediction for 5010 samples...\n",
            "0.24587232 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 426 [0/25046 (0%)]\tLoss: 0.070175\n",
            "Train epoch: 426 [82440/25046 (10%)]\tLoss: 0.034009\n",
            "Train epoch: 426 [164480/25046 (20%)]\tLoss: 0.040651\n",
            "Train epoch: 426 [241560/25046 (31%)]\tLoss: 0.040043\n",
            "Train epoch: 426 [329440/25046 (41%)]\tLoss: 0.034603\n",
            "Train epoch: 426 [409600/25046 (51%)]\tLoss: 0.054414\n",
            "Train epoch: 426 [482880/25046 (61%)]\tLoss: 0.090220\n",
            "Train epoch: 426 [585060/25046 (71%)]\tLoss: 0.038006\n",
            "Train epoch: 426 [659840/25046 (82%)]\tLoss: 0.033790\n",
            "Train epoch: 426 [735300/25046 (92%)]\tLoss: 0.026685\n",
            "Make prediction for 5010 samples...\n",
            "0.2553953 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 427 [0/25046 (0%)]\tLoss: 0.055632\n",
            "Train epoch: 427 [83080/25046 (10%)]\tLoss: 0.041472\n",
            "Train epoch: 427 [161640/25046 (20%)]\tLoss: 0.068149\n",
            "Train epoch: 427 [252000/25046 (31%)]\tLoss: 0.042638\n",
            "Train epoch: 427 [332560/25046 (41%)]\tLoss: 0.056892\n",
            "Train epoch: 427 [420000/25046 (51%)]\tLoss: 0.061757\n",
            "Train epoch: 427 [499560/25046 (61%)]\tLoss: 0.040793\n",
            "Train epoch: 427 [557760/25046 (71%)]\tLoss: 0.025370\n",
            "Train epoch: 427 [669280/25046 (82%)]\tLoss: 0.014671\n",
            "Train epoch: 427 [737820/25046 (92%)]\tLoss: 0.038182\n",
            "Make prediction for 5010 samples...\n",
            "0.2479728 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 428 [0/25046 (0%)]\tLoss: 0.023650\n",
            "Train epoch: 428 [83200/25046 (10%)]\tLoss: 0.100203\n",
            "Train epoch: 428 [166480/25046 (20%)]\tLoss: 0.026070\n",
            "Train epoch: 428 [246540/25046 (31%)]\tLoss: 0.042964\n",
            "Train epoch: 428 [321680/25046 (41%)]\tLoss: 0.054557\n",
            "Train epoch: 428 [405000/25046 (51%)]\tLoss: 0.055096\n",
            "Train epoch: 428 [504120/25046 (61%)]\tLoss: 0.032927\n",
            "Train epoch: 428 [587440/25046 (71%)]\tLoss: 0.061031\n",
            "Train epoch: 428 [662400/25046 (82%)]\tLoss: 0.099730\n",
            "Train epoch: 428 [750960/25046 (92%)]\tLoss: 0.020444\n",
            "Make prediction for 5010 samples...\n",
            "0.2575854 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 429 [0/25046 (0%)]\tLoss: 0.026615\n",
            "Train epoch: 429 [83140/25046 (10%)]\tLoss: 0.022867\n",
            "Train epoch: 429 [167760/25046 (20%)]\tLoss: 0.038882\n",
            "Train epoch: 429 [250500/25046 (31%)]\tLoss: 0.030571\n",
            "Train epoch: 429 [325040/25046 (41%)]\tLoss: 0.045748\n",
            "Train epoch: 429 [405700/25046 (51%)]\tLoss: 0.064989\n",
            "Train epoch: 429 [481800/25046 (61%)]\tLoss: 0.031791\n",
            "Train epoch: 429 [565180/25046 (71%)]\tLoss: 0.094393\n",
            "Train epoch: 429 [651680/25046 (82%)]\tLoss: 0.014544\n",
            "Train epoch: 429 [751140/25046 (92%)]\tLoss: 0.048620\n",
            "Make prediction for 5010 samples...\n",
            "0.251337 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 430 [0/25046 (0%)]\tLoss: 0.025631\n",
            "Train epoch: 430 [80800/25046 (10%)]\tLoss: 0.036354\n",
            "Train epoch: 430 [169080/25046 (20%)]\tLoss: 0.037696\n",
            "Train epoch: 430 [250380/25046 (31%)]\tLoss: 0.048100\n",
            "Train epoch: 430 [321680/25046 (41%)]\tLoss: 0.031801\n",
            "Train epoch: 430 [415000/25046 (51%)]\tLoss: 0.056583\n",
            "Train epoch: 430 [501120/25046 (61%)]\tLoss: 0.029112\n",
            "Train epoch: 430 [574000/25046 (71%)]\tLoss: 0.024308\n",
            "Train epoch: 430 [641920/25046 (82%)]\tLoss: 0.042586\n",
            "Train epoch: 430 [735480/25046 (92%)]\tLoss: 0.089169\n",
            "Make prediction for 5010 samples...\n",
            "0.24740967 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 431 [0/25046 (0%)]\tLoss: 0.058605\n",
            "Train epoch: 431 [82520/25046 (10%)]\tLoss: 0.024429\n",
            "Train epoch: 431 [162320/25046 (20%)]\tLoss: 0.038753\n",
            "Train epoch: 431 [248100/25046 (31%)]\tLoss: 0.038964\n",
            "Train epoch: 431 [327120/25046 (41%)]\tLoss: 0.142325\n",
            "Train epoch: 431 [409000/25046 (51%)]\tLoss: 0.038928\n",
            "Train epoch: 431 [483120/25046 (61%)]\tLoss: 0.030808\n",
            "Train epoch: 431 [568680/25046 (71%)]\tLoss: 0.056279\n",
            "Train epoch: 431 [660800/25046 (82%)]\tLoss: 0.039413\n",
            "Train epoch: 431 [738900/25046 (92%)]\tLoss: 0.016940\n",
            "Make prediction for 5010 samples...\n",
            "0.24588998 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 432 [0/25046 (0%)]\tLoss: 0.059533\n",
            "Train epoch: 432 [82060/25046 (10%)]\tLoss: 0.044788\n",
            "Train epoch: 432 [165120/25046 (20%)]\tLoss: 0.040116\n",
            "Train epoch: 432 [242760/25046 (31%)]\tLoss: 0.034164\n",
            "Train epoch: 432 [330880/25046 (41%)]\tLoss: 0.024841\n",
            "Train epoch: 432 [415600/25046 (51%)]\tLoss: 0.036118\n",
            "Train epoch: 432 [491160/25046 (61%)]\tLoss: 0.050614\n",
            "Train epoch: 432 [579040/25046 (71%)]\tLoss: 0.051878\n",
            "Train epoch: 432 [656480/25046 (82%)]\tLoss: 0.035817\n",
            "Train epoch: 432 [745920/25046 (92%)]\tLoss: 0.052941\n",
            "Make prediction for 5010 samples...\n",
            "0.24845529 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 433 [0/25046 (0%)]\tLoss: 0.036050\n",
            "Train epoch: 433 [81320/25046 (10%)]\tLoss: 0.086617\n",
            "Train epoch: 433 [157560/25046 (20%)]\tLoss: 0.248854\n",
            "Train epoch: 433 [248640/25046 (31%)]\tLoss: 0.034950\n",
            "Train epoch: 433 [322480/25046 (41%)]\tLoss: 0.043431\n",
            "Train epoch: 433 [408600/25046 (51%)]\tLoss: 0.032987\n",
            "Train epoch: 433 [492240/25046 (61%)]\tLoss: 0.024732\n",
            "Train epoch: 433 [588560/25046 (71%)]\tLoss: 0.037030\n",
            "Train epoch: 433 [652160/25046 (82%)]\tLoss: 0.028107\n",
            "Train epoch: 433 [734220/25046 (92%)]\tLoss: 0.066638\n",
            "Make prediction for 5010 samples...\n",
            "0.25105676 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 434 [0/25046 (0%)]\tLoss: 0.058144\n",
            "Train epoch: 434 [81220/25046 (10%)]\tLoss: 0.036520\n",
            "Train epoch: 434 [171800/25046 (20%)]\tLoss: 0.077103\n",
            "Train epoch: 434 [238740/25046 (31%)]\tLoss: 0.026075\n",
            "Train epoch: 434 [324560/25046 (41%)]\tLoss: 0.088817\n",
            "Train epoch: 434 [414100/25046 (51%)]\tLoss: 0.052040\n",
            "Train epoch: 434 [484680/25046 (61%)]\tLoss: 0.044135\n",
            "Train epoch: 434 [574000/25046 (71%)]\tLoss: 0.034897\n",
            "Train epoch: 434 [652480/25046 (82%)]\tLoss: 0.038815\n",
            "Train epoch: 434 [758880/25046 (92%)]\tLoss: 0.061909\n",
            "Make prediction for 5010 samples...\n",
            "0.24755675 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 435 [0/25046 (0%)]\tLoss: 0.045565\n",
            "Train epoch: 435 [83440/25046 (10%)]\tLoss: 0.049983\n",
            "Train epoch: 435 [165080/25046 (20%)]\tLoss: 0.083834\n",
            "Train epoch: 435 [245640/25046 (31%)]\tLoss: 0.037853\n",
            "Train epoch: 435 [321040/25046 (41%)]\tLoss: 0.072709\n",
            "Train epoch: 435 [400300/25046 (51%)]\tLoss: 0.041088\n",
            "Train epoch: 435 [498840/25046 (61%)]\tLoss: 0.026240\n",
            "Train epoch: 435 [589540/25046 (71%)]\tLoss: 0.034862\n",
            "Train epoch: 435 [651680/25046 (82%)]\tLoss: 0.033723\n",
            "Train epoch: 435 [734940/25046 (92%)]\tLoss: 0.037577\n",
            "Make prediction for 5010 samples...\n",
            "0.25762093 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 436 [0/25046 (0%)]\tLoss: 0.053109\n",
            "Train epoch: 436 [80640/25046 (10%)]\tLoss: 0.027365\n",
            "Train epoch: 436 [162880/25046 (20%)]\tLoss: 0.058285\n",
            "Train epoch: 436 [243900/25046 (31%)]\tLoss: 0.048382\n",
            "Train epoch: 436 [321280/25046 (41%)]\tLoss: 0.054276\n",
            "Train epoch: 436 [409800/25046 (51%)]\tLoss: 0.025133\n",
            "Train epoch: 436 [489600/25046 (61%)]\tLoss: 0.018092\n",
            "Train epoch: 436 [570360/25046 (71%)]\tLoss: 0.033305\n",
            "Train epoch: 436 [639200/25046 (82%)]\tLoss: 0.070725\n",
            "Train epoch: 436 [745020/25046 (92%)]\tLoss: 0.031037\n",
            "Make prediction for 5010 samples...\n",
            "0.2478426 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 437 [0/25046 (0%)]\tLoss: 0.051792\n",
            "Train epoch: 437 [83100/25046 (10%)]\tLoss: 0.022677\n",
            "Train epoch: 437 [165760/25046 (20%)]\tLoss: 0.068472\n",
            "Train epoch: 437 [250740/25046 (31%)]\tLoss: 0.058744\n",
            "Train epoch: 437 [316720/25046 (41%)]\tLoss: 0.021429\n",
            "Train epoch: 437 [402600/25046 (51%)]\tLoss: 0.035465\n",
            "Train epoch: 437 [483120/25046 (61%)]\tLoss: 0.082231\n",
            "Train epoch: 437 [576380/25046 (71%)]\tLoss: 0.028503\n",
            "Train epoch: 437 [643840/25046 (82%)]\tLoss: 0.018032\n",
            "Train epoch: 437 [746100/25046 (92%)]\tLoss: 0.069523\n",
            "Make prediction for 5010 samples...\n",
            "0.25213617 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 438 [0/25046 (0%)]\tLoss: 0.041682\n",
            "Train epoch: 438 [80920/25046 (10%)]\tLoss: 0.031520\n",
            "Train epoch: 438 [163800/25046 (20%)]\tLoss: 0.106389\n",
            "Train epoch: 438 [244680/25046 (31%)]\tLoss: 0.030812\n",
            "Train epoch: 438 [331200/25046 (41%)]\tLoss: 0.036791\n",
            "Train epoch: 438 [404800/25046 (51%)]\tLoss: 0.023945\n",
            "Train epoch: 438 [498480/25046 (61%)]\tLoss: 0.077921\n",
            "Train epoch: 438 [591640/25046 (71%)]\tLoss: 0.025628\n",
            "Train epoch: 438 [680480/25046 (82%)]\tLoss: 0.068980\n",
            "Train epoch: 438 [741600/25046 (92%)]\tLoss: 0.054459\n",
            "Make prediction for 5010 samples...\n",
            "0.24440196 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 439 [0/25046 (0%)]\tLoss: 0.045017\n",
            "Train epoch: 439 [79340/25046 (10%)]\tLoss: 0.026843\n",
            "Train epoch: 439 [168280/25046 (20%)]\tLoss: 0.100167\n",
            "Train epoch: 439 [248160/25046 (31%)]\tLoss: 0.031199\n",
            "Train epoch: 439 [326240/25046 (41%)]\tLoss: 0.041962\n",
            "Train epoch: 439 [425100/25046 (51%)]\tLoss: 0.050211\n",
            "Train epoch: 439 [495840/25046 (61%)]\tLoss: 0.056460\n",
            "Train epoch: 439 [568260/25046 (71%)]\tLoss: 0.066530\n",
            "Train epoch: 439 [674560/25046 (82%)]\tLoss: 0.143121\n",
            "Train epoch: 439 [733320/25046 (92%)]\tLoss: 0.041609\n",
            "Make prediction for 5010 samples...\n",
            "0.2523168 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 440 [0/25046 (0%)]\tLoss: 0.082612\n",
            "Train epoch: 440 [82380/25046 (10%)]\tLoss: 0.021172\n",
            "Train epoch: 440 [160920/25046 (20%)]\tLoss: 0.032386\n",
            "Train epoch: 440 [240240/25046 (31%)]\tLoss: 0.025759\n",
            "Train epoch: 440 [326560/25046 (41%)]\tLoss: 0.025736\n",
            "Train epoch: 440 [401700/25046 (51%)]\tLoss: 0.046575\n",
            "Train epoch: 440 [492960/25046 (61%)]\tLoss: 0.047682\n",
            "Train epoch: 440 [567000/25046 (71%)]\tLoss: 0.034261\n",
            "Train epoch: 440 [653280/25046 (82%)]\tLoss: 0.047485\n",
            "Train epoch: 440 [741420/25046 (92%)]\tLoss: 0.051281\n",
            "Make prediction for 5010 samples...\n",
            "0.25035962 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 441 [0/25046 (0%)]\tLoss: 0.019986\n",
            "Train epoch: 441 [81420/25046 (10%)]\tLoss: 0.084107\n",
            "Train epoch: 441 [160440/25046 (20%)]\tLoss: 0.051745\n",
            "Train epoch: 441 [254760/25046 (31%)]\tLoss: 0.043496\n",
            "Train epoch: 441 [332400/25046 (41%)]\tLoss: 0.046039\n",
            "Train epoch: 441 [429000/25046 (51%)]\tLoss: 0.024384\n",
            "Train epoch: 441 [504720/25046 (61%)]\tLoss: 0.062235\n",
            "Train epoch: 441 [568120/25046 (71%)]\tLoss: 0.032784\n",
            "Train epoch: 441 [650400/25046 (82%)]\tLoss: 0.052385\n",
            "Train epoch: 441 [721620/25046 (92%)]\tLoss: 0.059410\n",
            "Make prediction for 5010 samples...\n",
            "0.24243982 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 442 [0/25046 (0%)]\tLoss: 0.040616\n",
            "Train epoch: 442 [82340/25046 (10%)]\tLoss: 0.101953\n",
            "Train epoch: 442 [161280/25046 (20%)]\tLoss: 0.023934\n",
            "Train epoch: 442 [245160/25046 (31%)]\tLoss: 0.125755\n",
            "Train epoch: 442 [322800/25046 (41%)]\tLoss: 0.022755\n",
            "Train epoch: 442 [399200/25046 (51%)]\tLoss: 0.029658\n",
            "Train epoch: 442 [490680/25046 (61%)]\tLoss: 0.028860\n",
            "Train epoch: 442 [567700/25046 (71%)]\tLoss: 0.034404\n",
            "Train epoch: 442 [633600/25046 (82%)]\tLoss: 0.031710\n",
            "Train epoch: 442 [722340/25046 (92%)]\tLoss: 0.024206\n",
            "Make prediction for 5010 samples...\n",
            "0.24472658 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 443 [0/25046 (0%)]\tLoss: 0.041162\n",
            "Train epoch: 443 [82360/25046 (10%)]\tLoss: 0.012243\n",
            "Train epoch: 443 [169440/25046 (20%)]\tLoss: 0.035621\n",
            "Train epoch: 443 [244560/25046 (31%)]\tLoss: 0.022651\n",
            "Train epoch: 443 [324640/25046 (41%)]\tLoss: 0.037118\n",
            "Train epoch: 443 [414600/25046 (51%)]\tLoss: 0.024179\n",
            "Train epoch: 443 [506040/25046 (61%)]\tLoss: 0.021950\n",
            "Train epoch: 443 [567560/25046 (71%)]\tLoss: 0.069455\n",
            "Train epoch: 443 [657600/25046 (82%)]\tLoss: 0.017499\n",
            "Train epoch: 443 [728640/25046 (92%)]\tLoss: 0.096408\n",
            "Make prediction for 5010 samples...\n",
            "0.2521471 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 444 [0/25046 (0%)]\tLoss: 0.044793\n",
            "Train epoch: 444 [83400/25046 (10%)]\tLoss: 0.028522\n",
            "Train epoch: 444 [161240/25046 (20%)]\tLoss: 0.049919\n",
            "Train epoch: 444 [246360/25046 (31%)]\tLoss: 0.032559\n",
            "Train epoch: 444 [326000/25046 (41%)]\tLoss: 0.103976\n",
            "Train epoch: 444 [414000/25046 (51%)]\tLoss: 0.030178\n",
            "Train epoch: 444 [490440/25046 (61%)]\tLoss: 0.081882\n",
            "Train epoch: 444 [577500/25046 (71%)]\tLoss: 0.043490\n",
            "Train epoch: 444 [658720/25046 (82%)]\tLoss: 0.039915\n",
            "Train epoch: 444 [751680/25046 (92%)]\tLoss: 0.052470\n",
            "Make prediction for 5010 samples...\n",
            "0.24247433 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 445 [0/25046 (0%)]\tLoss: 0.057532\n",
            "Train epoch: 445 [80560/25046 (10%)]\tLoss: 0.097149\n",
            "Train epoch: 445 [164760/25046 (20%)]\tLoss: 0.035846\n",
            "Train epoch: 445 [246840/25046 (31%)]\tLoss: 0.143443\n",
            "Train epoch: 445 [327760/25046 (41%)]\tLoss: 0.025947\n",
            "Train epoch: 445 [410500/25046 (51%)]\tLoss: 0.071845\n",
            "Train epoch: 445 [496200/25046 (61%)]\tLoss: 0.040313\n",
            "Train epoch: 445 [578340/25046 (71%)]\tLoss: 0.071499\n",
            "Train epoch: 445 [673280/25046 (82%)]\tLoss: 0.029379\n",
            "Train epoch: 445 [732600/25046 (92%)]\tLoss: 0.027643\n",
            "Make prediction for 5010 samples...\n",
            "0.2530737 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 446 [0/25046 (0%)]\tLoss: 0.020171\n",
            "Train epoch: 446 [80140/25046 (10%)]\tLoss: 0.027412\n",
            "Train epoch: 446 [160480/25046 (20%)]\tLoss: 0.049766\n",
            "Train epoch: 446 [247560/25046 (31%)]\tLoss: 0.042623\n",
            "Train epoch: 446 [325760/25046 (41%)]\tLoss: 0.053768\n",
            "Train epoch: 446 [404800/25046 (51%)]\tLoss: 0.051217\n",
            "Train epoch: 446 [486720/25046 (61%)]\tLoss: 0.027419\n",
            "Train epoch: 446 [570500/25046 (71%)]\tLoss: 0.034051\n",
            "Train epoch: 446 [660000/25046 (82%)]\tLoss: 0.033591\n",
            "Train epoch: 446 [722340/25046 (92%)]\tLoss: 0.070279\n",
            "Make prediction for 5010 samples...\n",
            "0.24642314 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 447 [0/25046 (0%)]\tLoss: 0.036584\n",
            "Train epoch: 447 [81920/25046 (10%)]\tLoss: 0.022990\n",
            "Train epoch: 447 [164200/25046 (20%)]\tLoss: 0.064149\n",
            "Train epoch: 447 [248040/25046 (31%)]\tLoss: 0.050449\n",
            "Train epoch: 447 [316960/25046 (41%)]\tLoss: 0.042572\n",
            "Train epoch: 447 [420500/25046 (51%)]\tLoss: 0.094488\n",
            "Train epoch: 447 [472920/25046 (61%)]\tLoss: 0.063804\n",
            "Train epoch: 447 [590100/25046 (71%)]\tLoss: 0.087852\n",
            "Train epoch: 447 [671520/25046 (82%)]\tLoss: 0.031949\n",
            "Train epoch: 447 [752760/25046 (92%)]\tLoss: 0.084732\n",
            "Make prediction for 5010 samples...\n",
            "0.25167897 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 448 [0/25046 (0%)]\tLoss: 0.023570\n",
            "Train epoch: 448 [85180/25046 (10%)]\tLoss: 0.057621\n",
            "Train epoch: 448 [160640/25046 (20%)]\tLoss: 0.017773\n",
            "Train epoch: 448 [241440/25046 (31%)]\tLoss: 0.036857\n",
            "Train epoch: 448 [315360/25046 (41%)]\tLoss: 0.135375\n",
            "Train epoch: 448 [401500/25046 (51%)]\tLoss: 0.063985\n",
            "Train epoch: 448 [482520/25046 (61%)]\tLoss: 0.037206\n",
            "Train epoch: 448 [582540/25046 (71%)]\tLoss: 0.063837\n",
            "Train epoch: 448 [665920/25046 (82%)]\tLoss: 0.039508\n",
            "Train epoch: 448 [745740/25046 (92%)]\tLoss: 0.023114\n",
            "Make prediction for 5010 samples...\n",
            "0.2479365 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 449 [0/25046 (0%)]\tLoss: 0.187627\n",
            "Train epoch: 449 [82720/25046 (10%)]\tLoss: 0.057489\n",
            "Train epoch: 449 [163160/25046 (20%)]\tLoss: 0.024492\n",
            "Train epoch: 449 [247080/25046 (31%)]\tLoss: 0.073316\n",
            "Train epoch: 449 [325520/25046 (41%)]\tLoss: 0.026634\n",
            "Train epoch: 449 [403400/25046 (51%)]\tLoss: 0.027159\n",
            "Train epoch: 449 [505800/25046 (61%)]\tLoss: 0.042516\n",
            "Train epoch: 449 [586740/25046 (71%)]\tLoss: 0.025505\n",
            "Train epoch: 449 [650240/25046 (82%)]\tLoss: 0.019553\n",
            "Train epoch: 449 [719640/25046 (92%)]\tLoss: 0.184907\n",
            "Make prediction for 5010 samples...\n",
            "0.25106838 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 450 [0/25046 (0%)]\tLoss: 0.024179\n",
            "Train epoch: 450 [79840/25046 (10%)]\tLoss: 0.036067\n",
            "Train epoch: 450 [162800/25046 (20%)]\tLoss: 0.011957\n",
            "Train epoch: 450 [241980/25046 (31%)]\tLoss: 0.039950\n",
            "Train epoch: 450 [325360/25046 (41%)]\tLoss: 0.020861\n",
            "Train epoch: 450 [398500/25046 (51%)]\tLoss: 0.026314\n",
            "Train epoch: 450 [492480/25046 (61%)]\tLoss: 0.151418\n",
            "Train epoch: 450 [582820/25046 (71%)]\tLoss: 0.057718\n",
            "Train epoch: 450 [668800/25046 (82%)]\tLoss: 0.019231\n",
            "Train epoch: 450 [737640/25046 (92%)]\tLoss: 0.021840\n",
            "Make prediction for 5010 samples...\n",
            "0.24974144 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 451 [0/25046 (0%)]\tLoss: 0.021757\n",
            "Train epoch: 451 [79420/25046 (10%)]\tLoss: 0.036278\n",
            "Train epoch: 451 [164400/25046 (20%)]\tLoss: 0.088507\n",
            "Train epoch: 451 [244260/25046 (31%)]\tLoss: 0.037681\n",
            "Train epoch: 451 [335440/25046 (41%)]\tLoss: 0.045439\n",
            "Train epoch: 451 [415100/25046 (51%)]\tLoss: 0.142753\n",
            "Train epoch: 451 [491640/25046 (61%)]\tLoss: 0.052106\n",
            "Train epoch: 451 [575960/25046 (71%)]\tLoss: 0.078840\n",
            "Train epoch: 451 [653920/25046 (82%)]\tLoss: 0.037697\n",
            "Train epoch: 451 [741600/25046 (92%)]\tLoss: 0.038161\n",
            "Make prediction for 5010 samples...\n",
            "0.2502303 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 452 [0/25046 (0%)]\tLoss: 0.015169\n",
            "Train epoch: 452 [80560/25046 (10%)]\tLoss: 0.034248\n",
            "Train epoch: 452 [161080/25046 (20%)]\tLoss: 0.025459\n",
            "Train epoch: 452 [238440/25046 (31%)]\tLoss: 0.051440\n",
            "Train epoch: 452 [324800/25046 (41%)]\tLoss: 0.012404\n",
            "Train epoch: 452 [417900/25046 (51%)]\tLoss: 0.103397\n",
            "Train epoch: 452 [488280/25046 (61%)]\tLoss: 0.051817\n",
            "Train epoch: 452 [571760/25046 (71%)]\tLoss: 0.052434\n",
            "Train epoch: 452 [647520/25046 (82%)]\tLoss: 0.069394\n",
            "Train epoch: 452 [736200/25046 (92%)]\tLoss: 0.058186\n",
            "Make prediction for 5010 samples...\n",
            "0.2554702 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 453 [0/25046 (0%)]\tLoss: 0.043800\n",
            "Train epoch: 453 [82580/25046 (10%)]\tLoss: 0.046613\n",
            "Train epoch: 453 [160600/25046 (20%)]\tLoss: 0.038676\n",
            "Train epoch: 453 [246840/25046 (31%)]\tLoss: 0.036218\n",
            "Train epoch: 453 [329920/25046 (41%)]\tLoss: 0.066748\n",
            "Train epoch: 453 [405300/25046 (51%)]\tLoss: 0.052948\n",
            "Train epoch: 453 [488040/25046 (61%)]\tLoss: 0.136554\n",
            "Train epoch: 453 [592900/25046 (71%)]\tLoss: 0.077940\n",
            "Train epoch: 453 [650560/25046 (82%)]\tLoss: 0.065382\n",
            "Train epoch: 453 [748980/25046 (92%)]\tLoss: 0.030424\n",
            "Make prediction for 5010 samples...\n",
            "0.26072934 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 454 [0/25046 (0%)]\tLoss: 0.077248\n",
            "Train epoch: 454 [82180/25046 (10%)]\tLoss: 0.044427\n",
            "Train epoch: 454 [163680/25046 (20%)]\tLoss: 0.057291\n",
            "Train epoch: 454 [244080/25046 (31%)]\tLoss: 0.027701\n",
            "Train epoch: 454 [321760/25046 (41%)]\tLoss: 0.036128\n",
            "Train epoch: 454 [413900/25046 (51%)]\tLoss: 0.035432\n",
            "Train epoch: 454 [494880/25046 (61%)]\tLoss: 0.057016\n",
            "Train epoch: 454 [572600/25046 (71%)]\tLoss: 0.077134\n",
            "Train epoch: 454 [658240/25046 (82%)]\tLoss: 0.064057\n",
            "Train epoch: 454 [720900/25046 (92%)]\tLoss: 0.062864\n",
            "Make prediction for 5010 samples...\n",
            "0.2562383 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 455 [0/25046 (0%)]\tLoss: 0.029930\n",
            "Train epoch: 455 [81520/25046 (10%)]\tLoss: 0.086877\n",
            "Train epoch: 455 [163720/25046 (20%)]\tLoss: 0.127728\n",
            "Train epoch: 455 [247140/25046 (31%)]\tLoss: 0.029623\n",
            "Train epoch: 455 [323520/25046 (41%)]\tLoss: 0.015026\n",
            "Train epoch: 455 [413900/25046 (51%)]\tLoss: 0.046232\n",
            "Train epoch: 455 [487080/25046 (61%)]\tLoss: 0.039915\n",
            "Train epoch: 455 [569520/25046 (71%)]\tLoss: 0.098568\n",
            "Train epoch: 455 [665760/25046 (82%)]\tLoss: 0.085172\n",
            "Train epoch: 455 [742320/25046 (92%)]\tLoss: 0.058098\n",
            "Make prediction for 5010 samples...\n",
            "0.24978583 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 456 [0/25046 (0%)]\tLoss: 0.022868\n",
            "Train epoch: 456 [82040/25046 (10%)]\tLoss: 0.083683\n",
            "Train epoch: 456 [163640/25046 (20%)]\tLoss: 0.020646\n",
            "Train epoch: 456 [249060/25046 (31%)]\tLoss: 0.064121\n",
            "Train epoch: 456 [322160/25046 (41%)]\tLoss: 0.035159\n",
            "Train epoch: 456 [412800/25046 (51%)]\tLoss: 0.024725\n",
            "Train epoch: 456 [504720/25046 (61%)]\tLoss: 0.071702\n",
            "Train epoch: 456 [582960/25046 (71%)]\tLoss: 0.057822\n",
            "Train epoch: 456 [656480/25046 (82%)]\tLoss: 0.057846\n",
            "Train epoch: 456 [744840/25046 (92%)]\tLoss: 0.017632\n",
            "Make prediction for 5010 samples...\n",
            "0.24729185 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 457 [0/25046 (0%)]\tLoss: 0.031728\n",
            "Train epoch: 457 [79780/25046 (10%)]\tLoss: 0.046877\n",
            "Train epoch: 457 [169840/25046 (20%)]\tLoss: 0.028795\n",
            "Train epoch: 457 [246480/25046 (31%)]\tLoss: 0.022959\n",
            "Train epoch: 457 [320320/25046 (41%)]\tLoss: 0.019455\n",
            "Train epoch: 457 [412300/25046 (51%)]\tLoss: 0.047690\n",
            "Train epoch: 457 [494400/25046 (61%)]\tLoss: 0.095392\n",
            "Train epoch: 457 [585760/25046 (71%)]\tLoss: 0.064283\n",
            "Train epoch: 457 [641920/25046 (82%)]\tLoss: 0.060326\n",
            "Train epoch: 457 [731520/25046 (92%)]\tLoss: 0.052028\n",
            "Make prediction for 5010 samples...\n",
            "0.25310847 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 458 [0/25046 (0%)]\tLoss: 0.054082\n",
            "Train epoch: 458 [82580/25046 (10%)]\tLoss: 0.030906\n",
            "Train epoch: 458 [161080/25046 (20%)]\tLoss: 0.019796\n",
            "Train epoch: 458 [250620/25046 (31%)]\tLoss: 0.132830\n",
            "Train epoch: 458 [320720/25046 (41%)]\tLoss: 0.037620\n",
            "Train epoch: 458 [409500/25046 (51%)]\tLoss: 0.033699\n",
            "Train epoch: 458 [479760/25046 (61%)]\tLoss: 0.019306\n",
            "Train epoch: 458 [573300/25046 (71%)]\tLoss: 0.028320\n",
            "Train epoch: 458 [645440/25046 (82%)]\tLoss: 0.026211\n",
            "Train epoch: 458 [726840/25046 (92%)]\tLoss: 0.051392\n",
            "Make prediction for 5010 samples...\n",
            "0.25677335 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 459 [0/25046 (0%)]\tLoss: 0.059474\n",
            "Train epoch: 459 [82680/25046 (10%)]\tLoss: 0.060616\n",
            "Train epoch: 459 [164120/25046 (20%)]\tLoss: 0.028010\n",
            "Train epoch: 459 [256080/25046 (31%)]\tLoss: 0.029004\n",
            "Train epoch: 459 [337920/25046 (41%)]\tLoss: 0.072929\n",
            "Train epoch: 459 [417500/25046 (51%)]\tLoss: 0.032332\n",
            "Train epoch: 459 [490080/25046 (61%)]\tLoss: 0.042164\n",
            "Train epoch: 459 [586460/25046 (71%)]\tLoss: 0.175493\n",
            "Train epoch: 459 [646240/25046 (82%)]\tLoss: 0.028130\n",
            "Train epoch: 459 [740340/25046 (92%)]\tLoss: 0.034095\n",
            "Make prediction for 5010 samples...\n",
            "0.25515428 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 460 [0/25046 (0%)]\tLoss: 0.068608\n",
            "Train epoch: 460 [81580/25046 (10%)]\tLoss: 0.024010\n",
            "Train epoch: 460 [160240/25046 (20%)]\tLoss: 0.034866\n",
            "Train epoch: 460 [243180/25046 (31%)]\tLoss: 0.068720\n",
            "Train epoch: 460 [332400/25046 (41%)]\tLoss: 0.051366\n",
            "Train epoch: 460 [426100/25046 (51%)]\tLoss: 0.042492\n",
            "Train epoch: 460 [495000/25046 (61%)]\tLoss: 0.049489\n",
            "Train epoch: 460 [578480/25046 (71%)]\tLoss: 0.032841\n",
            "Train epoch: 460 [635840/25046 (82%)]\tLoss: 0.030342\n",
            "Train epoch: 460 [719280/25046 (92%)]\tLoss: 0.045796\n",
            "Make prediction for 5010 samples...\n",
            "0.2494991 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 461 [0/25046 (0%)]\tLoss: 0.025188\n",
            "Train epoch: 461 [81360/25046 (10%)]\tLoss: 0.040665\n",
            "Train epoch: 461 [165040/25046 (20%)]\tLoss: 0.030636\n",
            "Train epoch: 461 [244320/25046 (31%)]\tLoss: 0.086473\n",
            "Train epoch: 461 [329280/25046 (41%)]\tLoss: 0.031048\n",
            "Train epoch: 461 [402500/25046 (51%)]\tLoss: 0.024553\n",
            "Train epoch: 461 [497760/25046 (61%)]\tLoss: 0.030319\n",
            "Train epoch: 461 [592200/25046 (71%)]\tLoss: 0.053248\n",
            "Train epoch: 461 [656640/25046 (82%)]\tLoss: 0.045361\n",
            "Train epoch: 461 [752580/25046 (92%)]\tLoss: 0.042071\n",
            "Make prediction for 5010 samples...\n",
            "0.25661016 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 462 [0/25046 (0%)]\tLoss: 0.043729\n",
            "Train epoch: 462 [80100/25046 (10%)]\tLoss: 0.063311\n",
            "Train epoch: 462 [162240/25046 (20%)]\tLoss: 0.021422\n",
            "Train epoch: 462 [243120/25046 (31%)]\tLoss: 0.031309\n",
            "Train epoch: 462 [321600/25046 (41%)]\tLoss: 0.060087\n",
            "Train epoch: 462 [405800/25046 (51%)]\tLoss: 0.014270\n",
            "Train epoch: 462 [502920/25046 (61%)]\tLoss: 0.037150\n",
            "Train epoch: 462 [568960/25046 (71%)]\tLoss: 0.089400\n",
            "Train epoch: 462 [647040/25046 (82%)]\tLoss: 0.083019\n",
            "Train epoch: 462 [740880/25046 (92%)]\tLoss: 0.090848\n",
            "Make prediction for 5010 samples...\n",
            "0.24648537 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 463 [0/25046 (0%)]\tLoss: 0.039592\n",
            "Train epoch: 463 [80960/25046 (10%)]\tLoss: 0.041902\n",
            "Train epoch: 463 [160680/25046 (20%)]\tLoss: 0.093075\n",
            "Train epoch: 463 [241260/25046 (31%)]\tLoss: 0.023687\n",
            "Train epoch: 463 [327120/25046 (41%)]\tLoss: 0.122890\n",
            "Train epoch: 463 [425100/25046 (51%)]\tLoss: 0.072568\n",
            "Train epoch: 463 [495600/25046 (61%)]\tLoss: 0.047781\n",
            "Train epoch: 463 [555800/25046 (71%)]\tLoss: 0.020805\n",
            "Train epoch: 463 [646080/25046 (82%)]\tLoss: 0.130551\n",
            "Train epoch: 463 [737280/25046 (92%)]\tLoss: 0.032050\n",
            "Make prediction for 5010 samples...\n",
            "0.2485949 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 464 [0/25046 (0%)]\tLoss: 0.054226\n",
            "Train epoch: 464 [84340/25046 (10%)]\tLoss: 0.051213\n",
            "Train epoch: 464 [166080/25046 (20%)]\tLoss: 0.055792\n",
            "Train epoch: 464 [248460/25046 (31%)]\tLoss: 0.118021\n",
            "Train epoch: 464 [329120/25046 (41%)]\tLoss: 0.045498\n",
            "Train epoch: 464 [396300/25046 (51%)]\tLoss: 0.042136\n",
            "Train epoch: 464 [488880/25046 (61%)]\tLoss: 0.029488\n",
            "Train epoch: 464 [570920/25046 (71%)]\tLoss: 0.060081\n",
            "Train epoch: 464 [668960/25046 (82%)]\tLoss: 0.033721\n",
            "Train epoch: 464 [729720/25046 (92%)]\tLoss: 0.056311\n",
            "Make prediction for 5010 samples...\n",
            "0.25194383 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 465 [0/25046 (0%)]\tLoss: 0.049764\n",
            "Train epoch: 465 [81320/25046 (10%)]\tLoss: 0.044428\n",
            "Train epoch: 465 [163480/25046 (20%)]\tLoss: 0.068959\n",
            "Train epoch: 465 [247860/25046 (31%)]\tLoss: 0.045212\n",
            "Train epoch: 465 [324080/25046 (41%)]\tLoss: 0.026643\n",
            "Train epoch: 465 [413300/25046 (51%)]\tLoss: 0.034915\n",
            "Train epoch: 465 [500520/25046 (61%)]\tLoss: 0.041371\n",
            "Train epoch: 465 [579180/25046 (71%)]\tLoss: 0.061048\n",
            "Train epoch: 465 [658720/25046 (82%)]\tLoss: 0.052416\n",
            "Train epoch: 465 [756360/25046 (92%)]\tLoss: 0.031010\n",
            "Make prediction for 5010 samples...\n",
            "0.25152153 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 466 [0/25046 (0%)]\tLoss: 0.054465\n",
            "Train epoch: 466 [80220/25046 (10%)]\tLoss: 0.052215\n",
            "Train epoch: 466 [162200/25046 (20%)]\tLoss: 0.036028\n",
            "Train epoch: 466 [244080/25046 (31%)]\tLoss: 0.034027\n",
            "Train epoch: 466 [334640/25046 (41%)]\tLoss: 0.057299\n",
            "Train epoch: 466 [411200/25046 (51%)]\tLoss: 0.065482\n",
            "Train epoch: 466 [478440/25046 (61%)]\tLoss: 0.048094\n",
            "Train epoch: 466 [558600/25046 (71%)]\tLoss: 0.054898\n",
            "Train epoch: 466 [651680/25046 (82%)]\tLoss: 0.073991\n",
            "Train epoch: 466 [732960/25046 (92%)]\tLoss: 0.050231\n",
            "Make prediction for 5010 samples...\n",
            "0.2512332 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 467 [0/25046 (0%)]\tLoss: 0.085101\n",
            "Train epoch: 467 [83180/25046 (10%)]\tLoss: 0.023847\n",
            "Train epoch: 467 [168520/25046 (20%)]\tLoss: 0.016149\n",
            "Train epoch: 467 [243780/25046 (31%)]\tLoss: 0.017284\n",
            "Train epoch: 467 [329280/25046 (41%)]\tLoss: 0.024218\n",
            "Train epoch: 467 [411600/25046 (51%)]\tLoss: 0.026541\n",
            "Train epoch: 467 [515400/25046 (61%)]\tLoss: 0.024954\n",
            "Train epoch: 467 [564480/25046 (71%)]\tLoss: 0.040128\n",
            "Train epoch: 467 [655200/25046 (82%)]\tLoss: 0.091845\n",
            "Train epoch: 467 [723600/25046 (92%)]\tLoss: 0.011409\n",
            "Make prediction for 5010 samples...\n",
            "0.25250518 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 468 [0/25046 (0%)]\tLoss: 0.059472\n",
            "Train epoch: 468 [80640/25046 (10%)]\tLoss: 0.064604\n",
            "Train epoch: 468 [164760/25046 (20%)]\tLoss: 0.059398\n",
            "Train epoch: 468 [248520/25046 (31%)]\tLoss: 0.025116\n",
            "Train epoch: 468 [335600/25046 (41%)]\tLoss: 0.037732\n",
            "Train epoch: 468 [408400/25046 (51%)]\tLoss: 0.022227\n",
            "Train epoch: 468 [490800/25046 (61%)]\tLoss: 0.030235\n",
            "Train epoch: 468 [585340/25046 (71%)]\tLoss: 0.030187\n",
            "Train epoch: 468 [649600/25046 (82%)]\tLoss: 0.049774\n",
            "Train epoch: 468 [730440/25046 (92%)]\tLoss: 0.038614\n",
            "Make prediction for 5010 samples...\n",
            "0.24538389 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 469 [0/25046 (0%)]\tLoss: 0.030826\n",
            "Train epoch: 469 [81880/25046 (10%)]\tLoss: 0.061199\n",
            "Train epoch: 469 [166600/25046 (20%)]\tLoss: 0.065554\n",
            "Train epoch: 469 [247020/25046 (31%)]\tLoss: 0.026401\n",
            "Train epoch: 469 [327360/25046 (41%)]\tLoss: 0.057536\n",
            "Train epoch: 469 [414500/25046 (51%)]\tLoss: 0.042131\n",
            "Train epoch: 469 [495240/25046 (61%)]\tLoss: 0.054412\n",
            "Train epoch: 469 [567980/25046 (71%)]\tLoss: 0.072412\n",
            "Train epoch: 469 [668960/25046 (82%)]\tLoss: 0.063174\n",
            "Train epoch: 469 [762480/25046 (92%)]\tLoss: 0.051753\n",
            "Make prediction for 5010 samples...\n",
            "0.24778794 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 470 [0/25046 (0%)]\tLoss: 0.065399\n",
            "Train epoch: 470 [81920/25046 (10%)]\tLoss: 0.026493\n",
            "Train epoch: 470 [157760/25046 (20%)]\tLoss: 0.031307\n",
            "Train epoch: 470 [244920/25046 (31%)]\tLoss: 0.018836\n",
            "Train epoch: 470 [325760/25046 (41%)]\tLoss: 0.023463\n",
            "Train epoch: 470 [400900/25046 (51%)]\tLoss: 0.046904\n",
            "Train epoch: 470 [488640/25046 (61%)]\tLoss: 0.102235\n",
            "Train epoch: 470 [594580/25046 (71%)]\tLoss: 0.095927\n",
            "Train epoch: 470 [663680/25046 (82%)]\tLoss: 0.040528\n",
            "Train epoch: 470 [759420/25046 (92%)]\tLoss: 0.032504\n",
            "Make prediction for 5010 samples...\n",
            "0.24897778 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 471 [0/25046 (0%)]\tLoss: 0.123595\n",
            "Train epoch: 471 [81940/25046 (10%)]\tLoss: 0.043621\n",
            "Train epoch: 471 [161280/25046 (20%)]\tLoss: 0.095478\n",
            "Train epoch: 471 [248400/25046 (31%)]\tLoss: 0.019979\n",
            "Train epoch: 471 [325120/25046 (41%)]\tLoss: 0.031752\n",
            "Train epoch: 471 [430000/25046 (51%)]\tLoss: 0.033700\n",
            "Train epoch: 471 [488280/25046 (61%)]\tLoss: 0.032138\n",
            "Train epoch: 471 [554820/25046 (71%)]\tLoss: 0.133378\n",
            "Train epoch: 471 [658880/25046 (82%)]\tLoss: 0.036209\n",
            "Train epoch: 471 [758520/25046 (92%)]\tLoss: 0.063687\n",
            "Make prediction for 5010 samples...\n",
            "0.25190574 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 472 [0/25046 (0%)]\tLoss: 0.040791\n",
            "Train epoch: 472 [84060/25046 (10%)]\tLoss: 0.041806\n",
            "Train epoch: 472 [164640/25046 (20%)]\tLoss: 0.040851\n",
            "Train epoch: 472 [249480/25046 (31%)]\tLoss: 0.118562\n",
            "Train epoch: 472 [324320/25046 (41%)]\tLoss: 0.038487\n",
            "Train epoch: 472 [419000/25046 (51%)]\tLoss: 0.090301\n",
            "Train epoch: 472 [500280/25046 (61%)]\tLoss: 0.027718\n",
            "Train epoch: 472 [561400/25046 (71%)]\tLoss: 0.044864\n",
            "Train epoch: 472 [650400/25046 (82%)]\tLoss: 0.037364\n",
            "Train epoch: 472 [739980/25046 (92%)]\tLoss: 0.028352\n",
            "Make prediction for 5010 samples...\n",
            "0.25681823 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 473 [0/25046 (0%)]\tLoss: 0.060198\n",
            "Train epoch: 473 [82840/25046 (10%)]\tLoss: 0.094039\n",
            "Train epoch: 473 [165160/25046 (20%)]\tLoss: 0.077134\n",
            "Train epoch: 473 [253260/25046 (31%)]\tLoss: 0.018245\n",
            "Train epoch: 473 [331440/25046 (41%)]\tLoss: 0.034828\n",
            "Train epoch: 473 [409000/25046 (51%)]\tLoss: 0.019203\n",
            "Train epoch: 473 [498600/25046 (61%)]\tLoss: 0.039022\n",
            "Train epoch: 473 [558460/25046 (71%)]\tLoss: 0.100623\n",
            "Train epoch: 473 [647040/25046 (82%)]\tLoss: 0.051471\n",
            "Train epoch: 473 [742680/25046 (92%)]\tLoss: 0.128416\n",
            "Make prediction for 5010 samples...\n",
            "0.2572507 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 474 [0/25046 (0%)]\tLoss: 0.043571\n",
            "Train epoch: 474 [80640/25046 (10%)]\tLoss: 0.032115\n",
            "Train epoch: 474 [160320/25046 (20%)]\tLoss: 0.075867\n",
            "Train epoch: 474 [253500/25046 (31%)]\tLoss: 0.024967\n",
            "Train epoch: 474 [322960/25046 (41%)]\tLoss: 0.034745\n",
            "Train epoch: 474 [407400/25046 (51%)]\tLoss: 0.037758\n",
            "Train epoch: 474 [482640/25046 (61%)]\tLoss: 0.014347\n",
            "Train epoch: 474 [582960/25046 (71%)]\tLoss: 0.076716\n",
            "Train epoch: 474 [670560/25046 (82%)]\tLoss: 0.084648\n",
            "Train epoch: 474 [741780/25046 (92%)]\tLoss: 0.030119\n",
            "Make prediction for 5010 samples...\n",
            "0.25324756 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 475 [0/25046 (0%)]\tLoss: 0.025054\n",
            "Train epoch: 475 [84940/25046 (10%)]\tLoss: 0.062044\n",
            "Train epoch: 475 [163200/25046 (20%)]\tLoss: 0.113409\n",
            "Train epoch: 475 [242280/25046 (31%)]\tLoss: 0.035128\n",
            "Train epoch: 475 [326320/25046 (41%)]\tLoss: 0.058714\n",
            "Train epoch: 475 [412400/25046 (51%)]\tLoss: 0.038953\n",
            "Train epoch: 475 [488280/25046 (61%)]\tLoss: 0.069420\n",
            "Train epoch: 475 [600460/25046 (71%)]\tLoss: 0.046261\n",
            "Train epoch: 475 [651200/25046 (82%)]\tLoss: 0.049113\n",
            "Train epoch: 475 [726300/25046 (92%)]\tLoss: 0.058038\n",
            "Make prediction for 5010 samples...\n",
            "0.25305474 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 476 [0/25046 (0%)]\tLoss: 0.016999\n",
            "Train epoch: 476 [83140/25046 (10%)]\tLoss: 0.045108\n",
            "Train epoch: 476 [165920/25046 (20%)]\tLoss: 0.033093\n",
            "Train epoch: 476 [246060/25046 (31%)]\tLoss: 0.034091\n",
            "Train epoch: 476 [331840/25046 (41%)]\tLoss: 0.024914\n",
            "Train epoch: 476 [411600/25046 (51%)]\tLoss: 0.041876\n",
            "Train epoch: 476 [491520/25046 (61%)]\tLoss: 0.076501\n",
            "Train epoch: 476 [583380/25046 (71%)]\tLoss: 0.050801\n",
            "Train epoch: 476 [659840/25046 (82%)]\tLoss: 0.044477\n",
            "Train epoch: 476 [725040/25046 (92%)]\tLoss: 0.037882\n",
            "Make prediction for 5010 samples...\n",
            "0.24764828 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 477 [0/25046 (0%)]\tLoss: 0.020984\n",
            "Train epoch: 477 [81340/25046 (10%)]\tLoss: 0.118465\n",
            "Train epoch: 477 [164360/25046 (20%)]\tLoss: 0.044365\n",
            "Train epoch: 477 [240660/25046 (31%)]\tLoss: 0.028366\n",
            "Train epoch: 477 [327920/25046 (41%)]\tLoss: 0.049559\n",
            "Train epoch: 477 [423800/25046 (51%)]\tLoss: 0.050539\n",
            "Train epoch: 477 [486360/25046 (61%)]\tLoss: 0.038112\n",
            "Train epoch: 477 [567560/25046 (71%)]\tLoss: 0.053911\n",
            "Train epoch: 477 [651520/25046 (82%)]\tLoss: 0.044094\n",
            "Train epoch: 477 [740520/25046 (92%)]\tLoss: 0.031623\n",
            "Make prediction for 5010 samples...\n",
            "0.25345993 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 478 [0/25046 (0%)]\tLoss: 0.040247\n",
            "Train epoch: 478 [80860/25046 (10%)]\tLoss: 0.053788\n",
            "Train epoch: 478 [162880/25046 (20%)]\tLoss: 0.047728\n",
            "Train epoch: 478 [248700/25046 (31%)]\tLoss: 0.085394\n",
            "Train epoch: 478 [336480/25046 (41%)]\tLoss: 0.062127\n",
            "Train epoch: 478 [416400/25046 (51%)]\tLoss: 0.046304\n",
            "Train epoch: 478 [497880/25046 (61%)]\tLoss: 0.126196\n",
            "Train epoch: 478 [603260/25046 (71%)]\tLoss: 0.071166\n",
            "Train epoch: 478 [639360/25046 (82%)]\tLoss: 0.029677\n",
            "Train epoch: 478 [738000/25046 (92%)]\tLoss: 0.062772\n",
            "Make prediction for 5010 samples...\n",
            "0.25321743 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 479 [0/25046 (0%)]\tLoss: 0.072656\n",
            "Train epoch: 479 [81800/25046 (10%)]\tLoss: 0.096820\n",
            "Train epoch: 479 [163920/25046 (20%)]\tLoss: 0.038084\n",
            "Train epoch: 479 [238500/25046 (31%)]\tLoss: 0.020625\n",
            "Train epoch: 479 [332400/25046 (41%)]\tLoss: 0.034794\n",
            "Train epoch: 479 [406100/25046 (51%)]\tLoss: 0.020642\n",
            "Train epoch: 479 [485760/25046 (61%)]\tLoss: 0.037246\n",
            "Train epoch: 479 [583100/25046 (71%)]\tLoss: 0.081030\n",
            "Train epoch: 479 [661920/25046 (82%)]\tLoss: 0.060692\n",
            "Train epoch: 479 [750420/25046 (92%)]\tLoss: 0.049798\n",
            "Make prediction for 5010 samples...\n",
            "0.2505444 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 480 [0/25046 (0%)]\tLoss: 0.025606\n",
            "Train epoch: 480 [81840/25046 (10%)]\tLoss: 0.037265\n",
            "Train epoch: 480 [166960/25046 (20%)]\tLoss: 0.041535\n",
            "Train epoch: 480 [245640/25046 (31%)]\tLoss: 0.055364\n",
            "Train epoch: 480 [331120/25046 (41%)]\tLoss: 0.040850\n",
            "Train epoch: 480 [405800/25046 (51%)]\tLoss: 0.034109\n",
            "Train epoch: 480 [493680/25046 (61%)]\tLoss: 0.076525\n",
            "Train epoch: 480 [570780/25046 (71%)]\tLoss: 0.039976\n",
            "Train epoch: 480 [670240/25046 (82%)]\tLoss: 0.040641\n",
            "Train epoch: 480 [753480/25046 (92%)]\tLoss: 0.022791\n",
            "Make prediction for 5010 samples...\n",
            "0.26217383 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 481 [0/25046 (0%)]\tLoss: 0.096330\n",
            "Train epoch: 481 [81380/25046 (10%)]\tLoss: 0.042339\n",
            "Train epoch: 481 [164400/25046 (20%)]\tLoss: 0.049203\n",
            "Train epoch: 481 [248820/25046 (31%)]\tLoss: 0.068294\n",
            "Train epoch: 481 [329440/25046 (41%)]\tLoss: 0.087324\n",
            "Train epoch: 481 [385100/25046 (51%)]\tLoss: 0.038531\n",
            "Train epoch: 481 [492840/25046 (61%)]\tLoss: 0.052947\n",
            "Train epoch: 481 [562660/25046 (71%)]\tLoss: 0.084395\n",
            "Train epoch: 481 [673280/25046 (82%)]\tLoss: 0.090543\n",
            "Train epoch: 481 [737640/25046 (92%)]\tLoss: 0.050347\n",
            "Make prediction for 5010 samples...\n",
            "0.26009202 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 482 [0/25046 (0%)]\tLoss: 0.028107\n",
            "Train epoch: 482 [80880/25046 (10%)]\tLoss: 0.038395\n",
            "Train epoch: 482 [158840/25046 (20%)]\tLoss: 0.021732\n",
            "Train epoch: 482 [250680/25046 (31%)]\tLoss: 0.018512\n",
            "Train epoch: 482 [331200/25046 (41%)]\tLoss: 0.050961\n",
            "Train epoch: 482 [411000/25046 (51%)]\tLoss: 0.069304\n",
            "Train epoch: 482 [504480/25046 (61%)]\tLoss: 0.051114\n",
            "Train epoch: 482 [557900/25046 (71%)]\tLoss: 0.042843\n",
            "Train epoch: 482 [658560/25046 (82%)]\tLoss: 0.032771\n",
            "Train epoch: 482 [714960/25046 (92%)]\tLoss: 0.044459\n",
            "Make prediction for 5010 samples...\n",
            "0.25132054 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 483 [0/25046 (0%)]\tLoss: 0.025182\n",
            "Train epoch: 483 [83360/25046 (10%)]\tLoss: 0.053938\n",
            "Train epoch: 483 [166440/25046 (20%)]\tLoss: 0.033625\n",
            "Train epoch: 483 [243660/25046 (31%)]\tLoss: 0.041228\n",
            "Train epoch: 483 [339600/25046 (41%)]\tLoss: 0.025861\n",
            "Train epoch: 483 [410200/25046 (51%)]\tLoss: 0.053731\n",
            "Train epoch: 483 [489600/25046 (61%)]\tLoss: 0.021875\n",
            "Train epoch: 483 [570780/25046 (71%)]\tLoss: 0.053618\n",
            "Train epoch: 483 [650880/25046 (82%)]\tLoss: 0.045979\n",
            "Train epoch: 483 [741420/25046 (92%)]\tLoss: 0.058989\n",
            "Make prediction for 5010 samples...\n",
            "0.246892 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 484 [0/25046 (0%)]\tLoss: 0.152785\n",
            "Train epoch: 484 [83060/25046 (10%)]\tLoss: 0.026155\n",
            "Train epoch: 484 [163960/25046 (20%)]\tLoss: 0.044748\n",
            "Train epoch: 484 [241200/25046 (31%)]\tLoss: 0.029733\n",
            "Train epoch: 484 [335680/25046 (41%)]\tLoss: 0.070852\n",
            "Train epoch: 484 [398700/25046 (51%)]\tLoss: 0.029944\n",
            "Train epoch: 484 [496800/25046 (61%)]\tLoss: 0.020356\n",
            "Train epoch: 484 [584500/25046 (71%)]\tLoss: 0.037294\n",
            "Train epoch: 484 [665920/25046 (82%)]\tLoss: 0.026734\n",
            "Train epoch: 484 [746640/25046 (92%)]\tLoss: 0.053088\n",
            "Make prediction for 5010 samples...\n",
            "0.25719446 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 485 [0/25046 (0%)]\tLoss: 0.029768\n",
            "Train epoch: 485 [84260/25046 (10%)]\tLoss: 0.082289\n",
            "Train epoch: 485 [163680/25046 (20%)]\tLoss: 0.048821\n",
            "Train epoch: 485 [241560/25046 (31%)]\tLoss: 0.049309\n",
            "Train epoch: 485 [330720/25046 (41%)]\tLoss: 0.074639\n",
            "Train epoch: 485 [411600/25046 (51%)]\tLoss: 0.049464\n",
            "Train epoch: 485 [510960/25046 (61%)]\tLoss: 0.025339\n",
            "Train epoch: 485 [579180/25046 (71%)]\tLoss: 0.063700\n",
            "Train epoch: 485 [649600/25046 (82%)]\tLoss: 0.025486\n",
            "Train epoch: 485 [728280/25046 (92%)]\tLoss: 0.021969\n",
            "Make prediction for 5010 samples...\n",
            "0.24784225 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 486 [0/25046 (0%)]\tLoss: 0.019830\n",
            "Train epoch: 486 [79460/25046 (10%)]\tLoss: 0.031262\n",
            "Train epoch: 486 [168600/25046 (20%)]\tLoss: 0.020873\n",
            "Train epoch: 486 [236340/25046 (31%)]\tLoss: 0.016919\n",
            "Train epoch: 486 [336960/25046 (41%)]\tLoss: 0.050585\n",
            "Train epoch: 486 [412500/25046 (51%)]\tLoss: 0.023926\n",
            "Train epoch: 486 [489960/25046 (61%)]\tLoss: 0.044002\n",
            "Train epoch: 486 [589540/25046 (71%)]\tLoss: 0.055490\n",
            "Train epoch: 486 [652800/25046 (82%)]\tLoss: 0.086472\n",
            "Train epoch: 486 [738000/25046 (92%)]\tLoss: 0.053956\n",
            "Make prediction for 5010 samples...\n",
            "0.24958487 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 487 [0/25046 (0%)]\tLoss: 0.034601\n",
            "Train epoch: 487 [80320/25046 (10%)]\tLoss: 0.036984\n",
            "Train epoch: 487 [165200/25046 (20%)]\tLoss: 0.053322\n",
            "Train epoch: 487 [244380/25046 (31%)]\tLoss: 0.036274\n",
            "Train epoch: 487 [322560/25046 (41%)]\tLoss: 0.036198\n",
            "Train epoch: 487 [405300/25046 (51%)]\tLoss: 0.058075\n",
            "Train epoch: 487 [497880/25046 (61%)]\tLoss: 0.048419\n",
            "Train epoch: 487 [580300/25046 (71%)]\tLoss: 0.061431\n",
            "Train epoch: 487 [648960/25046 (82%)]\tLoss: 0.032689\n",
            "Train epoch: 487 [739260/25046 (92%)]\tLoss: 0.024139\n",
            "Make prediction for 5010 samples...\n",
            "0.25638512 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 488 [0/25046 (0%)]\tLoss: 0.030620\n",
            "Train epoch: 488 [84380/25046 (10%)]\tLoss: 0.048761\n",
            "Train epoch: 488 [161400/25046 (20%)]\tLoss: 0.035036\n",
            "Train epoch: 488 [249180/25046 (31%)]\tLoss: 0.056416\n",
            "Train epoch: 488 [330320/25046 (41%)]\tLoss: 0.041824\n",
            "Train epoch: 488 [411500/25046 (51%)]\tLoss: 0.044354\n",
            "Train epoch: 488 [487080/25046 (61%)]\tLoss: 0.021476\n",
            "Train epoch: 488 [579460/25046 (71%)]\tLoss: 0.057585\n",
            "Train epoch: 488 [656480/25046 (82%)]\tLoss: 0.040241\n",
            "Train epoch: 488 [738000/25046 (92%)]\tLoss: 0.065157\n",
            "Make prediction for 5010 samples...\n",
            "0.25301093 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 489 [0/25046 (0%)]\tLoss: 0.034972\n",
            "Train epoch: 489 [80400/25046 (10%)]\tLoss: 0.037284\n",
            "Train epoch: 489 [165760/25046 (20%)]\tLoss: 0.019733\n",
            "Train epoch: 489 [251760/25046 (31%)]\tLoss: 0.054641\n",
            "Train epoch: 489 [325040/25046 (41%)]\tLoss: 0.019948\n",
            "Train epoch: 489 [405900/25046 (51%)]\tLoss: 0.030963\n",
            "Train epoch: 489 [490440/25046 (61%)]\tLoss: 0.020476\n",
            "Train epoch: 489 [588840/25046 (71%)]\tLoss: 0.040298\n",
            "Train epoch: 489 [665440/25046 (82%)]\tLoss: 0.089348\n",
            "Train epoch: 489 [734580/25046 (92%)]\tLoss: 0.092122\n",
            "Make prediction for 5010 samples...\n",
            "0.25265345 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 490 [0/25046 (0%)]\tLoss: 0.031462\n",
            "Train epoch: 490 [81440/25046 (10%)]\tLoss: 0.032813\n",
            "Train epoch: 490 [160960/25046 (20%)]\tLoss: 0.037932\n",
            "Train epoch: 490 [237540/25046 (31%)]\tLoss: 0.017050\n",
            "Train epoch: 490 [332960/25046 (41%)]\tLoss: 0.101942\n",
            "Train epoch: 490 [422400/25046 (51%)]\tLoss: 0.028320\n",
            "Train epoch: 490 [504600/25046 (61%)]\tLoss: 0.125844\n",
            "Train epoch: 490 [590100/25046 (71%)]\tLoss: 0.030832\n",
            "Train epoch: 490 [646880/25046 (82%)]\tLoss: 0.042986\n",
            "Train epoch: 490 [727740/25046 (92%)]\tLoss: 0.060974\n",
            "Make prediction for 5010 samples...\n",
            "0.25342026 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 491 [0/25046 (0%)]\tLoss: 0.049801\n",
            "Train epoch: 491 [84200/25046 (10%)]\tLoss: 0.032241\n",
            "Train epoch: 491 [166520/25046 (20%)]\tLoss: 0.022873\n",
            "Train epoch: 491 [246300/25046 (31%)]\tLoss: 0.058831\n",
            "Train epoch: 491 [323840/25046 (41%)]\tLoss: 0.032311\n",
            "Train epoch: 491 [401500/25046 (51%)]\tLoss: 0.072619\n",
            "Train epoch: 491 [492600/25046 (61%)]\tLoss: 0.052720\n",
            "Train epoch: 491 [594440/25046 (71%)]\tLoss: 0.032459\n",
            "Train epoch: 491 [661760/25046 (82%)]\tLoss: 0.082821\n",
            "Train epoch: 491 [730080/25046 (92%)]\tLoss: 0.075882\n",
            "Make prediction for 5010 samples...\n",
            "0.24906395 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 492 [0/25046 (0%)]\tLoss: 0.031662\n",
            "Train epoch: 492 [82260/25046 (10%)]\tLoss: 0.115686\n",
            "Train epoch: 492 [165560/25046 (20%)]\tLoss: 0.039511\n",
            "Train epoch: 492 [241380/25046 (31%)]\tLoss: 0.098485\n",
            "Train epoch: 492 [321920/25046 (41%)]\tLoss: 0.033754\n",
            "Train epoch: 492 [420200/25046 (51%)]\tLoss: 0.021267\n",
            "Train epoch: 492 [502200/25046 (61%)]\tLoss: 0.052312\n",
            "Train epoch: 492 [579740/25046 (71%)]\tLoss: 0.030693\n",
            "Train epoch: 492 [659200/25046 (82%)]\tLoss: 0.036454\n",
            "Train epoch: 492 [745920/25046 (92%)]\tLoss: 0.017796\n",
            "Make prediction for 5010 samples...\n",
            "0.25164977 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 493 [0/25046 (0%)]\tLoss: 0.019639\n",
            "Train epoch: 493 [82220/25046 (10%)]\tLoss: 0.024395\n",
            "Train epoch: 493 [161960/25046 (20%)]\tLoss: 0.025076\n",
            "Train epoch: 493 [243660/25046 (31%)]\tLoss: 0.050152\n",
            "Train epoch: 493 [338640/25046 (41%)]\tLoss: 0.039204\n",
            "Train epoch: 493 [398700/25046 (51%)]\tLoss: 0.026750\n",
            "Train epoch: 493 [490320/25046 (61%)]\tLoss: 0.046201\n",
            "Train epoch: 493 [594720/25046 (71%)]\tLoss: 0.014611\n",
            "Train epoch: 493 [656960/25046 (82%)]\tLoss: 0.056665\n",
            "Train epoch: 493 [738360/25046 (92%)]\tLoss: 0.050701\n",
            "Make prediction for 5010 samples...\n",
            "0.25301585 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 494 [0/25046 (0%)]\tLoss: 0.036254\n",
            "Train epoch: 494 [82640/25046 (10%)]\tLoss: 0.073552\n",
            "Train epoch: 494 [166320/25046 (20%)]\tLoss: 0.045509\n",
            "Train epoch: 494 [252240/25046 (31%)]\tLoss: 0.028016\n",
            "Train epoch: 494 [329760/25046 (41%)]\tLoss: 0.063671\n",
            "Train epoch: 494 [413700/25046 (51%)]\tLoss: 0.191883\n",
            "Train epoch: 494 [498000/25046 (61%)]\tLoss: 0.030298\n",
            "Train epoch: 494 [569800/25046 (71%)]\tLoss: 0.047245\n",
            "Train epoch: 494 [654560/25046 (82%)]\tLoss: 0.023190\n",
            "Train epoch: 494 [742680/25046 (92%)]\tLoss: 0.107135\n",
            "Make prediction for 5010 samples...\n",
            "0.2616665 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 495 [0/25046 (0%)]\tLoss: 0.029212\n",
            "Train epoch: 495 [82920/25046 (10%)]\tLoss: 0.072472\n",
            "Train epoch: 495 [164520/25046 (20%)]\tLoss: 0.087427\n",
            "Train epoch: 495 [239100/25046 (31%)]\tLoss: 0.022174\n",
            "Train epoch: 495 [331440/25046 (41%)]\tLoss: 0.252568\n",
            "Train epoch: 495 [404600/25046 (51%)]\tLoss: 0.084640\n",
            "Train epoch: 495 [490560/25046 (61%)]\tLoss: 0.056124\n",
            "Train epoch: 495 [572180/25046 (71%)]\tLoss: 0.042839\n",
            "Train epoch: 495 [652640/25046 (82%)]\tLoss: 0.054762\n",
            "Train epoch: 495 [725940/25046 (92%)]\tLoss: 0.039407\n",
            "Make prediction for 5010 samples...\n",
            "0.25614834 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 496 [0/25046 (0%)]\tLoss: 0.056669\n",
            "Train epoch: 496 [82360/25046 (10%)]\tLoss: 0.046681\n",
            "Train epoch: 496 [164880/25046 (20%)]\tLoss: 0.030386\n",
            "Train epoch: 496 [246480/25046 (31%)]\tLoss: 0.037211\n",
            "Train epoch: 496 [329600/25046 (41%)]\tLoss: 0.016611\n",
            "Train epoch: 496 [413200/25046 (51%)]\tLoss: 0.026391\n",
            "Train epoch: 496 [495600/25046 (61%)]\tLoss: 0.033514\n",
            "Train epoch: 496 [572180/25046 (71%)]\tLoss: 0.061520\n",
            "Train epoch: 496 [654080/25046 (82%)]\tLoss: 0.030250\n",
            "Train epoch: 496 [744120/25046 (92%)]\tLoss: 0.058725\n",
            "Make prediction for 5010 samples...\n",
            "0.25407672 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 497 [0/25046 (0%)]\tLoss: 0.028346\n",
            "Train epoch: 497 [79680/25046 (10%)]\tLoss: 0.097505\n",
            "Train epoch: 497 [162400/25046 (20%)]\tLoss: 0.021017\n",
            "Train epoch: 497 [246180/25046 (31%)]\tLoss: 0.071602\n",
            "Train epoch: 497 [336880/25046 (41%)]\tLoss: 0.033523\n",
            "Train epoch: 497 [409800/25046 (51%)]\tLoss: 0.032511\n",
            "Train epoch: 497 [500400/25046 (61%)]\tLoss: 0.027435\n",
            "Train epoch: 497 [587160/25046 (71%)]\tLoss: 0.079977\n",
            "Train epoch: 497 [664160/25046 (82%)]\tLoss: 0.066141\n",
            "Train epoch: 497 [741420/25046 (92%)]\tLoss: 0.030037\n",
            "Make prediction for 5010 samples...\n",
            "0.2522771 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 498 [0/25046 (0%)]\tLoss: 0.133749\n",
            "Train epoch: 498 [83020/25046 (10%)]\tLoss: 0.099791\n",
            "Train epoch: 498 [169480/25046 (20%)]\tLoss: 0.042112\n",
            "Train epoch: 498 [240000/25046 (31%)]\tLoss: 0.038409\n",
            "Train epoch: 498 [337840/25046 (41%)]\tLoss: 0.066375\n",
            "Train epoch: 498 [417800/25046 (51%)]\tLoss: 0.026569\n",
            "Train epoch: 498 [506280/25046 (61%)]\tLoss: 0.054672\n",
            "Train epoch: 498 [589540/25046 (71%)]\tLoss: 0.073738\n",
            "Train epoch: 498 [640960/25046 (82%)]\tLoss: 0.031963\n",
            "Train epoch: 498 [753660/25046 (92%)]\tLoss: 0.045055\n",
            "Make prediction for 5010 samples...\n",
            "0.25159135 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 499 [0/25046 (0%)]\tLoss: 0.042081\n",
            "Train epoch: 499 [80980/25046 (10%)]\tLoss: 0.018719\n",
            "Train epoch: 499 [165760/25046 (20%)]\tLoss: 0.037254\n",
            "Train epoch: 499 [253200/25046 (31%)]\tLoss: 0.080230\n",
            "Train epoch: 499 [321040/25046 (41%)]\tLoss: 0.047781\n",
            "Train epoch: 499 [421200/25046 (51%)]\tLoss: 0.049636\n",
            "Train epoch: 499 [497880/25046 (61%)]\tLoss: 0.049994\n",
            "Train epoch: 499 [572320/25046 (71%)]\tLoss: 0.021858\n",
            "Train epoch: 499 [656480/25046 (82%)]\tLoss: 0.047887\n",
            "Train epoch: 499 [751860/25046 (92%)]\tLoss: 0.027042\n",
            "Make prediction for 5010 samples...\n",
            "0.25852624 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 500 [0/25046 (0%)]\tLoss: 0.025985\n",
            "Train epoch: 500 [80080/25046 (10%)]\tLoss: 0.045586\n",
            "Train epoch: 500 [163120/25046 (20%)]\tLoss: 0.060726\n",
            "Train epoch: 500 [246900/25046 (31%)]\tLoss: 0.045310\n",
            "Train epoch: 500 [327840/25046 (41%)]\tLoss: 0.063740\n",
            "Train epoch: 500 [412600/25046 (51%)]\tLoss: 0.056063\n",
            "Train epoch: 500 [474720/25046 (61%)]\tLoss: 0.042803\n",
            "Train epoch: 500 [589680/25046 (71%)]\tLoss: 0.059453\n",
            "Train epoch: 500 [659040/25046 (82%)]\tLoss: 0.035002\n",
            "Train epoch: 500 [756540/25046 (92%)]\tLoss: 0.019514\n",
            "Make prediction for 5010 samples...\n",
            "0.26791874 No improvement since epoch  152 ; best_mse,best_ci: 0.22838666 0.8910389309454588 GATNet davis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training.py 0 1 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp191fRA2mUa",
        "outputId": "438e5f87-bd4a-4878-d705-0db2cec5b34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train epoch: 154 [633020/25046 (79%)]\tLoss: 0.632504\n",
            "Train epoch: 154 [663040/25046 (82%)]\tLoss: 0.542150\n",
            "Train epoch: 154 [698940/25046 (84%)]\tLoss: 0.873960\n",
            "Train epoch: 154 [758880/25046 (87%)]\tLoss: 0.689996\n",
            "Train epoch: 154 [714700/25046 (89%)]\tLoss: 0.830941\n",
            "Train epoch: 154 [736560/25046 (92%)]\tLoss: 0.694505\n",
            "Train epoch: 154 [751840/25046 (95%)]\tLoss: 1.262341\n",
            "Train epoch: 154 [817000/25046 (97%)]\tLoss: 0.859942\n",
            "Train epoch: 154 [833040/25046 (100%)]\tLoss: 0.650608\n",
            "Make prediction for 5010 samples...\n",
            "0.8050461 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 155 [0/25046 (0%)]\tLoss: 0.702057\n",
            "Train epoch: 155 [20520/25046 (3%)]\tLoss: 0.589316\n",
            "Train epoch: 155 [39840/25046 (5%)]\tLoss: 0.256727\n",
            "Train epoch: 155 [60540/25046 (8%)]\tLoss: 0.380912\n",
            "Train epoch: 155 [81280/25046 (10%)]\tLoss: 0.889121\n",
            "Train epoch: 155 [102300/25046 (13%)]\tLoss: 1.095693\n",
            "Train epoch: 155 [124440/25046 (15%)]\tLoss: 0.793772\n",
            "Train epoch: 155 [141120/25046 (18%)]\tLoss: 0.505411\n",
            "Train epoch: 155 [164800/25046 (20%)]\tLoss: 1.324425\n",
            "Train epoch: 155 [189000/25046 (23%)]\tLoss: 0.894638\n",
            "Train epoch: 155 [204000/25046 (26%)]\tLoss: 1.276397\n",
            "Train epoch: 155 [219120/25046 (28%)]\tLoss: 0.721114\n",
            "Train epoch: 155 [234240/25046 (31%)]\tLoss: 0.326281\n",
            "Train epoch: 155 [261560/25046 (33%)]\tLoss: 1.229926\n",
            "Train epoch: 155 [298200/25046 (36%)]\tLoss: 0.898663\n",
            "Train epoch: 155 [305700/25046 (38%)]\tLoss: 0.377653\n",
            "Train epoch: 155 [323200/25046 (41%)]\tLoss: 0.977577\n",
            "Train epoch: 155 [336260/25046 (43%)]\tLoss: 0.992857\n",
            "Train epoch: 155 [360360/25046 (46%)]\tLoss: 1.001123\n",
            "Train epoch: 155 [383420/25046 (49%)]\tLoss: 0.725969\n",
            "Train epoch: 155 [441600/25046 (51%)]\tLoss: 1.045848\n",
            "Train epoch: 155 [460320/25046 (54%)]\tLoss: 0.522508\n",
            "Train epoch: 155 [447920/25046 (56%)]\tLoss: 0.774966\n",
            "Train epoch: 155 [466900/25046 (59%)]\tLoss: 0.431437\n",
            "Train epoch: 155 [487680/25046 (61%)]\tLoss: 1.133571\n",
            "Train epoch: 155 [547500/25046 (64%)]\tLoss: 0.785205\n",
            "Train epoch: 155 [558480/25046 (66%)]\tLoss: 0.324794\n",
            "Train epoch: 155 [536760/25046 (69%)]\tLoss: 0.387980\n",
            "Train epoch: 155 [597520/25046 (72%)]\tLoss: 1.205061\n",
            "Train epoch: 155 [571880/25046 (74%)]\tLoss: 0.335793\n",
            "Train epoch: 155 [604200/25046 (77%)]\tLoss: 0.705070\n",
            "Train epoch: 155 [636740/25046 (79%)]\tLoss: 1.118655\n",
            "Train epoch: 155 [683520/25046 (82%)]\tLoss: 1.150054\n",
            "Train epoch: 155 [679140/25046 (84%)]\tLoss: 0.506811\n",
            "Train epoch: 155 [687480/25046 (87%)]\tLoss: 1.911911\n",
            "Train epoch: 155 [759500/25046 (89%)]\tLoss: 1.219926\n",
            "Train epoch: 155 [703440/25046 (92%)]\tLoss: 0.600174\n",
            "Train epoch: 155 [788100/25046 (95%)]\tLoss: 0.251673\n",
            "Train epoch: 155 [802560/25046 (97%)]\tLoss: 1.087730\n",
            "Train epoch: 155 [779220/25046 (100%)]\tLoss: 1.370949\n",
            "Make prediction for 5010 samples...\n",
            "0.8017303 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 156 [0/25046 (0%)]\tLoss: 0.599236\n",
            "Train epoch: 156 [20640/25046 (3%)]\tLoss: 1.703517\n",
            "Train epoch: 156 [43720/25046 (5%)]\tLoss: 0.693738\n",
            "Train epoch: 156 [62100/25046 (8%)]\tLoss: 0.618070\n",
            "Train epoch: 156 [79920/25046 (10%)]\tLoss: 0.926343\n",
            "Train epoch: 156 [102700/25046 (13%)]\tLoss: 0.619423\n",
            "Train epoch: 156 [121680/25046 (15%)]\tLoss: 0.726974\n",
            "Train epoch: 156 [144060/25046 (18%)]\tLoss: 0.760482\n",
            "Train epoch: 156 [156160/25046 (20%)]\tLoss: 0.801553\n",
            "Train epoch: 156 [178380/25046 (23%)]\tLoss: 0.745021\n",
            "Train epoch: 156 [213000/25046 (26%)]\tLoss: 1.021200\n",
            "Train epoch: 156 [208780/25046 (28%)]\tLoss: 1.121118\n",
            "Train epoch: 156 [241440/25046 (31%)]\tLoss: 0.837707\n",
            "Train epoch: 156 [284960/25046 (33%)]\tLoss: 0.683754\n",
            "Train epoch: 156 [283920/25046 (36%)]\tLoss: 0.800495\n",
            "Train epoch: 156 [305100/25046 (38%)]\tLoss: 1.419357\n",
            "Train epoch: 156 [345920/25046 (41%)]\tLoss: 0.276505\n",
            "Train epoch: 156 [345780/25046 (43%)]\tLoss: 0.713485\n",
            "Train epoch: 156 [387000/25046 (46%)]\tLoss: 0.755111\n",
            "Train epoch: 156 [407740/25046 (49%)]\tLoss: 1.223499\n",
            "Train epoch: 156 [384400/25046 (51%)]\tLoss: 0.987431\n",
            "Train epoch: 156 [429660/25046 (54%)]\tLoss: 0.379603\n",
            "Train epoch: 156 [443960/25046 (56%)]\tLoss: 0.318748\n",
            "Train epoch: 156 [480700/25046 (59%)]\tLoss: 1.095164\n",
            "Train epoch: 156 [481440/25046 (61%)]\tLoss: 0.586601\n",
            "Train epoch: 156 [504500/25046 (64%)]\tLoss: 0.433871\n",
            "Train epoch: 156 [534560/25046 (66%)]\tLoss: 0.509298\n",
            "Train epoch: 156 [547560/25046 (69%)]\tLoss: 0.407018\n",
            "Train epoch: 156 [581840/25046 (72%)]\tLoss: 0.824988\n",
            "Train epoch: 156 [595660/25046 (74%)]\tLoss: 1.398880\n",
            "Train epoch: 156 [635400/25046 (77%)]\tLoss: 0.705053\n",
            "Train epoch: 156 [647900/25046 (79%)]\tLoss: 0.549996\n",
            "Train epoch: 156 [626560/25046 (82%)]\tLoss: 0.344604\n",
            "Train epoch: 156 [691020/25046 (84%)]\tLoss: 1.631825\n",
            "Train epoch: 156 [738480/25046 (87%)]\tLoss: 0.864933\n",
            "Train epoch: 156 [700000/25046 (89%)]\tLoss: 0.568502\n",
            "Train epoch: 156 [735120/25046 (92%)]\tLoss: 0.400574\n",
            "Train epoch: 156 [757760/25046 (95%)]\tLoss: 0.840558\n",
            "Train epoch: 156 [739480/25046 (97%)]\tLoss: 0.450470\n",
            "Train epoch: 156 [839280/25046 (100%)]\tLoss: 1.301147\n",
            "Make prediction for 5010 samples...\n",
            "0.809755 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 157 [0/25046 (0%)]\tLoss: 1.356370\n",
            "Train epoch: 157 [20240/25046 (3%)]\tLoss: 0.413269\n",
            "Train epoch: 157 [42200/25046 (5%)]\tLoss: 0.689252\n",
            "Train epoch: 157 [61680/25046 (8%)]\tLoss: 0.489182\n",
            "Train epoch: 157 [81760/25046 (10%)]\tLoss: 0.647825\n",
            "Train epoch: 157 [99600/25046 (13%)]\tLoss: 0.472772\n",
            "Train epoch: 157 [124440/25046 (15%)]\tLoss: 0.567137\n",
            "Train epoch: 157 [149240/25046 (18%)]\tLoss: 1.138121\n",
            "Train epoch: 157 [172160/25046 (20%)]\tLoss: 1.509238\n",
            "Train epoch: 157 [192960/25046 (23%)]\tLoss: 1.155570\n",
            "Train epoch: 157 [202600/25046 (26%)]\tLoss: 1.192018\n",
            "Train epoch: 157 [229680/25046 (28%)]\tLoss: 0.711822\n",
            "Train epoch: 157 [243360/25046 (31%)]\tLoss: 1.171667\n",
            "Train epoch: 157 [267280/25046 (33%)]\tLoss: 1.037942\n",
            "Train epoch: 157 [293160/25046 (36%)]\tLoss: 1.239699\n",
            "Train epoch: 157 [297900/25046 (38%)]\tLoss: 1.533994\n",
            "Train epoch: 157 [317440/25046 (41%)]\tLoss: 0.354985\n",
            "Train epoch: 157 [341020/25046 (43%)]\tLoss: 0.345822\n",
            "Train epoch: 157 [389520/25046 (46%)]\tLoss: 0.844448\n",
            "Train epoch: 157 [397480/25046 (49%)]\tLoss: 0.595801\n",
            "Train epoch: 157 [415600/25046 (51%)]\tLoss: 0.605730\n",
            "Train epoch: 157 [434280/25046 (54%)]\tLoss: 0.441338\n",
            "Train epoch: 157 [443520/25046 (56%)]\tLoss: 0.658616\n",
            "Train epoch: 157 [471500/25046 (59%)]\tLoss: 1.116650\n",
            "Train epoch: 157 [483360/25046 (61%)]\tLoss: 0.324971\n",
            "Train epoch: 157 [532000/25046 (64%)]\tLoss: 1.043706\n",
            "Train epoch: 157 [548080/25046 (66%)]\tLoss: 0.650956\n",
            "Train epoch: 157 [562680/25046 (69%)]\tLoss: 1.168595\n",
            "Train epoch: 157 [575680/25046 (72%)]\tLoss: 0.560726\n",
            "Train epoch: 157 [599140/25046 (74%)]\tLoss: 0.489930\n",
            "Train epoch: 157 [606000/25046 (77%)]\tLoss: 1.535197\n",
            "Train epoch: 157 [598920/25046 (79%)]\tLoss: 0.481750\n",
            "Train epoch: 157 [636800/25046 (82%)]\tLoss: 1.256312\n",
            "Train epoch: 157 [663960/25046 (84%)]\tLoss: 0.608212\n",
            "Train epoch: 157 [716040/25046 (87%)]\tLoss: 0.371246\n",
            "Train epoch: 157 [746900/25046 (89%)]\tLoss: 1.219716\n",
            "Train epoch: 157 [745200/25046 (92%)]\tLoss: 0.278682\n",
            "Train epoch: 157 [779220/25046 (95%)]\tLoss: 0.256566\n",
            "Train epoch: 157 [801800/25046 (97%)]\tLoss: 0.783167\n",
            "Train epoch: 157 [770640/25046 (100%)]\tLoss: 0.611586\n",
            "Make prediction for 5010 samples...\n",
            "0.80152357 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 158 [0/25046 (0%)]\tLoss: 1.795867\n",
            "Train epoch: 158 [20140/25046 (3%)]\tLoss: 0.678782\n",
            "Train epoch: 158 [43920/25046 (5%)]\tLoss: 0.397876\n",
            "Train epoch: 158 [62520/25046 (8%)]\tLoss: 0.978829\n",
            "Train epoch: 158 [79200/25046 (10%)]\tLoss: 0.490895\n",
            "Train epoch: 158 [99100/25046 (13%)]\tLoss: 0.442417\n",
            "Train epoch: 158 [118440/25046 (15%)]\tLoss: 0.612609\n",
            "Train epoch: 158 [146720/25046 (18%)]\tLoss: 0.938594\n",
            "Train epoch: 158 [160160/25046 (20%)]\tLoss: 0.733403\n",
            "Train epoch: 158 [182520/25046 (23%)]\tLoss: 0.650559\n",
            "Train epoch: 158 [196600/25046 (26%)]\tLoss: 0.827642\n",
            "Train epoch: 158 [229020/25046 (28%)]\tLoss: 1.778716\n",
            "Train epoch: 158 [255360/25046 (31%)]\tLoss: 1.353738\n",
            "Train epoch: 158 [268580/25046 (33%)]\tLoss: 1.826681\n",
            "Train epoch: 158 [290640/25046 (36%)]\tLoss: 0.476602\n",
            "Train epoch: 158 [313800/25046 (38%)]\tLoss: 0.737799\n",
            "Train epoch: 158 [343680/25046 (41%)]\tLoss: 1.647940\n",
            "Train epoch: 158 [386240/25046 (43%)]\tLoss: 0.958901\n",
            "Train epoch: 158 [375840/25046 (46%)]\tLoss: 0.970917\n",
            "Train epoch: 158 [389500/25046 (49%)]\tLoss: 1.181643\n",
            "Train epoch: 158 [410800/25046 (51%)]\tLoss: 0.550084\n",
            "Train epoch: 158 [427560/25046 (54%)]\tLoss: 1.529015\n",
            "Train epoch: 158 [467720/25046 (56%)]\tLoss: 0.578562\n",
            "Train epoch: 158 [480700/25046 (59%)]\tLoss: 0.164020\n",
            "Train epoch: 158 [497760/25046 (61%)]\tLoss: 0.369618\n",
            "Train epoch: 158 [477000/25046 (64%)]\tLoss: 0.868321\n",
            "Train epoch: 158 [534560/25046 (66%)]\tLoss: 0.594146\n",
            "Train epoch: 158 [534060/25046 (69%)]\tLoss: 0.387044\n",
            "Train epoch: 158 [594160/25046 (72%)]\tLoss: 0.491965\n",
            "Train epoch: 158 [581740/25046 (74%)]\tLoss: 0.525596\n",
            "Train epoch: 158 [651000/25046 (77%)]\tLoss: 0.828177\n",
            "Train epoch: 158 [623100/25046 (79%)]\tLoss: 0.794825\n",
            "Train epoch: 158 [664960/25046 (82%)]\tLoss: 0.359092\n",
            "Train epoch: 158 [669240/25046 (84%)]\tLoss: 0.309585\n",
            "Train epoch: 158 [671160/25046 (87%)]\tLoss: 0.910405\n",
            "Train epoch: 158 [674800/25046 (89%)]\tLoss: 0.768467\n",
            "Train epoch: 158 [726480/25046 (92%)]\tLoss: 1.165898\n",
            "Train epoch: 158 [758500/25046 (95%)]\tLoss: 0.419890\n",
            "Train epoch: 158 [781280/25046 (97%)]\tLoss: 0.917939\n",
            "Train epoch: 158 [764400/25046 (100%)]\tLoss: 0.557959\n",
            "Make prediction for 5010 samples...\n",
            "0.80318844 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 159 [0/25046 (0%)]\tLoss: 0.507213\n",
            "Train epoch: 159 [21160/25046 (3%)]\tLoss: 1.214135\n",
            "Train epoch: 159 [41400/25046 (5%)]\tLoss: 1.055073\n",
            "Train epoch: 159 [60600/25046 (8%)]\tLoss: 0.330300\n",
            "Train epoch: 159 [86480/25046 (10%)]\tLoss: 0.814897\n",
            "Train epoch: 159 [102600/25046 (13%)]\tLoss: 1.106725\n",
            "Train epoch: 159 [125160/25046 (15%)]\tLoss: 0.880619\n",
            "Train epoch: 159 [150220/25046 (18%)]\tLoss: 0.630403\n",
            "Train epoch: 159 [161440/25046 (20%)]\tLoss: 0.388884\n",
            "Train epoch: 159 [188460/25046 (23%)]\tLoss: 0.357754\n",
            "Train epoch: 159 [202200/25046 (26%)]\tLoss: 0.898623\n",
            "Train epoch: 159 [218680/25046 (28%)]\tLoss: 0.483484\n",
            "Train epoch: 159 [238320/25046 (31%)]\tLoss: 1.166723\n",
            "Train epoch: 159 [268580/25046 (33%)]\tLoss: 0.393823\n",
            "Train epoch: 159 [278040/25046 (36%)]\tLoss: 0.522887\n",
            "Train epoch: 159 [310200/25046 (38%)]\tLoss: 1.199231\n",
            "Train epoch: 159 [323200/25046 (41%)]\tLoss: 0.207815\n",
            "Train epoch: 159 [348840/25046 (43%)]\tLoss: 0.720643\n",
            "Train epoch: 159 [365040/25046 (46%)]\tLoss: 1.369840\n",
            "Train epoch: 159 [388360/25046 (49%)]\tLoss: 0.874498\n",
            "Train epoch: 159 [407200/25046 (51%)]\tLoss: 0.839221\n",
            "Train epoch: 159 [422100/25046 (54%)]\tLoss: 1.212499\n",
            "Train epoch: 159 [462000/25046 (56%)]\tLoss: 0.446666\n",
            "Train epoch: 159 [474720/25046 (59%)]\tLoss: 0.789371\n",
            "Train epoch: 159 [510720/25046 (61%)]\tLoss: 1.315530\n",
            "Train epoch: 159 [505500/25046 (64%)]\tLoss: 0.840432\n",
            "Train epoch: 159 [527800/25046 (66%)]\tLoss: 0.935611\n",
            "Train epoch: 159 [544860/25046 (69%)]\tLoss: 1.099441\n",
            "Train epoch: 159 [554400/25046 (72%)]\tLoss: 0.943240\n",
            "Train epoch: 159 [597400/25046 (74%)]\tLoss: 0.459348\n",
            "Train epoch: 159 [595800/25046 (77%)]\tLoss: 0.662963\n",
            "Train epoch: 159 [648520/25046 (79%)]\tLoss: 0.433797\n",
            "Train epoch: 159 [654080/25046 (82%)]\tLoss: 0.937364\n",
            "Train epoch: 159 [716760/25046 (84%)]\tLoss: 0.630493\n",
            "Train epoch: 159 [735760/25046 (87%)]\tLoss: 0.454365\n",
            "Train epoch: 159 [727300/25046 (89%)]\tLoss: 1.883536\n",
            "Train epoch: 159 [786960/25046 (92%)]\tLoss: 1.411092\n",
            "Train epoch: 159 [780700/25046 (95%)]\tLoss: 1.152717\n",
            "Train epoch: 159 [742520/25046 (97%)]\tLoss: 0.621607\n",
            "Train epoch: 159 [833820/25046 (100%)]\tLoss: 0.557773\n",
            "Make prediction for 5010 samples...\n",
            "0.8015627 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 160 [0/25046 (0%)]\tLoss: 0.493903\n",
            "Train epoch: 160 [20160/25046 (3%)]\tLoss: 0.413891\n",
            "Train epoch: 160 [42080/25046 (5%)]\tLoss: 0.423567\n",
            "Train epoch: 160 [65100/25046 (8%)]\tLoss: 0.236831\n",
            "Train epoch: 160 [77920/25046 (10%)]\tLoss: 0.874270\n",
            "Train epoch: 160 [101900/25046 (13%)]\tLoss: 0.487335\n",
            "Train epoch: 160 [120600/25046 (15%)]\tLoss: 2.128809\n",
            "Train epoch: 160 [139860/25046 (18%)]\tLoss: 0.823033\n",
            "Train epoch: 160 [166400/25046 (20%)]\tLoss: 1.413887\n",
            "Train epoch: 160 [190800/25046 (23%)]\tLoss: 0.774296\n",
            "Train epoch: 160 [211800/25046 (26%)]\tLoss: 0.693587\n",
            "Train epoch: 160 [226600/25046 (28%)]\tLoss: 1.070057\n",
            "Train epoch: 160 [240720/25046 (31%)]\tLoss: 0.584968\n",
            "Train epoch: 160 [266500/25046 (33%)]\tLoss: 0.501716\n",
            "Train epoch: 160 [287840/25046 (36%)]\tLoss: 1.190719\n",
            "Train epoch: 160 [296400/25046 (38%)]\tLoss: 0.806602\n",
            "Train epoch: 160 [341440/25046 (41%)]\tLoss: 0.827078\n",
            "Train epoch: 160 [355300/25046 (43%)]\tLoss: 0.985198\n",
            "Train epoch: 160 [384480/25046 (46%)]\tLoss: 0.727063\n",
            "Train epoch: 160 [375060/25046 (49%)]\tLoss: 0.529489\n",
            "Train epoch: 160 [407200/25046 (51%)]\tLoss: 0.562452\n",
            "Train epoch: 160 [404880/25046 (54%)]\tLoss: 0.969124\n",
            "Train epoch: 160 [434280/25046 (56%)]\tLoss: 0.673411\n",
            "Train epoch: 160 [475180/25046 (59%)]\tLoss: 0.764273\n",
            "Train epoch: 160 [467520/25046 (61%)]\tLoss: 0.900760\n",
            "Train epoch: 160 [510000/25046 (64%)]\tLoss: 0.728902\n",
            "Train epoch: 160 [574080/25046 (66%)]\tLoss: 0.639259\n",
            "Train epoch: 160 [529740/25046 (69%)]\tLoss: 0.541929\n",
            "Train epoch: 160 [588560/25046 (72%)]\tLoss: 0.781958\n",
            "Train epoch: 160 [624080/25046 (74%)]\tLoss: 0.824858\n",
            "Train epoch: 160 [614400/25046 (77%)]\tLoss: 0.477558\n",
            "Train epoch: 160 [644180/25046 (79%)]\tLoss: 1.464587\n",
            "Train epoch: 160 [640640/25046 (82%)]\tLoss: 0.599467\n",
            "Train epoch: 160 [636900/25046 (84%)]\tLoss: 0.510477\n",
            "Train epoch: 160 [703800/25046 (87%)]\tLoss: 0.883027\n",
            "Train epoch: 160 [697200/25046 (89%)]\tLoss: 0.888619\n",
            "Train epoch: 160 [752400/25046 (92%)]\tLoss: 0.970731\n",
            "Train epoch: 160 [728900/25046 (95%)]\tLoss: 0.505898\n",
            "Train epoch: 160 [779000/25046 (97%)]\tLoss: 1.451869\n",
            "Train epoch: 160 [783900/25046 (100%)]\tLoss: 0.972370\n",
            "Make prediction for 5010 samples...\n",
            "0.8019813 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 161 [0/25046 (0%)]\tLoss: 1.002959\n",
            "Train epoch: 161 [20420/25046 (3%)]\tLoss: 0.887253\n",
            "Train epoch: 161 [44480/25046 (5%)]\tLoss: 0.712528\n",
            "Train epoch: 161 [59760/25046 (8%)]\tLoss: 0.687096\n",
            "Train epoch: 161 [80720/25046 (10%)]\tLoss: 0.600750\n",
            "Train epoch: 161 [101400/25046 (13%)]\tLoss: 0.207591\n",
            "Train epoch: 161 [121560/25046 (15%)]\tLoss: 0.419116\n",
            "Train epoch: 161 [143780/25046 (18%)]\tLoss: 0.805573\n",
            "Train epoch: 161 [166400/25046 (20%)]\tLoss: 1.147258\n",
            "Train epoch: 161 [181080/25046 (23%)]\tLoss: 0.503697\n",
            "Train epoch: 161 [196600/25046 (26%)]\tLoss: 0.946813\n",
            "Train epoch: 161 [230340/25046 (28%)]\tLoss: 0.461869\n",
            "Train epoch: 161 [251520/25046 (31%)]\tLoss: 0.615418\n",
            "Train epoch: 161 [262860/25046 (33%)]\tLoss: 0.470642\n",
            "Train epoch: 161 [281680/25046 (36%)]\tLoss: 1.088813\n",
            "Train epoch: 161 [297600/25046 (38%)]\tLoss: 1.039543\n",
            "Train epoch: 161 [320640/25046 (41%)]\tLoss: 0.825055\n",
            "Train epoch: 161 [348500/25046 (43%)]\tLoss: 0.905684\n",
            "Train epoch: 161 [372960/25046 (46%)]\tLoss: 0.665786\n",
            "Train epoch: 161 [383420/25046 (49%)]\tLoss: 0.649489\n",
            "Train epoch: 161 [424000/25046 (51%)]\tLoss: 1.172493\n",
            "Train epoch: 161 [427980/25046 (54%)]\tLoss: 1.184310\n",
            "Train epoch: 161 [435600/25046 (56%)]\tLoss: 0.467595\n",
            "Train epoch: 161 [448960/25046 (59%)]\tLoss: 0.526447\n",
            "Train epoch: 161 [484800/25046 (61%)]\tLoss: 0.585552\n",
            "Train epoch: 161 [534500/25046 (64%)]\tLoss: 0.381635\n",
            "Train epoch: 161 [504400/25046 (66%)]\tLoss: 1.019936\n",
            "Train epoch: 161 [547020/25046 (69%)]\tLoss: 1.187351\n",
            "Train epoch: 161 [600320/25046 (72%)]\tLoss: 0.913875\n",
            "Train epoch: 161 [591020/25046 (74%)]\tLoss: 0.354808\n",
            "Train epoch: 161 [558000/25046 (77%)]\tLoss: 0.685694\n",
            "Train epoch: 161 [613180/25046 (79%)]\tLoss: 0.929967\n",
            "Train epoch: 161 [673920/25046 (82%)]\tLoss: 0.931194\n",
            "Train epoch: 161 [672540/25046 (84%)]\tLoss: 1.334148\n",
            "Train epoch: 161 [680000/25046 (87%)]\tLoss: 0.868695\n",
            "Train epoch: 161 [711900/25046 (89%)]\tLoss: 0.627190\n",
            "Train epoch: 161 [725760/25046 (92%)]\tLoss: 1.216184\n",
            "Train epoch: 161 [760720/25046 (95%)]\tLoss: 0.525965\n",
            "Train epoch: 161 [799520/25046 (97%)]\tLoss: 0.836392\n",
            "Train epoch: 161 [827580/25046 (100%)]\tLoss: 0.808527\n",
            "Make prediction for 5010 samples...\n",
            "0.801586 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 162 [0/25046 (0%)]\tLoss: 0.472960\n",
            "Train epoch: 162 [20020/25046 (3%)]\tLoss: 0.583564\n",
            "Train epoch: 162 [41600/25046 (5%)]\tLoss: 0.823677\n",
            "Train epoch: 162 [63300/25046 (8%)]\tLoss: 1.222799\n",
            "Train epoch: 162 [83520/25046 (10%)]\tLoss: 0.861746\n",
            "Train epoch: 162 [103900/25046 (13%)]\tLoss: 1.215351\n",
            "Train epoch: 162 [119040/25046 (15%)]\tLoss: 0.555242\n",
            "Train epoch: 162 [137060/25046 (18%)]\tLoss: 0.545751\n",
            "Train epoch: 162 [162400/25046 (20%)]\tLoss: 0.755082\n",
            "Train epoch: 162 [188280/25046 (23%)]\tLoss: 1.088965\n",
            "Train epoch: 162 [201600/25046 (26%)]\tLoss: 0.654274\n",
            "Train epoch: 162 [234080/25046 (28%)]\tLoss: 0.777402\n",
            "Train epoch: 162 [245280/25046 (31%)]\tLoss: 0.288453\n",
            "Train epoch: 162 [247000/25046 (33%)]\tLoss: 0.430612\n",
            "Train epoch: 162 [286160/25046 (36%)]\tLoss: 0.457542\n",
            "Train epoch: 162 [312900/25046 (38%)]\tLoss: 0.728440\n",
            "Train epoch: 162 [336320/25046 (41%)]\tLoss: 1.013797\n",
            "Train epoch: 162 [372640/25046 (43%)]\tLoss: 1.247970\n",
            "Train epoch: 162 [369720/25046 (46%)]\tLoss: 0.903589\n",
            "Train epoch: 162 [377340/25046 (49%)]\tLoss: 1.271466\n",
            "Train epoch: 162 [402800/25046 (51%)]\tLoss: 1.019404\n",
            "Train epoch: 162 [431760/25046 (54%)]\tLoss: 0.634057\n",
            "Train epoch: 162 [460680/25046 (56%)]\tLoss: 0.717186\n",
            "Train epoch: 162 [451260/25046 (59%)]\tLoss: 0.449471\n",
            "Train epoch: 162 [462240/25046 (61%)]\tLoss: 0.875386\n",
            "Train epoch: 162 [540500/25046 (64%)]\tLoss: 0.990640\n",
            "Train epoch: 162 [508560/25046 (66%)]\tLoss: 0.690792\n",
            "Train epoch: 162 [543780/25046 (69%)]\tLoss: 0.694709\n",
            "Train epoch: 162 [580720/25046 (72%)]\tLoss: 0.599208\n",
            "Train epoch: 162 [594500/25046 (74%)]\tLoss: 0.280560\n",
            "Train epoch: 162 [607200/25046 (77%)]\tLoss: 0.508681\n",
            "Train epoch: 162 [626820/25046 (79%)]\tLoss: 0.443178\n",
            "Train epoch: 162 [615680/25046 (82%)]\tLoss: 0.571361\n",
            "Train epoch: 162 [675840/25046 (84%)]\tLoss: 0.918317\n",
            "Train epoch: 162 [710600/25046 (87%)]\tLoss: 0.518352\n",
            "Train epoch: 162 [712600/25046 (89%)]\tLoss: 0.889416\n",
            "Train epoch: 162 [753120/25046 (92%)]\tLoss: 0.348603\n",
            "Train epoch: 162 [774040/25046 (95%)]\tLoss: 1.498684\n",
            "Train epoch: 162 [779760/25046 (97%)]\tLoss: 0.700623\n",
            "Train epoch: 162 [809640/25046 (100%)]\tLoss: 0.486479\n",
            "Make prediction for 5010 samples...\n",
            "0.80244356 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 163 [0/25046 (0%)]\tLoss: 0.299119\n",
            "Train epoch: 163 [20540/25046 (3%)]\tLoss: 0.804297\n",
            "Train epoch: 163 [37960/25046 (5%)]\tLoss: 0.333225\n",
            "Train epoch: 163 [59520/25046 (8%)]\tLoss: 0.550034\n",
            "Train epoch: 163 [79360/25046 (10%)]\tLoss: 1.091119\n",
            "Train epoch: 163 [101500/25046 (13%)]\tLoss: 0.323789\n",
            "Train epoch: 163 [126120/25046 (15%)]\tLoss: 0.615893\n",
            "Train epoch: 163 [141680/25046 (18%)]\tLoss: 1.048686\n",
            "Train epoch: 163 [166720/25046 (20%)]\tLoss: 0.805052\n",
            "Train epoch: 163 [192420/25046 (23%)]\tLoss: 0.610049\n",
            "Train epoch: 163 [190200/25046 (26%)]\tLoss: 0.459465\n",
            "Train epoch: 163 [221100/25046 (28%)]\tLoss: 0.322715\n",
            "Train epoch: 163 [235920/25046 (31%)]\tLoss: 0.537560\n",
            "Train epoch: 163 [258960/25046 (33%)]\tLoss: 0.495116\n",
            "Train epoch: 163 [283360/25046 (36%)]\tLoss: 0.629346\n",
            "Train epoch: 163 [310800/25046 (38%)]\tLoss: 1.355217\n",
            "Train epoch: 163 [335680/25046 (41%)]\tLoss: 0.670034\n",
            "Train epoch: 163 [339660/25046 (43%)]\tLoss: 0.832524\n",
            "Train epoch: 163 [369000/25046 (46%)]\tLoss: 0.910259\n",
            "Train epoch: 163 [410780/25046 (49%)]\tLoss: 0.800731\n",
            "Train epoch: 163 [422000/25046 (51%)]\tLoss: 0.833561\n",
            "Train epoch: 163 [433440/25046 (54%)]\tLoss: 0.546222\n",
            "Train epoch: 163 [436480/25046 (56%)]\tLoss: 0.386912\n",
            "Train epoch: 163 [485300/25046 (59%)]\tLoss: 1.085299\n",
            "Train epoch: 163 [515520/25046 (61%)]\tLoss: 0.855791\n",
            "Train epoch: 163 [521000/25046 (64%)]\tLoss: 0.497159\n",
            "Train epoch: 163 [510120/25046 (66%)]\tLoss: 0.626267\n",
            "Train epoch: 163 [511920/25046 (69%)]\tLoss: 0.621828\n",
            "Train epoch: 163 [571760/25046 (72%)]\tLoss: 0.926784\n",
            "Train epoch: 163 [604360/25046 (74%)]\tLoss: 0.920311\n",
            "Train epoch: 163 [631800/25046 (77%)]\tLoss: 0.608815\n",
            "Train epoch: 163 [642320/25046 (79%)]\tLoss: 0.663363\n",
            "Train epoch: 163 [660480/25046 (82%)]\tLoss: 0.657641\n",
            "Train epoch: 163 [670560/25046 (84%)]\tLoss: 1.316172\n",
            "Train epoch: 163 [718760/25046 (87%)]\tLoss: 1.178462\n",
            "Train epoch: 163 [697200/25046 (89%)]\tLoss: 0.731731\n",
            "Train epoch: 163 [761760/25046 (92%)]\tLoss: 0.887243\n",
            "Train epoch: 163 [768860/25046 (95%)]\tLoss: 0.737694\n",
            "Train epoch: 163 [794960/25046 (97%)]\tLoss: 0.459878\n",
            "Train epoch: 163 [790140/25046 (100%)]\tLoss: 0.654137\n",
            "Make prediction for 5010 samples...\n",
            "0.8041504 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 164 [0/25046 (0%)]\tLoss: 0.583589\n",
            "Train epoch: 164 [20080/25046 (3%)]\tLoss: 1.254998\n",
            "Train epoch: 164 [40520/25046 (5%)]\tLoss: 1.718428\n",
            "Train epoch: 164 [58800/25046 (8%)]\tLoss: 0.999960\n",
            "Train epoch: 164 [83760/25046 (10%)]\tLoss: 0.855542\n",
            "Train epoch: 164 [104500/25046 (13%)]\tLoss: 1.011542\n",
            "Train epoch: 164 [118800/25046 (15%)]\tLoss: 0.622198\n",
            "Train epoch: 164 [140140/25046 (18%)]\tLoss: 0.673226\n",
            "Train epoch: 164 [163200/25046 (20%)]\tLoss: 0.879819\n",
            "Train epoch: 164 [180900/25046 (23%)]\tLoss: 0.902138\n",
            "Train epoch: 164 [192200/25046 (26%)]\tLoss: 0.635155\n",
            "Train epoch: 164 [217580/25046 (28%)]\tLoss: 0.515450\n",
            "Train epoch: 164 [238320/25046 (31%)]\tLoss: 0.777089\n",
            "Train epoch: 164 [257920/25046 (33%)]\tLoss: 0.533648\n",
            "Train epoch: 164 [254240/25046 (36%)]\tLoss: 0.243357\n",
            "Train epoch: 164 [294300/25046 (38%)]\tLoss: 0.759899\n",
            "Train epoch: 164 [322560/25046 (41%)]\tLoss: 0.896608\n",
            "Train epoch: 164 [334900/25046 (43%)]\tLoss: 0.944347\n",
            "Train epoch: 164 [361800/25046 (46%)]\tLoss: 0.436596\n",
            "Train epoch: 164 [399000/25046 (49%)]\tLoss: 1.765810\n",
            "Train epoch: 164 [422800/25046 (51%)]\tLoss: 1.324446\n",
            "Train epoch: 164 [411600/25046 (54%)]\tLoss: 0.493234\n",
            "Train epoch: 164 [432080/25046 (56%)]\tLoss: 0.587290\n",
            "Train epoch: 164 [477940/25046 (59%)]\tLoss: 0.460566\n",
            "Train epoch: 164 [475200/25046 (61%)]\tLoss: 1.592725\n",
            "Train epoch: 164 [553500/25046 (64%)]\tLoss: 0.975299\n",
            "Train epoch: 164 [586560/25046 (66%)]\tLoss: 0.740899\n",
            "Train epoch: 164 [536220/25046 (69%)]\tLoss: 1.479561\n",
            "Train epoch: 164 [565040/25046 (72%)]\tLoss: 0.601081\n",
            "Train epoch: 164 [578260/25046 (74%)]\tLoss: 0.483391\n",
            "Train epoch: 164 [596400/25046 (77%)]\tLoss: 0.871207\n",
            "Train epoch: 164 [606980/25046 (79%)]\tLoss: 0.639070\n",
            "Train epoch: 164 [664960/25046 (82%)]\tLoss: 0.921475\n",
            "Train epoch: 164 [667920/25046 (84%)]\tLoss: 0.468545\n",
            "Train epoch: 164 [684760/25046 (87%)]\tLoss: 0.591395\n",
            "Train epoch: 164 [712600/25046 (89%)]\tLoss: 0.594728\n",
            "Train epoch: 164 [714960/25046 (92%)]\tLoss: 0.691400\n",
            "Train epoch: 164 [766640/25046 (95%)]\tLoss: 1.107241\n",
            "Train epoch: 164 [762280/25046 (97%)]\tLoss: 1.283100\n",
            "Train epoch: 164 [828360/25046 (100%)]\tLoss: 1.454314\n",
            "Make prediction for 5010 samples...\n",
            "0.8053143 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 165 [0/25046 (0%)]\tLoss: 0.468179\n",
            "Train epoch: 165 [22160/25046 (3%)]\tLoss: 0.774757\n",
            "Train epoch: 165 [41200/25046 (5%)]\tLoss: 0.599596\n",
            "Train epoch: 165 [64080/25046 (8%)]\tLoss: 0.938182\n",
            "Train epoch: 165 [83760/25046 (10%)]\tLoss: 0.430714\n",
            "Train epoch: 165 [101800/25046 (13%)]\tLoss: 0.421545\n",
            "Train epoch: 165 [126840/25046 (15%)]\tLoss: 1.091031\n",
            "Train epoch: 165 [148120/25046 (18%)]\tLoss: 1.315680\n",
            "Train epoch: 165 [153440/25046 (20%)]\tLoss: 0.237111\n",
            "Train epoch: 165 [192060/25046 (23%)]\tLoss: 1.125747\n",
            "Train epoch: 165 [213200/25046 (26%)]\tLoss: 0.871132\n",
            "Train epoch: 165 [231880/25046 (28%)]\tLoss: 0.531886\n",
            "Train epoch: 165 [246480/25046 (31%)]\tLoss: 0.497882\n",
            "Train epoch: 165 [278460/25046 (33%)]\tLoss: 0.578342\n",
            "Train epoch: 165 [281680/25046 (36%)]\tLoss: 0.900755\n",
            "Train epoch: 165 [308700/25046 (38%)]\tLoss: 0.325646\n",
            "Train epoch: 165 [328320/25046 (41%)]\tLoss: 0.741030\n",
            "Train epoch: 165 [354280/25046 (43%)]\tLoss: 0.938718\n",
            "Train epoch: 165 [357840/25046 (46%)]\tLoss: 0.242261\n",
            "Train epoch: 165 [397860/25046 (49%)]\tLoss: 0.470734\n",
            "Train epoch: 165 [421200/25046 (51%)]\tLoss: 0.559610\n",
            "Train epoch: 165 [448140/25046 (54%)]\tLoss: 0.936320\n",
            "Train epoch: 165 [473880/25046 (56%)]\tLoss: 0.712053\n",
            "Train epoch: 165 [486680/25046 (59%)]\tLoss: 0.444759\n",
            "Train epoch: 165 [480000/25046 (61%)]\tLoss: 1.090719\n",
            "Train epoch: 165 [488000/25046 (64%)]\tLoss: 0.422779\n",
            "Train epoch: 165 [562120/25046 (66%)]\tLoss: 0.349284\n",
            "Train epoch: 165 [531360/25046 (69%)]\tLoss: 0.310766\n",
            "Train epoch: 165 [579600/25046 (72%)]\tLoss: 1.414314\n",
            "Train epoch: 165 [611320/25046 (74%)]\tLoss: 0.789471\n",
            "Train epoch: 165 [583200/25046 (77%)]\tLoss: 0.411985\n",
            "Train epoch: 165 [648520/25046 (79%)]\tLoss: 0.270083\n",
            "Train epoch: 165 [669440/25046 (82%)]\tLoss: 1.302310\n",
            "Train epoch: 165 [646140/25046 (84%)]\tLoss: 0.919595\n",
            "Train epoch: 165 [671160/25046 (87%)]\tLoss: 1.122694\n",
            "Train epoch: 165 [716800/25046 (89%)]\tLoss: 0.321660\n",
            "Train epoch: 165 [768960/25046 (92%)]\tLoss: 2.035410\n",
            "Train epoch: 165 [748140/25046 (95%)]\tLoss: 0.602198\n",
            "Train epoch: 165 [795720/25046 (97%)]\tLoss: 0.386900\n",
            "Train epoch: 165 [779220/25046 (100%)]\tLoss: 0.426963\n",
            "Make prediction for 5010 samples...\n",
            "0.8033856 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 166 [0/25046 (0%)]\tLoss: 0.342775\n",
            "Train epoch: 166 [20420/25046 (3%)]\tLoss: 0.917752\n",
            "Train epoch: 166 [44160/25046 (5%)]\tLoss: 0.420280\n",
            "Train epoch: 166 [64140/25046 (8%)]\tLoss: 0.687028\n",
            "Train epoch: 166 [78000/25046 (10%)]\tLoss: 0.694453\n",
            "Train epoch: 166 [105400/25046 (13%)]\tLoss: 1.910676\n",
            "Train epoch: 166 [123000/25046 (15%)]\tLoss: 0.880204\n",
            "Train epoch: 166 [140140/25046 (18%)]\tLoss: 0.378039\n",
            "Train epoch: 166 [157120/25046 (20%)]\tLoss: 0.889958\n",
            "Train epoch: 166 [190980/25046 (23%)]\tLoss: 0.838646\n",
            "Train epoch: 166 [203200/25046 (26%)]\tLoss: 0.311015\n",
            "Train epoch: 166 [229900/25046 (28%)]\tLoss: 0.580969\n",
            "Train epoch: 166 [240240/25046 (31%)]\tLoss: 0.969450\n",
            "Train epoch: 166 [276380/25046 (33%)]\tLoss: 0.719644\n",
            "Train epoch: 166 [291200/25046 (36%)]\tLoss: 0.910485\n",
            "Train epoch: 166 [307800/25046 (38%)]\tLoss: 1.135925\n",
            "Train epoch: 166 [330560/25046 (41%)]\tLoss: 0.857129\n",
            "Train epoch: 166 [333540/25046 (43%)]\tLoss: 0.744069\n",
            "Train epoch: 166 [348120/25046 (46%)]\tLoss: 0.505192\n",
            "Train epoch: 166 [395200/25046 (49%)]\tLoss: 1.049575\n",
            "Train epoch: 166 [422800/25046 (51%)]\tLoss: 0.689497\n",
            "Train epoch: 166 [414120/25046 (54%)]\tLoss: 0.675999\n",
            "Train epoch: 166 [420200/25046 (56%)]\tLoss: 0.495543\n",
            "Train epoch: 166 [462300/25046 (59%)]\tLoss: 1.313098\n",
            "Train epoch: 166 [474240/25046 (61%)]\tLoss: 0.495249\n",
            "Train epoch: 166 [501000/25046 (64%)]\tLoss: 0.404228\n",
            "Train epoch: 166 [515840/25046 (66%)]\tLoss: 0.554682\n",
            "Train epoch: 166 [591840/25046 (69%)]\tLoss: 0.998741\n",
            "Train epoch: 166 [545440/25046 (72%)]\tLoss: 0.225891\n",
            "Train epoch: 166 [581740/25046 (74%)]\tLoss: 0.374569\n",
            "Train epoch: 166 [634800/25046 (77%)]\tLoss: 2.110932\n",
            "Train epoch: 166 [584660/25046 (79%)]\tLoss: 0.688470\n",
            "Train epoch: 166 [683520/25046 (82%)]\tLoss: 0.710721\n",
            "Train epoch: 166 [733260/25046 (84%)]\tLoss: 0.718277\n",
            "Train epoch: 166 [703120/25046 (87%)]\tLoss: 1.721430\n",
            "Train epoch: 166 [697900/25046 (89%)]\tLoss: 0.305588\n",
            "Train epoch: 166 [717840/25046 (92%)]\tLoss: 0.269638\n",
            "Train epoch: 166 [718540/25046 (95%)]\tLoss: 0.295201\n",
            "Train epoch: 166 [793440/25046 (97%)]\tLoss: 0.641755\n",
            "Train epoch: 166 [787020/25046 (100%)]\tLoss: 1.112848\n",
            "Make prediction for 5010 samples...\n",
            "0.80184424 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 167 [0/25046 (0%)]\tLoss: 0.594581\n",
            "Train epoch: 167 [20740/25046 (3%)]\tLoss: 0.802864\n",
            "Train epoch: 167 [41120/25046 (5%)]\tLoss: 0.762488\n",
            "Train epoch: 167 [61800/25046 (8%)]\tLoss: 1.298208\n",
            "Train epoch: 167 [83440/25046 (10%)]\tLoss: 0.620571\n",
            "Train epoch: 167 [102100/25046 (13%)]\tLoss: 0.506623\n",
            "Train epoch: 167 [120120/25046 (15%)]\tLoss: 0.458985\n",
            "Train epoch: 167 [146580/25046 (18%)]\tLoss: 0.620557\n",
            "Train epoch: 167 [173280/25046 (20%)]\tLoss: 1.239586\n",
            "Train epoch: 167 [189000/25046 (23%)]\tLoss: 0.465139\n",
            "Train epoch: 167 [198000/25046 (26%)]\tLoss: 0.539334\n",
            "Train epoch: 167 [233860/25046 (28%)]\tLoss: 0.310363\n",
            "Train epoch: 167 [242160/25046 (31%)]\tLoss: 0.376071\n",
            "Train epoch: 167 [271700/25046 (33%)]\tLoss: 0.678045\n",
            "Train epoch: 167 [284480/25046 (36%)]\tLoss: 0.716891\n",
            "Train epoch: 167 [320700/25046 (38%)]\tLoss: 1.231162\n",
            "Train epoch: 167 [344640/25046 (41%)]\tLoss: 1.116590\n",
            "Train epoch: 167 [358020/25046 (43%)]\tLoss: 1.163587\n",
            "Train epoch: 167 [376920/25046 (46%)]\tLoss: 0.722728\n",
            "Train epoch: 167 [387220/25046 (49%)]\tLoss: 1.256827\n",
            "Train epoch: 167 [416400/25046 (51%)]\tLoss: 1.783046\n",
            "Train epoch: 167 [430920/25046 (54%)]\tLoss: 0.250633\n",
            "Train epoch: 167 [457160/25046 (56%)]\tLoss: 0.500975\n",
            "Train epoch: 167 [480700/25046 (59%)]\tLoss: 1.473851\n",
            "Train epoch: 167 [509760/25046 (61%)]\tLoss: 0.408402\n",
            "Train epoch: 167 [530000/25046 (64%)]\tLoss: 0.646177\n",
            "Train epoch: 167 [512200/25046 (66%)]\tLoss: 0.260347\n",
            "Train epoch: 167 [525960/25046 (69%)]\tLoss: 0.490689\n",
            "Train epoch: 167 [566720/25046 (72%)]\tLoss: 1.334340\n",
            "Train epoch: 167 [577680/25046 (74%)]\tLoss: 1.402941\n",
            "Train epoch: 167 [632400/25046 (77%)]\tLoss: 0.942617\n",
            "Train epoch: 167 [650380/25046 (79%)]\tLoss: 0.766775\n",
            "Train epoch: 167 [650880/25046 (82%)]\tLoss: 0.395670\n",
            "Train epoch: 167 [656700/25046 (84%)]\tLoss: 0.819831\n",
            "Train epoch: 167 [689520/25046 (87%)]\tLoss: 0.873464\n",
            "Train epoch: 167 [753200/25046 (89%)]\tLoss: 0.978448\n",
            "Train epoch: 167 [770400/25046 (92%)]\tLoss: 0.791499\n",
            "Train epoch: 167 [769600/25046 (95%)]\tLoss: 0.430071\n",
            "Train epoch: 167 [739480/25046 (97%)]\tLoss: 1.270299\n",
            "Train epoch: 167 [762060/25046 (100%)]\tLoss: 0.542364\n",
            "Make prediction for 5010 samples...\n",
            "0.80184954 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 168 [0/25046 (0%)]\tLoss: 0.652293\n",
            "Train epoch: 168 [19420/25046 (3%)]\tLoss: 0.529174\n",
            "Train epoch: 168 [41720/25046 (5%)]\tLoss: 0.421943\n",
            "Train epoch: 168 [60720/25046 (8%)]\tLoss: 0.676458\n",
            "Train epoch: 168 [80960/25046 (10%)]\tLoss: 0.238477\n",
            "Train epoch: 168 [101400/25046 (13%)]\tLoss: 0.815412\n",
            "Train epoch: 168 [126000/25046 (15%)]\tLoss: 0.943337\n",
            "Train epoch: 168 [149800/25046 (18%)]\tLoss: 0.516692\n",
            "Train epoch: 168 [160640/25046 (20%)]\tLoss: 0.390823\n",
            "Train epoch: 168 [169920/25046 (23%)]\tLoss: 0.385769\n",
            "Train epoch: 168 [202800/25046 (26%)]\tLoss: 0.865871\n",
            "Train epoch: 168 [225720/25046 (28%)]\tLoss: 1.067133\n",
            "Train epoch: 168 [259440/25046 (31%)]\tLoss: 0.410092\n",
            "Train epoch: 168 [264420/25046 (33%)]\tLoss: 0.320467\n",
            "Train epoch: 168 [277480/25046 (36%)]\tLoss: 0.730879\n",
            "Train epoch: 168 [286200/25046 (38%)]\tLoss: 0.466517\n",
            "Train epoch: 168 [341120/25046 (41%)]\tLoss: 1.326844\n",
            "Train epoch: 168 [335580/25046 (43%)]\tLoss: 1.208294\n",
            "Train epoch: 168 [384480/25046 (46%)]\tLoss: 1.250351\n",
            "Train epoch: 168 [417620/25046 (49%)]\tLoss: 0.544336\n",
            "Train epoch: 168 [409600/25046 (51%)]\tLoss: 0.906259\n",
            "Train epoch: 168 [425040/25046 (54%)]\tLoss: 0.967253\n",
            "Train epoch: 168 [476960/25046 (56%)]\tLoss: 1.178658\n",
            "Train epoch: 168 [486680/25046 (59%)]\tLoss: 0.677192\n",
            "Train epoch: 168 [483360/25046 (61%)]\tLoss: 0.199961\n",
            "Train epoch: 168 [550500/25046 (64%)]\tLoss: 0.703222\n",
            "Train epoch: 168 [492440/25046 (66%)]\tLoss: 0.373582\n",
            "Train epoch: 168 [547560/25046 (69%)]\tLoss: 0.600162\n",
            "Train epoch: 168 [586320/25046 (72%)]\tLoss: 1.234601\n",
            "Train epoch: 168 [590440/25046 (74%)]\tLoss: 0.431466\n",
            "Train epoch: 168 [631800/25046 (77%)]\tLoss: 1.418589\n",
            "Train epoch: 168 [647280/25046 (79%)]\tLoss: 0.563256\n",
            "Train epoch: 168 [652800/25046 (82%)]\tLoss: 0.268729\n",
            "Train epoch: 168 [688380/25046 (84%)]\tLoss: 0.521225\n",
            "Train epoch: 168 [665720/25046 (87%)]\tLoss: 0.959201\n",
            "Train epoch: 168 [716800/25046 (89%)]\tLoss: 0.692283\n",
            "Train epoch: 168 [735840/25046 (92%)]\tLoss: 0.837119\n",
            "Train epoch: 168 [765900/25046 (95%)]\tLoss: 0.696121\n",
            "Train epoch: 168 [788880/25046 (97%)]\tLoss: 0.705539\n",
            "Train epoch: 168 [756600/25046 (100%)]\tLoss: 1.088922\n",
            "Make prediction for 5010 samples...\n",
            "0.802089 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 169 [0/25046 (0%)]\tLoss: 0.684139\n",
            "Train epoch: 169 [21400/25046 (3%)]\tLoss: 1.166836\n",
            "Train epoch: 169 [44200/25046 (5%)]\tLoss: 0.296651\n",
            "Train epoch: 169 [61020/25046 (8%)]\tLoss: 0.648476\n",
            "Train epoch: 169 [82320/25046 (10%)]\tLoss: 0.558093\n",
            "Train epoch: 169 [107200/25046 (13%)]\tLoss: 1.901816\n",
            "Train epoch: 169 [124800/25046 (15%)]\tLoss: 0.850270\n",
            "Train epoch: 169 [141680/25046 (18%)]\tLoss: 0.422271\n",
            "Train epoch: 169 [165600/25046 (20%)]\tLoss: 0.753764\n",
            "Train epoch: 169 [178200/25046 (23%)]\tLoss: 1.744396\n",
            "Train epoch: 169 [203800/25046 (26%)]\tLoss: 0.629875\n",
            "Train epoch: 169 [241560/25046 (28%)]\tLoss: 0.473138\n",
            "Train epoch: 169 [236640/25046 (31%)]\tLoss: 0.621260\n",
            "Train epoch: 169 [265460/25046 (33%)]\tLoss: 0.732100\n",
            "Train epoch: 169 [282240/25046 (36%)]\tLoss: 1.326637\n",
            "Train epoch: 169 [300900/25046 (38%)]\tLoss: 0.949400\n",
            "Train epoch: 169 [336960/25046 (41%)]\tLoss: 0.683043\n",
            "Train epoch: 169 [349180/25046 (43%)]\tLoss: 0.858808\n",
            "Train epoch: 169 [379080/25046 (46%)]\tLoss: 0.819634\n",
            "Train epoch: 169 [392920/25046 (49%)]\tLoss: 1.023778\n",
            "Train epoch: 169 [413200/25046 (51%)]\tLoss: 1.109150\n",
            "Train epoch: 169 [401100/25046 (54%)]\tLoss: 0.408875\n",
            "Train epoch: 169 [446600/25046 (56%)]\tLoss: 0.567025\n",
            "Train epoch: 169 [507840/25046 (59%)]\tLoss: 1.089363\n",
            "Train epoch: 169 [487200/25046 (61%)]\tLoss: 1.629253\n",
            "Train epoch: 169 [503000/25046 (64%)]\tLoss: 1.239921\n",
            "Train epoch: 169 [546520/25046 (66%)]\tLoss: 0.823185\n",
            "Train epoch: 169 [633960/25046 (69%)]\tLoss: 0.714446\n",
            "Train epoch: 169 [615440/25046 (72%)]\tLoss: 0.441800\n",
            "Train epoch: 169 [572460/25046 (74%)]\tLoss: 0.513366\n",
            "Train epoch: 169 [590400/25046 (77%)]\tLoss: 1.434998\n",
            "Train epoch: 169 [644180/25046 (79%)]\tLoss: 1.100172\n",
            "Train epoch: 169 [634240/25046 (82%)]\tLoss: 0.296458\n",
            "Train epoch: 169 [704880/25046 (84%)]\tLoss: 0.703328\n",
            "Train epoch: 169 [694280/25046 (87%)]\tLoss: 0.307335\n",
            "Train epoch: 169 [688800/25046 (89%)]\tLoss: 0.692041\n",
            "Train epoch: 169 [747360/25046 (92%)]\tLoss: 0.442294\n",
            "Train epoch: 169 [746660/25046 (95%)]\tLoss: 0.562648\n",
            "Train epoch: 169 [763800/25046 (97%)]\tLoss: 1.056867\n",
            "Train epoch: 169 [801060/25046 (100%)]\tLoss: 0.904554\n",
            "Make prediction for 5010 samples...\n",
            "0.8045171 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 170 [0/25046 (0%)]\tLoss: 0.848278\n",
            "Train epoch: 170 [19920/25046 (3%)]\tLoss: 0.366596\n",
            "Train epoch: 170 [40600/25046 (5%)]\tLoss: 1.139490\n",
            "Train epoch: 170 [63480/25046 (8%)]\tLoss: 0.828021\n",
            "Train epoch: 170 [78880/25046 (10%)]\tLoss: 0.540744\n",
            "Train epoch: 170 [105200/25046 (13%)]\tLoss: 0.570299\n",
            "Train epoch: 170 [124440/25046 (15%)]\tLoss: 0.551861\n",
            "Train epoch: 170 [143780/25046 (18%)]\tLoss: 1.670121\n",
            "Train epoch: 170 [168480/25046 (20%)]\tLoss: 1.011395\n",
            "Train epoch: 170 [182700/25046 (23%)]\tLoss: 0.990668\n",
            "Train epoch: 170 [205800/25046 (26%)]\tLoss: 0.389626\n",
            "Train epoch: 170 [230560/25046 (28%)]\tLoss: 1.479690\n",
            "Train epoch: 170 [252000/25046 (31%)]\tLoss: 0.348821\n",
            "Train epoch: 170 [270400/25046 (33%)]\tLoss: 0.754909\n",
            "Train epoch: 170 [280280/25046 (36%)]\tLoss: 0.701777\n",
            "Train epoch: 170 [311700/25046 (38%)]\tLoss: 0.682542\n",
            "Train epoch: 170 [336000/25046 (41%)]\tLoss: 0.391927\n",
            "Train epoch: 170 [336260/25046 (43%)]\tLoss: 0.837386\n",
            "Train epoch: 170 [362160/25046 (46%)]\tLoss: 1.002467\n",
            "Train epoch: 170 [402420/25046 (49%)]\tLoss: 0.229120\n",
            "Train epoch: 170 [400000/25046 (51%)]\tLoss: 0.963692\n",
            "Train epoch: 170 [433020/25046 (54%)]\tLoss: 0.999416\n",
            "Train epoch: 170 [454520/25046 (56%)]\tLoss: 1.017644\n",
            "Train epoch: 170 [478860/25046 (59%)]\tLoss: 0.695150\n",
            "Train epoch: 170 [506880/25046 (61%)]\tLoss: 0.225053\n",
            "Train epoch: 170 [494000/25046 (64%)]\tLoss: 0.508600\n",
            "Train epoch: 170 [516880/25046 (66%)]\tLoss: 1.571895\n",
            "Train epoch: 170 [527580/25046 (69%)]\tLoss: 1.137915\n",
            "Train epoch: 170 [543760/25046 (72%)]\tLoss: 0.770538\n",
            "Train epoch: 170 [617120/25046 (74%)]\tLoss: 0.841918\n",
            "Train epoch: 170 [622800/25046 (77%)]\tLoss: 1.300274\n",
            "Train epoch: 170 [611320/25046 (79%)]\tLoss: 0.978491\n",
            "Train epoch: 170 [663040/25046 (82%)]\tLoss: 0.434022\n",
            "Train epoch: 170 [668580/25046 (84%)]\tLoss: 0.480527\n",
            "Train epoch: 170 [663000/25046 (87%)]\tLoss: 0.672010\n",
            "Train epoch: 170 [737800/25046 (89%)]\tLoss: 1.144063\n",
            "Train epoch: 170 [728640/25046 (92%)]\tLoss: 0.780901\n",
            "Train epoch: 170 [762940/25046 (95%)]\tLoss: 1.162985\n",
            "Train epoch: 170 [817000/25046 (97%)]\tLoss: 0.988230\n",
            "Train epoch: 170 [776880/25046 (100%)]\tLoss: 1.424289\n",
            "Make prediction for 5010 samples...\n",
            "0.80151653 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 171 [0/25046 (0%)]\tLoss: 0.879749\n",
            "Train epoch: 171 [20000/25046 (3%)]\tLoss: 0.729239\n",
            "Train epoch: 171 [42280/25046 (5%)]\tLoss: 0.745276\n",
            "Train epoch: 171 [63720/25046 (8%)]\tLoss: 1.842378\n",
            "Train epoch: 171 [80080/25046 (10%)]\tLoss: 0.757945\n",
            "Train epoch: 171 [105900/25046 (13%)]\tLoss: 0.652389\n",
            "Train epoch: 171 [120600/25046 (15%)]\tLoss: 0.236800\n",
            "Train epoch: 171 [147840/25046 (18%)]\tLoss: 0.511202\n",
            "Train epoch: 171 [158400/25046 (20%)]\tLoss: 0.426245\n",
            "Train epoch: 171 [190620/25046 (23%)]\tLoss: 0.341353\n",
            "Train epoch: 171 [195200/25046 (26%)]\tLoss: 0.195952\n",
            "Train epoch: 171 [225280/25046 (28%)]\tLoss: 0.300455\n",
            "Train epoch: 171 [234480/25046 (31%)]\tLoss: 1.253730\n",
            "Train epoch: 171 [271700/25046 (33%)]\tLoss: 0.192110\n",
            "Train epoch: 171 [282240/25046 (36%)]\tLoss: 1.513689\n",
            "Train epoch: 171 [318300/25046 (38%)]\tLoss: 1.499836\n",
            "Train epoch: 171 [328640/25046 (41%)]\tLoss: 1.162555\n",
            "Train epoch: 171 [335240/25046 (43%)]\tLoss: 0.746858\n",
            "Train epoch: 171 [369000/25046 (46%)]\tLoss: 0.327693\n",
            "Train epoch: 171 [396340/25046 (49%)]\tLoss: 0.571319\n",
            "Train epoch: 171 [410400/25046 (51%)]\tLoss: 0.596367\n",
            "Train epoch: 171 [407400/25046 (54%)]\tLoss: 0.260266\n",
            "Train epoch: 171 [441760/25046 (56%)]\tLoss: 0.962539\n",
            "Train epoch: 171 [475640/25046 (59%)]\tLoss: 1.024993\n",
            "Train epoch: 171 [530880/25046 (61%)]\tLoss: 0.645330\n",
            "Train epoch: 171 [511000/25046 (64%)]\tLoss: 1.098660\n",
            "Train epoch: 171 [506480/25046 (66%)]\tLoss: 1.053302\n",
            "Train epoch: 171 [582120/25046 (69%)]\tLoss: 0.749309\n",
            "Train epoch: 171 [544320/25046 (72%)]\tLoss: 0.445329\n",
            "Train epoch: 171 [597400/25046 (74%)]\tLoss: 0.557401\n",
            "Train epoch: 171 [608400/25046 (77%)]\tLoss: 1.047471\n",
            "Train epoch: 171 [606360/25046 (79%)]\tLoss: 0.752867\n",
            "Train epoch: 171 [632960/25046 (82%)]\tLoss: 0.608019\n",
            "Train epoch: 171 [704880/25046 (84%)]\tLoss: 1.298817\n",
            "Train epoch: 171 [690200/25046 (87%)]\tLoss: 0.498655\n",
            "Train epoch: 171 [688100/25046 (89%)]\tLoss: 0.752494\n",
            "Train epoch: 171 [767520/25046 (92%)]\tLoss: 1.058727\n",
            "Train epoch: 171 [734080/25046 (95%)]\tLoss: 0.286730\n",
            "Train epoch: 171 [764560/25046 (97%)]\tLoss: 0.666747\n",
            "Train epoch: 171 [823680/25046 (100%)]\tLoss: 0.933704\n",
            "Make prediction for 5010 samples...\n",
            "0.8016023 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 172 [0/25046 (0%)]\tLoss: 0.607098\n",
            "Train epoch: 172 [20140/25046 (3%)]\tLoss: 0.645611\n",
            "Train epoch: 172 [39240/25046 (5%)]\tLoss: 0.236923\n",
            "Train epoch: 172 [63900/25046 (8%)]\tLoss: 0.821173\n",
            "Train epoch: 172 [81520/25046 (10%)]\tLoss: 0.380298\n",
            "Train epoch: 172 [101500/25046 (13%)]\tLoss: 1.115573\n",
            "Train epoch: 172 [123600/25046 (15%)]\tLoss: 0.698238\n",
            "Train epoch: 172 [143220/25046 (18%)]\tLoss: 1.009541\n",
            "Train epoch: 172 [169280/25046 (20%)]\tLoss: 0.394746\n",
            "Train epoch: 172 [192420/25046 (23%)]\tLoss: 0.837978\n",
            "Train epoch: 172 [200600/25046 (26%)]\tLoss: 1.471655\n",
            "Train epoch: 172 [228360/25046 (28%)]\tLoss: 0.572456\n",
            "Train epoch: 172 [232800/25046 (31%)]\tLoss: 0.978067\n",
            "Train epoch: 172 [263900/25046 (33%)]\tLoss: 1.164208\n",
            "Train epoch: 172 [303240/25046 (36%)]\tLoss: 0.602972\n",
            "Train epoch: 172 [305100/25046 (38%)]\tLoss: 1.080279\n",
            "Train epoch: 172 [320000/25046 (41%)]\tLoss: 1.316061\n",
            "Train epoch: 172 [345780/25046 (43%)]\tLoss: 0.928300\n",
            "Train epoch: 172 [355680/25046 (46%)]\tLoss: 1.100166\n",
            "Train epoch: 172 [404700/25046 (49%)]\tLoss: 0.371679\n",
            "Train epoch: 172 [442400/25046 (51%)]\tLoss: 0.514170\n",
            "Train epoch: 172 [423780/25046 (54%)]\tLoss: 1.528773\n",
            "Train epoch: 172 [455840/25046 (56%)]\tLoss: 0.491909\n",
            "Train epoch: 172 [471960/25046 (59%)]\tLoss: 0.407330\n",
            "Train epoch: 172 [526080/25046 (61%)]\tLoss: 1.610239\n",
            "Train epoch: 172 [512500/25046 (64%)]\tLoss: 0.586634\n",
            "Train epoch: 172 [512200/25046 (66%)]\tLoss: 1.069262\n",
            "Train epoch: 172 [545940/25046 (69%)]\tLoss: 1.119414\n",
            "Train epoch: 172 [566720/25046 (72%)]\tLoss: 0.751248\n",
            "Train epoch: 172 [581740/25046 (74%)]\tLoss: 0.865367\n",
            "Train epoch: 172 [609000/25046 (77%)]\tLoss: 0.666512\n",
            "Train epoch: 172 [657820/25046 (79%)]\tLoss: 1.107629\n",
            "Train epoch: 172 [666880/25046 (82%)]\tLoss: 0.715702\n",
            "Train epoch: 172 [687060/25046 (84%)]\tLoss: 0.620649\n",
            "Train epoch: 172 [665040/25046 (87%)]\tLoss: 0.715326\n",
            "Train epoch: 172 [678300/25046 (89%)]\tLoss: 0.695357\n",
            "Train epoch: 172 [727200/25046 (92%)]\tLoss: 0.678213\n",
            "Train epoch: 172 [731120/25046 (95%)]\tLoss: 0.574617\n",
            "Train epoch: 172 [807880/25046 (97%)]\tLoss: 0.837891\n",
            "Train epoch: 172 [833820/25046 (100%)]\tLoss: 0.633048\n",
            "Make prediction for 5010 samples...\n",
            "0.8034493 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 173 [0/25046 (0%)]\tLoss: 0.888133\n",
            "Train epoch: 173 [21280/25046 (3%)]\tLoss: 0.662196\n",
            "Train epoch: 173 [40520/25046 (5%)]\tLoss: 0.650323\n",
            "Train epoch: 173 [62700/25046 (8%)]\tLoss: 0.243544\n",
            "Train epoch: 173 [80800/25046 (10%)]\tLoss: 0.590579\n",
            "Train epoch: 173 [98700/25046 (13%)]\tLoss: 0.748930\n",
            "Train epoch: 173 [125280/25046 (15%)]\tLoss: 0.351209\n",
            "Train epoch: 173 [144620/25046 (18%)]\tLoss: 1.346705\n",
            "Train epoch: 173 [163680/25046 (20%)]\tLoss: 0.370354\n",
            "Train epoch: 173 [190440/25046 (23%)]\tLoss: 0.938038\n",
            "Train epoch: 173 [202000/25046 (26%)]\tLoss: 0.931026\n",
            "Train epoch: 173 [227700/25046 (28%)]\tLoss: 1.552211\n",
            "Train epoch: 173 [241920/25046 (31%)]\tLoss: 1.530766\n",
            "Train epoch: 173 [252200/25046 (33%)]\tLoss: 0.882351\n",
            "Train epoch: 173 [280000/25046 (36%)]\tLoss: 0.724834\n",
            "Train epoch: 173 [302400/25046 (38%)]\tLoss: 0.366021\n",
            "Train epoch: 173 [314240/25046 (41%)]\tLoss: 1.579219\n",
            "Train epoch: 173 [352240/25046 (43%)]\tLoss: 1.663996\n",
            "Train epoch: 173 [353880/25046 (46%)]\tLoss: 0.438306\n",
            "Train epoch: 173 [389120/25046 (49%)]\tLoss: 0.518946\n",
            "Train epoch: 173 [370800/25046 (51%)]\tLoss: 0.383642\n",
            "Train epoch: 173 [427140/25046 (54%)]\tLoss: 0.908291\n",
            "Train epoch: 173 [468160/25046 (56%)]\tLoss: 1.195085\n",
            "Train epoch: 173 [446660/25046 (59%)]\tLoss: 0.394141\n",
            "Train epoch: 173 [492960/25046 (61%)]\tLoss: 0.605946\n",
            "Train epoch: 173 [532500/25046 (64%)]\tLoss: 0.800301\n",
            "Train epoch: 173 [549640/25046 (66%)]\tLoss: 0.980399\n",
            "Train epoch: 173 [546480/25046 (69%)]\tLoss: 0.971319\n",
            "Train epoch: 173 [569520/25046 (72%)]\tLoss: 0.656473\n",
            "Train epoch: 173 [596820/25046 (74%)]\tLoss: 0.915852\n",
            "Train epoch: 173 [576000/25046 (77%)]\tLoss: 1.067741\n",
            "Train epoch: 173 [623100/25046 (79%)]\tLoss: 0.611235\n",
            "Train epoch: 173 [654080/25046 (82%)]\tLoss: 0.683430\n",
            "Train epoch: 173 [701580/25046 (84%)]\tLoss: 1.500528\n",
            "Train epoch: 173 [697000/25046 (87%)]\tLoss: 0.282762\n",
            "Train epoch: 173 [729400/25046 (89%)]\tLoss: 0.767227\n",
            "Train epoch: 173 [784800/25046 (92%)]\tLoss: 1.276336\n",
            "Train epoch: 173 [828060/25046 (95%)]\tLoss: 0.409104\n",
            "Train epoch: 173 [766080/25046 (97%)]\tLoss: 0.887796\n",
            "Train epoch: 173 [796380/25046 (100%)]\tLoss: 0.501777\n",
            "Make prediction for 5010 samples...\n",
            "0.80241513 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 174 [0/25046 (0%)]\tLoss: 0.934463\n",
            "Train epoch: 174 [19420/25046 (3%)]\tLoss: 1.842499\n",
            "Train epoch: 174 [39440/25046 (5%)]\tLoss: 1.238915\n",
            "Train epoch: 174 [61260/25046 (8%)]\tLoss: 1.168241\n",
            "Train epoch: 174 [80080/25046 (10%)]\tLoss: 0.836816\n",
            "Train epoch: 174 [101400/25046 (13%)]\tLoss: 0.878033\n",
            "Train epoch: 174 [122760/25046 (15%)]\tLoss: 0.823774\n",
            "Train epoch: 174 [138040/25046 (18%)]\tLoss: 0.841417\n",
            "Train epoch: 174 [174720/25046 (20%)]\tLoss: 0.403202\n",
            "Train epoch: 174 [195660/25046 (23%)]\tLoss: 0.837703\n",
            "Train epoch: 174 [195000/25046 (26%)]\tLoss: 0.887509\n",
            "Train epoch: 174 [219560/25046 (28%)]\tLoss: 0.275337\n",
            "Train epoch: 174 [232080/25046 (31%)]\tLoss: 0.526756\n",
            "Train epoch: 174 [276640/25046 (33%)]\tLoss: 1.282589\n",
            "Train epoch: 174 [286440/25046 (36%)]\tLoss: 1.369077\n",
            "Train epoch: 174 [310800/25046 (38%)]\tLoss: 0.454567\n",
            "Train epoch: 174 [320960/25046 (41%)]\tLoss: 0.658720\n",
            "Train epoch: 174 [339320/25046 (43%)]\tLoss: 1.069201\n",
            "Train epoch: 174 [377280/25046 (46%)]\tLoss: 0.750437\n",
            "Train epoch: 174 [387980/25046 (49%)]\tLoss: 0.371036\n",
            "Train epoch: 174 [434000/25046 (51%)]\tLoss: 0.863372\n",
            "Train epoch: 174 [462840/25046 (54%)]\tLoss: 1.272918\n",
            "Train epoch: 174 [484000/25046 (56%)]\tLoss: 1.368643\n",
            "Train epoch: 174 [455400/25046 (59%)]\tLoss: 0.743024\n",
            "Train epoch: 174 [501600/25046 (61%)]\tLoss: 0.678780\n",
            "Train epoch: 174 [539000/25046 (64%)]\tLoss: 0.670004\n",
            "Train epoch: 174 [541840/25046 (66%)]\tLoss: 1.688709\n",
            "Train epoch: 174 [592380/25046 (69%)]\tLoss: 0.870312\n",
            "Train epoch: 174 [576800/25046 (72%)]\tLoss: 0.578964\n",
            "Train epoch: 174 [612480/25046 (74%)]\tLoss: 1.195295\n",
            "Train epoch: 174 [649200/25046 (77%)]\tLoss: 1.227465\n",
            "Train epoch: 174 [634260/25046 (79%)]\tLoss: 0.288922\n",
            "Train epoch: 174 [629120/25046 (82%)]\tLoss: 0.647775\n",
            "Train epoch: 174 [672540/25046 (84%)]\tLoss: 0.800480\n",
            "Train epoch: 174 [735760/25046 (87%)]\tLoss: 0.573772\n",
            "Train epoch: 174 [724500/25046 (89%)]\tLoss: 0.384621\n",
            "Train epoch: 174 [721440/25046 (92%)]\tLoss: 0.596801\n",
            "Train epoch: 174 [763680/25046 (95%)]\tLoss: 0.948013\n",
            "Train epoch: 174 [769120/25046 (97%)]\tLoss: 0.889161\n",
            "Train epoch: 174 [860340/25046 (100%)]\tLoss: 1.249704\n",
            "Make prediction for 5010 samples...\n",
            "0.80155605 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 175 [0/25046 (0%)]\tLoss: 0.925463\n",
            "Train epoch: 175 [21200/25046 (3%)]\tLoss: 1.775293\n",
            "Train epoch: 175 [39520/25046 (5%)]\tLoss: 0.380948\n",
            "Train epoch: 175 [58920/25046 (8%)]\tLoss: 0.550865\n",
            "Train epoch: 175 [80560/25046 (10%)]\tLoss: 0.398382\n",
            "Train epoch: 175 [97700/25046 (13%)]\tLoss: 0.415163\n",
            "Train epoch: 175 [127440/25046 (15%)]\tLoss: 1.867314\n",
            "Train epoch: 175 [148120/25046 (18%)]\tLoss: 0.287019\n",
            "Train epoch: 175 [166080/25046 (20%)]\tLoss: 0.612250\n",
            "Train epoch: 175 [184680/25046 (23%)]\tLoss: 0.273248\n",
            "Train epoch: 175 [203200/25046 (26%)]\tLoss: 1.322414\n",
            "Train epoch: 175 [223740/25046 (28%)]\tLoss: 0.543170\n",
            "Train epoch: 175 [243840/25046 (31%)]\tLoss: 0.264679\n",
            "Train epoch: 175 [259740/25046 (33%)]\tLoss: 1.036109\n",
            "Train epoch: 175 [300160/25046 (36%)]\tLoss: 0.510636\n",
            "Train epoch: 175 [321300/25046 (38%)]\tLoss: 0.441336\n",
            "Train epoch: 175 [326400/25046 (41%)]\tLoss: 0.813483\n",
            "Train epoch: 175 [329460/25046 (43%)]\tLoss: 1.374308\n",
            "Train epoch: 175 [366840/25046 (46%)]\tLoss: 1.254224\n",
            "Train epoch: 175 [383420/25046 (49%)]\tLoss: 0.314646\n",
            "Train epoch: 175 [403200/25046 (51%)]\tLoss: 0.771599\n",
            "Train epoch: 175 [427980/25046 (54%)]\tLoss: 1.196110\n",
            "Train epoch: 175 [441320/25046 (56%)]\tLoss: 0.797913\n",
            "Train epoch: 175 [489440/25046 (59%)]\tLoss: 1.065841\n",
            "Train epoch: 175 [492000/25046 (61%)]\tLoss: 0.642796\n",
            "Train epoch: 175 [490500/25046 (64%)]\tLoss: 1.137052\n",
            "Train epoch: 175 [584480/25046 (66%)]\tLoss: 1.081865\n",
            "Train epoch: 175 [565920/25046 (69%)]\tLoss: 0.529566\n",
            "Train epoch: 175 [562240/25046 (72%)]\tLoss: 0.763098\n",
            "Train epoch: 175 [593340/25046 (74%)]\tLoss: 0.853153\n",
            "Train epoch: 175 [637200/25046 (77%)]\tLoss: 1.116027\n",
            "Train epoch: 175 [611940/25046 (79%)]\tLoss: 0.867396\n",
            "Train epoch: 175 [595840/25046 (82%)]\tLoss: 1.374164\n",
            "Train epoch: 175 [686400/25046 (84%)]\tLoss: 1.356503\n",
            "Train epoch: 175 [702440/25046 (87%)]\tLoss: 0.517161\n",
            "Train epoch: 175 [758800/25046 (89%)]\tLoss: 0.542814\n",
            "Train epoch: 175 [734400/25046 (92%)]\tLoss: 0.616738\n",
            "Train epoch: 175 [726680/25046 (95%)]\tLoss: 0.789956\n",
            "Train epoch: 175 [767600/25046 (97%)]\tLoss: 0.582887\n",
            "Train epoch: 175 [729300/25046 (100%)]\tLoss: 0.820745\n",
            "Make prediction for 5010 samples...\n",
            "0.8018009 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 176 [0/25046 (0%)]\tLoss: 0.533588\n",
            "Train epoch: 176 [20280/25046 (3%)]\tLoss: 0.209426\n",
            "Train epoch: 176 [41240/25046 (5%)]\tLoss: 1.838806\n",
            "Train epoch: 176 [61800/25046 (8%)]\tLoss: 1.122160\n",
            "Train epoch: 176 [83760/25046 (10%)]\tLoss: 0.473839\n",
            "Train epoch: 176 [99900/25046 (13%)]\tLoss: 0.407035\n",
            "Train epoch: 176 [118680/25046 (15%)]\tLoss: 0.780315\n",
            "Train epoch: 176 [138460/25046 (18%)]\tLoss: 1.241068\n",
            "Train epoch: 176 [170560/25046 (20%)]\tLoss: 0.723425\n",
            "Train epoch: 176 [183600/25046 (23%)]\tLoss: 1.020729\n",
            "Train epoch: 176 [207000/25046 (26%)]\tLoss: 0.933511\n",
            "Train epoch: 176 [225500/25046 (28%)]\tLoss: 0.603006\n",
            "Train epoch: 176 [250800/25046 (31%)]\tLoss: 1.102324\n",
            "Train epoch: 176 [275600/25046 (33%)]\tLoss: 0.316118\n",
            "Train epoch: 176 [300440/25046 (36%)]\tLoss: 1.311407\n",
            "Train epoch: 176 [312000/25046 (38%)]\tLoss: 0.351556\n",
            "Train epoch: 176 [336320/25046 (41%)]\tLoss: 1.286615\n",
            "Train epoch: 176 [347140/25046 (43%)]\tLoss: 1.198685\n",
            "Train epoch: 176 [375840/25046 (46%)]\tLoss: 1.363885\n",
            "Train epoch: 176 [391400/25046 (49%)]\tLoss: 1.121766\n",
            "Train epoch: 176 [402400/25046 (51%)]\tLoss: 1.228952\n",
            "Train epoch: 176 [442260/25046 (54%)]\tLoss: 0.744773\n",
            "Train epoch: 176 [450120/25046 (56%)]\tLoss: 0.626709\n",
            "Train epoch: 176 [471500/25046 (59%)]\tLoss: 0.928515\n",
            "Train epoch: 176 [485760/25046 (61%)]\tLoss: 0.421850\n",
            "Train epoch: 176 [503500/25046 (64%)]\tLoss: 0.399468\n",
            "Train epoch: 176 [533520/25046 (66%)]\tLoss: 0.899684\n",
            "Train epoch: 176 [571860/25046 (69%)]\tLoss: 0.248352\n",
            "Train epoch: 176 [577360/25046 (72%)]\tLoss: 0.871843\n",
            "Train epoch: 176 [575940/25046 (74%)]\tLoss: 0.344812\n",
            "Train epoch: 176 [602400/25046 (77%)]\tLoss: 0.561464\n",
            "Train epoch: 176 [590240/25046 (79%)]\tLoss: 0.950837\n",
            "Train epoch: 176 [618880/25046 (82%)]\tLoss: 0.324839\n",
            "Train epoch: 176 [669900/25046 (84%)]\tLoss: 1.585124\n",
            "Train epoch: 176 [664360/25046 (87%)]\tLoss: 1.149928\n",
            "Train epoch: 176 [702100/25046 (89%)]\tLoss: 0.973550\n",
            "Train epoch: 176 [783360/25046 (92%)]\tLoss: 0.923550\n",
            "Train epoch: 176 [742220/25046 (95%)]\tLoss: 0.586259\n",
            "Train epoch: 176 [789640/25046 (97%)]\tLoss: 0.358607\n",
            "Train epoch: 176 [770640/25046 (100%)]\tLoss: 0.313668\n",
            "Make prediction for 5010 samples...\n",
            "0.8023445 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 177 [0/25046 (0%)]\tLoss: 0.601363\n",
            "Train epoch: 177 [20440/25046 (3%)]\tLoss: 1.569687\n",
            "Train epoch: 177 [40640/25046 (5%)]\tLoss: 0.877558\n",
            "Train epoch: 177 [63720/25046 (8%)]\tLoss: 0.558647\n",
            "Train epoch: 177 [83520/25046 (10%)]\tLoss: 0.427015\n",
            "Train epoch: 177 [97500/25046 (13%)]\tLoss: 0.138408\n",
            "Train epoch: 177 [127560/25046 (15%)]\tLoss: 0.596805\n",
            "Train epoch: 177 [147560/25046 (18%)]\tLoss: 0.705446\n",
            "Train epoch: 177 [164960/25046 (20%)]\tLoss: 0.987320\n",
            "Train epoch: 177 [185580/25046 (23%)]\tLoss: 0.284466\n",
            "Train epoch: 177 [204200/25046 (26%)]\tLoss: 0.492687\n",
            "Train epoch: 177 [232540/25046 (28%)]\tLoss: 0.723184\n",
            "Train epoch: 177 [227760/25046 (31%)]\tLoss: 0.552860\n",
            "Train epoch: 177 [277160/25046 (33%)]\tLoss: 0.520163\n",
            "Train epoch: 177 [294560/25046 (36%)]\tLoss: 1.114543\n",
            "Train epoch: 177 [322500/25046 (38%)]\tLoss: 1.455205\n",
            "Train epoch: 177 [313280/25046 (41%)]\tLoss: 0.533422\n",
            "Train epoch: 177 [328100/25046 (43%)]\tLoss: 1.084672\n",
            "Train epoch: 177 [369360/25046 (46%)]\tLoss: 0.849923\n",
            "Train epoch: 177 [390260/25046 (49%)]\tLoss: 0.797988\n",
            "Train epoch: 177 [429600/25046 (51%)]\tLoss: 0.632612\n",
            "Train epoch: 177 [436800/25046 (54%)]\tLoss: 0.294151\n",
            "Train epoch: 177 [418000/25046 (56%)]\tLoss: 0.642255\n",
            "Train epoch: 177 [485300/25046 (59%)]\tLoss: 0.296735\n",
            "Train epoch: 177 [490080/25046 (61%)]\tLoss: 1.565774\n",
            "Train epoch: 177 [527000/25046 (64%)]\tLoss: 0.627320\n",
            "Train epoch: 177 [526760/25046 (66%)]\tLoss: 0.544672\n",
            "Train epoch: 177 [527040/25046 (69%)]\tLoss: 1.144562\n",
            "Train epoch: 177 [553280/25046 (72%)]\tLoss: 0.784536\n",
            "Train epoch: 177 [596240/25046 (74%)]\tLoss: 0.584700\n",
            "Train epoch: 177 [608400/25046 (77%)]\tLoss: 0.299931\n",
            "Train epoch: 177 [600780/25046 (79%)]\tLoss: 0.577899\n",
            "Train epoch: 177 [671360/25046 (82%)]\tLoss: 1.238159\n",
            "Train epoch: 177 [670560/25046 (84%)]\tLoss: 1.304226\n",
            "Train epoch: 177 [741200/25046 (87%)]\tLoss: 0.347475\n",
            "Train epoch: 177 [715400/25046 (89%)]\tLoss: 0.346442\n",
            "Train epoch: 177 [732240/25046 (92%)]\tLoss: 0.426950\n",
            "Train epoch: 177 [772560/25046 (95%)]\tLoss: 0.706183\n",
            "Train epoch: 177 [786600/25046 (97%)]\tLoss: 0.631887\n",
            "Train epoch: 177 [787020/25046 (100%)]\tLoss: 1.270381\n",
            "Make prediction for 5010 samples...\n",
            "0.8016015 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 178 [0/25046 (0%)]\tLoss: 0.460753\n",
            "Train epoch: 178 [20440/25046 (3%)]\tLoss: 0.645254\n",
            "Train epoch: 178 [43440/25046 (5%)]\tLoss: 1.086546\n",
            "Train epoch: 178 [59400/25046 (8%)]\tLoss: 0.372850\n",
            "Train epoch: 178 [82560/25046 (10%)]\tLoss: 0.770292\n",
            "Train epoch: 178 [97300/25046 (13%)]\tLoss: 1.088278\n",
            "Train epoch: 178 [122160/25046 (15%)]\tLoss: 0.499163\n",
            "Train epoch: 178 [145180/25046 (18%)]\tLoss: 0.638775\n",
            "Train epoch: 178 [149280/25046 (20%)]\tLoss: 0.965512\n",
            "Train epoch: 178 [186660/25046 (23%)]\tLoss: 0.512972\n",
            "Train epoch: 178 [206400/25046 (26%)]\tLoss: 0.699734\n",
            "Train epoch: 178 [225720/25046 (28%)]\tLoss: 1.425603\n",
            "Train epoch: 178 [241680/25046 (31%)]\tLoss: 0.881570\n",
            "Train epoch: 178 [259740/25046 (33%)]\tLoss: 0.348334\n",
            "Train epoch: 178 [286160/25046 (36%)]\tLoss: 0.779566\n",
            "Train epoch: 178 [294600/25046 (38%)]\tLoss: 0.705789\n",
            "Train epoch: 178 [323520/25046 (41%)]\tLoss: 0.667549\n",
            "Train epoch: 178 [349860/25046 (43%)]\tLoss: 0.631721\n",
            "Train epoch: 178 [381960/25046 (46%)]\tLoss: 0.693779\n",
            "Train epoch: 178 [390640/25046 (49%)]\tLoss: 0.537810\n",
            "Train epoch: 178 [412800/25046 (51%)]\tLoss: 0.605158\n",
            "Train epoch: 178 [431340/25046 (54%)]\tLoss: 2.028653\n",
            "Train epoch: 178 [458480/25046 (56%)]\tLoss: 1.838983\n",
            "Train epoch: 178 [474720/25046 (59%)]\tLoss: 1.607467\n",
            "Train epoch: 178 [507840/25046 (61%)]\tLoss: 0.971291\n",
            "Train epoch: 178 [529500/25046 (64%)]\tLoss: 0.993025\n",
            "Train epoch: 178 [510640/25046 (66%)]\tLoss: 0.680421\n",
            "Train epoch: 178 [548640/25046 (69%)]\tLoss: 0.809479\n",
            "Train epoch: 178 [609280/25046 (72%)]\tLoss: 0.386083\n",
            "Train epoch: 178 [607840/25046 (74%)]\tLoss: 0.781796\n",
            "Train epoch: 178 [573000/25046 (77%)]\tLoss: 0.637764\n",
            "Train epoch: 178 [695020/25046 (79%)]\tLoss: 0.999931\n",
            "Train epoch: 178 [670720/25046 (82%)]\tLoss: 0.927460\n",
            "Train epoch: 178 [665940/25046 (84%)]\tLoss: 0.688215\n",
            "Train epoch: 178 [713320/25046 (87%)]\tLoss: 0.981744\n",
            "Train epoch: 178 [744100/25046 (89%)]\tLoss: 1.293362\n",
            "Train epoch: 178 [717840/25046 (92%)]\tLoss: 1.284155\n",
            "Train epoch: 178 [765160/25046 (95%)]\tLoss: 1.044257\n",
            "Train epoch: 178 [780520/25046 (97%)]\tLoss: 1.550682\n",
            "Train epoch: 178 [736320/25046 (100%)]\tLoss: 0.515350\n",
            "Make prediction for 5010 samples...\n",
            "0.80347013 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 179 [0/25046 (0%)]\tLoss: 0.492176\n",
            "Train epoch: 179 [22180/25046 (3%)]\tLoss: 0.554500\n",
            "Train epoch: 179 [41120/25046 (5%)]\tLoss: 0.795874\n",
            "Train epoch: 179 [60480/25046 (8%)]\tLoss: 0.648739\n",
            "Train epoch: 179 [82960/25046 (10%)]\tLoss: 0.812972\n",
            "Train epoch: 179 [96500/25046 (13%)]\tLoss: 0.366855\n",
            "Train epoch: 179 [120840/25046 (15%)]\tLoss: 1.275167\n",
            "Train epoch: 179 [140560/25046 (18%)]\tLoss: 0.658881\n",
            "Train epoch: 179 [162240/25046 (20%)]\tLoss: 0.616053\n",
            "Train epoch: 179 [186480/25046 (23%)]\tLoss: 1.196190\n",
            "Train epoch: 179 [213800/25046 (26%)]\tLoss: 0.691956\n",
            "Train epoch: 179 [225500/25046 (28%)]\tLoss: 1.220131\n",
            "Train epoch: 179 [249840/25046 (31%)]\tLoss: 1.199959\n",
            "Train epoch: 179 [271180/25046 (33%)]\tLoss: 0.347554\n",
            "Train epoch: 179 [284200/25046 (36%)]\tLoss: 0.716149\n",
            "Train epoch: 179 [325800/25046 (38%)]\tLoss: 0.870778\n",
            "Train epoch: 179 [319360/25046 (41%)]\tLoss: 0.972747\n",
            "Train epoch: 179 [353600/25046 (43%)]\tLoss: 1.226027\n",
            "Train epoch: 179 [365760/25046 (46%)]\tLoss: 1.220314\n",
            "Train epoch: 179 [386080/25046 (49%)]\tLoss: 0.451119\n",
            "Train epoch: 179 [419600/25046 (51%)]\tLoss: 1.459077\n",
            "Train epoch: 179 [424620/25046 (54%)]\tLoss: 0.315875\n",
            "Train epoch: 179 [466840/25046 (56%)]\tLoss: 1.336870\n",
            "Train epoch: 179 [482540/25046 (59%)]\tLoss: 1.070274\n",
            "Train epoch: 179 [518880/25046 (61%)]\tLoss: 1.189194\n",
            "Train epoch: 179 [509000/25046 (64%)]\tLoss: 1.162058\n",
            "Train epoch: 179 [556920/25046 (66%)]\tLoss: 1.537227\n",
            "Train epoch: 179 [524340/25046 (69%)]\tLoss: 0.588470\n",
            "Train epoch: 179 [570080/25046 (72%)]\tLoss: 0.640770\n",
            "Train epoch: 179 [546360/25046 (74%)]\tLoss: 0.259752\n",
            "Train epoch: 179 [594600/25046 (77%)]\tLoss: 0.988457\n",
            "Train epoch: 179 [607600/25046 (79%)]\tLoss: 1.079426\n",
            "Train epoch: 179 [647040/25046 (82%)]\tLoss: 0.434532\n",
            "Train epoch: 179 [658680/25046 (84%)]\tLoss: 0.525582\n",
            "Train epoch: 179 [687480/25046 (87%)]\tLoss: 0.663103\n",
            "Train epoch: 179 [699300/25046 (89%)]\tLoss: 0.927244\n",
            "Train epoch: 179 [714240/25046 (92%)]\tLoss: 0.269071\n",
            "Train epoch: 179 [784400/25046 (95%)]\tLoss: 0.608628\n",
            "Train epoch: 179 [779000/25046 (97%)]\tLoss: 1.592472\n",
            "Train epoch: 179 [794820/25046 (100%)]\tLoss: 0.829018\n",
            "Make prediction for 5010 samples...\n",
            "0.80190784 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 180 [0/25046 (0%)]\tLoss: 0.953287\n",
            "Train epoch: 180 [21240/25046 (3%)]\tLoss: 0.808897\n",
            "Train epoch: 180 [40400/25046 (5%)]\tLoss: 1.284458\n",
            "Train epoch: 180 [58980/25046 (8%)]\tLoss: 1.074834\n",
            "Train epoch: 180 [83440/25046 (10%)]\tLoss: 1.127082\n",
            "Train epoch: 180 [101100/25046 (13%)]\tLoss: 0.356467\n",
            "Train epoch: 180 [122520/25046 (15%)]\tLoss: 0.690802\n",
            "Train epoch: 180 [155820/25046 (18%)]\tLoss: 1.178550\n",
            "Train epoch: 180 [161760/25046 (20%)]\tLoss: 0.821990\n",
            "Train epoch: 180 [185580/25046 (23%)]\tLoss: 0.740129\n",
            "Train epoch: 180 [213200/25046 (26%)]\tLoss: 1.297564\n",
            "Train epoch: 180 [231220/25046 (28%)]\tLoss: 0.918715\n",
            "Train epoch: 180 [242400/25046 (31%)]\tLoss: 1.704499\n",
            "Train epoch: 180 [257920/25046 (33%)]\tLoss: 1.436882\n",
            "Train epoch: 180 [267960/25046 (36%)]\tLoss: 0.641652\n",
            "Train epoch: 180 [305100/25046 (38%)]\tLoss: 0.807563\n",
            "Train epoch: 180 [323200/25046 (41%)]\tLoss: 0.717800\n",
            "Train epoch: 180 [323340/25046 (43%)]\tLoss: 0.403840\n",
            "Train epoch: 180 [377640/25046 (46%)]\tLoss: 1.059105\n",
            "Train epoch: 180 [392160/25046 (49%)]\tLoss: 0.717719\n",
            "Train epoch: 180 [432400/25046 (51%)]\tLoss: 1.072667\n",
            "Train epoch: 180 [420000/25046 (54%)]\tLoss: 0.847020\n",
            "Train epoch: 180 [438240/25046 (56%)]\tLoss: 0.404273\n",
            "Train epoch: 180 [516120/25046 (59%)]\tLoss: 0.389776\n",
            "Train epoch: 180 [471360/25046 (61%)]\tLoss: 1.155099\n",
            "Train epoch: 180 [513500/25046 (64%)]\tLoss: 0.448549\n",
            "Train epoch: 180 [544440/25046 (66%)]\tLoss: 0.526721\n",
            "Train epoch: 180 [553500/25046 (69%)]\tLoss: 0.666283\n",
            "Train epoch: 180 [562800/25046 (72%)]\tLoss: 0.600332\n",
            "Train epoch: 180 [568980/25046 (74%)]\tLoss: 0.864775\n",
            "Train epoch: 180 [586200/25046 (77%)]\tLoss: 0.450697\n",
            "Train epoch: 180 [627440/25046 (79%)]\tLoss: 1.219906\n",
            "Train epoch: 180 [647040/25046 (82%)]\tLoss: 0.655373\n",
            "Train epoch: 180 [701580/25046 (84%)]\tLoss: 1.603153\n",
            "Train epoch: 180 [729640/25046 (87%)]\tLoss: 0.603805\n",
            "Train epoch: 180 [713300/25046 (89%)]\tLoss: 1.458017\n",
            "Train epoch: 180 [716400/25046 (92%)]\tLoss: 0.397892\n",
            "Train epoch: 180 [757760/25046 (95%)]\tLoss: 0.469594\n",
            "Train epoch: 180 [779000/25046 (97%)]\tLoss: 1.163213\n",
            "Train epoch: 180 [801840/25046 (100%)]\tLoss: 0.958157\n",
            "Make prediction for 5010 samples...\n",
            "0.8044984 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 181 [0/25046 (0%)]\tLoss: 0.541870\n",
            "Train epoch: 181 [20700/25046 (3%)]\tLoss: 0.978436\n",
            "Train epoch: 181 [42720/25046 (5%)]\tLoss: 0.728194\n",
            "Train epoch: 181 [62580/25046 (8%)]\tLoss: 0.848057\n",
            "Train epoch: 181 [80000/25046 (10%)]\tLoss: 1.451594\n",
            "Train epoch: 181 [105900/25046 (13%)]\tLoss: 0.390553\n",
            "Train epoch: 181 [118440/25046 (15%)]\tLoss: 0.572150\n",
            "Train epoch: 181 [147840/25046 (18%)]\tLoss: 0.730258\n",
            "Train epoch: 181 [171040/25046 (20%)]\tLoss: 0.434704\n",
            "Train epoch: 181 [184860/25046 (23%)]\tLoss: 1.177679\n",
            "Train epoch: 181 [191200/25046 (26%)]\tLoss: 1.131703\n",
            "Train epoch: 181 [214720/25046 (28%)]\tLoss: 0.234033\n",
            "Train epoch: 181 [220080/25046 (31%)]\tLoss: 0.398867\n",
            "Train epoch: 181 [266760/25046 (33%)]\tLoss: 0.667540\n",
            "Train epoch: 181 [290080/25046 (36%)]\tLoss: 0.572727\n",
            "Train epoch: 181 [304200/25046 (38%)]\tLoss: 0.747760\n",
            "Train epoch: 181 [339200/25046 (41%)]\tLoss: 0.906659\n",
            "Train epoch: 181 [358020/25046 (43%)]\tLoss: 0.826303\n",
            "Train epoch: 181 [354600/25046 (46%)]\tLoss: 0.641467\n",
            "Train epoch: 181 [396340/25046 (49%)]\tLoss: 0.509726\n",
            "Train epoch: 181 [402400/25046 (51%)]\tLoss: 0.738167\n",
            "Train epoch: 181 [438060/25046 (54%)]\tLoss: 0.752298\n",
            "Train epoch: 181 [451440/25046 (56%)]\tLoss: 1.075672\n",
            "Train epoch: 181 [463220/25046 (59%)]\tLoss: 1.052486\n",
            "Train epoch: 181 [492480/25046 (61%)]\tLoss: 0.906397\n",
            "Train epoch: 181 [522000/25046 (64%)]\tLoss: 0.272506\n",
            "Train epoch: 181 [518440/25046 (66%)]\tLoss: 0.434876\n",
            "Train epoch: 181 [564840/25046 (69%)]\tLoss: 1.493591\n",
            "Train epoch: 181 [547120/25046 (72%)]\tLoss: 0.454676\n",
            "Train epoch: 181 [609000/25046 (74%)]\tLoss: 0.815315\n",
            "Train epoch: 181 [579000/25046 (77%)]\tLoss: 0.316506\n",
            "Train epoch: 181 [628060/25046 (79%)]\tLoss: 0.369505\n",
            "Train epoch: 181 [688640/25046 (82%)]\tLoss: 0.422226\n",
            "Train epoch: 181 [670560/25046 (84%)]\tLoss: 1.053099\n",
            "Train epoch: 181 [675240/25046 (87%)]\tLoss: 0.864310\n",
            "Train epoch: 181 [742000/25046 (89%)]\tLoss: 0.628262\n",
            "Train epoch: 181 [735840/25046 (92%)]\tLoss: 0.747981\n",
            "Train epoch: 181 [760720/25046 (95%)]\tLoss: 1.127990\n",
            "Train epoch: 181 [798000/25046 (97%)]\tLoss: 0.525658\n",
            "Train epoch: 181 [750360/25046 (100%)]\tLoss: 0.218690\n",
            "Make prediction for 5010 samples...\n",
            "0.8020043 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 182 [0/25046 (0%)]\tLoss: 0.534376\n",
            "Train epoch: 182 [19140/25046 (3%)]\tLoss: 1.546735\n",
            "Train epoch: 182 [39400/25046 (5%)]\tLoss: 1.593466\n",
            "Train epoch: 182 [58320/25046 (8%)]\tLoss: 0.848878\n",
            "Train epoch: 182 [78480/25046 (10%)]\tLoss: 0.465888\n",
            "Train epoch: 182 [100800/25046 (13%)]\tLoss: 0.611048\n",
            "Train epoch: 182 [126480/25046 (15%)]\tLoss: 0.307885\n",
            "Train epoch: 182 [136920/25046 (18%)]\tLoss: 0.396591\n",
            "Train epoch: 182 [160800/25046 (20%)]\tLoss: 0.824348\n",
            "Train epoch: 182 [187920/25046 (23%)]\tLoss: 0.654087\n",
            "Train epoch: 182 [209800/25046 (26%)]\tLoss: 0.392129\n",
            "Train epoch: 182 [234960/25046 (28%)]\tLoss: 1.384136\n",
            "Train epoch: 182 [244320/25046 (31%)]\tLoss: 0.437087\n",
            "Train epoch: 182 [258700/25046 (33%)]\tLoss: 0.962922\n",
            "Train epoch: 182 [289240/25046 (36%)]\tLoss: 1.115478\n",
            "Train epoch: 182 [318900/25046 (38%)]\tLoss: 0.900157\n",
            "Train epoch: 182 [322240/25046 (41%)]\tLoss: 0.454707\n",
            "Train epoch: 182 [334560/25046 (43%)]\tLoss: 0.485953\n",
            "Train epoch: 182 [368280/25046 (46%)]\tLoss: 1.629387\n",
            "Train epoch: 182 [392160/25046 (49%)]\tLoss: 1.251392\n",
            "Train epoch: 182 [428800/25046 (51%)]\tLoss: 0.761095\n",
            "Train epoch: 182 [417480/25046 (54%)]\tLoss: 1.508680\n",
            "Train epoch: 182 [485320/25046 (56%)]\tLoss: 0.978191\n",
            "Train epoch: 182 [483000/25046 (59%)]\tLoss: 0.579580\n",
            "Train epoch: 182 [513600/25046 (61%)]\tLoss: 0.959391\n",
            "Train epoch: 182 [511500/25046 (64%)]\tLoss: 1.060757\n",
            "Train epoch: 182 [513760/25046 (66%)]\tLoss: 0.384830\n",
            "Train epoch: 182 [568620/25046 (69%)]\tLoss: 0.675465\n",
            "Train epoch: 182 [572880/25046 (72%)]\tLoss: 1.681337\n",
            "Train epoch: 182 [584060/25046 (74%)]\tLoss: 0.669384\n",
            "Train epoch: 182 [587400/25046 (77%)]\tLoss: 1.012015\n",
            "Train epoch: 182 [628060/25046 (79%)]\tLoss: 0.924270\n",
            "Train epoch: 182 [632960/25046 (82%)]\tLoss: 1.083659\n",
            "Train epoch: 182 [678480/25046 (84%)]\tLoss: 1.128313\n",
            "Train epoch: 182 [707880/25046 (87%)]\tLoss: 0.798082\n",
            "Train epoch: 182 [746900/25046 (89%)]\tLoss: 0.895169\n",
            "Train epoch: 182 [683280/25046 (92%)]\tLoss: 0.635385\n",
            "Train epoch: 182 [758500/25046 (95%)]\tLoss: 0.718606\n",
            "Train epoch: 182 [782800/25046 (97%)]\tLoss: 1.874233\n",
            "Train epoch: 182 [839280/25046 (100%)]\tLoss: 0.832725\n",
            "Make prediction for 5010 samples...\n",
            "0.8033544 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 183 [0/25046 (0%)]\tLoss: 0.804250\n",
            "Train epoch: 183 [21700/25046 (3%)]\tLoss: 0.990274\n",
            "Train epoch: 183 [41680/25046 (5%)]\tLoss: 1.367743\n",
            "Train epoch: 183 [63900/25046 (8%)]\tLoss: 2.036876\n",
            "Train epoch: 183 [82800/25046 (10%)]\tLoss: 0.451467\n",
            "Train epoch: 183 [101000/25046 (13%)]\tLoss: 0.659259\n",
            "Train epoch: 183 [129960/25046 (15%)]\tLoss: 0.661815\n",
            "Train epoch: 183 [144620/25046 (18%)]\tLoss: 0.438690\n",
            "Train epoch: 183 [165120/25046 (20%)]\tLoss: 1.372045\n",
            "Train epoch: 183 [184140/25046 (23%)]\tLoss: 0.926732\n",
            "Train epoch: 183 [189600/25046 (26%)]\tLoss: 0.627061\n",
            "Train epoch: 183 [230120/25046 (28%)]\tLoss: 1.301313\n",
            "Train epoch: 183 [257760/25046 (31%)]\tLoss: 0.330748\n",
            "Train epoch: 183 [281840/25046 (33%)]\tLoss: 0.724769\n",
            "Train epoch: 183 [279160/25046 (36%)]\tLoss: 0.510641\n",
            "Train epoch: 183 [324300/25046 (38%)]\tLoss: 0.403884\n",
            "Train epoch: 183 [315200/25046 (41%)]\tLoss: 0.873164\n",
            "Train epoch: 183 [353940/25046 (43%)]\tLoss: 0.339574\n",
            "Train epoch: 183 [392760/25046 (46%)]\tLoss: 0.353628\n",
            "Train epoch: 183 [378860/25046 (49%)]\tLoss: 0.886544\n",
            "Train epoch: 183 [401600/25046 (51%)]\tLoss: 0.509191\n",
            "Train epoch: 183 [410760/25046 (54%)]\tLoss: 0.957689\n",
            "Train epoch: 183 [465520/25046 (56%)]\tLoss: 1.426730\n",
            "Train epoch: 183 [438380/25046 (59%)]\tLoss: 1.282865\n",
            "Train epoch: 183 [492480/25046 (61%)]\tLoss: 0.656940\n",
            "Train epoch: 183 [506500/25046 (64%)]\tLoss: 0.419169\n",
            "Train epoch: 183 [523640/25046 (66%)]\tLoss: 0.656712\n",
            "Train epoch: 183 [523800/25046 (69%)]\tLoss: 0.484278\n",
            "Train epoch: 183 [579600/25046 (72%)]\tLoss: 0.709990\n",
            "Train epoch: 183 [614800/25046 (74%)]\tLoss: 0.475049\n",
            "Train epoch: 183 [662400/25046 (77%)]\tLoss: 1.149180\n",
            "Train epoch: 183 [619380/25046 (79%)]\tLoss: 1.212155\n",
            "Train epoch: 183 [692480/25046 (82%)]\tLoss: 0.758351\n",
            "Train epoch: 183 [729960/25046 (84%)]\tLoss: 0.998323\n",
            "Train epoch: 183 [688840/25046 (87%)]\tLoss: 0.378394\n",
            "Train epoch: 183 [714000/25046 (89%)]\tLoss: 0.409075\n",
            "Train epoch: 183 [727920/25046 (92%)]\tLoss: 0.681496\n",
            "Train epoch: 183 [750360/25046 (95%)]\tLoss: 0.606673\n",
            "Train epoch: 183 [739480/25046 (97%)]\tLoss: 0.281058\n",
            "Train epoch: 183 [839280/25046 (100%)]\tLoss: 0.518646\n",
            "Make prediction for 5010 samples...\n",
            "0.8033379 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 184 [0/25046 (0%)]\tLoss: 0.488243\n",
            "Train epoch: 184 [20820/25046 (3%)]\tLoss: 0.266154\n",
            "Train epoch: 184 [40600/25046 (5%)]\tLoss: 0.351447\n",
            "Train epoch: 184 [58920/25046 (8%)]\tLoss: 0.654019\n",
            "Train epoch: 184 [79760/25046 (10%)]\tLoss: 1.146435\n",
            "Train epoch: 184 [101500/25046 (13%)]\tLoss: 0.505519\n",
            "Train epoch: 184 [120960/25046 (15%)]\tLoss: 1.421514\n",
            "Train epoch: 184 [145600/25046 (18%)]\tLoss: 0.926254\n",
            "Train epoch: 184 [155520/25046 (20%)]\tLoss: 1.271423\n",
            "Train epoch: 184 [191520/25046 (23%)]\tLoss: 1.092022\n",
            "Train epoch: 184 [199800/25046 (26%)]\tLoss: 0.546595\n",
            "Train epoch: 184 [233860/25046 (28%)]\tLoss: 0.509375\n",
            "Train epoch: 184 [239520/25046 (31%)]\tLoss: 0.420200\n",
            "Train epoch: 184 [267020/25046 (33%)]\tLoss: 0.878266\n",
            "Train epoch: 184 [274400/25046 (36%)]\tLoss: 0.903337\n",
            "Train epoch: 184 [315600/25046 (38%)]\tLoss: 0.279183\n",
            "Train epoch: 184 [325760/25046 (41%)]\tLoss: 0.665224\n",
            "Train epoch: 184 [367540/25046 (43%)]\tLoss: 1.727490\n",
            "Train epoch: 184 [349200/25046 (46%)]\tLoss: 0.898382\n",
            "Train epoch: 184 [427500/25046 (49%)]\tLoss: 1.580989\n",
            "Train epoch: 184 [417600/25046 (51%)]\tLoss: 0.233879\n",
            "Train epoch: 184 [455700/25046 (54%)]\tLoss: 0.222634\n",
            "Train epoch: 184 [452320/25046 (56%)]\tLoss: 0.511708\n",
            "Train epoch: 184 [486680/25046 (59%)]\tLoss: 1.459922\n",
            "Train epoch: 184 [521760/25046 (61%)]\tLoss: 0.685804\n",
            "Train epoch: 184 [509000/25046 (64%)]\tLoss: 0.780591\n",
            "Train epoch: 184 [537680/25046 (66%)]\tLoss: 1.565804\n",
            "Train epoch: 184 [563760/25046 (69%)]\tLoss: 1.112555\n",
            "Train epoch: 184 [542080/25046 (72%)]\tLoss: 1.171968\n",
            "Train epoch: 184 [586960/25046 (74%)]\tLoss: 0.900912\n",
            "Train epoch: 184 [588000/25046 (77%)]\tLoss: 0.476824\n",
            "Train epoch: 184 [666500/25046 (79%)]\tLoss: 0.856322\n",
            "Train epoch: 184 [668160/25046 (82%)]\tLoss: 0.754827\n",
            "Train epoch: 184 [691020/25046 (84%)]\tLoss: 0.447276\n",
            "Train epoch: 184 [687480/25046 (87%)]\tLoss: 0.855369\n",
            "Train epoch: 184 [718900/25046 (89%)]\tLoss: 0.470505\n",
            "Train epoch: 184 [743040/25046 (92%)]\tLoss: 1.237593\n",
            "Train epoch: 184 [801420/25046 (95%)]\tLoss: 0.720844\n",
            "Train epoch: 184 [769880/25046 (97%)]\tLoss: 1.785872\n",
            "Train epoch: 184 [742560/25046 (100%)]\tLoss: 0.273926\n",
            "Make prediction for 5010 samples...\n",
            "0.8084924 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 185 [0/25046 (0%)]\tLoss: 1.213379\n",
            "Train epoch: 185 [19220/25046 (3%)]\tLoss: 0.709811\n",
            "Train epoch: 185 [41520/25046 (5%)]\tLoss: 0.640103\n",
            "Train epoch: 185 [62040/25046 (8%)]\tLoss: 0.565090\n",
            "Train epoch: 185 [77440/25046 (10%)]\tLoss: 1.599757\n",
            "Train epoch: 185 [102900/25046 (13%)]\tLoss: 0.778487\n",
            "Train epoch: 185 [123360/25046 (15%)]\tLoss: 0.774768\n",
            "Train epoch: 185 [142240/25046 (18%)]\tLoss: 1.037978\n",
            "Train epoch: 185 [168480/25046 (20%)]\tLoss: 1.105013\n",
            "Train epoch: 185 [180360/25046 (23%)]\tLoss: 0.593197\n",
            "Train epoch: 185 [203000/25046 (26%)]\tLoss: 1.006640\n",
            "Train epoch: 185 [220880/25046 (28%)]\tLoss: 0.882101\n",
            "Train epoch: 185 [253680/25046 (31%)]\tLoss: 0.896775\n",
            "Train epoch: 185 [268580/25046 (33%)]\tLoss: 0.865747\n",
            "Train epoch: 185 [292040/25046 (36%)]\tLoss: 0.863837\n",
            "Train epoch: 185 [337200/25046 (38%)]\tLoss: 0.859543\n",
            "Train epoch: 185 [345600/25046 (41%)]\tLoss: 0.183426\n",
            "Train epoch: 185 [316200/25046 (43%)]\tLoss: 1.127670\n",
            "Train epoch: 185 [378360/25046 (46%)]\tLoss: 1.816900\n",
            "Train epoch: 185 [400140/25046 (49%)]\tLoss: 1.197860\n",
            "Train epoch: 185 [409600/25046 (51%)]\tLoss: 0.643004\n",
            "Train epoch: 185 [418320/25046 (54%)]\tLoss: 0.630740\n",
            "Train epoch: 185 [454960/25046 (56%)]\tLoss: 0.426255\n",
            "Train epoch: 185 [476560/25046 (59%)]\tLoss: 1.052346\n",
            "Train epoch: 185 [508800/25046 (61%)]\tLoss: 0.736925\n",
            "Train epoch: 185 [496500/25046 (64%)]\tLoss: 0.971730\n",
            "Train epoch: 185 [530920/25046 (66%)]\tLoss: 0.885257\n",
            "Train epoch: 185 [542700/25046 (69%)]\tLoss: 0.190800\n",
            "Train epoch: 185 [534800/25046 (72%)]\tLoss: 0.698094\n",
            "Train epoch: 185 [625240/25046 (74%)]\tLoss: 0.808724\n",
            "Train epoch: 185 [655200/25046 (77%)]\tLoss: 0.775375\n",
            "Train epoch: 185 [639220/25046 (79%)]\tLoss: 0.809334\n",
            "Train epoch: 185 [652800/25046 (82%)]\tLoss: 0.304247\n",
            "Train epoch: 185 [646140/25046 (84%)]\tLoss: 0.582354\n",
            "Train epoch: 185 [709240/25046 (87%)]\tLoss: 0.901790\n",
            "Train epoch: 185 [669200/25046 (89%)]\tLoss: 0.374728\n",
            "Train epoch: 185 [747360/25046 (92%)]\tLoss: 0.795557\n",
            "Train epoch: 185 [752580/25046 (95%)]\tLoss: 0.426181\n",
            "Train epoch: 185 [794960/25046 (97%)]\tLoss: 0.476598\n",
            "Train epoch: 185 [783900/25046 (100%)]\tLoss: 1.259493\n",
            "Make prediction for 5010 samples...\n",
            "0.8050687 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 186 [0/25046 (0%)]\tLoss: 1.283437\n",
            "Train epoch: 186 [19780/25046 (3%)]\tLoss: 0.979230\n",
            "Train epoch: 186 [42480/25046 (5%)]\tLoss: 1.606628\n",
            "Train epoch: 186 [64140/25046 (8%)]\tLoss: 0.531669\n",
            "Train epoch: 186 [83840/25046 (10%)]\tLoss: 0.440722\n",
            "Train epoch: 186 [101600/25046 (13%)]\tLoss: 0.725273\n",
            "Train epoch: 186 [127200/25046 (15%)]\tLoss: 0.575334\n",
            "Train epoch: 186 [146300/25046 (18%)]\tLoss: 0.978230\n",
            "Train epoch: 186 [171040/25046 (20%)]\tLoss: 0.519553\n",
            "Train epoch: 186 [183780/25046 (23%)]\tLoss: 0.768352\n",
            "Train epoch: 186 [195800/25046 (26%)]\tLoss: 0.642955\n",
            "Train epoch: 186 [223740/25046 (28%)]\tLoss: 1.050159\n",
            "Train epoch: 186 [254880/25046 (31%)]\tLoss: 1.224367\n",
            "Train epoch: 186 [268840/25046 (33%)]\tLoss: 1.021387\n",
            "Train epoch: 186 [278040/25046 (36%)]\tLoss: 0.787076\n",
            "Train epoch: 186 [316800/25046 (38%)]\tLoss: 0.965792\n",
            "Train epoch: 186 [313920/25046 (41%)]\tLoss: 0.377192\n",
            "Train epoch: 186 [357340/25046 (43%)]\tLoss: 1.072500\n",
            "Train epoch: 186 [367200/25046 (46%)]\tLoss: 0.594605\n",
            "Train epoch: 186 [387220/25046 (49%)]\tLoss: 1.830482\n",
            "Train epoch: 186 [424400/25046 (51%)]\tLoss: 0.866347\n",
            "Train epoch: 186 [439320/25046 (54%)]\tLoss: 1.322744\n",
            "Train epoch: 186 [441320/25046 (56%)]\tLoss: 0.319584\n",
            "Train epoch: 186 [476100/25046 (59%)]\tLoss: 0.505689\n",
            "Train epoch: 186 [491520/25046 (61%)]\tLoss: 0.352813\n",
            "Train epoch: 186 [541500/25046 (64%)]\tLoss: 1.191481\n",
            "Train epoch: 186 [536120/25046 (66%)]\tLoss: 1.337040\n",
            "Train epoch: 186 [564840/25046 (69%)]\tLoss: 1.010068\n",
            "Train epoch: 186 [597520/25046 (72%)]\tLoss: 1.277789\n",
            "Train epoch: 186 [582320/25046 (74%)]\tLoss: 0.882129\n",
            "Train epoch: 186 [648000/25046 (77%)]\tLoss: 0.317448\n",
            "Train epoch: 186 [631160/25046 (79%)]\tLoss: 1.051479\n",
            "Train epoch: 186 [656000/25046 (82%)]\tLoss: 1.072678\n",
            "Train epoch: 186 [738540/25046 (84%)]\tLoss: 1.241835\n",
            "Train epoch: 186 [710600/25046 (87%)]\tLoss: 0.283307\n",
            "Train epoch: 186 [691600/25046 (89%)]\tLoss: 0.477040\n",
            "Train epoch: 186 [767520/25046 (92%)]\tLoss: 1.163226\n",
            "Train epoch: 186 [777000/25046 (95%)]\tLoss: 0.691125\n",
            "Train epoch: 186 [761520/25046 (97%)]\tLoss: 0.584044\n",
            "Train epoch: 186 [780000/25046 (100%)]\tLoss: 0.639464\n",
            "Make prediction for 5010 samples...\n",
            "0.8140826 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 187 [0/25046 (0%)]\tLoss: 0.981625\n",
            "Train epoch: 187 [21580/25046 (3%)]\tLoss: 0.785648\n",
            "Train epoch: 187 [40040/25046 (5%)]\tLoss: 0.283822\n",
            "Train epoch: 187 [62100/25046 (8%)]\tLoss: 0.437105\n",
            "Train epoch: 187 [86800/25046 (10%)]\tLoss: 0.983089\n",
            "Train epoch: 187 [96900/25046 (13%)]\tLoss: 0.445834\n",
            "Train epoch: 187 [129720/25046 (15%)]\tLoss: 0.988137\n",
            "Train epoch: 187 [140420/25046 (18%)]\tLoss: 0.857363\n",
            "Train epoch: 187 [171520/25046 (20%)]\tLoss: 1.016783\n",
            "Train epoch: 187 [195840/25046 (23%)]\tLoss: 0.394342\n",
            "Train epoch: 187 [210800/25046 (26%)]\tLoss: 1.035350\n",
            "Train epoch: 187 [221980/25046 (28%)]\tLoss: 0.495446\n",
            "Train epoch: 187 [238080/25046 (31%)]\tLoss: 0.365684\n",
            "Train epoch: 187 [256100/25046 (33%)]\tLoss: 0.761440\n",
            "Train epoch: 187 [290920/25046 (36%)]\tLoss: 1.274600\n",
            "Train epoch: 187 [283200/25046 (38%)]\tLoss: 0.596235\n",
            "Train epoch: 187 [316160/25046 (41%)]\tLoss: 1.184527\n",
            "Train epoch: 187 [343740/25046 (43%)]\tLoss: 0.712323\n",
            "Train epoch: 187 [356760/25046 (46%)]\tLoss: 0.533565\n",
            "Train epoch: 187 [413820/25046 (49%)]\tLoss: 1.314369\n",
            "Train epoch: 187 [431600/25046 (51%)]\tLoss: 0.733352\n",
            "Train epoch: 187 [417480/25046 (54%)]\tLoss: 0.493517\n",
            "Train epoch: 187 [434280/25046 (56%)]\tLoss: 1.009908\n",
            "Train epoch: 187 [471960/25046 (59%)]\tLoss: 0.867026\n",
            "Train epoch: 187 [489120/25046 (61%)]\tLoss: 1.329656\n",
            "Train epoch: 187 [504500/25046 (64%)]\tLoss: 0.483083\n",
            "Train epoch: 187 [573040/25046 (66%)]\tLoss: 0.647384\n",
            "Train epoch: 187 [583740/25046 (69%)]\tLoss: 0.443576\n",
            "Train epoch: 187 [557200/25046 (72%)]\tLoss: 1.049802\n",
            "Train epoch: 187 [571300/25046 (74%)]\tLoss: 1.035112\n",
            "Train epoch: 187 [618000/25046 (77%)]\tLoss: 0.553416\n",
            "Train epoch: 187 [639840/25046 (79%)]\tLoss: 0.330161\n",
            "Train epoch: 187 [682880/25046 (82%)]\tLoss: 2.007099\n",
            "Train epoch: 187 [733920/25046 (84%)]\tLoss: 1.433143\n",
            "Train epoch: 187 [662320/25046 (87%)]\tLoss: 1.497705\n",
            "Train epoch: 187 [717500/25046 (89%)]\tLoss: 0.641566\n",
            "Train epoch: 187 [755280/25046 (92%)]\tLoss: 1.084382\n",
            "Train epoch: 187 [754060/25046 (95%)]\tLoss: 0.637524\n",
            "Train epoch: 187 [775200/25046 (97%)]\tLoss: 0.924130\n",
            "Train epoch: 187 [826020/25046 (100%)]\tLoss: 0.393713\n",
            "Make prediction for 5010 samples...\n",
            "0.80167216 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 188 [0/25046 (0%)]\tLoss: 0.812064\n",
            "Train epoch: 188 [21160/25046 (3%)]\tLoss: 0.375864\n",
            "Train epoch: 188 [42160/25046 (5%)]\tLoss: 1.117225\n",
            "Train epoch: 188 [59880/25046 (8%)]\tLoss: 0.800885\n",
            "Train epoch: 188 [80800/25046 (10%)]\tLoss: 0.502197\n",
            "Train epoch: 188 [102600/25046 (13%)]\tLoss: 1.116174\n",
            "Train epoch: 188 [124680/25046 (15%)]\tLoss: 0.733645\n",
            "Train epoch: 188 [146580/25046 (18%)]\tLoss: 0.594953\n",
            "Train epoch: 188 [169440/25046 (20%)]\tLoss: 1.407402\n",
            "Train epoch: 188 [197460/25046 (23%)]\tLoss: 0.809210\n",
            "Train epoch: 188 [208600/25046 (26%)]\tLoss: 0.457224\n",
            "Train epoch: 188 [226160/25046 (28%)]\tLoss: 2.308310\n",
            "Train epoch: 188 [248640/25046 (31%)]\tLoss: 0.850083\n",
            "Train epoch: 188 [259740/25046 (33%)]\tLoss: 0.759845\n",
            "Train epoch: 188 [311920/25046 (36%)]\tLoss: 0.735207\n",
            "Train epoch: 188 [303300/25046 (38%)]\tLoss: 0.932546\n",
            "Train epoch: 188 [330240/25046 (41%)]\tLoss: 0.397226\n",
            "Train epoch: 188 [348160/25046 (43%)]\tLoss: 0.491456\n",
            "Train epoch: 188 [393840/25046 (46%)]\tLoss: 0.611163\n",
            "Train epoch: 188 [370120/25046 (49%)]\tLoss: 0.859998\n",
            "Train epoch: 188 [393600/25046 (51%)]\tLoss: 0.654380\n",
            "Train epoch: 188 [424620/25046 (54%)]\tLoss: 0.945156\n",
            "Train epoch: 188 [460240/25046 (56%)]\tLoss: 0.890070\n",
            "Train epoch: 188 [459540/25046 (59%)]\tLoss: 0.342935\n",
            "Train epoch: 188 [516960/25046 (61%)]\tLoss: 0.485197\n",
            "Train epoch: 188 [500500/25046 (64%)]\tLoss: 0.610619\n",
            "Train epoch: 188 [530400/25046 (66%)]\tLoss: 2.418643\n",
            "Train epoch: 188 [550260/25046 (69%)]\tLoss: 1.106903\n",
            "Train epoch: 188 [579600/25046 (72%)]\tLoss: 0.952839\n",
            "Train epoch: 188 [588700/25046 (74%)]\tLoss: 0.729652\n",
            "Train epoch: 188 [612000/25046 (77%)]\tLoss: 0.703552\n",
            "Train epoch: 188 [653480/25046 (79%)]\tLoss: 0.856947\n",
            "Train epoch: 188 [716160/25046 (82%)]\tLoss: 0.833322\n",
            "Train epoch: 188 [636900/25046 (84%)]\tLoss: 0.636190\n",
            "Train epoch: 188 [688160/25046 (87%)]\tLoss: 0.653989\n",
            "Train epoch: 188 [744800/25046 (89%)]\tLoss: 1.558416\n",
            "Train epoch: 188 [729360/25046 (92%)]\tLoss: 0.765838\n",
            "Train epoch: 188 [758500/25046 (95%)]\tLoss: 0.689481\n",
            "Train epoch: 188 [762280/25046 (97%)]\tLoss: 1.386927\n",
            "Train epoch: 188 [820560/25046 (100%)]\tLoss: 1.365435\n",
            "Make prediction for 5010 samples...\n",
            "0.803498 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 189 [0/25046 (0%)]\tLoss: 1.073598\n",
            "Train epoch: 189 [21440/25046 (3%)]\tLoss: 0.859693\n",
            "Train epoch: 189 [41040/25046 (5%)]\tLoss: 0.824581\n",
            "Train epoch: 189 [61920/25046 (8%)]\tLoss: 0.602478\n",
            "Train epoch: 189 [81280/25046 (10%)]\tLoss: 1.616539\n",
            "Train epoch: 189 [100200/25046 (13%)]\tLoss: 1.221892\n",
            "Train epoch: 189 [118320/25046 (15%)]\tLoss: 0.875869\n",
            "Train epoch: 189 [143500/25046 (18%)]\tLoss: 0.427455\n",
            "Train epoch: 189 [164320/25046 (20%)]\tLoss: 1.114881\n",
            "Train epoch: 189 [182340/25046 (23%)]\tLoss: 0.328706\n",
            "Train epoch: 189 [209800/25046 (26%)]\tLoss: 0.932599\n",
            "Train epoch: 189 [224620/25046 (28%)]\tLoss: 0.316498\n",
            "Train epoch: 189 [246480/25046 (31%)]\tLoss: 0.308390\n",
            "Train epoch: 189 [271700/25046 (33%)]\tLoss: 0.326283\n",
            "Train epoch: 189 [287000/25046 (36%)]\tLoss: 1.116200\n",
            "Train epoch: 189 [306900/25046 (38%)]\tLoss: 1.126219\n",
            "Train epoch: 189 [314880/25046 (41%)]\tLoss: 0.407008\n",
            "Train epoch: 189 [360740/25046 (43%)]\tLoss: 0.826127\n",
            "Train epoch: 189 [370080/25046 (46%)]\tLoss: 0.510853\n",
            "Train epoch: 189 [411540/25046 (49%)]\tLoss: 0.598413\n",
            "Train epoch: 189 [421200/25046 (51%)]\tLoss: 0.838993\n",
            "Train epoch: 189 [429240/25046 (54%)]\tLoss: 1.055734\n",
            "Train epoch: 189 [434720/25046 (56%)]\tLoss: 0.971477\n",
            "Train epoch: 189 [490360/25046 (59%)]\tLoss: 1.199671\n",
            "Train epoch: 189 [496800/25046 (61%)]\tLoss: 0.362695\n",
            "Train epoch: 189 [540500/25046 (64%)]\tLoss: 0.627683\n",
            "Train epoch: 189 [513240/25046 (66%)]\tLoss: 0.418855\n",
            "Train epoch: 189 [589680/25046 (69%)]\tLoss: 1.074524\n",
            "Train epoch: 189 [570080/25046 (72%)]\tLoss: 1.358413\n",
            "Train epoch: 189 [564920/25046 (74%)]\tLoss: 0.733667\n",
            "Train epoch: 189 [615000/25046 (77%)]\tLoss: 0.740630\n",
            "Train epoch: 189 [669600/25046 (79%)]\tLoss: 0.766840\n",
            "Train epoch: 189 [633600/25046 (82%)]\tLoss: 1.111692\n",
            "Train epoch: 189 [664620/25046 (84%)]\tLoss: 0.450598\n",
            "Train epoch: 189 [717400/25046 (87%)]\tLoss: 0.614912\n",
            "Train epoch: 189 [712600/25046 (89%)]\tLoss: 1.471672\n",
            "Train epoch: 189 [753120/25046 (92%)]\tLoss: 0.564820\n",
            "Train epoch: 189 [735560/25046 (95%)]\tLoss: 1.163914\n",
            "Train epoch: 189 [766840/25046 (97%)]\tLoss: 0.683593\n",
            "Train epoch: 189 [831480/25046 (100%)]\tLoss: 1.045018\n",
            "Make prediction for 5010 samples...\n",
            "0.803847 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 190 [0/25046 (0%)]\tLoss: 1.610648\n",
            "Train epoch: 190 [20420/25046 (3%)]\tLoss: 1.450218\n",
            "Train epoch: 190 [41200/25046 (5%)]\tLoss: 1.485438\n",
            "Train epoch: 190 [65640/25046 (8%)]\tLoss: 1.190720\n",
            "Train epoch: 190 [81120/25046 (10%)]\tLoss: 0.540225\n",
            "Train epoch: 190 [104300/25046 (13%)]\tLoss: 0.848297\n",
            "Train epoch: 190 [121920/25046 (15%)]\tLoss: 0.884425\n",
            "Train epoch: 190 [136500/25046 (18%)]\tLoss: 0.882473\n",
            "Train epoch: 190 [166720/25046 (20%)]\tLoss: 0.491873\n",
            "Train epoch: 190 [183240/25046 (23%)]\tLoss: 0.958567\n",
            "Train epoch: 190 [226000/25046 (26%)]\tLoss: 0.384346\n",
            "Train epoch: 190 [225720/25046 (28%)]\tLoss: 0.710514\n",
            "Train epoch: 190 [253200/25046 (31%)]\tLoss: 1.267662\n",
            "Train epoch: 190 [265720/25046 (33%)]\tLoss: 0.347324\n",
            "Train epoch: 190 [296520/25046 (36%)]\tLoss: 0.645212\n",
            "Train epoch: 190 [308100/25046 (38%)]\tLoss: 1.100119\n",
            "Train epoch: 190 [310400/25046 (41%)]\tLoss: 0.504798\n",
            "Train epoch: 190 [335920/25046 (43%)]\tLoss: 1.038636\n",
            "Train epoch: 190 [381240/25046 (46%)]\tLoss: 1.348494\n",
            "Train epoch: 190 [369360/25046 (49%)]\tLoss: 0.875090\n",
            "Train epoch: 190 [409200/25046 (51%)]\tLoss: 0.420330\n",
            "Train epoch: 190 [430500/25046 (54%)]\tLoss: 0.905661\n",
            "Train epoch: 190 [439560/25046 (56%)]\tLoss: 0.544949\n",
            "Train epoch: 190 [455860/25046 (59%)]\tLoss: 0.702610\n",
            "Train epoch: 190 [484320/25046 (61%)]\tLoss: 1.033152\n",
            "Train epoch: 190 [499500/25046 (64%)]\tLoss: 0.849763\n",
            "Train epoch: 190 [517920/25046 (66%)]\tLoss: 0.773081\n",
            "Train epoch: 190 [568080/25046 (69%)]\tLoss: 0.610788\n",
            "Train epoch: 190 [547680/25046 (72%)]\tLoss: 0.357705\n",
            "Train epoch: 190 [613060/25046 (74%)]\tLoss: 1.041107\n",
            "Train epoch: 190 [641400/25046 (77%)]\tLoss: 1.981154\n",
            "Train epoch: 190 [626200/25046 (79%)]\tLoss: 1.210204\n",
            "Train epoch: 190 [654080/25046 (82%)]\tLoss: 0.856901\n",
            "Train epoch: 190 [653400/25046 (84%)]\tLoss: 1.133182\n",
            "Train epoch: 190 [698360/25046 (87%)]\tLoss: 0.732380\n",
            "Train epoch: 190 [715400/25046 (89%)]\tLoss: 1.002076\n",
            "Train epoch: 190 [774720/25046 (92%)]\tLoss: 1.013088\n",
            "Train epoch: 190 [776260/25046 (95%)]\tLoss: 0.516820\n",
            "Train epoch: 190 [757720/25046 (97%)]\tLoss: 0.292735\n",
            "Train epoch: 190 [774540/25046 (100%)]\tLoss: 0.500736\n",
            "Make prediction for 5010 samples...\n",
            "0.80151445 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 191 [0/25046 (0%)]\tLoss: 0.881418\n",
            "Train epoch: 191 [20700/25046 (3%)]\tLoss: 1.243991\n",
            "Train epoch: 191 [39240/25046 (5%)]\tLoss: 0.421522\n",
            "Train epoch: 191 [63720/25046 (8%)]\tLoss: 0.484692\n",
            "Train epoch: 191 [81120/25046 (10%)]\tLoss: 0.750919\n",
            "Train epoch: 191 [99200/25046 (13%)]\tLoss: 1.461165\n",
            "Train epoch: 191 [131760/25046 (15%)]\tLoss: 0.547023\n",
            "Train epoch: 191 [132580/25046 (18%)]\tLoss: 0.803223\n",
            "Train epoch: 191 [170880/25046 (20%)]\tLoss: 0.898590\n",
            "Train epoch: 191 [188820/25046 (23%)]\tLoss: 0.849139\n",
            "Train epoch: 191 [217200/25046 (26%)]\tLoss: 0.896952\n",
            "Train epoch: 191 [220440/25046 (28%)]\tLoss: 1.066821\n",
            "Train epoch: 191 [241440/25046 (31%)]\tLoss: 0.421431\n",
            "Train epoch: 191 [256100/25046 (33%)]\tLoss: 1.117240\n",
            "Train epoch: 191 [295960/25046 (36%)]\tLoss: 0.446607\n",
            "Train epoch: 191 [306600/25046 (38%)]\tLoss: 0.488597\n",
            "Train epoch: 191 [328960/25046 (41%)]\tLoss: 0.519987\n",
            "Train epoch: 191 [347140/25046 (43%)]\tLoss: 1.167631\n",
            "Train epoch: 191 [397800/25046 (46%)]\tLoss: 1.103277\n",
            "Train epoch: 191 [384940/25046 (49%)]\tLoss: 0.682695\n",
            "Train epoch: 191 [438800/25046 (51%)]\tLoss: 0.841736\n",
            "Train epoch: 191 [438480/25046 (54%)]\tLoss: 1.290739\n",
            "Train epoch: 191 [465520/25046 (56%)]\tLoss: 0.508252\n",
            "Train epoch: 191 [485760/25046 (59%)]\tLoss: 0.785761\n",
            "Train epoch: 191 [490560/25046 (61%)]\tLoss: 0.445193\n",
            "Train epoch: 191 [479000/25046 (64%)]\tLoss: 1.503875\n",
            "Train epoch: 191 [494000/25046 (66%)]\tLoss: 0.273300\n",
            "Train epoch: 191 [574560/25046 (69%)]\tLoss: 0.467771\n",
            "Train epoch: 191 [560560/25046 (72%)]\tLoss: 1.031097\n",
            "Train epoch: 191 [567240/25046 (74%)]\tLoss: 0.316101\n",
            "Train epoch: 191 [630000/25046 (77%)]\tLoss: 0.553533\n",
            "Train epoch: 191 [648520/25046 (79%)]\tLoss: 1.044893\n",
            "Train epoch: 191 [659200/25046 (82%)]\tLoss: 1.077235\n",
            "Train epoch: 191 [660000/25046 (84%)]\tLoss: 0.957459\n",
            "Train epoch: 191 [673200/25046 (87%)]\tLoss: 0.971480\n",
            "Train epoch: 191 [700700/25046 (89%)]\tLoss: 0.899552\n",
            "Train epoch: 191 [817920/25046 (92%)]\tLoss: 0.784455\n",
            "Train epoch: 191 [785140/25046 (95%)]\tLoss: 1.741414\n",
            "Train epoch: 191 [769880/25046 (97%)]\tLoss: 1.009671\n",
            "Train epoch: 191 [841620/25046 (100%)]\tLoss: 0.612744\n",
            "Make prediction for 5010 samples...\n",
            "0.8024098 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 192 [0/25046 (0%)]\tLoss: 0.336952\n",
            "Train epoch: 192 [20600/25046 (3%)]\tLoss: 0.684921\n",
            "Train epoch: 192 [40560/25046 (5%)]\tLoss: 0.550038\n",
            "Train epoch: 192 [63360/25046 (8%)]\tLoss: 0.638852\n",
            "Train epoch: 192 [82160/25046 (10%)]\tLoss: 0.434948\n",
            "Train epoch: 192 [95100/25046 (13%)]\tLoss: 0.276980\n",
            "Train epoch: 192 [113280/25046 (15%)]\tLoss: 0.803920\n",
            "Train epoch: 192 [143780/25046 (18%)]\tLoss: 1.237706\n",
            "Train epoch: 192 [164480/25046 (20%)]\tLoss: 0.716171\n",
            "Train epoch: 192 [182160/25046 (23%)]\tLoss: 0.762890\n",
            "Train epoch: 192 [199800/25046 (26%)]\tLoss: 0.514075\n",
            "Train epoch: 192 [233200/25046 (28%)]\tLoss: 0.953181\n",
            "Train epoch: 192 [234240/25046 (31%)]\tLoss: 1.306285\n",
            "Train epoch: 192 [286260/25046 (33%)]\tLoss: 0.457839\n",
            "Train epoch: 192 [295120/25046 (36%)]\tLoss: 0.682363\n",
            "Train epoch: 192 [325500/25046 (38%)]\tLoss: 0.369545\n",
            "Train epoch: 192 [339840/25046 (41%)]\tLoss: 1.269458\n",
            "Train epoch: 192 [354280/25046 (43%)]\tLoss: 1.014460\n",
            "Train epoch: 192 [372240/25046 (46%)]\tLoss: 1.382962\n",
            "Train epoch: 192 [390260/25046 (49%)]\tLoss: 1.413777\n",
            "Train epoch: 192 [401200/25046 (51%)]\tLoss: 0.636825\n",
            "Train epoch: 192 [433860/25046 (54%)]\tLoss: 0.446801\n",
            "Train epoch: 192 [434720/25046 (56%)]\tLoss: 0.935074\n",
            "Train epoch: 192 [479320/25046 (59%)]\tLoss: 0.649466\n",
            "Train epoch: 192 [501120/25046 (61%)]\tLoss: 0.892898\n",
            "Train epoch: 192 [512500/25046 (64%)]\tLoss: 1.123222\n",
            "Train epoch: 192 [522600/25046 (66%)]\tLoss: 1.177826\n",
            "Train epoch: 192 [547560/25046 (69%)]\tLoss: 0.372950\n",
            "Train epoch: 192 [577920/25046 (72%)]\tLoss: 0.777998\n",
            "Train epoch: 192 [606100/25046 (74%)]\tLoss: 0.217989\n",
            "Train epoch: 192 [595800/25046 (77%)]\tLoss: 1.896022\n",
            "Train epoch: 192 [641700/25046 (79%)]\tLoss: 0.392129\n",
            "Train epoch: 192 [673280/25046 (82%)]\tLoss: 1.473970\n",
            "Train epoch: 192 [694980/25046 (84%)]\tLoss: 1.050570\n",
            "Train epoch: 192 [699040/25046 (87%)]\tLoss: 1.204957\n",
            "Train epoch: 192 [728700/25046 (89%)]\tLoss: 0.716404\n",
            "Train epoch: 192 [721440/25046 (92%)]\tLoss: 0.984950\n",
            "Train epoch: 192 [754060/25046 (95%)]\tLoss: 0.368630\n",
            "Train epoch: 192 [815480/25046 (97%)]\tLoss: 0.464275\n",
            "Train epoch: 192 [805740/25046 (100%)]\tLoss: 0.327245\n",
            "Make prediction for 5010 samples...\n",
            "0.8019554 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 193 [0/25046 (0%)]\tLoss: 0.414023\n",
            "Train epoch: 193 [20740/25046 (3%)]\tLoss: 0.501327\n",
            "Train epoch: 193 [40640/25046 (5%)]\tLoss: 0.674823\n",
            "Train epoch: 193 [63660/25046 (8%)]\tLoss: 0.705736\n",
            "Train epoch: 193 [82720/25046 (10%)]\tLoss: 0.902107\n",
            "Train epoch: 193 [100800/25046 (13%)]\tLoss: 0.385840\n",
            "Train epoch: 193 [124560/25046 (15%)]\tLoss: 1.941527\n",
            "Train epoch: 193 [143500/25046 (18%)]\tLoss: 0.690364\n",
            "Train epoch: 193 [162880/25046 (20%)]\tLoss: 1.249663\n",
            "Train epoch: 193 [188640/25046 (23%)]\tLoss: 1.055942\n",
            "Train epoch: 193 [211400/25046 (26%)]\tLoss: 0.779239\n",
            "Train epoch: 193 [227040/25046 (28%)]\tLoss: 0.840810\n",
            "Train epoch: 193 [266160/25046 (31%)]\tLoss: 0.855151\n",
            "Train epoch: 193 [273520/25046 (33%)]\tLoss: 0.765397\n",
            "Train epoch: 193 [269920/25046 (36%)]\tLoss: 1.203160\n",
            "Train epoch: 193 [300600/25046 (38%)]\tLoss: 0.696457\n",
            "Train epoch: 193 [360320/25046 (41%)]\tLoss: 0.599187\n",
            "Train epoch: 193 [346800/25046 (43%)]\tLoss: 1.135688\n",
            "Train epoch: 193 [362880/25046 (46%)]\tLoss: 0.841764\n",
            "Train epoch: 193 [372400/25046 (49%)]\tLoss: 0.554909\n",
            "Train epoch: 193 [405600/25046 (51%)]\tLoss: 1.579930\n",
            "Train epoch: 193 [445620/25046 (54%)]\tLoss: 0.470894\n",
            "Train epoch: 193 [451440/25046 (56%)]\tLoss: 0.315124\n",
            "Train epoch: 193 [470580/25046 (59%)]\tLoss: 0.383698\n",
            "Train epoch: 193 [496320/25046 (61%)]\tLoss: 1.316345\n",
            "Train epoch: 193 [518500/25046 (64%)]\tLoss: 1.102963\n",
            "Train epoch: 193 [512200/25046 (66%)]\tLoss: 0.563343\n",
            "Train epoch: 193 [526500/25046 (69%)]\tLoss: 0.978973\n",
            "Train epoch: 193 [590240/25046 (72%)]\tLoss: 1.375280\n",
            "Train epoch: 193 [596240/25046 (74%)]\tLoss: 0.372076\n",
            "Train epoch: 193 [610200/25046 (77%)]\tLoss: 0.947356\n",
            "Train epoch: 193 [667120/25046 (79%)]\tLoss: 0.240316\n",
            "Train epoch: 193 [634240/25046 (82%)]\tLoss: 0.451479\n",
            "Train epoch: 193 [685080/25046 (84%)]\tLoss: 0.497952\n",
            "Train epoch: 193 [694280/25046 (87%)]\tLoss: 0.610454\n",
            "Train epoch: 193 [704200/25046 (89%)]\tLoss: 1.270675\n",
            "Train epoch: 193 [720720/25046 (92%)]\tLoss: 0.659549\n",
            "Train epoch: 193 [761460/25046 (95%)]\tLoss: 0.884716\n",
            "Train epoch: 193 [751640/25046 (97%)]\tLoss: 0.241739\n",
            "Train epoch: 193 [822900/25046 (100%)]\tLoss: 1.414039\n",
            "Make prediction for 5010 samples...\n",
            "0.8049293 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 194 [0/25046 (0%)]\tLoss: 0.739703\n",
            "Train epoch: 194 [19920/25046 (3%)]\tLoss: 0.942917\n",
            "Train epoch: 194 [40680/25046 (5%)]\tLoss: 0.955640\n",
            "Train epoch: 194 [65280/25046 (8%)]\tLoss: 0.350815\n",
            "Train epoch: 194 [83760/25046 (10%)]\tLoss: 0.573560\n",
            "Train epoch: 194 [107500/25046 (13%)]\tLoss: 1.865741\n",
            "Train epoch: 194 [127200/25046 (15%)]\tLoss: 0.381990\n",
            "Train epoch: 194 [139720/25046 (18%)]\tLoss: 0.415858\n",
            "Train epoch: 194 [163520/25046 (20%)]\tLoss: 0.734712\n",
            "Train epoch: 194 [183420/25046 (23%)]\tLoss: 0.379576\n",
            "Train epoch: 194 [214400/25046 (26%)]\tLoss: 1.157280\n",
            "Train epoch: 194 [215820/25046 (28%)]\tLoss: 0.223256\n",
            "Train epoch: 194 [246480/25046 (31%)]\tLoss: 1.031252\n",
            "Train epoch: 194 [260780/25046 (33%)]\tLoss: 0.775362\n",
            "Train epoch: 194 [285600/25046 (36%)]\tLoss: 1.011022\n",
            "Train epoch: 194 [291300/25046 (38%)]\tLoss: 0.826958\n",
            "Train epoch: 194 [336000/25046 (41%)]\tLoss: 0.509196\n",
            "Train epoch: 194 [336260/25046 (43%)]\tLoss: 0.305604\n",
            "Train epoch: 194 [379080/25046 (46%)]\tLoss: 1.510719\n",
            "Train epoch: 194 [381900/25046 (49%)]\tLoss: 0.767392\n",
            "Train epoch: 194 [399600/25046 (51%)]\tLoss: 0.402426\n",
            "Train epoch: 194 [410760/25046 (54%)]\tLoss: 0.504364\n",
            "Train epoch: 194 [436480/25046 (56%)]\tLoss: 0.775326\n",
            "Train epoch: 194 [500940/25046 (59%)]\tLoss: 0.799858\n",
            "Train epoch: 194 [529440/25046 (61%)]\tLoss: 0.839605\n",
            "Train epoch: 194 [538000/25046 (64%)]\tLoss: 0.620364\n",
            "Train epoch: 194 [553280/25046 (66%)]\tLoss: 0.494237\n",
            "Train epoch: 194 [544860/25046 (69%)]\tLoss: 0.803510\n",
            "Train epoch: 194 [558320/25046 (72%)]\tLoss: 0.739810\n",
            "Train epoch: 194 [594500/25046 (74%)]\tLoss: 0.384493\n",
            "Train epoch: 194 [608400/25046 (77%)]\tLoss: 0.677932\n",
            "Train epoch: 194 [636120/25046 (79%)]\tLoss: 1.379537\n",
            "Train epoch: 194 [645120/25046 (82%)]\tLoss: 0.516640\n",
            "Train epoch: 194 [721380/25046 (84%)]\tLoss: 0.631677\n",
            "Train epoch: 194 [688840/25046 (87%)]\tLoss: 0.529885\n",
            "Train epoch: 194 [718900/25046 (89%)]\tLoss: 0.946031\n",
            "Train epoch: 194 [786240/25046 (92%)]\tLoss: 0.683474\n",
            "Train epoch: 194 [785140/25046 (95%)]\tLoss: 1.015309\n",
            "Train epoch: 194 [785840/25046 (97%)]\tLoss: 1.162650\n",
            "Train epoch: 194 [779220/25046 (100%)]\tLoss: 0.657143\n",
            "Make prediction for 5010 samples...\n",
            "0.8015169 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 195 [0/25046 (0%)]\tLoss: 0.518227\n",
            "Train epoch: 195 [20880/25046 (3%)]\tLoss: 1.253666\n",
            "Train epoch: 195 [41960/25046 (5%)]\tLoss: 0.674719\n",
            "Train epoch: 195 [63660/25046 (8%)]\tLoss: 0.530943\n",
            "Train epoch: 195 [82400/25046 (10%)]\tLoss: 0.999564\n",
            "Train epoch: 195 [105600/25046 (13%)]\tLoss: 0.978707\n",
            "Train epoch: 195 [123360/25046 (15%)]\tLoss: 0.553254\n",
            "Train epoch: 195 [151620/25046 (18%)]\tLoss: 1.634322\n",
            "Train epoch: 195 [157920/25046 (20%)]\tLoss: 0.645369\n",
            "Train epoch: 195 [175320/25046 (23%)]\tLoss: 0.472891\n",
            "Train epoch: 195 [207000/25046 (26%)]\tLoss: 0.382848\n",
            "Train epoch: 195 [223960/25046 (28%)]\tLoss: 0.508755\n",
            "Train epoch: 195 [257040/25046 (31%)]\tLoss: 1.233891\n",
            "Train epoch: 195 [274820/25046 (33%)]\tLoss: 0.532625\n",
            "Train epoch: 195 [293160/25046 (36%)]\tLoss: 1.442154\n",
            "Train epoch: 195 [298800/25046 (38%)]\tLoss: 0.310414\n",
            "Train epoch: 195 [322240/25046 (41%)]\tLoss: 1.108215\n",
            "Train epoch: 195 [349520/25046 (43%)]\tLoss: 0.993093\n",
            "Train epoch: 195 [372240/25046 (46%)]\tLoss: 0.648539\n",
            "Train epoch: 195 [380000/25046 (49%)]\tLoss: 0.422136\n",
            "Train epoch: 195 [407200/25046 (51%)]\tLoss: 0.957742\n",
            "Train epoch: 195 [409920/25046 (54%)]\tLoss: 0.466212\n",
            "Train epoch: 195 [468160/25046 (56%)]\tLoss: 0.770620\n",
            "Train epoch: 195 [483920/25046 (59%)]\tLoss: 0.243073\n",
            "Train epoch: 195 [491040/25046 (61%)]\tLoss: 0.622442\n",
            "Train epoch: 195 [541500/25046 (64%)]\tLoss: 0.872727\n",
            "Train epoch: 195 [537680/25046 (66%)]\tLoss: 1.125921\n",
            "Train epoch: 195 [550260/25046 (69%)]\tLoss: 1.834352\n",
            "Train epoch: 195 [565040/25046 (72%)]\tLoss: 1.071126\n",
            "Train epoch: 195 [573040/25046 (74%)]\tLoss: 0.819245\n",
            "Train epoch: 195 [634800/25046 (77%)]\tLoss: 0.913346\n",
            "Train epoch: 195 [633020/25046 (79%)]\tLoss: 0.569060\n",
            "Train epoch: 195 [652160/25046 (82%)]\tLoss: 1.152840\n",
            "Train epoch: 195 [673860/25046 (84%)]\tLoss: 0.419089\n",
            "Train epoch: 195 [739160/25046 (87%)]\tLoss: 1.068016\n",
            "Train epoch: 195 [690200/25046 (89%)]\tLoss: 1.158092\n",
            "Train epoch: 195 [701280/25046 (92%)]\tLoss: 0.858423\n",
            "Train epoch: 195 [782920/25046 (95%)]\tLoss: 0.434798\n",
            "Train epoch: 195 [812440/25046 (97%)]\tLoss: 2.287976\n",
            "Train epoch: 195 [794820/25046 (100%)]\tLoss: 0.650353\n",
            "Make prediction for 5010 samples...\n",
            "0.80239654 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 196 [0/25046 (0%)]\tLoss: 0.599333\n",
            "Train epoch: 196 [21900/25046 (3%)]\tLoss: 1.628479\n",
            "Train epoch: 196 [42440/25046 (5%)]\tLoss: 0.173833\n",
            "Train epoch: 196 [58440/25046 (8%)]\tLoss: 2.285033\n",
            "Train epoch: 196 [86880/25046 (10%)]\tLoss: 1.345328\n",
            "Train epoch: 196 [100300/25046 (13%)]\tLoss: 0.672264\n",
            "Train epoch: 196 [117480/25046 (15%)]\tLoss: 0.406500\n",
            "Train epoch: 196 [149380/25046 (18%)]\tLoss: 1.305882\n",
            "Train epoch: 196 [159840/25046 (20%)]\tLoss: 0.878710\n",
            "Train epoch: 196 [185040/25046 (23%)]\tLoss: 0.963067\n",
            "Train epoch: 196 [198400/25046 (26%)]\tLoss: 0.520843\n",
            "Train epoch: 196 [235180/25046 (28%)]\tLoss: 0.626541\n",
            "Train epoch: 196 [250080/25046 (31%)]\tLoss: 0.454118\n",
            "Train epoch: 196 [263120/25046 (33%)]\tLoss: 0.447940\n",
            "Train epoch: 196 [268520/25046 (36%)]\tLoss: 0.500365\n",
            "Train epoch: 196 [309900/25046 (38%)]\tLoss: 1.644403\n",
            "Train epoch: 196 [326720/25046 (41%)]\tLoss: 0.786786\n",
            "Train epoch: 196 [330480/25046 (43%)]\tLoss: 0.222181\n",
            "Train epoch: 196 [383040/25046 (46%)]\tLoss: 0.792569\n",
            "Train epoch: 196 [384560/25046 (49%)]\tLoss: 1.528536\n",
            "Train epoch: 196 [418000/25046 (51%)]\tLoss: 0.879914\n",
            "Train epoch: 196 [428400/25046 (54%)]\tLoss: 0.554513\n",
            "Train epoch: 196 [482240/25046 (56%)]\tLoss: 1.214024\n",
            "Train epoch: 196 [477480/25046 (59%)]\tLoss: 0.426604\n",
            "Train epoch: 196 [502080/25046 (61%)]\tLoss: 0.611289\n",
            "Train epoch: 196 [519000/25046 (64%)]\tLoss: 0.921201\n",
            "Train epoch: 196 [509080/25046 (66%)]\tLoss: 1.133345\n",
            "Train epoch: 196 [542700/25046 (69%)]\tLoss: 1.729113\n",
            "Train epoch: 196 [572320/25046 (72%)]\tLoss: 1.713943\n",
            "Train epoch: 196 [571880/25046 (74%)]\tLoss: 0.396350\n",
            "Train epoch: 196 [640800/25046 (77%)]\tLoss: 0.280855\n",
            "Train epoch: 196 [664640/25046 (79%)]\tLoss: 2.339232\n",
            "Train epoch: 196 [664960/25046 (82%)]\tLoss: 0.393231\n",
            "Train epoch: 196 [639540/25046 (84%)]\tLoss: 0.727001\n",
            "Train epoch: 196 [711280/25046 (87%)]\tLoss: 0.261891\n",
            "Train epoch: 196 [751800/25046 (89%)]\tLoss: 0.335700\n",
            "Train epoch: 196 [752400/25046 (92%)]\tLoss: 0.969417\n",
            "Train epoch: 196 [782180/25046 (95%)]\tLoss: 1.007176\n",
            "Train epoch: 196 [763040/25046 (97%)]\tLoss: 0.700748\n",
            "Train epoch: 196 [756600/25046 (100%)]\tLoss: 0.653724\n",
            "Make prediction for 5010 samples...\n",
            "0.8019068 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 197 [0/25046 (0%)]\tLoss: 0.446307\n",
            "Train epoch: 197 [21020/25046 (3%)]\tLoss: 0.366075\n",
            "Train epoch: 197 [44440/25046 (5%)]\tLoss: 0.848104\n",
            "Train epoch: 197 [63780/25046 (8%)]\tLoss: 1.003666\n",
            "Train epoch: 197 [81200/25046 (10%)]\tLoss: 0.305837\n",
            "Train epoch: 197 [107000/25046 (13%)]\tLoss: 0.461167\n",
            "Train epoch: 197 [127200/25046 (15%)]\tLoss: 0.810989\n",
            "Train epoch: 197 [141540/25046 (18%)]\tLoss: 0.533912\n",
            "Train epoch: 197 [169120/25046 (20%)]\tLoss: 0.419187\n",
            "Train epoch: 197 [197280/25046 (23%)]\tLoss: 0.675620\n",
            "Train epoch: 197 [205000/25046 (26%)]\tLoss: 0.587711\n",
            "Train epoch: 197 [210980/25046 (28%)]\tLoss: 0.435021\n",
            "Train epoch: 197 [255600/25046 (31%)]\tLoss: 1.227173\n",
            "Train epoch: 197 [252980/25046 (33%)]\tLoss: 0.379009\n",
            "Train epoch: 197 [293440/25046 (36%)]\tLoss: 1.278260\n",
            "Train epoch: 197 [284400/25046 (38%)]\tLoss: 0.625672\n",
            "Train epoch: 197 [333440/25046 (41%)]\tLoss: 0.366111\n",
            "Train epoch: 197 [342040/25046 (43%)]\tLoss: 1.148379\n",
            "Train epoch: 197 [376920/25046 (46%)]\tLoss: 0.755665\n",
            "Train epoch: 197 [413440/25046 (49%)]\tLoss: 0.827666\n",
            "Train epoch: 197 [422400/25046 (51%)]\tLoss: 0.928487\n",
            "Train epoch: 197 [418740/25046 (54%)]\tLoss: 0.271036\n",
            "Train epoch: 197 [455840/25046 (56%)]\tLoss: 0.683952\n",
            "Train epoch: 197 [480700/25046 (59%)]\tLoss: 1.157784\n",
            "Train epoch: 197 [483360/25046 (61%)]\tLoss: 0.926521\n",
            "Train epoch: 197 [488500/25046 (64%)]\tLoss: 0.557510\n",
            "Train epoch: 197 [511160/25046 (66%)]\tLoss: 0.653096\n",
            "Train epoch: 197 [524880/25046 (69%)]\tLoss: 0.819411\n",
            "Train epoch: 197 [571200/25046 (72%)]\tLoss: 0.578343\n",
            "Train epoch: 197 [606100/25046 (74%)]\tLoss: 0.705333\n",
            "Train epoch: 197 [657000/25046 (77%)]\tLoss: 0.603555\n",
            "Train epoch: 197 [649760/25046 (79%)]\tLoss: 0.429132\n",
            "Train epoch: 197 [681600/25046 (82%)]\tLoss: 0.519065\n",
            "Train epoch: 197 [664620/25046 (84%)]\tLoss: 0.673035\n",
            "Train epoch: 197 [687480/25046 (87%)]\tLoss: 1.365475\n",
            "Train epoch: 197 [728000/25046 (89%)]\tLoss: 1.130225\n",
            "Train epoch: 197 [732240/25046 (92%)]\tLoss: 0.700799\n",
            "Train epoch: 197 [745180/25046 (95%)]\tLoss: 0.432058\n",
            "Train epoch: 197 [797240/25046 (97%)]\tLoss: 0.934851\n",
            "Train epoch: 197 [782340/25046 (100%)]\tLoss: 1.163338\n",
            "Make prediction for 5010 samples...\n",
            "0.8029897 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 198 [0/25046 (0%)]\tLoss: 0.900157\n",
            "Train epoch: 198 [19080/25046 (3%)]\tLoss: 0.484727\n",
            "Train epoch: 198 [41400/25046 (5%)]\tLoss: 0.690756\n",
            "Train epoch: 198 [59160/25046 (8%)]\tLoss: 0.611050\n",
            "Train epoch: 198 [82880/25046 (10%)]\tLoss: 0.380963\n",
            "Train epoch: 198 [104100/25046 (13%)]\tLoss: 0.687788\n",
            "Train epoch: 198 [119880/25046 (15%)]\tLoss: 0.238445\n",
            "Train epoch: 198 [144340/25046 (18%)]\tLoss: 1.219784\n",
            "Train epoch: 198 [168160/25046 (20%)]\tLoss: 0.890367\n",
            "Train epoch: 198 [180900/25046 (23%)]\tLoss: 0.757011\n",
            "Train epoch: 198 [203400/25046 (26%)]\tLoss: 0.312606\n",
            "Train epoch: 198 [225940/25046 (28%)]\tLoss: 0.246837\n",
            "Train epoch: 198 [247920/25046 (31%)]\tLoss: 1.046163\n",
            "Train epoch: 198 [268580/25046 (33%)]\tLoss: 0.780774\n",
            "Train epoch: 198 [278040/25046 (36%)]\tLoss: 0.533391\n",
            "Train epoch: 198 [307800/25046 (38%)]\tLoss: 0.528654\n",
            "Train epoch: 198 [319680/25046 (41%)]\tLoss: 1.240764\n",
            "Train epoch: 198 [354280/25046 (43%)]\tLoss: 0.517617\n",
            "Train epoch: 198 [392400/25046 (46%)]\tLoss: 1.241342\n",
            "Train epoch: 198 [411160/25046 (49%)]\tLoss: 0.798630\n",
            "Train epoch: 198 [423600/25046 (51%)]\tLoss: 1.121101\n",
            "Train epoch: 198 [449400/25046 (54%)]\tLoss: 1.128281\n",
            "Train epoch: 198 [432520/25046 (56%)]\tLoss: 0.813919\n",
            "Train epoch: 198 [461380/25046 (59%)]\tLoss: 0.701058\n",
            "Train epoch: 198 [523200/25046 (61%)]\tLoss: 0.469997\n",
            "Train epoch: 198 [525500/25046 (64%)]\tLoss: 0.545298\n",
            "Train epoch: 198 [544440/25046 (66%)]\tLoss: 0.464302\n",
            "Train epoch: 198 [559980/25046 (69%)]\tLoss: 1.759286\n",
            "Train epoch: 198 [614880/25046 (72%)]\tLoss: 1.289950\n",
            "Train epoch: 198 [590440/25046 (74%)]\tLoss: 1.113051\n",
            "Train epoch: 198 [624000/25046 (77%)]\tLoss: 0.916828\n",
            "Train epoch: 198 [673320/25046 (79%)]\tLoss: 1.108853\n",
            "Train epoch: 198 [680960/25046 (82%)]\tLoss: 1.741372\n",
            "Train epoch: 198 [659340/25046 (84%)]\tLoss: 0.404300\n",
            "Train epoch: 198 [710600/25046 (87%)]\tLoss: 0.543622\n",
            "Train epoch: 198 [705600/25046 (89%)]\tLoss: 1.496975\n",
            "Train epoch: 198 [735840/25046 (92%)]\tLoss: 0.492318\n",
            "Train epoch: 198 [764420/25046 (95%)]\tLoss: 0.715548\n",
            "Train epoch: 198 [769120/25046 (97%)]\tLoss: 0.474391\n",
            "Train epoch: 198 [843180/25046 (100%)]\tLoss: 0.344242\n",
            "Make prediction for 5010 samples...\n",
            "0.80161345 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 199 [0/25046 (0%)]\tLoss: 1.317300\n",
            "Train epoch: 199 [21220/25046 (3%)]\tLoss: 0.404394\n",
            "Train epoch: 199 [38360/25046 (5%)]\tLoss: 0.715260\n",
            "Train epoch: 199 [58440/25046 (8%)]\tLoss: 1.645404\n",
            "Train epoch: 199 [81520/25046 (10%)]\tLoss: 0.386212\n",
            "Train epoch: 199 [100900/25046 (13%)]\tLoss: 0.785291\n",
            "Train epoch: 199 [127920/25046 (15%)]\tLoss: 0.861172\n",
            "Train epoch: 199 [142380/25046 (18%)]\tLoss: 1.226245\n",
            "Train epoch: 199 [162240/25046 (20%)]\tLoss: 0.423315\n",
            "Train epoch: 199 [182520/25046 (23%)]\tLoss: 0.352247\n",
            "Train epoch: 199 [204200/25046 (26%)]\tLoss: 1.175050\n",
            "Train epoch: 199 [234080/25046 (28%)]\tLoss: 0.638482\n",
            "Train epoch: 199 [246240/25046 (31%)]\tLoss: 1.574085\n",
            "Train epoch: 199 [261040/25046 (33%)]\tLoss: 0.655688\n",
            "Train epoch: 199 [280000/25046 (36%)]\tLoss: 0.551484\n",
            "Train epoch: 199 [313500/25046 (38%)]\tLoss: 0.896867\n",
            "Train epoch: 199 [327680/25046 (41%)]\tLoss: 0.929043\n",
            "Train epoch: 199 [347480/25046 (43%)]\tLoss: 0.918590\n",
            "Train epoch: 199 [381960/25046 (46%)]\tLoss: 0.977973\n",
            "Train epoch: 199 [391400/25046 (49%)]\tLoss: 0.507560\n",
            "Train epoch: 199 [386400/25046 (51%)]\tLoss: 1.141527\n",
            "Train epoch: 199 [409920/25046 (54%)]\tLoss: 1.550412\n",
            "Train epoch: 199 [443080/25046 (56%)]\tLoss: 0.784694\n",
            "Train epoch: 199 [476100/25046 (59%)]\tLoss: 0.801289\n",
            "Train epoch: 199 [522240/25046 (61%)]\tLoss: 0.894523\n",
            "Train epoch: 199 [528500/25046 (64%)]\tLoss: 0.318466\n",
            "Train epoch: 199 [547560/25046 (66%)]\tLoss: 0.280998\n",
            "Train epoch: 199 [532440/25046 (69%)]\tLoss: 0.322979\n",
            "Train epoch: 199 [560560/25046 (72%)]\tLoss: 0.728563\n",
            "Train epoch: 199 [573620/25046 (74%)]\tLoss: 0.833037\n",
            "Train epoch: 199 [608400/25046 (77%)]\tLoss: 0.919601\n",
            "Train epoch: 199 [611320/25046 (79%)]\tLoss: 0.307636\n",
            "Train epoch: 199 [627200/25046 (82%)]\tLoss: 0.276742\n",
            "Train epoch: 199 [656700/25046 (84%)]\tLoss: 0.876619\n",
            "Train epoch: 199 [735080/25046 (87%)]\tLoss: 0.623890\n",
            "Train epoch: 199 [718900/25046 (89%)]\tLoss: 0.563868\n",
            "Train epoch: 199 [758160/25046 (92%)]\tLoss: 0.283451\n",
            "Train epoch: 199 [737040/25046 (95%)]\tLoss: 0.646860\n",
            "Train epoch: 199 [788120/25046 (97%)]\tLoss: 0.307694\n",
            "Train epoch: 199 [833820/25046 (100%)]\tLoss: 0.976567\n",
            "Make prediction for 5010 samples...\n",
            "0.8015921 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 200 [0/25046 (0%)]\tLoss: 0.232845\n",
            "Train epoch: 200 [19840/25046 (3%)]\tLoss: 0.632517\n",
            "Train epoch: 200 [40960/25046 (5%)]\tLoss: 1.487317\n",
            "Train epoch: 200 [61200/25046 (8%)]\tLoss: 0.865032\n",
            "Train epoch: 200 [80240/25046 (10%)]\tLoss: 0.900817\n",
            "Train epoch: 200 [99300/25046 (13%)]\tLoss: 1.587063\n",
            "Train epoch: 200 [123240/25046 (15%)]\tLoss: 0.769187\n",
            "Train epoch: 200 [143920/25046 (18%)]\tLoss: 0.156953\n",
            "Train epoch: 200 [172640/25046 (20%)]\tLoss: 1.224718\n",
            "Train epoch: 200 [201240/25046 (23%)]\tLoss: 0.480678\n",
            "Train epoch: 200 [212800/25046 (26%)]\tLoss: 0.322281\n",
            "Train epoch: 200 [224840/25046 (28%)]\tLoss: 0.960067\n",
            "Train epoch: 200 [250800/25046 (31%)]\tLoss: 0.723303\n",
            "Train epoch: 200 [265720/25046 (33%)]\tLoss: 0.455730\n",
            "Train epoch: 200 [295400/25046 (36%)]\tLoss: 0.709653\n",
            "Train epoch: 200 [322200/25046 (38%)]\tLoss: 1.145547\n",
            "Train epoch: 200 [340160/25046 (41%)]\tLoss: 0.577634\n",
            "Train epoch: 200 [358360/25046 (43%)]\tLoss: 1.431569\n",
            "Train epoch: 200 [374760/25046 (46%)]\tLoss: 0.724548\n",
            "Train epoch: 200 [384560/25046 (49%)]\tLoss: 0.925404\n",
            "Train epoch: 200 [387200/25046 (51%)]\tLoss: 1.754194\n",
            "Train epoch: 200 [435120/25046 (54%)]\tLoss: 1.254544\n",
            "Train epoch: 200 [443960/25046 (56%)]\tLoss: 0.871972\n",
            "Train epoch: 200 [470580/25046 (59%)]\tLoss: 0.817355\n",
            "Train epoch: 200 [500160/25046 (61%)]\tLoss: 0.940459\n",
            "Train epoch: 200 [514500/25046 (64%)]\tLoss: 2.057600\n",
            "Train epoch: 200 [521560/25046 (66%)]\tLoss: 0.589080\n",
            "Train epoch: 200 [556740/25046 (69%)]\tLoss: 0.411673\n",
            "Train epoch: 200 [560000/25046 (72%)]\tLoss: 0.662474\n",
            "Train epoch: 200 [584060/25046 (74%)]\tLoss: 0.581205\n",
            "Train epoch: 200 [624600/25046 (77%)]\tLoss: 0.853436\n",
            "Train epoch: 200 [611320/25046 (79%)]\tLoss: 0.807268\n",
            "Train epoch: 200 [662400/25046 (82%)]\tLoss: 0.376884\n",
            "Train epoch: 200 [667260/25046 (84%)]\tLoss: 0.405913\n",
            "Train epoch: 200 [713320/25046 (87%)]\tLoss: 0.928587\n",
            "Train epoch: 200 [718200/25046 (89%)]\tLoss: 0.423972\n",
            "Train epoch: 200 [720000/25046 (92%)]\tLoss: 0.640766\n",
            "Train epoch: 200 [751100/25046 (95%)]\tLoss: 0.363576\n",
            "Train epoch: 200 [785840/25046 (97%)]\tLoss: 0.578319\n",
            "Train epoch: 200 [806520/25046 (100%)]\tLoss: 1.126599\n",
            "Make prediction for 5010 samples...\n",
            "0.8015222 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 201 [0/25046 (0%)]\tLoss: 1.433313\n",
            "Train epoch: 201 [21260/25046 (3%)]\tLoss: 1.384313\n",
            "Train epoch: 201 [40520/25046 (5%)]\tLoss: 1.121192\n",
            "Train epoch: 201 [60960/25046 (8%)]\tLoss: 1.100586\n",
            "Train epoch: 201 [83200/25046 (10%)]\tLoss: 1.274410\n",
            "Train epoch: 201 [105500/25046 (13%)]\tLoss: 0.971070\n",
            "Train epoch: 201 [129600/25046 (15%)]\tLoss: 0.804921\n",
            "Train epoch: 201 [141680/25046 (18%)]\tLoss: 1.572427\n",
            "Train epoch: 201 [160160/25046 (20%)]\tLoss: 1.363851\n",
            "Train epoch: 201 [184320/25046 (23%)]\tLoss: 0.733497\n",
            "Train epoch: 201 [209800/25046 (26%)]\tLoss: 0.878678\n",
            "Train epoch: 201 [220000/25046 (28%)]\tLoss: 0.489651\n",
            "Train epoch: 201 [253440/25046 (31%)]\tLoss: 0.519439\n",
            "Train epoch: 201 [270140/25046 (33%)]\tLoss: 0.344466\n",
            "Train epoch: 201 [287560/25046 (36%)]\tLoss: 0.836277\n",
            "Train epoch: 201 [279600/25046 (38%)]\tLoss: 0.924268\n",
            "Train epoch: 201 [328000/25046 (41%)]\tLoss: 0.528166\n",
            "Train epoch: 201 [353600/25046 (43%)]\tLoss: 0.762597\n",
            "Train epoch: 201 [374040/25046 (46%)]\tLoss: 0.666999\n",
            "Train epoch: 201 [401660/25046 (49%)]\tLoss: 0.313732\n",
            "Train epoch: 201 [424400/25046 (51%)]\tLoss: 0.528355\n",
            "Train epoch: 201 [454440/25046 (54%)]\tLoss: 0.851194\n",
            "Train epoch: 201 [455840/25046 (56%)]\tLoss: 0.367417\n",
            "Train epoch: 201 [483920/25046 (59%)]\tLoss: 0.681314\n",
            "Train epoch: 201 [476640/25046 (61%)]\tLoss: 0.978986\n",
            "Train epoch: 201 [527500/25046 (64%)]\tLoss: 0.444199\n",
            "Train epoch: 201 [541840/25046 (66%)]\tLoss: 1.090327\n",
            "Train epoch: 201 [548100/25046 (69%)]\tLoss: 0.367797\n",
            "Train epoch: 201 [563920/25046 (72%)]\tLoss: 2.255384\n",
            "Train epoch: 201 [573040/25046 (74%)]\tLoss: 0.703563\n",
            "Train epoch: 201 [606600/25046 (77%)]\tLoss: 1.048247\n",
            "Train epoch: 201 [628060/25046 (79%)]\tLoss: 1.245176\n",
            "Train epoch: 201 [619520/25046 (82%)]\tLoss: 0.821730\n",
            "Train epoch: 201 [648780/25046 (84%)]\tLoss: 0.514675\n",
            "Train epoch: 201 [697000/25046 (87%)]\tLoss: 0.654360\n",
            "Train epoch: 201 [689500/25046 (89%)]\tLoss: 1.258860\n",
            "Train epoch: 201 [750240/25046 (92%)]\tLoss: 0.794653\n",
            "Train epoch: 201 [751100/25046 (95%)]\tLoss: 0.568969\n",
            "Train epoch: 201 [752400/25046 (97%)]\tLoss: 0.647699\n",
            "Train epoch: 201 [879060/25046 (100%)]\tLoss: 1.410833\n",
            "Make prediction for 5010 samples...\n",
            "0.80513835 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 202 [0/25046 (0%)]\tLoss: 0.588391\n",
            "Train epoch: 202 [20740/25046 (3%)]\tLoss: 0.658161\n",
            "Train epoch: 202 [39080/25046 (5%)]\tLoss: 0.590135\n",
            "Train epoch: 202 [67320/25046 (8%)]\tLoss: 0.856205\n",
            "Train epoch: 202 [86320/25046 (10%)]\tLoss: 1.254399\n",
            "Train epoch: 202 [98700/25046 (13%)]\tLoss: 0.952988\n",
            "Train epoch: 202 [124680/25046 (15%)]\tLoss: 1.030825\n",
            "Train epoch: 202 [141680/25046 (18%)]\tLoss: 0.291006\n",
            "Train epoch: 202 [165120/25046 (20%)]\tLoss: 1.073544\n",
            "Train epoch: 202 [179640/25046 (23%)]\tLoss: 0.955624\n",
            "Train epoch: 202 [200400/25046 (26%)]\tLoss: 0.965906\n",
            "Train epoch: 202 [233640/25046 (28%)]\tLoss: 0.496869\n",
            "Train epoch: 202 [257280/25046 (31%)]\tLoss: 0.869389\n",
            "Train epoch: 202 [246740/25046 (33%)]\tLoss: 1.480010\n",
            "Train epoch: 202 [296520/25046 (36%)]\tLoss: 0.696797\n",
            "Train epoch: 202 [316800/25046 (38%)]\tLoss: 0.330456\n",
            "Train epoch: 202 [334400/25046 (41%)]\tLoss: 0.674492\n",
            "Train epoch: 202 [346800/25046 (43%)]\tLoss: 1.115151\n",
            "Train epoch: 202 [391680/25046 (46%)]\tLoss: 0.848623\n",
            "Train epoch: 202 [395200/25046 (49%)]\tLoss: 0.818842\n",
            "Train epoch: 202 [388400/25046 (51%)]\tLoss: 0.929619\n",
            "Train epoch: 202 [418320/25046 (54%)]\tLoss: 0.612121\n",
            "Train epoch: 202 [438680/25046 (56%)]\tLoss: 1.064290\n",
            "Train epoch: 202 [472880/25046 (59%)]\tLoss: 0.417532\n",
            "Train epoch: 202 [497280/25046 (61%)]\tLoss: 0.926176\n",
            "Train epoch: 202 [505000/25046 (64%)]\tLoss: 1.215810\n",
            "Train epoch: 202 [527280/25046 (66%)]\tLoss: 0.292441\n",
            "Train epoch: 202 [598320/25046 (69%)]\tLoss: 0.731442\n",
            "Train epoch: 202 [560000/25046 (72%)]\tLoss: 0.417918\n",
            "Train epoch: 202 [577680/25046 (74%)]\tLoss: 0.464219\n",
            "Train epoch: 202 [633000/25046 (77%)]\tLoss: 0.760523\n",
            "Train epoch: 202 [660920/25046 (79%)]\tLoss: 1.032201\n",
            "Train epoch: 202 [650240/25046 (82%)]\tLoss: 1.951100\n",
            "Train epoch: 202 [661320/25046 (84%)]\tLoss: 0.483165\n",
            "Train epoch: 202 [724200/25046 (87%)]\tLoss: 1.789137\n",
            "Train epoch: 202 [733600/25046 (89%)]\tLoss: 1.474250\n",
            "Train epoch: 202 [749520/25046 (92%)]\tLoss: 1.756268\n",
            "Train epoch: 202 [771820/25046 (95%)]\tLoss: 0.478513\n",
            "Train epoch: 202 [782800/25046 (97%)]\tLoss: 0.411277\n",
            "Train epoch: 202 [772200/25046 (100%)]\tLoss: 0.677917\n",
            "Make prediction for 5010 samples...\n",
            "0.8015157 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 203 [0/25046 (0%)]\tLoss: 0.972391\n",
            "Train epoch: 203 [19920/25046 (3%)]\tLoss: 1.029258\n",
            "Train epoch: 203 [40320/25046 (5%)]\tLoss: 1.407417\n",
            "Train epoch: 203 [59940/25046 (8%)]\tLoss: 0.391168\n",
            "Train epoch: 203 [83600/25046 (10%)]\tLoss: 0.568429\n",
            "Train epoch: 203 [101200/25046 (13%)]\tLoss: 0.449842\n",
            "Train epoch: 203 [123000/25046 (15%)]\tLoss: 1.163920\n",
            "Train epoch: 203 [142940/25046 (18%)]\tLoss: 0.713130\n",
            "Train epoch: 203 [168000/25046 (20%)]\tLoss: 0.340248\n",
            "Train epoch: 203 [191340/25046 (23%)]\tLoss: 0.549886\n",
            "Train epoch: 203 [202200/25046 (26%)]\tLoss: 0.555328\n",
            "Train epoch: 203 [232760/25046 (28%)]\tLoss: 0.619800\n",
            "Train epoch: 203 [243360/25046 (31%)]\tLoss: 0.505914\n",
            "Train epoch: 203 [267540/25046 (33%)]\tLoss: 0.553593\n",
            "Train epoch: 203 [280000/25046 (36%)]\tLoss: 0.747767\n",
            "Train epoch: 203 [313800/25046 (38%)]\tLoss: 0.431754\n",
            "Train epoch: 203 [330560/25046 (41%)]\tLoss: 0.909810\n",
            "Train epoch: 203 [363460/25046 (43%)]\tLoss: 0.346480\n",
            "Train epoch: 203 [351360/25046 (46%)]\tLoss: 0.538714\n",
            "Train epoch: 203 [394820/25046 (49%)]\tLoss: 0.507412\n",
            "Train epoch: 203 [403200/25046 (51%)]\tLoss: 1.431103\n",
            "Train epoch: 203 [434280/25046 (54%)]\tLoss: 0.565887\n",
            "Train epoch: 203 [462440/25046 (56%)]\tLoss: 1.085530\n",
            "Train epoch: 203 [489900/25046 (59%)]\tLoss: 0.244924\n",
            "Train epoch: 203 [504960/25046 (61%)]\tLoss: 1.184847\n",
            "Train epoch: 203 [506500/25046 (64%)]\tLoss: 0.883884\n",
            "Train epoch: 203 [530400/25046 (66%)]\tLoss: 0.413523\n",
            "Train epoch: 203 [556740/25046 (69%)]\tLoss: 1.223568\n",
            "Train epoch: 203 [599200/25046 (72%)]\tLoss: 0.334301\n",
            "Train epoch: 203 [569560/25046 (74%)]\tLoss: 0.889723\n",
            "Train epoch: 203 [603600/25046 (77%)]\tLoss: 1.061272\n",
            "Train epoch: 203 [641080/25046 (79%)]\tLoss: 0.468035\n",
            "Train epoch: 203 [648320/25046 (82%)]\tLoss: 0.516929\n",
            "Train epoch: 203 [646140/25046 (84%)]\tLoss: 0.780675\n",
            "Train epoch: 203 [688840/25046 (87%)]\tLoss: 0.263295\n",
            "Train epoch: 203 [715400/25046 (89%)]\tLoss: 0.959247\n",
            "Train epoch: 203 [717120/25046 (92%)]\tLoss: 1.025285\n",
            "Train epoch: 203 [725200/25046 (95%)]\tLoss: 0.814328\n",
            "Train epoch: 203 [791160/25046 (97%)]\tLoss: 1.627971\n",
            "Train epoch: 203 [781560/25046 (100%)]\tLoss: 0.860468\n",
            "Make prediction for 5010 samples...\n",
            "0.8020699 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 204 [0/25046 (0%)]\tLoss: 0.551692\n",
            "Train epoch: 204 [20120/25046 (3%)]\tLoss: 0.848679\n",
            "Train epoch: 204 [43480/25046 (5%)]\tLoss: 0.609272\n",
            "Train epoch: 204 [65520/25046 (8%)]\tLoss: 1.012192\n",
            "Train epoch: 204 [86960/25046 (10%)]\tLoss: 2.350986\n",
            "Train epoch: 204 [102000/25046 (13%)]\tLoss: 1.554404\n",
            "Train epoch: 204 [126240/25046 (15%)]\tLoss: 0.533392\n",
            "Train epoch: 204 [136640/25046 (18%)]\tLoss: 0.470928\n",
            "Train epoch: 204 [166720/25046 (20%)]\tLoss: 0.183811\n",
            "Train epoch: 204 [179100/25046 (23%)]\tLoss: 1.041330\n",
            "Train epoch: 204 [200200/25046 (26%)]\tLoss: 0.685387\n",
            "Train epoch: 204 [229460/25046 (28%)]\tLoss: 0.682911\n",
            "Train epoch: 204 [246720/25046 (31%)]\tLoss: 0.661092\n",
            "Train epoch: 204 [264940/25046 (33%)]\tLoss: 1.274489\n",
            "Train epoch: 204 [289800/25046 (36%)]\tLoss: 0.890195\n",
            "Train epoch: 204 [312600/25046 (38%)]\tLoss: 1.009054\n",
            "Train epoch: 204 [317440/25046 (41%)]\tLoss: 1.304900\n",
            "Train epoch: 204 [365500/25046 (43%)]\tLoss: 0.788388\n",
            "Train epoch: 204 [376560/25046 (46%)]\tLoss: 1.205805\n",
            "Train epoch: 204 [398620/25046 (49%)]\tLoss: 0.497523\n",
            "Train epoch: 204 [407600/25046 (51%)]\tLoss: 0.804124\n",
            "Train epoch: 204 [461580/25046 (54%)]\tLoss: 0.979167\n",
            "Train epoch: 204 [447040/25046 (56%)]\tLoss: 0.601180\n",
            "Train epoch: 204 [473340/25046 (59%)]\tLoss: 0.510886\n",
            "Train epoch: 204 [478080/25046 (61%)]\tLoss: 0.505843\n",
            "Train epoch: 204 [498000/25046 (64%)]\tLoss: 0.724808\n",
            "Train epoch: 204 [521560/25046 (66%)]\tLoss: 0.987135\n",
            "Train epoch: 204 [561600/25046 (69%)]\tLoss: 1.661949\n",
            "Train epoch: 204 [572320/25046 (72%)]\tLoss: 1.210536\n",
            "Train epoch: 204 [570720/25046 (74%)]\tLoss: 0.605417\n",
            "Train epoch: 204 [653400/25046 (77%)]\tLoss: 0.920569\n",
            "Train epoch: 204 [626200/25046 (79%)]\tLoss: 0.279106\n",
            "Train epoch: 204 [647040/25046 (82%)]\tLoss: 0.538410\n",
            "Train epoch: 204 [677160/25046 (84%)]\tLoss: 0.529174\n",
            "Train epoch: 204 [677960/25046 (87%)]\tLoss: 0.621703\n",
            "Train epoch: 204 [726600/25046 (89%)]\tLoss: 0.641181\n",
            "Train epoch: 204 [722880/25046 (92%)]\tLoss: 0.396208\n",
            "Train epoch: 204 [755540/25046 (95%)]\tLoss: 0.649223\n",
            "Train epoch: 204 [776720/25046 (97%)]\tLoss: 0.888033\n",
            "Train epoch: 204 [803400/25046 (100%)]\tLoss: 0.907659\n",
            "Make prediction for 5010 samples...\n",
            "0.80170864 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 205 [0/25046 (0%)]\tLoss: 0.557479\n",
            "Train epoch: 205 [20300/25046 (3%)]\tLoss: 1.289826\n",
            "Train epoch: 205 [42160/25046 (5%)]\tLoss: 0.909277\n",
            "Train epoch: 205 [62220/25046 (8%)]\tLoss: 0.332751\n",
            "Train epoch: 205 [76960/25046 (10%)]\tLoss: 0.595593\n",
            "Train epoch: 205 [111500/25046 (13%)]\tLoss: 1.169129\n",
            "Train epoch: 205 [118920/25046 (15%)]\tLoss: 0.744785\n",
            "Train epoch: 205 [149940/25046 (18%)]\tLoss: 0.629052\n",
            "Train epoch: 205 [172800/25046 (20%)]\tLoss: 0.981810\n",
            "Train epoch: 205 [181440/25046 (23%)]\tLoss: 0.345769\n",
            "Train epoch: 205 [209000/25046 (26%)]\tLoss: 0.961003\n",
            "Train epoch: 205 [228360/25046 (28%)]\tLoss: 0.999372\n",
            "Train epoch: 205 [253920/25046 (31%)]\tLoss: 0.723003\n",
            "Train epoch: 205 [269360/25046 (33%)]\tLoss: 1.095267\n",
            "Train epoch: 205 [288680/25046 (36%)]\tLoss: 0.489197\n",
            "Train epoch: 205 [298200/25046 (38%)]\tLoss: 0.439153\n",
            "Train epoch: 205 [330560/25046 (41%)]\tLoss: 0.210523\n",
            "Train epoch: 205 [335240/25046 (43%)]\tLoss: 0.617505\n",
            "Train epoch: 205 [389880/25046 (46%)]\tLoss: 1.158426\n",
            "Train epoch: 205 [412300/25046 (49%)]\tLoss: 0.738150\n",
            "Train epoch: 205 [384800/25046 (51%)]\tLoss: 0.745876\n",
            "Train epoch: 205 [448560/25046 (54%)]\tLoss: 0.659672\n",
            "Train epoch: 205 [483120/25046 (56%)]\tLoss: 0.949731\n",
            "Train epoch: 205 [482540/25046 (59%)]\tLoss: 0.828894\n",
            "Train epoch: 205 [518400/25046 (61%)]\tLoss: 1.127876\n",
            "Train epoch: 205 [522000/25046 (64%)]\tLoss: 0.218303\n",
            "Train epoch: 205 [561080/25046 (66%)]\tLoss: 0.612932\n",
            "Train epoch: 205 [530820/25046 (69%)]\tLoss: 1.500037\n",
            "Train epoch: 205 [565600/25046 (72%)]\tLoss: 1.249802\n",
            "Train epoch: 205 [578260/25046 (74%)]\tLoss: 0.734918\n",
            "Train epoch: 205 [585000/25046 (77%)]\tLoss: 0.702826\n",
            "Train epoch: 205 [594580/25046 (79%)]\tLoss: 1.043103\n",
            "Train epoch: 205 [688640/25046 (82%)]\tLoss: 1.142079\n",
            "Train epoch: 205 [693000/25046 (84%)]\tLoss: 0.291354\n",
            "Train epoch: 205 [688840/25046 (87%)]\tLoss: 0.458548\n",
            "Train epoch: 205 [697900/25046 (89%)]\tLoss: 0.806324\n",
            "Train epoch: 205 [735840/25046 (92%)]\tLoss: 1.157799\n",
            "Train epoch: 205 [785140/25046 (95%)]\tLoss: 0.936375\n",
            "Train epoch: 205 [791160/25046 (97%)]\tLoss: 0.938617\n",
            "Train epoch: 205 [757380/25046 (100%)]\tLoss: 0.870529\n",
            "Make prediction for 5010 samples...\n",
            "0.8017596 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 206 [0/25046 (0%)]\tLoss: 0.339413\n",
            "Train epoch: 206 [21500/25046 (3%)]\tLoss: 0.979368\n",
            "Train epoch: 206 [38560/25046 (5%)]\tLoss: 0.414125\n",
            "Train epoch: 206 [61500/25046 (8%)]\tLoss: 1.268414\n",
            "Train epoch: 206 [80720/25046 (10%)]\tLoss: 0.567312\n",
            "Train epoch: 206 [105700/25046 (13%)]\tLoss: 0.677064\n",
            "Train epoch: 206 [119400/25046 (15%)]\tLoss: 0.881831\n",
            "Train epoch: 206 [139440/25046 (18%)]\tLoss: 0.780861\n",
            "Train epoch: 206 [169280/25046 (20%)]\tLoss: 1.275654\n",
            "Train epoch: 206 [177840/25046 (23%)]\tLoss: 0.879127\n",
            "Train epoch: 206 [206600/25046 (26%)]\tLoss: 0.652473\n",
            "Train epoch: 206 [233420/25046 (28%)]\tLoss: 0.728482\n",
            "Train epoch: 206 [251280/25046 (31%)]\tLoss: 0.315942\n",
            "Train epoch: 206 [262600/25046 (33%)]\tLoss: 0.605784\n",
            "Train epoch: 206 [306600/25046 (36%)]\tLoss: 0.598462\n",
            "Train epoch: 206 [315300/25046 (38%)]\tLoss: 0.912439\n",
            "Train epoch: 206 [325760/25046 (41%)]\tLoss: 0.480485\n",
            "Train epoch: 206 [350540/25046 (43%)]\tLoss: 0.264969\n",
            "Train epoch: 206 [379080/25046 (46%)]\tLoss: 0.310455\n",
            "Train epoch: 206 [376960/25046 (49%)]\tLoss: 1.223961\n",
            "Train epoch: 206 [422800/25046 (51%)]\tLoss: 1.569784\n",
            "Train epoch: 206 [405300/25046 (54%)]\tLoss: 1.335910\n",
            "Train epoch: 206 [464640/25046 (56%)]\tLoss: 0.272468\n",
            "Train epoch: 206 [453560/25046 (59%)]\tLoss: 0.716333\n",
            "Train epoch: 206 [537600/25046 (61%)]\tLoss: 0.657076\n",
            "Train epoch: 206 [506000/25046 (64%)]\tLoss: 0.592322\n",
            "Train epoch: 206 [534560/25046 (66%)]\tLoss: 0.225925\n",
            "Train epoch: 206 [537300/25046 (69%)]\tLoss: 0.800856\n",
            "Train epoch: 206 [584080/25046 (72%)]\tLoss: 0.619268\n",
            "Train epoch: 206 [588120/25046 (74%)]\tLoss: 0.929561\n",
            "Train epoch: 206 [615000/25046 (77%)]\tLoss: 0.588733\n",
            "Train epoch: 206 [645420/25046 (79%)]\tLoss: 1.222141\n",
            "Train epoch: 206 [627840/25046 (82%)]\tLoss: 0.672245\n",
            "Train epoch: 206 [689700/25046 (84%)]\tLoss: 0.682700\n",
            "Train epoch: 206 [679320/25046 (87%)]\tLoss: 0.460138\n",
            "Train epoch: 206 [718900/25046 (89%)]\tLoss: 1.078095\n",
            "Train epoch: 206 [750240/25046 (92%)]\tLoss: 0.390412\n",
            "Train epoch: 206 [758500/25046 (95%)]\tLoss: 0.941850\n",
            "Train epoch: 206 [791920/25046 (97%)]\tLoss: 0.655285\n",
            "Train epoch: 206 [836160/25046 (100%)]\tLoss: 0.370265\n",
            "Make prediction for 5010 samples...\n",
            "0.80455476 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 207 [0/25046 (0%)]\tLoss: 1.298135\n",
            "Train epoch: 207 [18560/25046 (3%)]\tLoss: 0.203242\n",
            "Train epoch: 207 [38880/25046 (5%)]\tLoss: 0.345218\n",
            "Train epoch: 207 [61560/25046 (8%)]\tLoss: 0.349412\n",
            "Train epoch: 207 [81760/25046 (10%)]\tLoss: 0.671919\n",
            "Train epoch: 207 [98000/25046 (13%)]\tLoss: 0.260852\n",
            "Train epoch: 207 [121800/25046 (15%)]\tLoss: 0.744619\n",
            "Train epoch: 207 [148260/25046 (18%)]\tLoss: 1.229626\n",
            "Train epoch: 207 [165440/25046 (20%)]\tLoss: 0.478655\n",
            "Train epoch: 207 [177120/25046 (23%)]\tLoss: 0.982836\n",
            "Train epoch: 207 [205400/25046 (26%)]\tLoss: 0.664686\n",
            "Train epoch: 207 [239800/25046 (28%)]\tLoss: 0.822841\n",
            "Train epoch: 207 [245760/25046 (31%)]\tLoss: 1.235424\n",
            "Train epoch: 207 [263380/25046 (33%)]\tLoss: 0.522866\n",
            "Train epoch: 207 [276920/25046 (36%)]\tLoss: 0.827499\n",
            "Train epoch: 207 [308100/25046 (38%)]\tLoss: 1.008906\n",
            "Train epoch: 207 [342720/25046 (41%)]\tLoss: 0.880250\n",
            "Train epoch: 207 [333880/25046 (43%)]\tLoss: 0.632814\n",
            "Train epoch: 207 [376200/25046 (46%)]\tLoss: 0.557981\n",
            "Train epoch: 207 [381900/25046 (49%)]\tLoss: 1.003663\n",
            "Train epoch: 207 [404400/25046 (51%)]\tLoss: 1.566829\n",
            "Train epoch: 207 [417060/25046 (54%)]\tLoss: 0.424265\n",
            "Train epoch: 207 [435160/25046 (56%)]\tLoss: 0.488098\n",
            "Train epoch: 207 [480700/25046 (59%)]\tLoss: 1.159937\n",
            "Train epoch: 207 [499200/25046 (61%)]\tLoss: 0.400366\n",
            "Train epoch: 207 [498500/25046 (64%)]\tLoss: 0.404592\n",
            "Train epoch: 207 [557960/25046 (66%)]\tLoss: 0.865635\n",
            "Train epoch: 207 [560520/25046 (69%)]\tLoss: 0.504632\n",
            "Train epoch: 207 [571200/25046 (72%)]\tLoss: 0.886940\n",
            "Train epoch: 207 [632780/25046 (74%)]\tLoss: 0.482488\n",
            "Train epoch: 207 [629400/25046 (77%)]\tLoss: 1.092717\n",
            "Train epoch: 207 [649760/25046 (79%)]\tLoss: 1.335430\n",
            "Train epoch: 207 [641280/25046 (82%)]\tLoss: 0.607579\n",
            "Train epoch: 207 [691680/25046 (84%)]\tLoss: 0.479478\n",
            "Train epoch: 207 [720800/25046 (87%)]\tLoss: 0.717228\n",
            "Train epoch: 207 [721700/25046 (89%)]\tLoss: 0.521266\n",
            "Train epoch: 207 [802800/25046 (92%)]\tLoss: 1.285481\n",
            "Train epoch: 207 [731860/25046 (95%)]\tLoss: 1.326162\n",
            "Train epoch: 207 [814720/25046 (97%)]\tLoss: 0.583061\n",
            "Train epoch: 207 [776100/25046 (100%)]\tLoss: 0.803134\n",
            "Make prediction for 5010 samples...\n",
            "0.8015864 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 208 [0/25046 (0%)]\tLoss: 0.805510\n",
            "Train epoch: 208 [20180/25046 (3%)]\tLoss: 0.559150\n",
            "Train epoch: 208 [40720/25046 (5%)]\tLoss: 1.356287\n",
            "Train epoch: 208 [63960/25046 (8%)]\tLoss: 0.516016\n",
            "Train epoch: 208 [76880/25046 (10%)]\tLoss: 1.137177\n",
            "Train epoch: 208 [109300/25046 (13%)]\tLoss: 0.399299\n",
            "Train epoch: 208 [123480/25046 (15%)]\tLoss: 0.864884\n",
            "Train epoch: 208 [148540/25046 (18%)]\tLoss: 0.946289\n",
            "Train epoch: 208 [165120/25046 (20%)]\tLoss: 0.632030\n",
            "Train epoch: 208 [185760/25046 (23%)]\tLoss: 1.127998\n",
            "Train epoch: 208 [206800/25046 (26%)]\tLoss: 0.459419\n",
            "Train epoch: 208 [218680/25046 (28%)]\tLoss: 0.478378\n",
            "Train epoch: 208 [236880/25046 (31%)]\tLoss: 1.466013\n",
            "Train epoch: 208 [264940/25046 (33%)]\tLoss: 1.620037\n",
            "Train epoch: 208 [276920/25046 (36%)]\tLoss: 1.116912\n",
            "Train epoch: 208 [318000/25046 (38%)]\tLoss: 1.703825\n",
            "Train epoch: 208 [332160/25046 (41%)]\tLoss: 0.199515\n",
            "Train epoch: 208 [320960/25046 (43%)]\tLoss: 0.584164\n",
            "Train epoch: 208 [356760/25046 (46%)]\tLoss: 0.672120\n",
            "Train epoch: 208 [377340/25046 (49%)]\tLoss: 1.084243\n",
            "Train epoch: 208 [406800/25046 (51%)]\tLoss: 0.956285\n",
            "Train epoch: 208 [443520/25046 (54%)]\tLoss: 1.012213\n",
            "Train epoch: 208 [437800/25046 (56%)]\tLoss: 1.111654\n",
            "Train epoch: 208 [482080/25046 (59%)]\tLoss: 0.676093\n",
            "Train epoch: 208 [503520/25046 (61%)]\tLoss: 0.724829\n",
            "Train epoch: 208 [515500/25046 (64%)]\tLoss: 0.388929\n",
            "Train epoch: 208 [529360/25046 (66%)]\tLoss: 1.259530\n",
            "Train epoch: 208 [538380/25046 (69%)]\tLoss: 1.499382\n",
            "Train epoch: 208 [540960/25046 (72%)]\tLoss: 0.882390\n",
            "Train epoch: 208 [589280/25046 (74%)]\tLoss: 1.287630\n",
            "Train epoch: 208 [631200/25046 (77%)]\tLoss: 0.323872\n",
            "Train epoch: 208 [621240/25046 (79%)]\tLoss: 0.960001\n",
            "Train epoch: 208 [685440/25046 (82%)]\tLoss: 1.013579\n",
            "Train epoch: 208 [677820/25046 (84%)]\tLoss: 0.467675\n",
            "Train epoch: 208 [711280/25046 (87%)]\tLoss: 0.768268\n",
            "Train epoch: 208 [719600/25046 (89%)]\tLoss: 1.210344\n",
            "Train epoch: 208 [776160/25046 (92%)]\tLoss: 0.958723\n",
            "Train epoch: 208 [780700/25046 (95%)]\tLoss: 0.589477\n",
            "Train epoch: 208 [818520/25046 (97%)]\tLoss: 0.845626\n",
            "Train epoch: 208 [807300/25046 (100%)]\tLoss: 0.525702\n",
            "Make prediction for 5010 samples...\n",
            "0.8015243 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 209 [0/25046 (0%)]\tLoss: 1.279978\n",
            "Train epoch: 209 [20700/25046 (3%)]\tLoss: 0.954983\n",
            "Train epoch: 209 [40960/25046 (5%)]\tLoss: 0.344295\n",
            "Train epoch: 209 [64980/25046 (8%)]\tLoss: 0.628280\n",
            "Train epoch: 209 [82080/25046 (10%)]\tLoss: 0.517020\n",
            "Train epoch: 209 [107200/25046 (13%)]\tLoss: 1.056816\n",
            "Train epoch: 209 [124920/25046 (15%)]\tLoss: 1.146079\n",
            "Train epoch: 209 [143500/25046 (18%)]\tLoss: 0.951922\n",
            "Train epoch: 209 [156000/25046 (20%)]\tLoss: 0.542006\n",
            "Train epoch: 209 [191880/25046 (23%)]\tLoss: 1.158654\n",
            "Train epoch: 209 [211200/25046 (26%)]\tLoss: 0.235705\n",
            "Train epoch: 209 [226820/25046 (28%)]\tLoss: 1.011017\n",
            "Train epoch: 209 [255360/25046 (31%)]\tLoss: 1.382553\n",
            "Train epoch: 209 [266500/25046 (33%)]\tLoss: 0.596656\n",
            "Train epoch: 209 [290640/25046 (36%)]\tLoss: 0.707999\n",
            "Train epoch: 209 [309000/25046 (38%)]\tLoss: 1.320718\n",
            "Train epoch: 209 [310400/25046 (41%)]\tLoss: 0.546741\n",
            "Train epoch: 209 [344760/25046 (43%)]\tLoss: 0.573465\n",
            "Train epoch: 209 [371880/25046 (46%)]\tLoss: 1.546749\n",
            "Train epoch: 209 [379620/25046 (49%)]\tLoss: 0.363292\n",
            "Train epoch: 209 [425200/25046 (51%)]\tLoss: 1.006444\n",
            "Train epoch: 209 [435540/25046 (54%)]\tLoss: 0.949428\n",
            "Train epoch: 209 [458040/25046 (56%)]\tLoss: 1.054458\n",
            "Train epoch: 209 [469200/25046 (59%)]\tLoss: 0.717875\n",
            "Train epoch: 209 [490080/25046 (61%)]\tLoss: 0.871800\n",
            "Train epoch: 209 [516500/25046 (64%)]\tLoss: 1.000682\n",
            "Train epoch: 209 [507520/25046 (66%)]\tLoss: 0.552047\n",
            "Train epoch: 209 [564300/25046 (69%)]\tLoss: 1.773428\n",
            "Train epoch: 209 [603680/25046 (72%)]\tLoss: 0.390829\n",
            "Train epoch: 209 [593920/25046 (74%)]\tLoss: 0.730716\n",
            "Train epoch: 209 [597000/25046 (77%)]\tLoss: 0.407080\n",
            "Train epoch: 209 [659060/25046 (79%)]\tLoss: 0.749584\n",
            "Train epoch: 209 [638720/25046 (82%)]\tLoss: 1.444602\n",
            "Train epoch: 209 [681780/25046 (84%)]\tLoss: 1.053738\n",
            "Train epoch: 209 [735080/25046 (87%)]\tLoss: 0.808970\n",
            "Train epoch: 209 [685300/25046 (89%)]\tLoss: 0.331129\n",
            "Train epoch: 209 [749520/25046 (92%)]\tLoss: 2.499854\n",
            "Train epoch: 209 [769600/25046 (95%)]\tLoss: 0.628277\n",
            "Train epoch: 209 [769880/25046 (97%)]\tLoss: 0.483222\n",
            "Train epoch: 209 [797940/25046 (100%)]\tLoss: 0.746438\n",
            "Make prediction for 5010 samples...\n",
            "0.8018465 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 210 [0/25046 (0%)]\tLoss: 0.941302\n",
            "Train epoch: 210 [20300/25046 (3%)]\tLoss: 0.576671\n",
            "Train epoch: 210 [40120/25046 (5%)]\tLoss: 0.379980\n",
            "Train epoch: 210 [61620/25046 (8%)]\tLoss: 0.671504\n",
            "Train epoch: 210 [75280/25046 (10%)]\tLoss: 1.218890\n",
            "Train epoch: 210 [100200/25046 (13%)]\tLoss: 0.267837\n",
            "Train epoch: 210 [117840/25046 (15%)]\tLoss: 0.645992\n",
            "Train epoch: 210 [147420/25046 (18%)]\tLoss: 0.852956\n",
            "Train epoch: 210 [167040/25046 (20%)]\tLoss: 0.348502\n",
            "Train epoch: 210 [187380/25046 (23%)]\tLoss: 0.638511\n",
            "Train epoch: 210 [200400/25046 (26%)]\tLoss: 0.681365\n",
            "Train epoch: 210 [229020/25046 (28%)]\tLoss: 0.717522\n",
            "Train epoch: 210 [251760/25046 (31%)]\tLoss: 0.495911\n",
            "Train epoch: 210 [275600/25046 (33%)]\tLoss: 2.028223\n",
            "Train epoch: 210 [295960/25046 (36%)]\tLoss: 0.807741\n",
            "Train epoch: 210 [321900/25046 (38%)]\tLoss: 0.380565\n",
            "Train epoch: 210 [333440/25046 (41%)]\tLoss: 1.058646\n",
            "Train epoch: 210 [345440/25046 (43%)]\tLoss: 0.745311\n",
            "Train epoch: 210 [370440/25046 (46%)]\tLoss: 0.588203\n",
            "Train epoch: 210 [391780/25046 (49%)]\tLoss: 1.174881\n",
            "Train epoch: 210 [417200/25046 (51%)]\tLoss: 1.260440\n",
            "Train epoch: 210 [449400/25046 (54%)]\tLoss: 1.242194\n",
            "Train epoch: 210 [451880/25046 (56%)]\tLoss: 0.527866\n",
            "Train epoch: 210 [506920/25046 (59%)]\tLoss: 0.619907\n",
            "Train epoch: 210 [493440/25046 (61%)]\tLoss: 1.055076\n",
            "Train epoch: 210 [529500/25046 (64%)]\tLoss: 1.174947\n",
            "Train epoch: 210 [540800/25046 (66%)]\tLoss: 0.891635\n",
            "Train epoch: 210 [538920/25046 (69%)]\tLoss: 0.752830\n",
            "Train epoch: 210 [570640/25046 (72%)]\tLoss: 0.499645\n",
            "Train epoch: 210 [611900/25046 (74%)]\tLoss: 0.434915\n",
            "Train epoch: 210 [613800/25046 (77%)]\tLoss: 0.410544\n",
            "Train epoch: 210 [663400/25046 (79%)]\tLoss: 1.358444\n",
            "Train epoch: 210 [640000/25046 (82%)]\tLoss: 0.925452\n",
            "Train epoch: 210 [670560/25046 (84%)]\tLoss: 0.665664\n",
            "Train epoch: 210 [690880/25046 (87%)]\tLoss: 0.581633\n",
            "Train epoch: 210 [690200/25046 (89%)]\tLoss: 0.681936\n",
            "Train epoch: 210 [699120/25046 (92%)]\tLoss: 0.738743\n",
            "Train epoch: 210 [754060/25046 (95%)]\tLoss: 1.410308\n",
            "Train epoch: 210 [803320/25046 (97%)]\tLoss: 0.672772\n",
            "Train epoch: 210 [776100/25046 (100%)]\tLoss: 0.525771\n",
            "Make prediction for 5010 samples...\n",
            "0.80175686 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 211 [0/25046 (0%)]\tLoss: 0.717517\n",
            "Train epoch: 211 [20620/25046 (3%)]\tLoss: 0.727394\n",
            "Train epoch: 211 [38960/25046 (5%)]\tLoss: 0.446931\n",
            "Train epoch: 211 [61500/25046 (8%)]\tLoss: 1.139637\n",
            "Train epoch: 211 [76320/25046 (10%)]\tLoss: 0.996112\n",
            "Train epoch: 211 [103400/25046 (13%)]\tLoss: 0.903320\n",
            "Train epoch: 211 [123960/25046 (15%)]\tLoss: 1.046518\n",
            "Train epoch: 211 [155120/25046 (18%)]\tLoss: 1.235793\n",
            "Train epoch: 211 [173280/25046 (20%)]\tLoss: 1.210002\n",
            "Train epoch: 211 [178020/25046 (23%)]\tLoss: 0.996385\n",
            "Train epoch: 211 [205200/25046 (26%)]\tLoss: 0.795102\n",
            "Train epoch: 211 [210540/25046 (28%)]\tLoss: 1.327441\n",
            "Train epoch: 211 [241920/25046 (31%)]\tLoss: 0.649612\n",
            "Train epoch: 211 [262340/25046 (33%)]\tLoss: 0.935821\n",
            "Train epoch: 211 [303800/25046 (36%)]\tLoss: 1.231185\n",
            "Train epoch: 211 [311100/25046 (38%)]\tLoss: 0.844465\n",
            "Train epoch: 211 [333760/25046 (41%)]\tLoss: 1.000527\n",
            "Train epoch: 211 [341020/25046 (43%)]\tLoss: 0.343338\n",
            "Train epoch: 211 [374400/25046 (46%)]\tLoss: 1.720325\n",
            "Train epoch: 211 [403560/25046 (49%)]\tLoss: 1.357505\n",
            "Train epoch: 211 [420000/25046 (51%)]\tLoss: 1.512696\n",
            "Train epoch: 211 [427560/25046 (54%)]\tLoss: 0.953334\n",
            "Train epoch: 211 [461560/25046 (56%)]\tLoss: 0.452720\n",
            "Train epoch: 211 [461380/25046 (59%)]\tLoss: 0.498943\n",
            "Train epoch: 211 [498720/25046 (61%)]\tLoss: 0.644243\n",
            "Train epoch: 211 [514000/25046 (64%)]\tLoss: 0.637038\n",
            "Train epoch: 211 [518960/25046 (66%)]\tLoss: 0.316616\n",
            "Train epoch: 211 [525960/25046 (69%)]\tLoss: 0.325897\n",
            "Train epoch: 211 [563920/25046 (72%)]\tLoss: 0.787266\n",
            "Train epoch: 211 [610740/25046 (74%)]\tLoss: 0.840159\n",
            "Train epoch: 211 [637200/25046 (77%)]\tLoss: 1.628188\n",
            "Train epoch: 211 [653480/25046 (79%)]\tLoss: 0.495087\n",
            "Train epoch: 211 [654720/25046 (82%)]\tLoss: 0.908637\n",
            "Train epoch: 211 [675180/25046 (84%)]\tLoss: 0.512004\n",
            "Train epoch: 211 [706520/25046 (87%)]\tLoss: 0.227387\n",
            "Train epoch: 211 [710500/25046 (89%)]\tLoss: 0.502051\n",
            "Train epoch: 211 [722160/25046 (92%)]\tLoss: 1.466457\n",
            "Train epoch: 211 [734820/25046 (95%)]\tLoss: 0.654389\n",
            "Train epoch: 211 [739480/25046 (97%)]\tLoss: 0.524593\n",
            "Train epoch: 211 [817440/25046 (100%)]\tLoss: 0.409066\n",
            "Make prediction for 5010 samples...\n",
            "0.80194736 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 212 [0/25046 (0%)]\tLoss: 0.958498\n",
            "Train epoch: 212 [20380/25046 (3%)]\tLoss: 0.831511\n",
            "Train epoch: 212 [39760/25046 (5%)]\tLoss: 1.060690\n",
            "Train epoch: 212 [58320/25046 (8%)]\tLoss: 0.539507\n",
            "Train epoch: 212 [80320/25046 (10%)]\tLoss: 0.550701\n",
            "Train epoch: 212 [98800/25046 (13%)]\tLoss: 0.609585\n",
            "Train epoch: 212 [117000/25046 (15%)]\tLoss: 0.660306\n",
            "Train epoch: 212 [146300/25046 (18%)]\tLoss: 0.193234\n",
            "Train epoch: 212 [171040/25046 (20%)]\tLoss: 0.635843\n",
            "Train epoch: 212 [180900/25046 (23%)]\tLoss: 0.696351\n",
            "Train epoch: 212 [204200/25046 (26%)]\tLoss: 1.810520\n",
            "Train epoch: 212 [214940/25046 (28%)]\tLoss: 0.542055\n",
            "Train epoch: 212 [241440/25046 (31%)]\tLoss: 0.623386\n",
            "Train epoch: 212 [263900/25046 (33%)]\tLoss: 0.518183\n",
            "Train epoch: 212 [277760/25046 (36%)]\tLoss: 0.768032\n",
            "Train epoch: 212 [292800/25046 (38%)]\tLoss: 0.382843\n",
            "Train epoch: 212 [333760/25046 (41%)]\tLoss: 0.456149\n",
            "Train epoch: 212 [341700/25046 (43%)]\tLoss: 0.796022\n",
            "Train epoch: 212 [384840/25046 (46%)]\tLoss: 1.098613\n",
            "Train epoch: 212 [386840/25046 (49%)]\tLoss: 0.690309\n",
            "Train epoch: 212 [415600/25046 (51%)]\tLoss: 0.285673\n",
            "Train epoch: 212 [412020/25046 (54%)]\tLoss: 0.835828\n",
            "Train epoch: 212 [430760/25046 (56%)]\tLoss: 0.219373\n",
            "Train epoch: 212 [467820/25046 (59%)]\tLoss: 1.229492\n",
            "Train epoch: 212 [482880/25046 (61%)]\tLoss: 0.499151\n",
            "Train epoch: 212 [521000/25046 (64%)]\tLoss: 0.663400\n",
            "Train epoch: 212 [547560/25046 (66%)]\tLoss: 0.905143\n",
            "Train epoch: 212 [544320/25046 (69%)]\tLoss: 0.433310\n",
            "Train epoch: 212 [535360/25046 (72%)]\tLoss: 0.791308\n",
            "Train epoch: 212 [599140/25046 (74%)]\tLoss: 0.896816\n",
            "Train epoch: 212 [631800/25046 (77%)]\tLoss: 0.728512\n",
            "Train epoch: 212 [671460/25046 (79%)]\tLoss: 1.138238\n",
            "Train epoch: 212 [644480/25046 (82%)]\tLoss: 0.903348\n",
            "Train epoch: 212 [677820/25046 (84%)]\tLoss: 0.207987\n",
            "Train epoch: 212 [677960/25046 (87%)]\tLoss: 0.814488\n",
            "Train epoch: 212 [716100/25046 (89%)]\tLoss: 0.736908\n",
            "Train epoch: 212 [711360/25046 (92%)]\tLoss: 0.406785\n",
            "Train epoch: 212 [766640/25046 (95%)]\tLoss: 1.052187\n",
            "Train epoch: 212 [768360/25046 (97%)]\tLoss: 1.440191\n",
            "Train epoch: 212 [789360/25046 (100%)]\tLoss: 0.329406\n",
            "Make prediction for 5010 samples...\n",
            "0.8061141 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 213 [0/25046 (0%)]\tLoss: 1.533305\n",
            "Train epoch: 213 [19920/25046 (3%)]\tLoss: 1.224245\n",
            "Train epoch: 213 [40000/25046 (5%)]\tLoss: 0.724583\n",
            "Train epoch: 213 [63300/25046 (8%)]\tLoss: 0.668134\n",
            "Train epoch: 213 [82880/25046 (10%)]\tLoss: 1.179230\n",
            "Train epoch: 213 [102000/25046 (13%)]\tLoss: 0.668531\n",
            "Train epoch: 213 [122160/25046 (15%)]\tLoss: 0.540070\n",
            "Train epoch: 213 [153440/25046 (18%)]\tLoss: 0.525564\n",
            "Train epoch: 213 [163040/25046 (20%)]\tLoss: 0.428607\n",
            "Train epoch: 213 [182700/25046 (23%)]\tLoss: 1.100240\n",
            "Train epoch: 213 [200000/25046 (26%)]\tLoss: 0.666183\n",
            "Train epoch: 213 [226600/25046 (28%)]\tLoss: 0.930099\n",
            "Train epoch: 213 [242160/25046 (31%)]\tLoss: 0.765141\n",
            "Train epoch: 213 [273000/25046 (33%)]\tLoss: 0.938292\n",
            "Train epoch: 213 [281960/25046 (36%)]\tLoss: 1.362450\n",
            "Train epoch: 213 [322200/25046 (38%)]\tLoss: 0.988753\n",
            "Train epoch: 213 [319360/25046 (41%)]\tLoss: 1.391100\n",
            "Train epoch: 213 [333880/25046 (43%)]\tLoss: 0.828182\n",
            "Train epoch: 213 [365760/25046 (46%)]\tLoss: 0.730762\n",
            "Train epoch: 213 [378860/25046 (49%)]\tLoss: 0.585756\n",
            "Train epoch: 213 [398400/25046 (51%)]\tLoss: 0.336576\n",
            "Train epoch: 213 [412440/25046 (54%)]\tLoss: 0.781418\n",
            "Train epoch: 213 [452760/25046 (56%)]\tLoss: 0.851630\n",
            "Train epoch: 213 [449880/25046 (59%)]\tLoss: 0.401182\n",
            "Train epoch: 213 [478080/25046 (61%)]\tLoss: 1.240428\n",
            "Train epoch: 213 [507500/25046 (64%)]\tLoss: 0.686604\n",
            "Train epoch: 213 [521560/25046 (66%)]\tLoss: 0.472553\n",
            "Train epoch: 213 [545400/25046 (69%)]\tLoss: 0.611014\n",
            "Train epoch: 213 [601440/25046 (72%)]\tLoss: 0.543784\n",
            "Train epoch: 213 [615380/25046 (74%)]\tLoss: 0.818876\n",
            "Train epoch: 213 [631800/25046 (77%)]\tLoss: 1.073798\n",
            "Train epoch: 213 [609460/25046 (79%)]\tLoss: 0.259255\n",
            "Train epoch: 213 [666880/25046 (82%)]\tLoss: 1.105223\n",
            "Train epoch: 213 [691680/25046 (84%)]\tLoss: 0.256244\n",
            "Train epoch: 213 [729640/25046 (87%)]\tLoss: 0.643354\n",
            "Train epoch: 213 [759500/25046 (89%)]\tLoss: 0.973604\n",
            "Train epoch: 213 [784080/25046 (92%)]\tLoss: 0.583437\n",
            "Train epoch: 213 [791800/25046 (95%)]\tLoss: 0.987046\n",
            "Train epoch: 213 [738720/25046 (97%)]\tLoss: 0.807672\n",
            "Train epoch: 213 [801060/25046 (100%)]\tLoss: 1.224505\n",
            "Make prediction for 5010 samples...\n",
            "0.8035222 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 214 [0/25046 (0%)]\tLoss: 0.332678\n",
            "Train epoch: 214 [21240/25046 (3%)]\tLoss: 0.557231\n",
            "Train epoch: 214 [39760/25046 (5%)]\tLoss: 0.668212\n",
            "Train epoch: 214 [61320/25046 (8%)]\tLoss: 0.817624\n",
            "Train epoch: 214 [77040/25046 (10%)]\tLoss: 1.951302\n",
            "Train epoch: 214 [106200/25046 (13%)]\tLoss: 0.291785\n",
            "Train epoch: 214 [124920/25046 (15%)]\tLoss: 0.734801\n",
            "Train epoch: 214 [148680/25046 (18%)]\tLoss: 0.915248\n",
            "Train epoch: 214 [169920/25046 (20%)]\tLoss: 1.029524\n",
            "Train epoch: 214 [194940/25046 (23%)]\tLoss: 1.042517\n",
            "Train epoch: 214 [215800/25046 (26%)]\tLoss: 0.350861\n",
            "Train epoch: 214 [227920/25046 (28%)]\tLoss: 1.049049\n",
            "Train epoch: 214 [240960/25046 (31%)]\tLoss: 1.165655\n",
            "Train epoch: 214 [245440/25046 (33%)]\tLoss: 0.528845\n",
            "Train epoch: 214 [295400/25046 (36%)]\tLoss: 1.815799\n",
            "Train epoch: 214 [308400/25046 (38%)]\tLoss: 0.955298\n",
            "Train epoch: 214 [345600/25046 (41%)]\tLoss: 0.533230\n",
            "Train epoch: 214 [336600/25046 (43%)]\tLoss: 0.307132\n",
            "Train epoch: 214 [372600/25046 (46%)]\tLoss: 0.524530\n",
            "Train epoch: 214 [398240/25046 (49%)]\tLoss: 1.062076\n",
            "Train epoch: 214 [433600/25046 (51%)]\tLoss: 0.805340\n",
            "Train epoch: 214 [427560/25046 (54%)]\tLoss: 1.010808\n",
            "Train epoch: 214 [452320/25046 (56%)]\tLoss: 0.551849\n",
            "Train epoch: 214 [460920/25046 (59%)]\tLoss: 0.755379\n",
            "Train epoch: 214 [488160/25046 (61%)]\tLoss: 0.609650\n",
            "Train epoch: 214 [514500/25046 (64%)]\tLoss: 1.275347\n",
            "Train epoch: 214 [531440/25046 (66%)]\tLoss: 1.067047\n",
            "Train epoch: 214 [552420/25046 (69%)]\tLoss: 0.913656\n",
            "Train epoch: 214 [575680/25046 (72%)]\tLoss: 0.778984\n",
            "Train epoch: 214 [600300/25046 (74%)]\tLoss: 0.475111\n",
            "Train epoch: 214 [619800/25046 (77%)]\tLoss: 1.087524\n",
            "Train epoch: 214 [590240/25046 (79%)]\tLoss: 0.656724\n",
            "Train epoch: 214 [641920/25046 (82%)]\tLoss: 0.618327\n",
            "Train epoch: 214 [706200/25046 (84%)]\tLoss: 0.191673\n",
            "Train epoch: 214 [724200/25046 (87%)]\tLoss: 1.969767\n",
            "Train epoch: 214 [676900/25046 (89%)]\tLoss: 0.451471\n",
            "Train epoch: 214 [676800/25046 (92%)]\tLoss: 0.823348\n",
            "Train epoch: 214 [766640/25046 (95%)]\tLoss: 0.306211\n",
            "Train epoch: 214 [814720/25046 (97%)]\tLoss: 1.902840\n",
            "Train epoch: 214 [752700/25046 (100%)]\tLoss: 0.551129\n",
            "Make prediction for 5010 samples...\n",
            "0.80814564 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 215 [0/25046 (0%)]\tLoss: 0.778710\n",
            "Train epoch: 215 [19800/25046 (3%)]\tLoss: 0.536190\n",
            "Train epoch: 215 [41320/25046 (5%)]\tLoss: 0.443628\n",
            "Train epoch: 215 [61620/25046 (8%)]\tLoss: 0.877004\n",
            "Train epoch: 215 [83680/25046 (10%)]\tLoss: 0.544654\n",
            "Train epoch: 215 [100000/25046 (13%)]\tLoss: 0.278071\n",
            "Train epoch: 215 [119880/25046 (15%)]\tLoss: 0.360382\n",
            "Train epoch: 215 [149800/25046 (18%)]\tLoss: 1.313539\n",
            "Train epoch: 215 [161120/25046 (20%)]\tLoss: 0.854645\n",
            "Train epoch: 215 [181080/25046 (23%)]\tLoss: 0.577458\n",
            "Train epoch: 215 [204000/25046 (26%)]\tLoss: 1.168543\n",
            "Train epoch: 215 [238920/25046 (28%)]\tLoss: 0.241091\n",
            "Train epoch: 215 [255840/25046 (31%)]\tLoss: 1.122050\n",
            "Train epoch: 215 [266240/25046 (33%)]\tLoss: 1.100422\n",
            "Train epoch: 215 [286160/25046 (36%)]\tLoss: 0.581605\n",
            "Train epoch: 215 [305400/25046 (38%)]\tLoss: 0.368846\n",
            "Train epoch: 215 [352320/25046 (41%)]\tLoss: 1.050237\n",
            "Train epoch: 215 [345100/25046 (43%)]\tLoss: 0.700539\n",
            "Train epoch: 215 [376200/25046 (46%)]\tLoss: 1.379135\n",
            "Train epoch: 215 [368980/25046 (49%)]\tLoss: 1.256402\n",
            "Train epoch: 215 [432000/25046 (51%)]\tLoss: 0.282132\n",
            "Train epoch: 215 [438480/25046 (54%)]\tLoss: 0.450679\n",
            "Train epoch: 215 [447920/25046 (56%)]\tLoss: 1.097563\n",
            "Train epoch: 215 [486220/25046 (59%)]\tLoss: 0.493832\n",
            "Train epoch: 215 [500640/25046 (61%)]\tLoss: 0.794917\n",
            "Train epoch: 215 [540000/25046 (64%)]\tLoss: 0.472628\n",
            "Train epoch: 215 [545480/25046 (66%)]\tLoss: 0.388963\n",
            "Train epoch: 215 [565380/25046 (69%)]\tLoss: 0.654407\n",
            "Train epoch: 215 [616000/25046 (72%)]\tLoss: 0.888426\n",
            "Train epoch: 215 [567240/25046 (74%)]\tLoss: 1.026134\n",
            "Train epoch: 215 [582000/25046 (77%)]\tLoss: 0.959992\n",
            "Train epoch: 215 [661540/25046 (79%)]\tLoss: 0.726643\n",
            "Train epoch: 215 [693760/25046 (82%)]\tLoss: 1.182552\n",
            "Train epoch: 215 [657360/25046 (84%)]\tLoss: 0.574178\n",
            "Train epoch: 215 [688160/25046 (87%)]\tLoss: 0.845975\n",
            "Train epoch: 215 [693700/25046 (89%)]\tLoss: 0.528968\n",
            "Train epoch: 215 [705600/25046 (92%)]\tLoss: 0.548077\n",
            "Train epoch: 215 [765160/25046 (95%)]\tLoss: 0.663392\n",
            "Train epoch: 215 [788120/25046 (97%)]\tLoss: 0.925701\n",
            "Train epoch: 215 [790140/25046 (100%)]\tLoss: 1.084273\n",
            "Make prediction for 5010 samples...\n",
            "0.80612886 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 216 [0/25046 (0%)]\tLoss: 1.517629\n",
            "Train epoch: 216 [19440/25046 (3%)]\tLoss: 0.576020\n",
            "Train epoch: 216 [43080/25046 (5%)]\tLoss: 0.552845\n",
            "Train epoch: 216 [62940/25046 (8%)]\tLoss: 0.870371\n",
            "Train epoch: 216 [84400/25046 (10%)]\tLoss: 1.123000\n",
            "Train epoch: 216 [109900/25046 (13%)]\tLoss: 0.742823\n",
            "Train epoch: 216 [129720/25046 (15%)]\tLoss: 0.803877\n",
            "Train epoch: 216 [139860/25046 (18%)]\tLoss: 0.427369\n",
            "Train epoch: 216 [156160/25046 (20%)]\tLoss: 1.301618\n",
            "Train epoch: 216 [176040/25046 (23%)]\tLoss: 0.297014\n",
            "Train epoch: 216 [203400/25046 (26%)]\tLoss: 0.343433\n",
            "Train epoch: 216 [240680/25046 (28%)]\tLoss: 1.912999\n",
            "Train epoch: 216 [235200/25046 (31%)]\tLoss: 1.003923\n",
            "Train epoch: 216 [270140/25046 (33%)]\tLoss: 0.347408\n",
            "Train epoch: 216 [276080/25046 (36%)]\tLoss: 0.760946\n",
            "Train epoch: 216 [306900/25046 (38%)]\tLoss: 0.986461\n",
            "Train epoch: 216 [335040/25046 (41%)]\tLoss: 0.711095\n",
            "Train epoch: 216 [337280/25046 (43%)]\tLoss: 0.544943\n",
            "Train epoch: 216 [373680/25046 (46%)]\tLoss: 0.552720\n",
            "Train epoch: 216 [375440/25046 (49%)]\tLoss: 0.345060\n",
            "Train epoch: 216 [402400/25046 (51%)]\tLoss: 0.632535\n",
            "Train epoch: 216 [420420/25046 (54%)]\tLoss: 0.497545\n",
            "Train epoch: 216 [462000/25046 (56%)]\tLoss: 1.246608\n",
            "Train epoch: 216 [478400/25046 (59%)]\tLoss: 1.530831\n",
            "Train epoch: 216 [493920/25046 (61%)]\tLoss: 1.628184\n",
            "Train epoch: 216 [498000/25046 (64%)]\tLoss: 0.854718\n",
            "Train epoch: 216 [560040/25046 (66%)]\tLoss: 0.779120\n",
            "Train epoch: 216 [536220/25046 (69%)]\tLoss: 1.309986\n",
            "Train epoch: 216 [596400/25046 (72%)]\tLoss: 0.703593\n",
            "Train epoch: 216 [586960/25046 (74%)]\tLoss: 1.079835\n",
            "Train epoch: 216 [641400/25046 (77%)]\tLoss: 0.580655\n",
            "Train epoch: 216 [622480/25046 (79%)]\tLoss: 0.728132\n",
            "Train epoch: 216 [689280/25046 (82%)]\tLoss: 1.016919\n",
            "Train epoch: 216 [724020/25046 (84%)]\tLoss: 0.416565\n",
            "Train epoch: 216 [712640/25046 (87%)]\tLoss: 0.223569\n",
            "Train epoch: 216 [754600/25046 (89%)]\tLoss: 1.325937\n",
            "Train epoch: 216 [746640/25046 (92%)]\tLoss: 0.823642\n",
            "Train epoch: 216 [732600/25046 (95%)]\tLoss: 0.777877\n",
            "Train epoch: 216 [833720/25046 (97%)]\tLoss: 0.890175\n",
            "Train epoch: 216 [842400/25046 (100%)]\tLoss: 0.293379\n",
            "Make prediction for 5010 samples...\n",
            "0.80241823 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 217 [0/25046 (0%)]\tLoss: 0.208640\n",
            "Train epoch: 217 [19120/25046 (3%)]\tLoss: 0.652437\n",
            "Train epoch: 217 [42280/25046 (5%)]\tLoss: 0.798653\n",
            "Train epoch: 217 [63780/25046 (8%)]\tLoss: 0.790186\n",
            "Train epoch: 217 [79120/25046 (10%)]\tLoss: 0.281521\n",
            "Train epoch: 217 [103100/25046 (13%)]\tLoss: 0.230727\n",
            "Train epoch: 217 [118200/25046 (15%)]\tLoss: 0.923036\n",
            "Train epoch: 217 [148260/25046 (18%)]\tLoss: 0.595409\n",
            "Train epoch: 217 [172000/25046 (20%)]\tLoss: 0.533008\n",
            "Train epoch: 217 [185760/25046 (23%)]\tLoss: 0.793626\n",
            "Train epoch: 217 [204600/25046 (26%)]\tLoss: 0.848293\n",
            "Train epoch: 217 [225060/25046 (28%)]\tLoss: 0.718752\n",
            "Train epoch: 217 [243360/25046 (31%)]\tLoss: 1.115039\n",
            "Train epoch: 217 [267280/25046 (33%)]\tLoss: 0.387026\n",
            "Train epoch: 217 [302400/25046 (36%)]\tLoss: 0.301037\n",
            "Train epoch: 217 [315000/25046 (38%)]\tLoss: 1.842250\n",
            "Train epoch: 217 [306880/25046 (41%)]\tLoss: 1.366370\n",
            "Train epoch: 217 [341020/25046 (43%)]\tLoss: 0.817793\n",
            "Train epoch: 217 [367920/25046 (46%)]\tLoss: 0.719151\n",
            "Train epoch: 217 [377340/25046 (49%)]\tLoss: 0.754757\n",
            "Train epoch: 217 [418000/25046 (51%)]\tLoss: 0.575801\n",
            "Train epoch: 217 [426720/25046 (54%)]\tLoss: 0.670357\n",
            "Train epoch: 217 [461560/25046 (56%)]\tLoss: 0.717744\n",
            "Train epoch: 217 [464140/25046 (59%)]\tLoss: 0.306490\n",
            "Train epoch: 217 [479520/25046 (61%)]\tLoss: 0.464418\n",
            "Train epoch: 217 [508500/25046 (64%)]\tLoss: 0.538795\n",
            "Train epoch: 217 [541840/25046 (66%)]\tLoss: 0.445883\n",
            "Train epoch: 217 [536760/25046 (69%)]\tLoss: 1.037871\n",
            "Train epoch: 217 [576800/25046 (72%)]\tLoss: 0.777439\n",
            "Train epoch: 217 [620600/25046 (74%)]\tLoss: 0.891589\n",
            "Train epoch: 217 [585600/25046 (77%)]\tLoss: 0.388761\n",
            "Train epoch: 217 [626200/25046 (79%)]\tLoss: 1.125103\n",
            "Train epoch: 217 [682880/25046 (82%)]\tLoss: 0.300583\n",
            "Train epoch: 217 [669900/25046 (84%)]\tLoss: 0.680690\n",
            "Train epoch: 217 [703120/25046 (87%)]\tLoss: 0.535260\n",
            "Train epoch: 217 [751100/25046 (89%)]\tLoss: 0.529851\n",
            "Train epoch: 217 [722880/25046 (92%)]\tLoss: 0.596965\n",
            "Train epoch: 217 [765900/25046 (95%)]\tLoss: 0.921771\n",
            "Train epoch: 217 [756200/25046 (97%)]\tLoss: 1.372548\n",
            "Train epoch: 217 [791700/25046 (100%)]\tLoss: 1.156442\n",
            "Make prediction for 5010 samples...\n",
            "0.81298035 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 218 [0/25046 (0%)]\tLoss: 0.810282\n",
            "Train epoch: 218 [20940/25046 (3%)]\tLoss: 0.566092\n",
            "Train epoch: 218 [43800/25046 (5%)]\tLoss: 1.124785\n",
            "Train epoch: 218 [61980/25046 (8%)]\tLoss: 1.083113\n",
            "Train epoch: 218 [82160/25046 (10%)]\tLoss: 0.964456\n",
            "Train epoch: 218 [109000/25046 (13%)]\tLoss: 0.870571\n",
            "Train epoch: 218 [126960/25046 (15%)]\tLoss: 0.632966\n",
            "Train epoch: 218 [147560/25046 (18%)]\tLoss: 1.022285\n",
            "Train epoch: 218 [162080/25046 (20%)]\tLoss: 0.664873\n",
            "Train epoch: 218 [183060/25046 (23%)]\tLoss: 0.833396\n",
            "Train epoch: 218 [195600/25046 (26%)]\tLoss: 0.603700\n",
            "Train epoch: 218 [216480/25046 (28%)]\tLoss: 0.293297\n",
            "Train epoch: 218 [237360/25046 (31%)]\tLoss: 0.432222\n",
            "Train epoch: 218 [250380/25046 (33%)]\tLoss: 0.341892\n",
            "Train epoch: 218 [293440/25046 (36%)]\tLoss: 0.865746\n",
            "Train epoch: 218 [304500/25046 (38%)]\tLoss: 0.404045\n",
            "Train epoch: 218 [333440/25046 (41%)]\tLoss: 0.342624\n",
            "Train epoch: 218 [352240/25046 (43%)]\tLoss: 1.363096\n",
            "Train epoch: 218 [359280/25046 (46%)]\tLoss: 0.487094\n",
            "Train epoch: 218 [384180/25046 (49%)]\tLoss: 0.720383\n",
            "Train epoch: 218 [390400/25046 (51%)]\tLoss: 1.134887\n",
            "Train epoch: 218 [430920/25046 (54%)]\tLoss: 0.694893\n",
            "Train epoch: 218 [435600/25046 (56%)]\tLoss: 0.689206\n",
            "Train epoch: 218 [463220/25046 (59%)]\tLoss: 1.677580\n",
            "Train epoch: 218 [509760/25046 (61%)]\tLoss: 1.474599\n",
            "Train epoch: 218 [497000/25046 (64%)]\tLoss: 0.310371\n",
            "Train epoch: 218 [532480/25046 (66%)]\tLoss: 0.678318\n",
            "Train epoch: 218 [552420/25046 (69%)]\tLoss: 0.840325\n",
            "Train epoch: 218 [557200/25046 (72%)]\tLoss: 1.230035\n",
            "Train epoch: 218 [566080/25046 (74%)]\tLoss: 0.528017\n",
            "Train epoch: 218 [637800/25046 (77%)]\tLoss: 0.901100\n",
            "Train epoch: 218 [679520/25046 (79%)]\tLoss: 0.772697\n",
            "Train epoch: 218 [620160/25046 (82%)]\tLoss: 0.335207\n",
            "Train epoch: 218 [696960/25046 (84%)]\tLoss: 0.917872\n",
            "Train epoch: 218 [675920/25046 (87%)]\tLoss: 1.159166\n",
            "Train epoch: 218 [723100/25046 (89%)]\tLoss: 1.366751\n",
            "Train epoch: 218 [742320/25046 (92%)]\tLoss: 1.033541\n",
            "Train epoch: 218 [711880/25046 (95%)]\tLoss: 0.535569\n",
            "Train epoch: 218 [763800/25046 (97%)]\tLoss: 0.576703\n",
            "Train epoch: 218 [806520/25046 (100%)]\tLoss: 0.790991\n",
            "Make prediction for 5010 samples...\n",
            "0.8018433 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 219 [0/25046 (0%)]\tLoss: 1.832745\n",
            "Train epoch: 219 [21280/25046 (3%)]\tLoss: 0.452989\n",
            "Train epoch: 219 [42560/25046 (5%)]\tLoss: 0.733008\n",
            "Train epoch: 219 [65040/25046 (8%)]\tLoss: 0.923979\n",
            "Train epoch: 219 [88960/25046 (10%)]\tLoss: 1.058171\n",
            "Train epoch: 219 [107400/25046 (13%)]\tLoss: 0.188136\n",
            "Train epoch: 219 [125160/25046 (15%)]\tLoss: 1.210207\n",
            "Train epoch: 219 [143360/25046 (18%)]\tLoss: 0.602149\n",
            "Train epoch: 219 [160800/25046 (20%)]\tLoss: 0.391726\n",
            "Train epoch: 219 [181800/25046 (23%)]\tLoss: 0.884185\n",
            "Train epoch: 219 [199600/25046 (26%)]\tLoss: 0.264971\n",
            "Train epoch: 219 [236940/25046 (28%)]\tLoss: 0.701587\n",
            "Train epoch: 219 [246000/25046 (31%)]\tLoss: 1.352914\n",
            "Train epoch: 219 [262860/25046 (33%)]\tLoss: 0.516642\n",
            "Train epoch: 219 [290640/25046 (36%)]\tLoss: 0.818988\n",
            "Train epoch: 219 [291900/25046 (38%)]\tLoss: 0.542740\n",
            "Train epoch: 219 [321600/25046 (41%)]\tLoss: 0.876414\n",
            "Train epoch: 219 [337960/25046 (43%)]\tLoss: 0.340719\n",
            "Train epoch: 219 [382680/25046 (46%)]\tLoss: 0.640059\n",
            "Train epoch: 219 [374300/25046 (49%)]\tLoss: 0.376497\n",
            "Train epoch: 219 [418000/25046 (51%)]\tLoss: 0.673329\n",
            "Train epoch: 219 [450660/25046 (54%)]\tLoss: 0.540978\n",
            "Train epoch: 219 [440880/25046 (56%)]\tLoss: 0.785822\n",
            "Train epoch: 219 [500480/25046 (59%)]\tLoss: 0.579342\n",
            "Train epoch: 219 [510240/25046 (61%)]\tLoss: 1.070968\n",
            "Train epoch: 219 [509000/25046 (64%)]\tLoss: 1.773677\n",
            "Train epoch: 219 [538200/25046 (66%)]\tLoss: 1.698175\n",
            "Train epoch: 219 [545940/25046 (69%)]\tLoss: 0.513240\n",
            "Train epoch: 219 [539840/25046 (72%)]\tLoss: 0.251297\n",
            "Train epoch: 219 [591020/25046 (74%)]\tLoss: 0.425837\n",
            "Train epoch: 219 [635400/25046 (77%)]\tLoss: 1.513883\n",
            "Train epoch: 219 [631160/25046 (79%)]\tLoss: 0.953752\n",
            "Train epoch: 219 [626560/25046 (82%)]\tLoss: 1.646575\n",
            "Train epoch: 219 [635580/25046 (84%)]\tLoss: 0.583848\n",
            "Train epoch: 219 [721480/25046 (87%)]\tLoss: 0.733858\n",
            "Train epoch: 219 [728700/25046 (89%)]\tLoss: 0.702196\n",
            "Train epoch: 219 [703440/25046 (92%)]\tLoss: 0.747466\n",
            "Train epoch: 219 [810300/25046 (95%)]\tLoss: 0.625934\n",
            "Train epoch: 219 [792680/25046 (97%)]\tLoss: 0.988075\n",
            "Train epoch: 219 [818220/25046 (100%)]\tLoss: 1.961308\n",
            "Make prediction for 5010 samples...\n",
            "0.80204904 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 220 [0/25046 (0%)]\tLoss: 0.316696\n",
            "Train epoch: 220 [20540/25046 (3%)]\tLoss: 1.036936\n",
            "Train epoch: 220 [36520/25046 (5%)]\tLoss: 0.609080\n",
            "Train epoch: 220 [60180/25046 (8%)]\tLoss: 0.628668\n",
            "Train epoch: 220 [78960/25046 (10%)]\tLoss: 1.242515\n",
            "Train epoch: 220 [98900/25046 (13%)]\tLoss: 0.553772\n",
            "Train epoch: 220 [126240/25046 (15%)]\tLoss: 0.797349\n",
            "Train epoch: 220 [129780/25046 (18%)]\tLoss: 0.191562\n",
            "Train epoch: 220 [156800/25046 (20%)]\tLoss: 0.393995\n",
            "Train epoch: 220 [189180/25046 (23%)]\tLoss: 1.217548\n",
            "Train epoch: 220 [207200/25046 (26%)]\tLoss: 0.899580\n",
            "Train epoch: 220 [222420/25046 (28%)]\tLoss: 0.832926\n",
            "Train epoch: 220 [240960/25046 (31%)]\tLoss: 0.845974\n",
            "Train epoch: 220 [270400/25046 (33%)]\tLoss: 0.674823\n",
            "Train epoch: 220 [299040/25046 (36%)]\tLoss: 0.400438\n",
            "Train epoch: 220 [317400/25046 (38%)]\tLoss: 1.206744\n",
            "Train epoch: 220 [319040/25046 (41%)]\tLoss: 1.731007\n",
            "Train epoch: 220 [372980/25046 (43%)]\tLoss: 0.801370\n",
            "Train epoch: 220 [366840/25046 (46%)]\tLoss: 0.759917\n",
            "Train epoch: 220 [405460/25046 (49%)]\tLoss: 1.364423\n",
            "Train epoch: 220 [408000/25046 (51%)]\tLoss: 0.496611\n",
            "Train epoch: 220 [416220/25046 (54%)]\tLoss: 1.497184\n",
            "Train epoch: 220 [465960/25046 (56%)]\tLoss: 0.815149\n",
            "Train epoch: 220 [470580/25046 (59%)]\tLoss: 0.449268\n",
            "Train epoch: 220 [521280/25046 (61%)]\tLoss: 0.645029\n",
            "Train epoch: 220 [535500/25046 (64%)]\tLoss: 0.553170\n",
            "Train epoch: 220 [530920/25046 (66%)]\tLoss: 0.458549\n",
            "Train epoch: 220 [559980/25046 (69%)]\tLoss: 1.508272\n",
            "Train epoch: 220 [595840/25046 (72%)]\tLoss: 0.967657\n",
            "Train epoch: 220 [595660/25046 (74%)]\tLoss: 0.741735\n",
            "Train epoch: 220 [597000/25046 (77%)]\tLoss: 0.365366\n",
            "Train epoch: 220 [646660/25046 (79%)]\tLoss: 0.705794\n",
            "Train epoch: 220 [643200/25046 (82%)]\tLoss: 0.627047\n",
            "Train epoch: 220 [667260/25046 (84%)]\tLoss: 0.688159\n",
            "Train epoch: 220 [678640/25046 (87%)]\tLoss: 1.195625\n",
            "Train epoch: 220 [723100/25046 (89%)]\tLoss: 1.101536\n",
            "Train epoch: 220 [691200/25046 (92%)]\tLoss: 0.345363\n",
            "Train epoch: 220 [766640/25046 (95%)]\tLoss: 0.674186\n",
            "Train epoch: 220 [758480/25046 (97%)]\tLoss: 1.409816\n",
            "Train epoch: 220 [822900/25046 (100%)]\tLoss: 0.865318\n",
            "Make prediction for 5010 samples...\n",
            "0.80198497 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 221 [0/25046 (0%)]\tLoss: 0.289186\n",
            "Train epoch: 221 [20980/25046 (3%)]\tLoss: 0.350681\n",
            "Train epoch: 221 [40080/25046 (5%)]\tLoss: 0.676868\n",
            "Train epoch: 221 [58440/25046 (8%)]\tLoss: 0.654743\n",
            "Train epoch: 221 [79760/25046 (10%)]\tLoss: 1.508704\n",
            "Train epoch: 221 [102300/25046 (13%)]\tLoss: 0.983873\n",
            "Train epoch: 221 [122160/25046 (15%)]\tLoss: 1.682851\n",
            "Train epoch: 221 [143500/25046 (18%)]\tLoss: 0.853127\n",
            "Train epoch: 221 [172640/25046 (20%)]\tLoss: 0.335325\n",
            "Train epoch: 221 [196020/25046 (23%)]\tLoss: 0.554040\n",
            "Train epoch: 221 [198800/25046 (26%)]\tLoss: 0.289133\n",
            "Train epoch: 221 [205920/25046 (28%)]\tLoss: 1.092290\n",
            "Train epoch: 221 [248880/25046 (31%)]\tLoss: 0.776600\n",
            "Train epoch: 221 [251680/25046 (33%)]\tLoss: 2.056950\n",
            "Train epoch: 221 [281960/25046 (36%)]\tLoss: 1.132635\n",
            "Train epoch: 221 [314100/25046 (38%)]\tLoss: 0.609055\n",
            "Train epoch: 221 [353920/25046 (41%)]\tLoss: 0.469711\n",
            "Train epoch: 221 [351900/25046 (43%)]\tLoss: 0.504973\n",
            "Train epoch: 221 [367920/25046 (46%)]\tLoss: 0.547394\n",
            "Train epoch: 221 [413820/25046 (49%)]\tLoss: 0.324445\n",
            "Train epoch: 221 [396000/25046 (51%)]\tLoss: 0.535561\n",
            "Train epoch: 221 [435120/25046 (54%)]\tLoss: 1.328950\n",
            "Train epoch: 221 [446600/25046 (56%)]\tLoss: 0.350125\n",
            "Train epoch: 221 [475640/25046 (59%)]\tLoss: 0.414229\n",
            "Train epoch: 221 [485760/25046 (61%)]\tLoss: 0.355544\n",
            "Train epoch: 221 [520000/25046 (64%)]\tLoss: 1.135867\n",
            "Train epoch: 221 [541320/25046 (66%)]\tLoss: 1.281912\n",
            "Train epoch: 221 [591840/25046 (69%)]\tLoss: 1.417064\n",
            "Train epoch: 221 [603120/25046 (72%)]\tLoss: 1.507066\n",
            "Train epoch: 221 [598560/25046 (74%)]\tLoss: 1.907394\n",
            "Train epoch: 221 [651000/25046 (77%)]\tLoss: 1.317650\n",
            "Train epoch: 221 [677040/25046 (79%)]\tLoss: 1.432537\n",
            "Train epoch: 221 [634240/25046 (82%)]\tLoss: 1.158498\n",
            "Train epoch: 221 [689700/25046 (84%)]\tLoss: 1.114095\n",
            "Train epoch: 221 [679320/25046 (87%)]\tLoss: 0.715404\n",
            "Train epoch: 221 [717500/25046 (89%)]\tLoss: 0.719118\n",
            "Train epoch: 221 [761040/25046 (92%)]\tLoss: 0.299650\n",
            "Train epoch: 221 [752580/25046 (95%)]\tLoss: 0.601737\n",
            "Train epoch: 221 [803320/25046 (97%)]\tLoss: 0.283310\n",
            "Train epoch: 221 [795600/25046 (100%)]\tLoss: 0.564633\n",
            "Make prediction for 5010 samples...\n",
            "0.80416054 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 222 [0/25046 (0%)]\tLoss: 0.866192\n",
            "Train epoch: 222 [21180/25046 (3%)]\tLoss: 0.419330\n",
            "Train epoch: 222 [42760/25046 (5%)]\tLoss: 1.360190\n",
            "Train epoch: 222 [63240/25046 (8%)]\tLoss: 1.186944\n",
            "Train epoch: 222 [82240/25046 (10%)]\tLoss: 0.454125\n",
            "Train epoch: 222 [104100/25046 (13%)]\tLoss: 0.516589\n",
            "Train epoch: 222 [125640/25046 (15%)]\tLoss: 0.961605\n",
            "Train epoch: 222 [140280/25046 (18%)]\tLoss: 0.277553\n",
            "Train epoch: 222 [163520/25046 (20%)]\tLoss: 0.921570\n",
            "Train epoch: 222 [176760/25046 (23%)]\tLoss: 1.085411\n",
            "Train epoch: 222 [208400/25046 (26%)]\tLoss: 0.551567\n",
            "Train epoch: 222 [220000/25046 (28%)]\tLoss: 1.829156\n",
            "Train epoch: 222 [256320/25046 (31%)]\tLoss: 2.340456\n",
            "Train epoch: 222 [269360/25046 (33%)]\tLoss: 1.164562\n",
            "Train epoch: 222 [284760/25046 (36%)]\tLoss: 1.359938\n",
            "Train epoch: 222 [303900/25046 (38%)]\tLoss: 1.781369\n",
            "Train epoch: 222 [317120/25046 (41%)]\tLoss: 0.667858\n",
            "Train epoch: 222 [351220/25046 (43%)]\tLoss: 0.849095\n",
            "Train epoch: 222 [367560/25046 (46%)]\tLoss: 0.976395\n",
            "Train epoch: 222 [372400/25046 (49%)]\tLoss: 0.588811\n",
            "Train epoch: 222 [412000/25046 (51%)]\tLoss: 0.535149\n",
            "Train epoch: 222 [448980/25046 (54%)]\tLoss: 0.676568\n",
            "Train epoch: 222 [431200/25046 (56%)]\tLoss: 0.396999\n",
            "Train epoch: 222 [500480/25046 (59%)]\tLoss: 1.075557\n",
            "Train epoch: 222 [493920/25046 (61%)]\tLoss: 0.582543\n",
            "Train epoch: 222 [494000/25046 (64%)]\tLoss: 1.268845\n",
            "Train epoch: 222 [492960/25046 (66%)]\tLoss: 0.635927\n",
            "Train epoch: 222 [534600/25046 (69%)]\tLoss: 0.665544\n",
            "Train epoch: 222 [553840/25046 (72%)]\tLoss: 0.291955\n",
            "Train epoch: 222 [581160/25046 (74%)]\tLoss: 0.499549\n",
            "Train epoch: 222 [636000/25046 (77%)]\tLoss: 0.927130\n",
            "Train epoch: 222 [682620/25046 (79%)]\tLoss: 0.431796\n",
            "Train epoch: 222 [652160/25046 (82%)]\tLoss: 0.290615\n",
            "Train epoch: 222 [673200/25046 (84%)]\tLoss: 0.763996\n",
            "Train epoch: 222 [676600/25046 (87%)]\tLoss: 0.418781\n",
            "Train epoch: 222 [711900/25046 (89%)]\tLoss: 0.761020\n",
            "Train epoch: 222 [817920/25046 (92%)]\tLoss: 0.720560\n",
            "Train epoch: 222 [761460/25046 (95%)]\tLoss: 0.717267\n",
            "Train epoch: 222 [735680/25046 (97%)]\tLoss: 0.337573\n",
            "Train epoch: 222 [779220/25046 (100%)]\tLoss: 0.274748\n",
            "Make prediction for 5010 samples...\n",
            "0.80153555 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 223 [0/25046 (0%)]\tLoss: 0.966079\n",
            "Train epoch: 223 [21180/25046 (3%)]\tLoss: 0.617326\n",
            "Train epoch: 223 [43400/25046 (5%)]\tLoss: 0.432450\n",
            "Train epoch: 223 [62340/25046 (8%)]\tLoss: 0.427625\n",
            "Train epoch: 223 [78960/25046 (10%)]\tLoss: 0.442221\n",
            "Train epoch: 223 [101000/25046 (13%)]\tLoss: 0.480318\n",
            "Train epoch: 223 [124680/25046 (15%)]\tLoss: 1.155496\n",
            "Train epoch: 223 [143220/25046 (18%)]\tLoss: 1.547082\n",
            "Train epoch: 223 [158720/25046 (20%)]\tLoss: 1.201911\n",
            "Train epoch: 223 [177660/25046 (23%)]\tLoss: 0.504470\n",
            "Train epoch: 223 [198600/25046 (26%)]\tLoss: 0.890205\n",
            "Train epoch: 223 [223080/25046 (28%)]\tLoss: 0.367975\n",
            "Train epoch: 223 [242400/25046 (31%)]\tLoss: 1.253095\n",
            "Train epoch: 223 [269100/25046 (33%)]\tLoss: 0.781962\n",
            "Train epoch: 223 [295680/25046 (36%)]\tLoss: 1.215445\n",
            "Train epoch: 223 [310800/25046 (38%)]\tLoss: 0.437154\n",
            "Train epoch: 223 [336960/25046 (41%)]\tLoss: 0.491650\n",
            "Train epoch: 223 [350880/25046 (43%)]\tLoss: 0.869434\n",
            "Train epoch: 223 [365400/25046 (46%)]\tLoss: 1.723841\n",
            "Train epoch: 223 [395200/25046 (49%)]\tLoss: 0.690648\n",
            "Train epoch: 223 [425200/25046 (51%)]\tLoss: 0.372905\n",
            "Train epoch: 223 [452340/25046 (54%)]\tLoss: 0.913871\n",
            "Train epoch: 223 [440000/25046 (56%)]\tLoss: 0.892549\n",
            "Train epoch: 223 [455400/25046 (59%)]\tLoss: 0.886486\n",
            "Train epoch: 223 [486240/25046 (61%)]\tLoss: 0.770277\n",
            "Train epoch: 223 [528000/25046 (64%)]\tLoss: 0.374870\n",
            "Train epoch: 223 [530920/25046 (66%)]\tLoss: 0.542120\n",
            "Train epoch: 223 [525960/25046 (69%)]\tLoss: 0.692917\n",
            "Train epoch: 223 [591360/25046 (72%)]\tLoss: 0.597557\n",
            "Train epoch: 223 [627560/25046 (74%)]\tLoss: 1.166183\n",
            "Train epoch: 223 [632400/25046 (77%)]\tLoss: 0.729252\n",
            "Train epoch: 223 [628680/25046 (79%)]\tLoss: 0.508606\n",
            "Train epoch: 223 [650240/25046 (82%)]\tLoss: 0.624664\n",
            "Train epoch: 223 [683100/25046 (84%)]\tLoss: 0.688694\n",
            "Train epoch: 223 [738480/25046 (87%)]\tLoss: 0.219358\n",
            "Train epoch: 223 [690900/25046 (89%)]\tLoss: 0.316666\n",
            "Train epoch: 223 [735840/25046 (92%)]\tLoss: 0.534928\n",
            "Train epoch: 223 [778480/25046 (95%)]\tLoss: 1.232156\n",
            "Train epoch: 223 [738720/25046 (97%)]\tLoss: 0.373369\n",
            "Train epoch: 223 [860340/25046 (100%)]\tLoss: 0.675184\n",
            "Make prediction for 5010 samples...\n",
            "0.8017573 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 224 [0/25046 (0%)]\tLoss: 0.567844\n",
            "Train epoch: 224 [19680/25046 (3%)]\tLoss: 1.145490\n",
            "Train epoch: 224 [41840/25046 (5%)]\tLoss: 0.367519\n",
            "Train epoch: 224 [62640/25046 (8%)]\tLoss: 1.354908\n",
            "Train epoch: 224 [81760/25046 (10%)]\tLoss: 0.314561\n",
            "Train epoch: 224 [102100/25046 (13%)]\tLoss: 0.430229\n",
            "Train epoch: 224 [120000/25046 (15%)]\tLoss: 1.121248\n",
            "Train epoch: 224 [150220/25046 (18%)]\tLoss: 1.260705\n",
            "Train epoch: 224 [155360/25046 (20%)]\tLoss: 0.881015\n",
            "Train epoch: 224 [175320/25046 (23%)]\tLoss: 0.750975\n",
            "Train epoch: 224 [202000/25046 (26%)]\tLoss: 0.713879\n",
            "Train epoch: 224 [224180/25046 (28%)]\tLoss: 0.307965\n",
            "Train epoch: 224 [243120/25046 (31%)]\tLoss: 0.250991\n",
            "Train epoch: 224 [263640/25046 (33%)]\tLoss: 0.830525\n",
            "Train epoch: 224 [298200/25046 (36%)]\tLoss: 0.955287\n",
            "Train epoch: 224 [316500/25046 (38%)]\tLoss: 1.128702\n",
            "Train epoch: 224 [314880/25046 (41%)]\tLoss: 0.718791\n",
            "Train epoch: 224 [373660/25046 (43%)]\tLoss: 0.861992\n",
            "Train epoch: 224 [388800/25046 (46%)]\tLoss: 1.178116\n",
            "Train epoch: 224 [411160/25046 (49%)]\tLoss: 1.429930\n",
            "Train epoch: 224 [410400/25046 (51%)]\tLoss: 0.843743\n",
            "Train epoch: 224 [433860/25046 (54%)]\tLoss: 0.664891\n",
            "Train epoch: 224 [441760/25046 (56%)]\tLoss: 1.213152\n",
            "Train epoch: 224 [474260/25046 (59%)]\tLoss: 0.711538\n",
            "Train epoch: 224 [496320/25046 (61%)]\tLoss: 0.624882\n",
            "Train epoch: 224 [517500/25046 (64%)]\tLoss: 1.020831\n",
            "Train epoch: 224 [534560/25046 (66%)]\tLoss: 0.557978\n",
            "Train epoch: 224 [564300/25046 (69%)]\tLoss: 0.842774\n",
            "Train epoch: 224 [560000/25046 (72%)]\tLoss: 0.853883\n",
            "Train epoch: 224 [614220/25046 (74%)]\tLoss: 0.597757\n",
            "Train epoch: 224 [670800/25046 (77%)]\tLoss: 0.592765\n",
            "Train epoch: 224 [628060/25046 (79%)]\tLoss: 0.396210\n",
            "Train epoch: 224 [638720/25046 (82%)]\tLoss: 0.584455\n",
            "Train epoch: 224 [665280/25046 (84%)]\tLoss: 1.789990\n",
            "Train epoch: 224 [713320/25046 (87%)]\tLoss: 0.996415\n",
            "Train epoch: 224 [700000/25046 (89%)]\tLoss: 0.799768\n",
            "Train epoch: 224 [720720/25046 (92%)]\tLoss: 0.307004\n",
            "Train epoch: 224 [733340/25046 (95%)]\tLoss: 1.833217\n",
            "Train epoch: 224 [816240/25046 (97%)]\tLoss: 0.682234\n",
            "Train epoch: 224 [790920/25046 (100%)]\tLoss: 0.661181\n",
            "Make prediction for 5010 samples...\n",
            "0.8015776 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 225 [0/25046 (0%)]\tLoss: 1.186884\n",
            "Train epoch: 225 [19820/25046 (3%)]\tLoss: 1.194313\n",
            "Train epoch: 225 [44240/25046 (5%)]\tLoss: 1.047591\n",
            "Train epoch: 225 [62100/25046 (8%)]\tLoss: 0.429653\n",
            "Train epoch: 225 [85760/25046 (10%)]\tLoss: 0.659458\n",
            "Train epoch: 225 [105300/25046 (13%)]\tLoss: 0.642668\n",
            "Train epoch: 225 [116640/25046 (15%)]\tLoss: 0.423986\n",
            "Train epoch: 225 [149100/25046 (18%)]\tLoss: 1.372140\n",
            "Train epoch: 225 [162240/25046 (20%)]\tLoss: 0.573224\n",
            "Train epoch: 225 [192060/25046 (23%)]\tLoss: 0.574672\n",
            "Train epoch: 225 [198200/25046 (26%)]\tLoss: 0.583247\n",
            "Train epoch: 225 [218460/25046 (28%)]\tLoss: 0.244789\n",
            "Train epoch: 225 [242880/25046 (31%)]\tLoss: 1.054868\n",
            "Train epoch: 225 [260260/25046 (33%)]\tLoss: 0.617763\n",
            "Train epoch: 225 [279160/25046 (36%)]\tLoss: 1.357571\n",
            "Train epoch: 225 [316200/25046 (38%)]\tLoss: 0.877482\n",
            "Train epoch: 225 [321280/25046 (41%)]\tLoss: 0.650154\n",
            "Train epoch: 225 [374000/25046 (43%)]\tLoss: 0.404036\n",
            "Train epoch: 225 [358200/25046 (46%)]\tLoss: 0.991814\n",
            "Train epoch: 225 [399760/25046 (49%)]\tLoss: 1.078787\n",
            "Train epoch: 225 [401600/25046 (51%)]\tLoss: 1.014734\n",
            "Train epoch: 225 [420000/25046 (54%)]\tLoss: 0.523372\n",
            "Train epoch: 225 [467280/25046 (56%)]\tLoss: 0.555493\n",
            "Train epoch: 225 [454480/25046 (59%)]\tLoss: 0.811789\n",
            "Train epoch: 225 [464160/25046 (61%)]\tLoss: 0.479672\n",
            "Train epoch: 225 [484500/25046 (64%)]\tLoss: 0.289023\n",
            "Train epoch: 225 [553280/25046 (66%)]\tLoss: 0.988812\n",
            "Train epoch: 225 [544860/25046 (69%)]\tLoss: 0.437250\n",
            "Train epoch: 225 [586320/25046 (72%)]\tLoss: 1.284791\n",
            "Train epoch: 225 [620020/25046 (74%)]\tLoss: 0.764664\n",
            "Train epoch: 225 [583800/25046 (77%)]\tLoss: 0.792762\n",
            "Train epoch: 225 [654100/25046 (79%)]\tLoss: 0.354173\n",
            "Train epoch: 225 [677120/25046 (82%)]\tLoss: 0.858590\n",
            "Train epoch: 225 [708180/25046 (84%)]\tLoss: 0.357763\n",
            "Train epoch: 225 [660960/25046 (87%)]\tLoss: 0.766194\n",
            "Train epoch: 225 [751100/25046 (89%)]\tLoss: 1.002685\n",
            "Train epoch: 225 [707760/25046 (92%)]\tLoss: 0.672028\n",
            "Train epoch: 225 [743700/25046 (95%)]\tLoss: 1.449693\n",
            "Train epoch: 225 [794200/25046 (97%)]\tLoss: 0.552360\n",
            "Train epoch: 225 [830700/25046 (100%)]\tLoss: 0.412012\n",
            "Make prediction for 5010 samples...\n",
            "0.801849 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 226 [0/25046 (0%)]\tLoss: 0.876632\n",
            "Train epoch: 226 [20060/25046 (3%)]\tLoss: 0.453430\n",
            "Train epoch: 226 [40680/25046 (5%)]\tLoss: 0.599129\n",
            "Train epoch: 226 [58680/25046 (8%)]\tLoss: 0.439143\n",
            "Train epoch: 226 [82800/25046 (10%)]\tLoss: 0.866582\n",
            "Train epoch: 226 [96900/25046 (13%)]\tLoss: 0.467717\n",
            "Train epoch: 226 [123720/25046 (15%)]\tLoss: 0.845135\n",
            "Train epoch: 226 [144620/25046 (18%)]\tLoss: 0.694235\n",
            "Train epoch: 226 [165920/25046 (20%)]\tLoss: 1.004894\n",
            "Train epoch: 226 [177480/25046 (23%)]\tLoss: 0.613229\n",
            "Train epoch: 226 [195000/25046 (26%)]\tLoss: 0.822575\n",
            "Train epoch: 226 [218240/25046 (28%)]\tLoss: 0.629374\n",
            "Train epoch: 226 [239760/25046 (31%)]\tLoss: 0.447417\n",
            "Train epoch: 226 [263640/25046 (33%)]\tLoss: 1.294289\n",
            "Train epoch: 226 [290920/25046 (36%)]\tLoss: 0.486217\n",
            "Train epoch: 226 [301200/25046 (38%)]\tLoss: 0.679840\n",
            "Train epoch: 226 [326400/25046 (41%)]\tLoss: 0.678147\n",
            "Train epoch: 226 [331160/25046 (43%)]\tLoss: 0.633132\n",
            "Train epoch: 226 [363960/25046 (46%)]\tLoss: 0.736771\n",
            "Train epoch: 226 [374680/25046 (49%)]\tLoss: 0.764018\n",
            "Train epoch: 226 [402000/25046 (51%)]\tLoss: 0.922938\n",
            "Train epoch: 226 [441000/25046 (54%)]\tLoss: 1.188632\n",
            "Train epoch: 226 [454080/25046 (56%)]\tLoss: 0.905549\n",
            "Train epoch: 226 [487140/25046 (59%)]\tLoss: 0.352344\n",
            "Train epoch: 226 [454080/25046 (61%)]\tLoss: 0.655941\n",
            "Train epoch: 226 [496000/25046 (64%)]\tLoss: 0.650725\n",
            "Train epoch: 226 [494520/25046 (66%)]\tLoss: 0.441640\n",
            "Train epoch: 226 [541080/25046 (69%)]\tLoss: 0.797969\n",
            "Train epoch: 226 [558880/25046 (72%)]\tLoss: 1.103058\n",
            "Train epoch: 226 [570720/25046 (74%)]\tLoss: 0.427501\n",
            "Train epoch: 226 [641400/25046 (77%)]\tLoss: 0.375054\n",
            "Train epoch: 226 [633640/25046 (79%)]\tLoss: 0.912392\n",
            "Train epoch: 226 [679040/25046 (82%)]\tLoss: 0.758387\n",
            "Train epoch: 226 [649440/25046 (84%)]\tLoss: 0.441663\n",
            "Train epoch: 226 [709920/25046 (87%)]\tLoss: 0.865432\n",
            "Train epoch: 226 [681800/25046 (89%)]\tLoss: 0.635738\n",
            "Train epoch: 226 [761040/25046 (92%)]\tLoss: 0.392743\n",
            "Train epoch: 226 [756280/25046 (95%)]\tLoss: 0.410981\n",
            "Train epoch: 226 [774440/25046 (97%)]\tLoss: 0.860764\n",
            "Train epoch: 226 [763620/25046 (100%)]\tLoss: 1.437182\n",
            "Make prediction for 5010 samples...\n",
            "0.8052527 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 227 [0/25046 (0%)]\tLoss: 1.215455\n",
            "Train epoch: 227 [20120/25046 (3%)]\tLoss: 1.096174\n",
            "Train epoch: 227 [39560/25046 (5%)]\tLoss: 0.299151\n",
            "Train epoch: 227 [59520/25046 (8%)]\tLoss: 0.720174\n",
            "Train epoch: 227 [82400/25046 (10%)]\tLoss: 1.265141\n",
            "Train epoch: 227 [99300/25046 (13%)]\tLoss: 0.824202\n",
            "Train epoch: 227 [126960/25046 (15%)]\tLoss: 0.430573\n",
            "Train epoch: 227 [143780/25046 (18%)]\tLoss: 0.829775\n",
            "Train epoch: 227 [163520/25046 (20%)]\tLoss: 0.971993\n",
            "Train epoch: 227 [170640/25046 (23%)]\tLoss: 0.144749\n",
            "Train epoch: 227 [190000/25046 (26%)]\tLoss: 0.268861\n",
            "Train epoch: 227 [226600/25046 (28%)]\tLoss: 0.839585\n",
            "Train epoch: 227 [250320/25046 (31%)]\tLoss: 0.769801\n",
            "Train epoch: 227 [274040/25046 (33%)]\tLoss: 0.693935\n",
            "Train epoch: 227 [272160/25046 (36%)]\tLoss: 1.049963\n",
            "Train epoch: 227 [294300/25046 (38%)]\tLoss: 1.510873\n",
            "Train epoch: 227 [328960/25046 (41%)]\tLoss: 0.562667\n",
            "Train epoch: 227 [349520/25046 (43%)]\tLoss: 0.959279\n",
            "Train epoch: 227 [361440/25046 (46%)]\tLoss: 1.377049\n",
            "Train epoch: 227 [372780/25046 (49%)]\tLoss: 0.660335\n",
            "Train epoch: 227 [414400/25046 (51%)]\tLoss: 0.671822\n",
            "Train epoch: 227 [450660/25046 (54%)]\tLoss: 0.542149\n",
            "Train epoch: 227 [450120/25046 (56%)]\tLoss: 0.333988\n",
            "Train epoch: 227 [457240/25046 (59%)]\tLoss: 0.839342\n",
            "Train epoch: 227 [499200/25046 (61%)]\tLoss: 0.652369\n",
            "Train epoch: 227 [500000/25046 (64%)]\tLoss: 0.249246\n",
            "Train epoch: 227 [539760/25046 (66%)]\tLoss: 1.118324\n",
            "Train epoch: 227 [540540/25046 (69%)]\tLoss: 0.940395\n",
            "Train epoch: 227 [569520/25046 (72%)]\tLoss: 0.796800\n",
            "Train epoch: 227 [599720/25046 (74%)]\tLoss: 1.035501\n",
            "Train epoch: 227 [619800/25046 (77%)]\tLoss: 0.563678\n",
            "Train epoch: 227 [618140/25046 (79%)]\tLoss: 0.543626\n",
            "Train epoch: 227 [625280/25046 (82%)]\tLoss: 0.425336\n",
            "Train epoch: 227 [701580/25046 (84%)]\tLoss: 0.657502\n",
            "Train epoch: 227 [705840/25046 (87%)]\tLoss: 0.503541\n",
            "Train epoch: 227 [703500/25046 (89%)]\tLoss: 0.512393\n",
            "Train epoch: 227 [763920/25046 (92%)]\tLoss: 0.923407\n",
            "Train epoch: 227 [759980/25046 (95%)]\tLoss: 0.529086\n",
            "Train epoch: 227 [793440/25046 (97%)]\tLoss: 0.748927\n",
            "Train epoch: 227 [836160/25046 (100%)]\tLoss: 0.300492\n",
            "Make prediction for 5010 samples...\n",
            "0.80728716 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 228 [0/25046 (0%)]\tLoss: 0.861863\n",
            "Train epoch: 228 [21560/25046 (3%)]\tLoss: 0.851542\n",
            "Train epoch: 228 [42240/25046 (5%)]\tLoss: 0.216531\n",
            "Train epoch: 228 [61440/25046 (8%)]\tLoss: 1.342587\n",
            "Train epoch: 228 [83760/25046 (10%)]\tLoss: 0.668242\n",
            "Train epoch: 228 [106900/25046 (13%)]\tLoss: 0.720620\n",
            "Train epoch: 228 [121800/25046 (15%)]\tLoss: 0.777772\n",
            "Train epoch: 228 [137200/25046 (18%)]\tLoss: 0.435919\n",
            "Train epoch: 228 [160320/25046 (20%)]\tLoss: 0.514660\n",
            "Train epoch: 228 [192060/25046 (23%)]\tLoss: 0.896230\n",
            "Train epoch: 228 [201400/25046 (26%)]\tLoss: 0.448733\n",
            "Train epoch: 228 [231220/25046 (28%)]\tLoss: 0.542096\n",
            "Train epoch: 228 [241680/25046 (31%)]\tLoss: 0.833666\n",
            "Train epoch: 228 [277940/25046 (33%)]\tLoss: 2.283546\n",
            "Train epoch: 228 [284200/25046 (36%)]\tLoss: 1.348140\n",
            "Train epoch: 228 [327900/25046 (38%)]\tLoss: 0.605526\n",
            "Train epoch: 228 [332480/25046 (41%)]\tLoss: 0.853853\n",
            "Train epoch: 228 [349860/25046 (43%)]\tLoss: 0.999057\n",
            "Train epoch: 228 [376560/25046 (46%)]\tLoss: 0.755504\n",
            "Train epoch: 228 [397860/25046 (49%)]\tLoss: 0.440041\n",
            "Train epoch: 228 [419600/25046 (51%)]\tLoss: 1.343451\n",
            "Train epoch: 228 [450240/25046 (54%)]\tLoss: 0.807991\n",
            "Train epoch: 228 [429440/25046 (56%)]\tLoss: 0.560544\n",
            "Train epoch: 228 [512900/25046 (59%)]\tLoss: 1.195839\n",
            "Train epoch: 228 [511200/25046 (61%)]\tLoss: 0.623115\n",
            "Train epoch: 228 [525000/25046 (64%)]\tLoss: 0.703191\n",
            "Train epoch: 228 [544960/25046 (66%)]\tLoss: 1.272071\n",
            "Train epoch: 228 [584820/25046 (69%)]\tLoss: 0.613458\n",
            "Train epoch: 228 [575120/25046 (72%)]\tLoss: 0.819353\n",
            "Train epoch: 228 [579420/25046 (74%)]\tLoss: 0.712229\n",
            "Train epoch: 228 [628800/25046 (77%)]\tLoss: 1.734682\n",
            "Train epoch: 228 [646040/25046 (79%)]\tLoss: 0.837429\n",
            "Train epoch: 228 [608000/25046 (82%)]\tLoss: 0.474023\n",
            "Train epoch: 228 [657360/25046 (84%)]\tLoss: 1.221838\n",
            "Train epoch: 228 [698360/25046 (87%)]\tLoss: 0.861511\n",
            "Train epoch: 228 [679000/25046 (89%)]\tLoss: 0.572828\n",
            "Train epoch: 228 [733680/25046 (92%)]\tLoss: 1.098293\n",
            "Train epoch: 228 [760720/25046 (95%)]\tLoss: 0.691910\n",
            "Train epoch: 228 [758480/25046 (97%)]\tLoss: 0.672174\n",
            "Train epoch: 228 [786240/25046 (100%)]\tLoss: 1.338015\n",
            "Make prediction for 5010 samples...\n",
            "0.80443853 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 229 [0/25046 (0%)]\tLoss: 0.858331\n",
            "Train epoch: 229 [19820/25046 (3%)]\tLoss: 0.590504\n",
            "Train epoch: 229 [38440/25046 (5%)]\tLoss: 0.413876\n",
            "Train epoch: 229 [61320/25046 (8%)]\tLoss: 0.553690\n",
            "Train epoch: 229 [82480/25046 (10%)]\tLoss: 0.700806\n",
            "Train epoch: 229 [102100/25046 (13%)]\tLoss: 0.772027\n",
            "Train epoch: 229 [125880/25046 (15%)]\tLoss: 0.741639\n",
            "Train epoch: 229 [146300/25046 (18%)]\tLoss: 0.380064\n",
            "Train epoch: 229 [169760/25046 (20%)]\tLoss: 0.886034\n",
            "Train epoch: 229 [189900/25046 (23%)]\tLoss: 1.072583\n",
            "Train epoch: 229 [201200/25046 (26%)]\tLoss: 0.394993\n",
            "Train epoch: 229 [231220/25046 (28%)]\tLoss: 0.635068\n",
            "Train epoch: 229 [240720/25046 (31%)]\tLoss: 0.899452\n",
            "Train epoch: 229 [261300/25046 (33%)]\tLoss: 0.549715\n",
            "Train epoch: 229 [292600/25046 (36%)]\tLoss: 0.505097\n",
            "Train epoch: 229 [291600/25046 (38%)]\tLoss: 0.484579\n",
            "Train epoch: 229 [325120/25046 (41%)]\tLoss: 1.061041\n",
            "Train epoch: 229 [353600/25046 (43%)]\tLoss: 1.127701\n",
            "Train epoch: 229 [356760/25046 (46%)]\tLoss: 0.432003\n",
            "Train epoch: 229 [381140/25046 (49%)]\tLoss: 0.891452\n",
            "Train epoch: 229 [403600/25046 (51%)]\tLoss: 1.762150\n",
            "Train epoch: 229 [431760/25046 (54%)]\tLoss: 0.350205\n",
            "Train epoch: 229 [421960/25046 (56%)]\tLoss: 0.360465\n",
            "Train epoch: 229 [447580/25046 (59%)]\tLoss: 0.867064\n",
            "Train epoch: 229 [477120/25046 (61%)]\tLoss: 0.617145\n",
            "Train epoch: 229 [500000/25046 (64%)]\tLoss: 0.488578\n",
            "Train epoch: 229 [549120/25046 (66%)]\tLoss: 0.238817\n",
            "Train epoch: 229 [567540/25046 (69%)]\tLoss: 0.610570\n",
            "Train epoch: 229 [571200/25046 (72%)]\tLoss: 1.065703\n",
            "Train epoch: 229 [610160/25046 (74%)]\tLoss: 0.491539\n",
            "Train epoch: 229 [607200/25046 (77%)]\tLoss: 1.489581\n",
            "Train epoch: 229 [704320/25046 (79%)]\tLoss: 0.961996\n",
            "Train epoch: 229 [661120/25046 (82%)]\tLoss: 0.724772\n",
            "Train epoch: 229 [683100/25046 (84%)]\tLoss: 0.655778\n",
            "Train epoch: 229 [703800/25046 (87%)]\tLoss: 1.477429\n",
            "Train epoch: 229 [718200/25046 (89%)]\tLoss: 1.164881\n",
            "Train epoch: 229 [758160/25046 (92%)]\tLoss: 0.639732\n",
            "Train epoch: 229 [797720/25046 (95%)]\tLoss: 1.496977\n",
            "Train epoch: 229 [764560/25046 (97%)]\tLoss: 1.265062\n",
            "Train epoch: 229 [788580/25046 (100%)]\tLoss: 0.760578\n",
            "Make prediction for 5010 samples...\n",
            "0.8016176 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 230 [0/25046 (0%)]\tLoss: 2.317859\n",
            "Train epoch: 230 [20220/25046 (3%)]\tLoss: 1.024829\n",
            "Train epoch: 230 [43160/25046 (5%)]\tLoss: 0.508957\n",
            "Train epoch: 230 [60180/25046 (8%)]\tLoss: 0.304911\n",
            "Train epoch: 230 [80720/25046 (10%)]\tLoss: 0.402706\n",
            "Train epoch: 230 [104500/25046 (13%)]\tLoss: 0.772205\n",
            "Train epoch: 230 [123720/25046 (15%)]\tLoss: 0.464277\n",
            "Train epoch: 230 [141540/25046 (18%)]\tLoss: 0.775223\n",
            "Train epoch: 230 [161600/25046 (20%)]\tLoss: 0.511476\n",
            "Train epoch: 230 [176220/25046 (23%)]\tLoss: 0.810669\n",
            "Train epoch: 230 [212200/25046 (26%)]\tLoss: 0.795009\n",
            "Train epoch: 230 [232980/25046 (28%)]\tLoss: 0.461852\n",
            "Train epoch: 230 [245280/25046 (31%)]\tLoss: 0.609184\n",
            "Train epoch: 230 [262860/25046 (33%)]\tLoss: 1.092028\n",
            "Train epoch: 230 [289520/25046 (36%)]\tLoss: 1.371526\n",
            "Train epoch: 230 [308100/25046 (38%)]\tLoss: 0.533350\n",
            "Train epoch: 230 [311360/25046 (41%)]\tLoss: 0.375550\n",
            "Train epoch: 230 [330480/25046 (43%)]\tLoss: 0.314671\n",
            "Train epoch: 230 [384120/25046 (46%)]\tLoss: 0.721067\n",
            "Train epoch: 230 [381900/25046 (49%)]\tLoss: 0.914373\n",
            "Train epoch: 230 [408800/25046 (51%)]\tLoss: 0.642697\n",
            "Train epoch: 230 [422940/25046 (54%)]\tLoss: 0.590656\n",
            "Train epoch: 230 [448800/25046 (56%)]\tLoss: 0.541645\n",
            "Train epoch: 230 [487140/25046 (59%)]\tLoss: 0.860986\n",
            "Train epoch: 230 [480000/25046 (61%)]\tLoss: 1.089561\n",
            "Train epoch: 230 [529500/25046 (64%)]\tLoss: 0.509652\n",
            "Train epoch: 230 [524160/25046 (66%)]\tLoss: 1.325839\n",
            "Train epoch: 230 [515700/25046 (69%)]\tLoss: 0.440581\n",
            "Train epoch: 230 [583520/25046 (72%)]\tLoss: 1.086762\n",
            "Train epoch: 230 [592180/25046 (74%)]\tLoss: 0.517156\n",
            "Train epoch: 230 [585000/25046 (77%)]\tLoss: 0.259919\n",
            "Train epoch: 230 [634260/25046 (79%)]\tLoss: 0.747003\n",
            "Train epoch: 230 [645120/25046 (82%)]\tLoss: 0.449983\n",
            "Train epoch: 230 [654720/25046 (84%)]\tLoss: 0.458611\n",
            "Train epoch: 230 [691560/25046 (87%)]\tLoss: 0.751952\n",
            "Train epoch: 230 [704200/25046 (89%)]\tLoss: 0.398320\n",
            "Train epoch: 230 [733680/25046 (92%)]\tLoss: 0.720838\n",
            "Train epoch: 230 [762940/25046 (95%)]\tLoss: 0.608647\n",
            "Train epoch: 230 [784320/25046 (97%)]\tLoss: 1.010615\n",
            "Train epoch: 230 [801840/25046 (100%)]\tLoss: 0.990594\n",
            "Make prediction for 5010 samples...\n",
            "0.8015191 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 231 [0/25046 (0%)]\tLoss: 0.567795\n",
            "Train epoch: 231 [20800/25046 (3%)]\tLoss: 0.585282\n",
            "Train epoch: 231 [41200/25046 (5%)]\tLoss: 0.948815\n",
            "Train epoch: 231 [59220/25046 (8%)]\tLoss: 0.641956\n",
            "Train epoch: 231 [80560/25046 (10%)]\tLoss: 0.794500\n",
            "Train epoch: 231 [101200/25046 (13%)]\tLoss: 1.194936\n",
            "Train epoch: 231 [119160/25046 (15%)]\tLoss: 0.256298\n",
            "Train epoch: 231 [145320/25046 (18%)]\tLoss: 0.578140\n",
            "Train epoch: 231 [172000/25046 (20%)]\tLoss: 0.834010\n",
            "Train epoch: 231 [186300/25046 (23%)]\tLoss: 1.376200\n",
            "Train epoch: 231 [204000/25046 (26%)]\tLoss: 0.791324\n",
            "Train epoch: 231 [238260/25046 (28%)]\tLoss: 0.911559\n",
            "Train epoch: 231 [254640/25046 (31%)]\tLoss: 0.606935\n",
            "Train epoch: 231 [279500/25046 (33%)]\tLoss: 0.542123\n",
            "Train epoch: 231 [279160/25046 (36%)]\tLoss: 0.398226\n",
            "Train epoch: 231 [302400/25046 (38%)]\tLoss: 1.206726\n",
            "Train epoch: 231 [318720/25046 (41%)]\tLoss: 0.308675\n",
            "Train epoch: 231 [355980/25046 (43%)]\tLoss: 0.483398\n",
            "Train epoch: 231 [382680/25046 (46%)]\tLoss: 0.891961\n",
            "Train epoch: 231 [410020/25046 (49%)]\tLoss: 1.789631\n",
            "Train epoch: 231 [391200/25046 (51%)]\tLoss: 0.445408\n",
            "Train epoch: 231 [444360/25046 (54%)]\tLoss: 1.097009\n",
            "Train epoch: 231 [437360/25046 (56%)]\tLoss: 0.831885\n",
            "Train epoch: 231 [481160/25046 (59%)]\tLoss: 0.671879\n",
            "Train epoch: 231 [467040/25046 (61%)]\tLoss: 1.289835\n",
            "Train epoch: 231 [500000/25046 (64%)]\tLoss: 0.715461\n",
            "Train epoch: 231 [563160/25046 (66%)]\tLoss: 0.381346\n",
            "Train epoch: 231 [550260/25046 (69%)]\tLoss: 1.205965\n",
            "Train epoch: 231 [600880/25046 (72%)]\tLoss: 0.460415\n",
            "Train epoch: 231 [585220/25046 (74%)]\tLoss: 1.091337\n",
            "Train epoch: 231 [627600/25046 (77%)]\tLoss: 1.309833\n",
            "Train epoch: 231 [638600/25046 (79%)]\tLoss: 0.713104\n",
            "Train epoch: 231 [697600/25046 (82%)]\tLoss: 0.990632\n",
            "Train epoch: 231 [700920/25046 (84%)]\tLoss: 0.670089\n",
            "Train epoch: 231 [688840/25046 (87%)]\tLoss: 0.315724\n",
            "Train epoch: 231 [693700/25046 (89%)]\tLoss: 1.129046\n",
            "Train epoch: 231 [763200/25046 (92%)]\tLoss: 0.370085\n",
            "Train epoch: 231 [788100/25046 (95%)]\tLoss: 1.184981\n",
            "Train epoch: 231 [794960/25046 (97%)]\tLoss: 0.581109\n",
            "Train epoch: 231 [777660/25046 (100%)]\tLoss: 0.747919\n",
            "Make prediction for 5010 samples...\n",
            "0.8018576 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 232 [0/25046 (0%)]\tLoss: 0.698176\n",
            "Train epoch: 232 [19760/25046 (3%)]\tLoss: 0.427009\n",
            "Train epoch: 232 [42160/25046 (5%)]\tLoss: 1.420029\n",
            "Train epoch: 232 [62460/25046 (8%)]\tLoss: 1.754158\n",
            "Train epoch: 232 [83440/25046 (10%)]\tLoss: 0.328869\n",
            "Train epoch: 232 [106600/25046 (13%)]\tLoss: 0.784363\n",
            "Train epoch: 232 [118800/25046 (15%)]\tLoss: 0.394893\n",
            "Train epoch: 232 [136080/25046 (18%)]\tLoss: 0.408357\n",
            "Train epoch: 232 [166720/25046 (20%)]\tLoss: 0.837656\n",
            "Train epoch: 232 [186840/25046 (23%)]\tLoss: 0.513975\n",
            "Train epoch: 232 [206000/25046 (26%)]\tLoss: 1.160285\n",
            "Train epoch: 232 [231660/25046 (28%)]\tLoss: 1.259142\n",
            "Train epoch: 232 [231840/25046 (31%)]\tLoss: 0.561966\n",
            "Train epoch: 232 [262340/25046 (33%)]\tLoss: 1.135710\n",
            "Train epoch: 232 [277760/25046 (36%)]\tLoss: 0.756589\n",
            "Train epoch: 232 [299400/25046 (38%)]\tLoss: 0.596624\n",
            "Train epoch: 232 [324480/25046 (41%)]\tLoss: 0.561906\n",
            "Train epoch: 232 [350200/25046 (43%)]\tLoss: 0.467745\n",
            "Train epoch: 232 [379080/25046 (46%)]\tLoss: 0.530988\n",
            "Train epoch: 232 [405840/25046 (49%)]\tLoss: 0.543147\n",
            "Train epoch: 232 [433600/25046 (51%)]\tLoss: 0.560252\n",
            "Train epoch: 232 [415800/25046 (54%)]\tLoss: 0.685678\n",
            "Train epoch: 232 [421080/25046 (56%)]\tLoss: 0.773244\n",
            "Train epoch: 232 [470120/25046 (59%)]\tLoss: 0.420362\n",
            "Train epoch: 232 [464640/25046 (61%)]\tLoss: 1.381118\n",
            "Train epoch: 232 [517500/25046 (64%)]\tLoss: 1.664976\n",
            "Train epoch: 232 [536640/25046 (66%)]\tLoss: 0.329063\n",
            "Train epoch: 232 [546480/25046 (69%)]\tLoss: 1.579468\n",
            "Train epoch: 232 [582400/25046 (72%)]\tLoss: 0.734264\n",
            "Train epoch: 232 [626980/25046 (74%)]\tLoss: 1.266119\n",
            "Train epoch: 232 [625200/25046 (77%)]\tLoss: 0.377167\n",
            "Train epoch: 232 [655340/25046 (79%)]\tLoss: 0.660147\n",
            "Train epoch: 232 [623360/25046 (82%)]\tLoss: 0.379098\n",
            "Train epoch: 232 [626340/25046 (84%)]\tLoss: 0.268631\n",
            "Train epoch: 232 [685440/25046 (87%)]\tLoss: 0.999830\n",
            "Train epoch: 232 [751100/25046 (89%)]\tLoss: 1.472757\n",
            "Train epoch: 232 [784080/25046 (92%)]\tLoss: 0.998058\n",
            "Train epoch: 232 [757020/25046 (95%)]\tLoss: 0.531532\n",
            "Train epoch: 232 [787360/25046 (97%)]\tLoss: 0.693625\n",
            "Train epoch: 232 [819000/25046 (100%)]\tLoss: 0.686598\n",
            "Make prediction for 5010 samples...\n",
            "0.8027962 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 233 [0/25046 (0%)]\tLoss: 0.343274\n",
            "Train epoch: 233 [20980/25046 (3%)]\tLoss: 1.330843\n",
            "Train epoch: 233 [39680/25046 (5%)]\tLoss: 0.702324\n",
            "Train epoch: 233 [61920/25046 (8%)]\tLoss: 0.534935\n",
            "Train epoch: 233 [85040/25046 (10%)]\tLoss: 0.364566\n",
            "Train epoch: 233 [105800/25046 (13%)]\tLoss: 1.048466\n",
            "Train epoch: 233 [127080/25046 (15%)]\tLoss: 0.543261\n",
            "Train epoch: 233 [150360/25046 (18%)]\tLoss: 0.377130\n",
            "Train epoch: 233 [166560/25046 (20%)]\tLoss: 0.540153\n",
            "Train epoch: 233 [180000/25046 (23%)]\tLoss: 0.918866\n",
            "Train epoch: 233 [198000/25046 (26%)]\tLoss: 0.316102\n",
            "Train epoch: 233 [213840/25046 (28%)]\tLoss: 0.505574\n",
            "Train epoch: 233 [237840/25046 (31%)]\tLoss: 0.959526\n",
            "Train epoch: 233 [266760/25046 (33%)]\tLoss: 0.804462\n",
            "Train epoch: 233 [284200/25046 (36%)]\tLoss: 0.266176\n",
            "Train epoch: 233 [314100/25046 (38%)]\tLoss: 0.696042\n",
            "Train epoch: 233 [309120/25046 (41%)]\tLoss: 0.793821\n",
            "Train epoch: 233 [356660/25046 (43%)]\tLoss: 0.516008\n",
            "Train epoch: 233 [374760/25046 (46%)]\tLoss: 0.605883\n",
            "Train epoch: 233 [387980/25046 (49%)]\tLoss: 1.568850\n",
            "Train epoch: 233 [376400/25046 (51%)]\tLoss: 0.321733\n",
            "Train epoch: 233 [452340/25046 (54%)]\tLoss: 1.023011\n",
            "Train epoch: 233 [451880/25046 (56%)]\tLoss: 0.529195\n",
            "Train epoch: 233 [494500/25046 (59%)]\tLoss: 0.848697\n",
            "Train epoch: 233 [488640/25046 (61%)]\tLoss: 1.815873\n",
            "Train epoch: 233 [529500/25046 (64%)]\tLoss: 0.528273\n",
            "Train epoch: 233 [500240/25046 (66%)]\tLoss: 1.137359\n",
            "Train epoch: 233 [548100/25046 (69%)]\tLoss: 1.033614\n",
            "Train epoch: 233 [561680/25046 (72%)]\tLoss: 0.299105\n",
            "Train epoch: 233 [630460/25046 (74%)]\tLoss: 0.321038\n",
            "Train epoch: 233 [610200/25046 (77%)]\tLoss: 0.745735\n",
            "Train epoch: 233 [633640/25046 (79%)]\tLoss: 0.316120\n",
            "Train epoch: 233 [657920/25046 (82%)]\tLoss: 0.654786\n",
            "Train epoch: 233 [673200/25046 (84%)]\tLoss: 0.961168\n",
            "Train epoch: 233 [690200/25046 (87%)]\tLoss: 0.573662\n",
            "Train epoch: 233 [704200/25046 (89%)]\tLoss: 0.636186\n",
            "Train epoch: 233 [709200/25046 (92%)]\tLoss: 0.341045\n",
            "Train epoch: 233 [757760/25046 (95%)]\tLoss: 0.843684\n",
            "Train epoch: 233 [794960/25046 (97%)]\tLoss: 1.735676\n",
            "Train epoch: 233 [775320/25046 (100%)]\tLoss: 1.084375\n",
            "Make prediction for 5010 samples...\n",
            "0.80154127 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 234 [0/25046 (0%)]\tLoss: 0.784882\n",
            "Train epoch: 234 [20780/25046 (3%)]\tLoss: 0.719591\n",
            "Train epoch: 234 [43400/25046 (5%)]\tLoss: 0.846847\n",
            "Train epoch: 234 [62460/25046 (8%)]\tLoss: 0.841761\n",
            "Train epoch: 234 [78880/25046 (10%)]\tLoss: 0.432048\n",
            "Train epoch: 234 [99100/25046 (13%)]\tLoss: 1.016118\n",
            "Train epoch: 234 [120000/25046 (15%)]\tLoss: 1.128726\n",
            "Train epoch: 234 [145600/25046 (18%)]\tLoss: 1.114618\n",
            "Train epoch: 234 [166240/25046 (20%)]\tLoss: 1.456526\n",
            "Train epoch: 234 [185220/25046 (23%)]\tLoss: 0.639775\n",
            "Train epoch: 234 [214200/25046 (26%)]\tLoss: 1.049260\n",
            "Train epoch: 234 [229240/25046 (28%)]\tLoss: 0.677300\n",
            "Train epoch: 234 [245520/25046 (31%)]\tLoss: 0.365668\n",
            "Train epoch: 234 [268580/25046 (33%)]\tLoss: 0.590171\n",
            "Train epoch: 234 [290640/25046 (36%)]\tLoss: 1.496997\n",
            "Train epoch: 234 [312000/25046 (38%)]\tLoss: 1.810196\n",
            "Train epoch: 234 [318080/25046 (41%)]\tLoss: 0.992249\n",
            "Train epoch: 234 [343400/25046 (43%)]\tLoss: 1.754598\n",
            "Train epoch: 234 [384480/25046 (46%)]\tLoss: 0.849312\n",
            "Train epoch: 234 [386460/25046 (49%)]\tLoss: 0.642979\n",
            "Train epoch: 234 [388400/25046 (51%)]\tLoss: 0.514081\n",
            "Train epoch: 234 [447720/25046 (54%)]\tLoss: 0.552357\n",
            "Train epoch: 234 [465520/25046 (56%)]\tLoss: 0.279507\n",
            "Train epoch: 234 [483460/25046 (59%)]\tLoss: 1.446142\n",
            "Train epoch: 234 [482400/25046 (61%)]\tLoss: 1.031045\n",
            "Train epoch: 234 [509500/25046 (64%)]\tLoss: 0.367586\n",
            "Train epoch: 234 [534040/25046 (66%)]\tLoss: 0.842918\n",
            "Train epoch: 234 [549720/25046 (69%)]\tLoss: 0.484897\n",
            "Train epoch: 234 [551040/25046 (72%)]\tLoss: 0.414939\n",
            "Train epoch: 234 [586380/25046 (74%)]\tLoss: 0.390304\n",
            "Train epoch: 234 [595200/25046 (77%)]\tLoss: 0.755224\n",
            "Train epoch: 234 [652860/25046 (79%)]\tLoss: 1.267095\n",
            "Train epoch: 234 [659840/25046 (82%)]\tLoss: 0.492218\n",
            "Train epoch: 234 [667260/25046 (84%)]\tLoss: 0.429524\n",
            "Train epoch: 234 [687480/25046 (87%)]\tLoss: 1.425600\n",
            "Train epoch: 234 [706300/25046 (89%)]\tLoss: 0.885590\n",
            "Train epoch: 234 [737280/25046 (92%)]\tLoss: 0.493216\n",
            "Train epoch: 234 [742960/25046 (95%)]\tLoss: 0.625073\n",
            "Train epoch: 234 [773680/25046 (97%)]\tLoss: 1.038888\n",
            "Train epoch: 234 [780780/25046 (100%)]\tLoss: 1.367748\n",
            "Make prediction for 5010 samples...\n",
            "0.8020595 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 235 [0/25046 (0%)]\tLoss: 1.919288\n",
            "Train epoch: 235 [21160/25046 (3%)]\tLoss: 0.495896\n",
            "Train epoch: 235 [42000/25046 (5%)]\tLoss: 0.952907\n",
            "Train epoch: 235 [59880/25046 (8%)]\tLoss: 0.753915\n",
            "Train epoch: 235 [81600/25046 (10%)]\tLoss: 1.171756\n",
            "Train epoch: 235 [107400/25046 (13%)]\tLoss: 0.720845\n",
            "Train epoch: 235 [123240/25046 (15%)]\tLoss: 1.749663\n",
            "Train epoch: 235 [139160/25046 (18%)]\tLoss: 0.951482\n",
            "Train epoch: 235 [175200/25046 (20%)]\tLoss: 0.595052\n",
            "Train epoch: 235 [183780/25046 (23%)]\tLoss: 0.535981\n",
            "Train epoch: 235 [204200/25046 (26%)]\tLoss: 0.882018\n",
            "Train epoch: 235 [231000/25046 (28%)]\tLoss: 0.730017\n",
            "Train epoch: 235 [244080/25046 (31%)]\tLoss: 0.761735\n",
            "Train epoch: 235 [264940/25046 (33%)]\tLoss: 0.852284\n",
            "Train epoch: 235 [285040/25046 (36%)]\tLoss: 0.615975\n",
            "Train epoch: 235 [300300/25046 (38%)]\tLoss: 0.941269\n",
            "Train epoch: 235 [318720/25046 (41%)]\tLoss: 0.366475\n",
            "Train epoch: 235 [359380/25046 (43%)]\tLoss: 0.679850\n",
            "Train epoch: 235 [383400/25046 (46%)]\tLoss: 1.066684\n",
            "Train epoch: 235 [389500/25046 (49%)]\tLoss: 0.825921\n",
            "Train epoch: 235 [412000/25046 (51%)]\tLoss: 1.319921\n",
            "Train epoch: 235 [431340/25046 (54%)]\tLoss: 0.594450\n",
            "Train epoch: 235 [454520/25046 (56%)]\tLoss: 1.092743\n",
            "Train epoch: 235 [479780/25046 (59%)]\tLoss: 0.748259\n",
            "Train epoch: 235 [481920/25046 (61%)]\tLoss: 0.278522\n",
            "Train epoch: 235 [512000/25046 (64%)]\tLoss: 0.806331\n",
            "Train epoch: 235 [559000/25046 (66%)]\tLoss: 0.521314\n",
            "Train epoch: 235 [531360/25046 (69%)]\tLoss: 0.521610\n",
            "Train epoch: 235 [586320/25046 (72%)]\tLoss: 1.298559\n",
            "Train epoch: 235 [567240/25046 (74%)]\tLoss: 0.430505\n",
            "Train epoch: 235 [614400/25046 (77%)]\tLoss: 0.652360\n",
            "Train epoch: 235 [630540/25046 (79%)]\tLoss: 1.094002\n",
            "Train epoch: 235 [696960/25046 (82%)]\tLoss: 0.660396\n",
            "Train epoch: 235 [687060/25046 (84%)]\tLoss: 0.797563\n",
            "Train epoch: 235 [714680/25046 (87%)]\tLoss: 1.809627\n",
            "Train epoch: 235 [716100/25046 (89%)]\tLoss: 0.357374\n",
            "Train epoch: 235 [748080/25046 (92%)]\tLoss: 1.092449\n",
            "Train epoch: 235 [779960/25046 (95%)]\tLoss: 0.893608\n",
            "Train epoch: 235 [795720/25046 (97%)]\tLoss: 0.524751\n",
            "Train epoch: 235 [811200/25046 (100%)]\tLoss: 0.316154\n",
            "Make prediction for 5010 samples...\n",
            "0.8043887 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 236 [0/25046 (0%)]\tLoss: 0.803127\n",
            "Train epoch: 236 [20680/25046 (3%)]\tLoss: 0.578610\n",
            "Train epoch: 236 [37480/25046 (5%)]\tLoss: 0.225671\n",
            "Train epoch: 236 [60780/25046 (8%)]\tLoss: 0.474416\n",
            "Train epoch: 236 [83280/25046 (10%)]\tLoss: 0.951681\n",
            "Train epoch: 236 [97200/25046 (13%)]\tLoss: 1.212087\n",
            "Train epoch: 236 [121560/25046 (15%)]\tLoss: 0.603406\n",
            "Train epoch: 236 [139160/25046 (18%)]\tLoss: 0.231046\n",
            "Train epoch: 236 [160320/25046 (20%)]\tLoss: 1.055895\n",
            "Train epoch: 236 [203220/25046 (23%)]\tLoss: 0.813209\n",
            "Train epoch: 236 [210400/25046 (26%)]\tLoss: 0.351107\n",
            "Train epoch: 236 [231880/25046 (28%)]\tLoss: 0.859600\n",
            "Train epoch: 236 [254640/25046 (31%)]\tLoss: 0.954471\n",
            "Train epoch: 236 [270400/25046 (33%)]\tLoss: 1.041717\n",
            "Train epoch: 236 [295960/25046 (36%)]\tLoss: 1.054204\n",
            "Train epoch: 236 [294900/25046 (38%)]\tLoss: 0.646708\n",
            "Train epoch: 236 [339200/25046 (41%)]\tLoss: 0.556832\n",
            "Train epoch: 236 [357000/25046 (43%)]\tLoss: 1.447096\n",
            "Train epoch: 236 [365760/25046 (46%)]\tLoss: 0.369742\n",
            "Train epoch: 236 [399760/25046 (49%)]\tLoss: 0.718074\n",
            "Train epoch: 236 [407200/25046 (51%)]\tLoss: 1.316862\n",
            "Train epoch: 236 [455280/25046 (54%)]\tLoss: 0.401100\n",
            "Train epoch: 236 [438680/25046 (56%)]\tLoss: 0.645655\n",
            "Train epoch: 236 [458160/25046 (59%)]\tLoss: 0.562271\n",
            "Train epoch: 236 [504960/25046 (61%)]\tLoss: 1.309458\n",
            "Train epoch: 236 [481000/25046 (64%)]\tLoss: 0.316013\n",
            "Train epoch: 236 [537680/25046 (66%)]\tLoss: 0.273944\n",
            "Train epoch: 236 [541080/25046 (69%)]\tLoss: 0.941471\n",
            "Train epoch: 236 [557760/25046 (72%)]\tLoss: 0.414158\n",
            "Train epoch: 236 [604940/25046 (74%)]\tLoss: 0.771829\n",
            "Train epoch: 236 [606000/25046 (77%)]\tLoss: 1.511397\n",
            "Train epoch: 236 [621860/25046 (79%)]\tLoss: 0.426824\n",
            "Train epoch: 236 [662400/25046 (82%)]\tLoss: 1.238593\n",
            "Train epoch: 236 [681780/25046 (84%)]\tLoss: 1.473207\n",
            "Train epoch: 236 [694960/25046 (87%)]\tLoss: 1.044586\n",
            "Train epoch: 236 [696500/25046 (89%)]\tLoss: 1.513697\n",
            "Train epoch: 236 [739440/25046 (92%)]\tLoss: 0.362198\n",
            "Train epoch: 236 [749620/25046 (95%)]\tLoss: 0.493708\n",
            "Train epoch: 236 [813960/25046 (97%)]\tLoss: 0.795610\n",
            "Train epoch: 236 [769080/25046 (100%)]\tLoss: 0.723914\n",
            "Make prediction for 5010 samples...\n",
            "0.80586326 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 237 [0/25046 (0%)]\tLoss: 0.690056\n",
            "Train epoch: 237 [20460/25046 (3%)]\tLoss: 1.021958\n",
            "Train epoch: 237 [37920/25046 (5%)]\tLoss: 0.849239\n",
            "Train epoch: 237 [61020/25046 (8%)]\tLoss: 1.395176\n",
            "Train epoch: 237 [80080/25046 (10%)]\tLoss: 0.951259\n",
            "Train epoch: 237 [100700/25046 (13%)]\tLoss: 0.558359\n",
            "Train epoch: 237 [124800/25046 (15%)]\tLoss: 0.689940\n",
            "Train epoch: 237 [146440/25046 (18%)]\tLoss: 1.190963\n",
            "Train epoch: 237 [159520/25046 (20%)]\tLoss: 1.106876\n",
            "Train epoch: 237 [193680/25046 (23%)]\tLoss: 0.366458\n",
            "Train epoch: 237 [202200/25046 (26%)]\tLoss: 0.594994\n",
            "Train epoch: 237 [213400/25046 (28%)]\tLoss: 0.566197\n",
            "Train epoch: 237 [245520/25046 (31%)]\tLoss: 0.463455\n",
            "Train epoch: 237 [265720/25046 (33%)]\tLoss: 0.496543\n",
            "Train epoch: 237 [281400/25046 (36%)]\tLoss: 1.451357\n",
            "Train epoch: 237 [320100/25046 (38%)]\tLoss: 1.578711\n",
            "Train epoch: 237 [332160/25046 (41%)]\tLoss: 0.315095\n",
            "Train epoch: 237 [352240/25046 (43%)]\tLoss: 0.979131\n",
            "Train epoch: 237 [370800/25046 (46%)]\tLoss: 0.876750\n",
            "Train epoch: 237 [370500/25046 (49%)]\tLoss: 0.661690\n",
            "Train epoch: 237 [397200/25046 (51%)]\tLoss: 0.646072\n",
            "Train epoch: 237 [428820/25046 (54%)]\tLoss: 1.081551\n",
            "Train epoch: 237 [440440/25046 (56%)]\tLoss: 0.892796\n",
            "Train epoch: 237 [516580/25046 (59%)]\tLoss: 0.435026\n",
            "Train epoch: 237 [515040/25046 (61%)]\tLoss: 1.532637\n",
            "Train epoch: 237 [509500/25046 (64%)]\tLoss: 1.773382\n",
            "Train epoch: 237 [541320/25046 (66%)]\tLoss: 0.542835\n",
            "Train epoch: 237 [557820/25046 (69%)]\tLoss: 1.025127\n",
            "Train epoch: 237 [552160/25046 (72%)]\tLoss: 0.965600\n",
            "Train epoch: 237 [593340/25046 (74%)]\tLoss: 1.407343\n",
            "Train epoch: 237 [588600/25046 (77%)]\tLoss: 0.499140\n",
            "Train epoch: 237 [657200/25046 (79%)]\tLoss: 1.171903\n",
            "Train epoch: 237 [634880/25046 (82%)]\tLoss: 0.155109\n",
            "Train epoch: 237 [668580/25046 (84%)]\tLoss: 0.632942\n",
            "Train epoch: 237 [674560/25046 (87%)]\tLoss: 0.214103\n",
            "Train epoch: 237 [745500/25046 (89%)]\tLoss: 1.072534\n",
            "Train epoch: 237 [776880/25046 (92%)]\tLoss: 0.564613\n",
            "Train epoch: 237 [823620/25046 (95%)]\tLoss: 0.706127\n",
            "Train epoch: 237 [792680/25046 (97%)]\tLoss: 0.982036\n",
            "Train epoch: 237 [834600/25046 (100%)]\tLoss: 0.691776\n",
            "Make prediction for 5010 samples...\n",
            "0.8017072 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 238 [0/25046 (0%)]\tLoss: 0.936877\n",
            "Train epoch: 238 [21120/25046 (3%)]\tLoss: 0.767257\n",
            "Train epoch: 238 [39640/25046 (5%)]\tLoss: 1.432019\n",
            "Train epoch: 238 [58080/25046 (8%)]\tLoss: 0.599881\n",
            "Train epoch: 238 [81920/25046 (10%)]\tLoss: 0.240697\n",
            "Train epoch: 238 [103300/25046 (13%)]\tLoss: 0.947722\n",
            "Train epoch: 238 [126120/25046 (15%)]\tLoss: 1.131364\n",
            "Train epoch: 238 [144480/25046 (18%)]\tLoss: 1.267104\n",
            "Train epoch: 238 [167040/25046 (20%)]\tLoss: 0.632106\n",
            "Train epoch: 238 [190620/25046 (23%)]\tLoss: 0.263703\n",
            "Train epoch: 238 [206000/25046 (26%)]\tLoss: 0.783942\n",
            "Train epoch: 238 [224840/25046 (28%)]\tLoss: 1.205050\n",
            "Train epoch: 238 [247680/25046 (31%)]\tLoss: 0.753780\n",
            "Train epoch: 238 [277680/25046 (33%)]\tLoss: 0.574064\n",
            "Train epoch: 238 [297920/25046 (36%)]\tLoss: 0.732328\n",
            "Train epoch: 238 [304200/25046 (38%)]\tLoss: 1.404807\n",
            "Train epoch: 238 [335040/25046 (41%)]\tLoss: 1.042796\n",
            "Train epoch: 238 [358360/25046 (43%)]\tLoss: 0.187752\n",
            "Train epoch: 238 [346680/25046 (46%)]\tLoss: 0.860571\n",
            "Train epoch: 238 [398620/25046 (49%)]\tLoss: 0.844010\n",
            "Train epoch: 238 [416800/25046 (51%)]\tLoss: 1.001803\n",
            "Train epoch: 238 [446040/25046 (54%)]\tLoss: 0.461919\n",
            "Train epoch: 238 [437360/25046 (56%)]\tLoss: 0.965120\n",
            "Train epoch: 238 [494960/25046 (59%)]\tLoss: 0.677146\n",
            "Train epoch: 238 [492000/25046 (61%)]\tLoss: 0.306639\n",
            "Train epoch: 238 [525000/25046 (64%)]\tLoss: 0.923432\n",
            "Train epoch: 238 [500760/25046 (66%)]\tLoss: 0.911318\n",
            "Train epoch: 238 [561060/25046 (69%)]\tLoss: 1.603229\n",
            "Train epoch: 238 [555520/25046 (72%)]\tLoss: 0.236351\n",
            "Train epoch: 238 [583480/25046 (74%)]\tLoss: 0.240334\n",
            "Train epoch: 238 [651000/25046 (77%)]\tLoss: 1.191492\n",
            "Train epoch: 238 [673940/25046 (79%)]\tLoss: 0.682880\n",
            "Train epoch: 238 [669440/25046 (82%)]\tLoss: 0.689148\n",
            "Train epoch: 238 [653400/25046 (84%)]\tLoss: 0.441135\n",
            "Train epoch: 238 [665720/25046 (87%)]\tLoss: 0.909613\n",
            "Train epoch: 238 [664300/25046 (89%)]\tLoss: 0.617444\n",
            "Train epoch: 238 [717120/25046 (92%)]\tLoss: 0.773866\n",
            "Train epoch: 238 [735560/25046 (95%)]\tLoss: 0.465280\n",
            "Train epoch: 238 [792680/25046 (97%)]\tLoss: 1.496880\n",
            "Train epoch: 238 [807300/25046 (100%)]\tLoss: 0.357451\n",
            "Make prediction for 5010 samples...\n",
            "0.80331504 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 239 [0/25046 (0%)]\tLoss: 1.054896\n",
            "Train epoch: 239 [20720/25046 (3%)]\tLoss: 1.076523\n",
            "Train epoch: 239 [41440/25046 (5%)]\tLoss: 1.231022\n",
            "Train epoch: 239 [58380/25046 (8%)]\tLoss: 0.324329\n",
            "Train epoch: 239 [79760/25046 (10%)]\tLoss: 1.007616\n",
            "Train epoch: 239 [97600/25046 (13%)]\tLoss: 1.218622\n",
            "Train epoch: 239 [129720/25046 (15%)]\tLoss: 0.901733\n",
            "Train epoch: 239 [139160/25046 (18%)]\tLoss: 0.790069\n",
            "Train epoch: 239 [165440/25046 (20%)]\tLoss: 0.641277\n",
            "Train epoch: 239 [172080/25046 (23%)]\tLoss: 0.641379\n",
            "Train epoch: 239 [216600/25046 (26%)]\tLoss: 1.226104\n",
            "Train epoch: 239 [227480/25046 (28%)]\tLoss: 0.950920\n",
            "Train epoch: 239 [263760/25046 (31%)]\tLoss: 0.426109\n",
            "Train epoch: 239 [275600/25046 (33%)]\tLoss: 0.938880\n",
            "Train epoch: 239 [293160/25046 (36%)]\tLoss: 2.326910\n",
            "Train epoch: 239 [326400/25046 (38%)]\tLoss: 1.149299\n",
            "Train epoch: 239 [325760/25046 (41%)]\tLoss: 0.642229\n",
            "Train epoch: 239 [358700/25046 (43%)]\tLoss: 0.604137\n",
            "Train epoch: 239 [388440/25046 (46%)]\tLoss: 0.738515\n",
            "Train epoch: 239 [400140/25046 (49%)]\tLoss: 0.880679\n",
            "Train epoch: 239 [402800/25046 (51%)]\tLoss: 0.830290\n",
            "Train epoch: 239 [426300/25046 (54%)]\tLoss: 0.288805\n",
            "Train epoch: 239 [429880/25046 (56%)]\tLoss: 0.908872\n",
            "Train epoch: 239 [474260/25046 (59%)]\tLoss: 1.622973\n",
            "Train epoch: 239 [488160/25046 (61%)]\tLoss: 0.708591\n",
            "Train epoch: 239 [514500/25046 (64%)]\tLoss: 1.387413\n",
            "Train epoch: 239 [514280/25046 (66%)]\tLoss: 0.262032\n",
            "Train epoch: 239 [538920/25046 (69%)]\tLoss: 1.296767\n",
            "Train epoch: 239 [566160/25046 (72%)]\tLoss: 0.584915\n",
            "Train epoch: 239 [611900/25046 (74%)]\tLoss: 0.554411\n",
            "Train epoch: 239 [617400/25046 (77%)]\tLoss: 0.230781\n",
            "Train epoch: 239 [608220/25046 (79%)]\tLoss: 0.423541\n",
            "Train epoch: 239 [699520/25046 (82%)]\tLoss: 1.078017\n",
            "Train epoch: 239 [700920/25046 (84%)]\tLoss: 1.061614\n",
            "Train epoch: 239 [710600/25046 (87%)]\tLoss: 0.832074\n",
            "Train epoch: 239 [673400/25046 (89%)]\tLoss: 0.445881\n",
            "Train epoch: 239 [731520/25046 (92%)]\tLoss: 0.693630\n",
            "Train epoch: 239 [725200/25046 (95%)]\tLoss: 0.681259\n",
            "Train epoch: 239 [778240/25046 (97%)]\tLoss: 1.384501\n",
            "Train epoch: 239 [801840/25046 (100%)]\tLoss: 0.757372\n",
            "Make prediction for 5010 samples...\n",
            "0.8018649 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 240 [0/25046 (0%)]\tLoss: 0.795011\n",
            "Train epoch: 240 [21240/25046 (3%)]\tLoss: 0.802778\n",
            "Train epoch: 240 [41560/25046 (5%)]\tLoss: 0.598012\n",
            "Train epoch: 240 [61380/25046 (8%)]\tLoss: 1.048105\n",
            "Train epoch: 240 [85840/25046 (10%)]\tLoss: 1.046526\n",
            "Train epoch: 240 [106300/25046 (13%)]\tLoss: 0.311702\n",
            "Train epoch: 240 [117840/25046 (15%)]\tLoss: 0.569743\n",
            "Train epoch: 240 [139020/25046 (18%)]\tLoss: 0.799305\n",
            "Train epoch: 240 [158880/25046 (20%)]\tLoss: 0.546248\n",
            "Train epoch: 240 [187020/25046 (23%)]\tLoss: 0.404942\n",
            "Train epoch: 240 [214600/25046 (26%)]\tLoss: 1.281455\n",
            "Train epoch: 240 [231220/25046 (28%)]\tLoss: 0.471311\n",
            "Train epoch: 240 [241440/25046 (31%)]\tLoss: 0.806805\n",
            "Train epoch: 240 [248300/25046 (33%)]\tLoss: 0.252504\n",
            "Train epoch: 240 [289520/25046 (36%)]\tLoss: 1.081115\n",
            "Train epoch: 240 [306600/25046 (38%)]\tLoss: 0.886319\n",
            "Train epoch: 240 [331520/25046 (41%)]\tLoss: 0.738580\n",
            "Train epoch: 240 [344080/25046 (43%)]\tLoss: 0.221305\n",
            "Train epoch: 240 [374040/25046 (46%)]\tLoss: 1.195750\n",
            "Train epoch: 240 [379240/25046 (49%)]\tLoss: 0.613892\n",
            "Train epoch: 240 [423200/25046 (51%)]\tLoss: 0.789502\n",
            "Train epoch: 240 [415380/25046 (54%)]\tLoss: 0.411054\n",
            "Train epoch: 240 [418000/25046 (56%)]\tLoss: 0.422267\n",
            "Train epoch: 240 [459080/25046 (59%)]\tLoss: 0.377618\n",
            "Train epoch: 240 [471840/25046 (61%)]\tLoss: 0.276865\n",
            "Train epoch: 240 [509500/25046 (64%)]\tLoss: 0.974321\n",
            "Train epoch: 240 [520520/25046 (66%)]\tLoss: 0.621100\n",
            "Train epoch: 240 [554040/25046 (69%)]\tLoss: 0.969556\n",
            "Train epoch: 240 [600320/25046 (72%)]\tLoss: 0.461079\n",
            "Train epoch: 240 [577680/25046 (74%)]\tLoss: 1.315211\n",
            "Train epoch: 240 [618600/25046 (77%)]\tLoss: 0.814564\n",
            "Train epoch: 240 [650380/25046 (79%)]\tLoss: 1.344320\n",
            "Train epoch: 240 [659840/25046 (82%)]\tLoss: 0.934296\n",
            "Train epoch: 240 [672540/25046 (84%)]\tLoss: 0.719965\n",
            "Train epoch: 240 [687480/25046 (87%)]\tLoss: 1.418991\n",
            "Train epoch: 240 [707700/25046 (89%)]\tLoss: 0.673292\n",
            "Train epoch: 240 [722880/25046 (92%)]\tLoss: 0.902826\n",
            "Train epoch: 240 [720760/25046 (95%)]\tLoss: 0.287812\n",
            "Train epoch: 240 [781280/25046 (97%)]\tLoss: 1.344908\n",
            "Train epoch: 240 [796380/25046 (100%)]\tLoss: 0.969497\n",
            "Make prediction for 5010 samples...\n",
            "0.80399424 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 241 [0/25046 (0%)]\tLoss: 0.371609\n",
            "Train epoch: 241 [20000/25046 (3%)]\tLoss: 0.779225\n",
            "Train epoch: 241 [41480/25046 (5%)]\tLoss: 0.489618\n",
            "Train epoch: 241 [63600/25046 (8%)]\tLoss: 0.547600\n",
            "Train epoch: 241 [79040/25046 (10%)]\tLoss: 1.042527\n",
            "Train epoch: 241 [98500/25046 (13%)]\tLoss: 0.374045\n",
            "Train epoch: 241 [127920/25046 (15%)]\tLoss: 0.422948\n",
            "Train epoch: 241 [139440/25046 (18%)]\tLoss: 0.516368\n",
            "Train epoch: 241 [165440/25046 (20%)]\tLoss: 1.247908\n",
            "Train epoch: 241 [192060/25046 (23%)]\tLoss: 1.548384\n",
            "Train epoch: 241 [206800/25046 (26%)]\tLoss: 1.263616\n",
            "Train epoch: 241 [235840/25046 (28%)]\tLoss: 0.419060\n",
            "Train epoch: 241 [240960/25046 (31%)]\tLoss: 0.888848\n",
            "Train epoch: 241 [263120/25046 (33%)]\tLoss: 1.058676\n",
            "Train epoch: 241 [294000/25046 (36%)]\tLoss: 0.660639\n",
            "Train epoch: 241 [308700/25046 (38%)]\tLoss: 1.402768\n",
            "Train epoch: 241 [328640/25046 (41%)]\tLoss: 0.278435\n",
            "Train epoch: 241 [347480/25046 (43%)]\tLoss: 0.610273\n",
            "Train epoch: 241 [364680/25046 (46%)]\tLoss: 0.403790\n",
            "Train epoch: 241 [396340/25046 (49%)]\tLoss: 0.997629\n",
            "Train epoch: 241 [414000/25046 (51%)]\tLoss: 0.402143\n",
            "Train epoch: 241 [423780/25046 (54%)]\tLoss: 0.604671\n",
            "Train epoch: 241 [443080/25046 (56%)]\tLoss: 0.769771\n",
            "Train epoch: 241 [510140/25046 (59%)]\tLoss: 1.727276\n",
            "Train epoch: 241 [483360/25046 (61%)]\tLoss: 0.928592\n",
            "Train epoch: 241 [501500/25046 (64%)]\tLoss: 0.759812\n",
            "Train epoch: 241 [560560/25046 (66%)]\tLoss: 1.109776\n",
            "Train epoch: 241 [539460/25046 (69%)]\tLoss: 1.144842\n",
            "Train epoch: 241 [543760/25046 (72%)]\tLoss: 0.383114\n",
            "Train epoch: 241 [600880/25046 (74%)]\tLoss: 2.182414\n",
            "Train epoch: 241 [637200/25046 (77%)]\tLoss: 0.945935\n",
            "Train epoch: 241 [606360/25046 (79%)]\tLoss: 0.244995\n",
            "Train epoch: 241 [656000/25046 (82%)]\tLoss: 0.690203\n",
            "Train epoch: 241 [670560/25046 (84%)]\tLoss: 0.743406\n",
            "Train epoch: 241 [736440/25046 (87%)]\tLoss: 1.243306\n",
            "Train epoch: 241 [711900/25046 (89%)]\tLoss: 0.933052\n",
            "Train epoch: 241 [735840/25046 (92%)]\tLoss: 1.164464\n",
            "Train epoch: 241 [736300/25046 (95%)]\tLoss: 0.402090\n",
            "Train epoch: 241 [817760/25046 (97%)]\tLoss: 1.261667\n",
            "Train epoch: 241 [802620/25046 (100%)]\tLoss: 0.318987\n",
            "Make prediction for 5010 samples...\n",
            "0.8062417 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 242 [0/25046 (0%)]\tLoss: 0.763715\n",
            "Train epoch: 242 [19760/25046 (3%)]\tLoss: 0.699490\n",
            "Train epoch: 242 [41040/25046 (5%)]\tLoss: 0.904281\n",
            "Train epoch: 242 [59220/25046 (8%)]\tLoss: 2.146415\n",
            "Train epoch: 242 [80480/25046 (10%)]\tLoss: 0.584567\n",
            "Train epoch: 242 [97500/25046 (13%)]\tLoss: 0.362470\n",
            "Train epoch: 242 [124800/25046 (15%)]\tLoss: 0.283908\n",
            "Train epoch: 242 [140420/25046 (18%)]\tLoss: 0.674274\n",
            "Train epoch: 242 [167520/25046 (20%)]\tLoss: 0.707709\n",
            "Train epoch: 242 [181980/25046 (23%)]\tLoss: 0.415071\n",
            "Train epoch: 242 [206000/25046 (26%)]\tLoss: 0.718002\n",
            "Train epoch: 242 [230120/25046 (28%)]\tLoss: 0.604517\n",
            "Train epoch: 242 [252960/25046 (31%)]\tLoss: 0.892139\n",
            "Train epoch: 242 [270400/25046 (33%)]\tLoss: 0.426715\n",
            "Train epoch: 242 [307720/25046 (36%)]\tLoss: 0.826349\n",
            "Train epoch: 242 [306000/25046 (38%)]\tLoss: 0.411236\n",
            "Train epoch: 242 [336960/25046 (41%)]\tLoss: 0.983314\n",
            "Train epoch: 242 [362780/25046 (43%)]\tLoss: 1.003688\n",
            "Train epoch: 242 [353160/25046 (46%)]\tLoss: 0.608321\n",
            "Train epoch: 242 [387980/25046 (49%)]\tLoss: 0.502070\n",
            "Train epoch: 242 [400000/25046 (51%)]\tLoss: 0.499400\n",
            "Train epoch: 242 [413280/25046 (54%)]\tLoss: 1.221832\n",
            "Train epoch: 242 [465520/25046 (56%)]\tLoss: 1.976506\n",
            "Train epoch: 242 [485300/25046 (59%)]\tLoss: 0.516083\n",
            "Train epoch: 242 [486240/25046 (61%)]\tLoss: 0.548598\n",
            "Train epoch: 242 [512500/25046 (64%)]\tLoss: 0.479202\n",
            "Train epoch: 242 [564720/25046 (66%)]\tLoss: 0.961800\n",
            "Train epoch: 242 [576180/25046 (69%)]\tLoss: 1.057084\n",
            "Train epoch: 242 [565040/25046 (72%)]\tLoss: 0.609527\n",
            "Train epoch: 242 [610740/25046 (74%)]\tLoss: 1.175953\n",
            "Train epoch: 242 [601200/25046 (77%)]\tLoss: 0.759949\n",
            "Train epoch: 242 [647900/25046 (79%)]\tLoss: 0.845313\n",
            "Train epoch: 242 [670080/25046 (82%)]\tLoss: 0.765728\n",
            "Train epoch: 242 [659340/25046 (84%)]\tLoss: 0.683162\n",
            "Train epoch: 242 [687480/25046 (87%)]\tLoss: 0.681859\n",
            "Train epoch: 242 [691600/25046 (89%)]\tLoss: 0.349374\n",
            "Train epoch: 242 [749520/25046 (92%)]\tLoss: 1.501381\n",
            "Train epoch: 242 [745180/25046 (95%)]\tLoss: 0.445148\n",
            "Train epoch: 242 [789640/25046 (97%)]\tLoss: 0.559055\n",
            "Train epoch: 242 [775320/25046 (100%)]\tLoss: 0.834778\n",
            "Make prediction for 5010 samples...\n",
            "0.80464065 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 243 [0/25046 (0%)]\tLoss: 0.644182\n",
            "Train epoch: 243 [19640/25046 (3%)]\tLoss: 1.008233\n",
            "Train epoch: 243 [38760/25046 (5%)]\tLoss: 1.469355\n",
            "Train epoch: 243 [61440/25046 (8%)]\tLoss: 0.752137\n",
            "Train epoch: 243 [79680/25046 (10%)]\tLoss: 1.315274\n",
            "Train epoch: 243 [105600/25046 (13%)]\tLoss: 0.587020\n",
            "Train epoch: 243 [123240/25046 (15%)]\tLoss: 1.998126\n",
            "Train epoch: 243 [145040/25046 (18%)]\tLoss: 1.552112\n",
            "Train epoch: 243 [168320/25046 (20%)]\tLoss: 0.757080\n",
            "Train epoch: 243 [185760/25046 (23%)]\tLoss: 0.593018\n",
            "Train epoch: 243 [205000/25046 (26%)]\tLoss: 1.396615\n",
            "Train epoch: 243 [213840/25046 (28%)]\tLoss: 0.953085\n",
            "Train epoch: 243 [248160/25046 (31%)]\tLoss: 0.410245\n",
            "Train epoch: 243 [266240/25046 (33%)]\tLoss: 0.528923\n",
            "Train epoch: 243 [302680/25046 (36%)]\tLoss: 0.943190\n",
            "Train epoch: 243 [301200/25046 (38%)]\tLoss: 0.284486\n",
            "Train epoch: 243 [317760/25046 (41%)]\tLoss: 0.213918\n",
            "Train epoch: 243 [342720/25046 (43%)]\tLoss: 0.813527\n",
            "Train epoch: 243 [383400/25046 (46%)]\tLoss: 0.427419\n",
            "Train epoch: 243 [383040/25046 (49%)]\tLoss: 0.888286\n",
            "Train epoch: 243 [393200/25046 (51%)]\tLoss: 0.367817\n",
            "Train epoch: 243 [421260/25046 (54%)]\tLoss: 0.907318\n",
            "Train epoch: 243 [438680/25046 (56%)]\tLoss: 1.427292\n",
            "Train epoch: 243 [457700/25046 (59%)]\tLoss: 0.807227\n",
            "Train epoch: 243 [461760/25046 (61%)]\tLoss: 1.079564\n",
            "Train epoch: 243 [513000/25046 (64%)]\tLoss: 0.494439\n",
            "Train epoch: 243 [524160/25046 (66%)]\tLoss: 0.227927\n",
            "Train epoch: 243 [554580/25046 (69%)]\tLoss: 0.516020\n",
            "Train epoch: 243 [568960/25046 (72%)]\tLoss: 0.508645\n",
            "Train epoch: 243 [613060/25046 (74%)]\tLoss: 0.214727\n",
            "Train epoch: 243 [615000/25046 (77%)]\tLoss: 0.796517\n",
            "Train epoch: 243 [638600/25046 (79%)]\tLoss: 0.820149\n",
            "Train epoch: 243 [662400/25046 (82%)]\tLoss: 0.785348\n",
            "Train epoch: 243 [685740/25046 (84%)]\tLoss: 1.394307\n",
            "Train epoch: 243 [713320/25046 (87%)]\tLoss: 0.671557\n",
            "Train epoch: 243 [716100/25046 (89%)]\tLoss: 0.765082\n",
            "Train epoch: 243 [709920/25046 (92%)]\tLoss: 0.563174\n",
            "Train epoch: 243 [785140/25046 (95%)]\tLoss: 0.324662\n",
            "Train epoch: 243 [782800/25046 (97%)]\tLoss: 1.288134\n",
            "Train epoch: 243 [846300/25046 (100%)]\tLoss: 0.691409\n",
            "Make prediction for 5010 samples...\n",
            "0.8030612 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 244 [0/25046 (0%)]\tLoss: 0.557618\n",
            "Train epoch: 244 [20020/25046 (3%)]\tLoss: 0.615636\n",
            "Train epoch: 244 [42760/25046 (5%)]\tLoss: 1.132925\n",
            "Train epoch: 244 [59040/25046 (8%)]\tLoss: 0.830109\n",
            "Train epoch: 244 [78640/25046 (10%)]\tLoss: 0.463077\n",
            "Train epoch: 244 [100900/25046 (13%)]\tLoss: 1.043396\n",
            "Train epoch: 244 [114240/25046 (15%)]\tLoss: 0.248560\n",
            "Train epoch: 244 [137760/25046 (18%)]\tLoss: 0.874648\n",
            "Train epoch: 244 [169280/25046 (20%)]\tLoss: 0.369098\n",
            "Train epoch: 244 [184320/25046 (23%)]\tLoss: 0.825250\n",
            "Train epoch: 244 [219800/25046 (26%)]\tLoss: 1.046448\n",
            "Train epoch: 244 [238920/25046 (28%)]\tLoss: 0.646310\n",
            "Train epoch: 244 [249120/25046 (31%)]\tLoss: 0.331985\n",
            "Train epoch: 244 [274040/25046 (33%)]\tLoss: 1.297063\n",
            "Train epoch: 244 [277200/25046 (36%)]\tLoss: 1.456753\n",
            "Train epoch: 244 [312300/25046 (38%)]\tLoss: 1.061365\n",
            "Train epoch: 244 [327360/25046 (41%)]\tLoss: 0.774945\n",
            "Train epoch: 244 [344760/25046 (43%)]\tLoss: 0.733359\n",
            "Train epoch: 244 [351360/25046 (46%)]\tLoss: 0.800893\n",
            "Train epoch: 244 [402040/25046 (49%)]\tLoss: 0.523628\n",
            "Train epoch: 244 [410800/25046 (51%)]\tLoss: 0.407039\n",
            "Train epoch: 244 [417480/25046 (54%)]\tLoss: 0.463897\n",
            "Train epoch: 244 [449680/25046 (56%)]\tLoss: 1.584656\n",
            "Train epoch: 244 [461840/25046 (59%)]\tLoss: 0.753146\n",
            "Train epoch: 244 [476640/25046 (61%)]\tLoss: 1.291307\n",
            "Train epoch: 244 [543500/25046 (64%)]\tLoss: 1.925888\n",
            "Train epoch: 244 [538720/25046 (66%)]\tLoss: 0.737581\n",
            "Train epoch: 244 [565920/25046 (69%)]\tLoss: 0.550702\n",
            "Train epoch: 244 [588000/25046 (72%)]\tLoss: 0.675013\n",
            "Train epoch: 244 [615960/25046 (74%)]\tLoss: 0.479368\n",
            "Train epoch: 244 [657000/25046 (77%)]\tLoss: 0.490906\n",
            "Train epoch: 244 [610080/25046 (79%)]\tLoss: 1.019202\n",
            "Train epoch: 244 [600320/25046 (82%)]\tLoss: 0.633357\n",
            "Train epoch: 244 [698940/25046 (84%)]\tLoss: 0.696410\n",
            "Train epoch: 244 [738480/25046 (87%)]\tLoss: 0.455126\n",
            "Train epoch: 244 [717500/25046 (89%)]\tLoss: 0.977930\n",
            "Train epoch: 244 [753120/25046 (92%)]\tLoss: 1.314297\n",
            "Train epoch: 244 [762940/25046 (95%)]\tLoss: 0.380046\n",
            "Train epoch: 244 [807120/25046 (97%)]\tLoss: 0.697503\n",
            "Train epoch: 244 [810420/25046 (100%)]\tLoss: 1.716882\n",
            "Make prediction for 5010 samples...\n",
            "0.80213416 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 245 [0/25046 (0%)]\tLoss: 0.516379\n",
            "Train epoch: 245 [20100/25046 (3%)]\tLoss: 0.672875\n",
            "Train epoch: 245 [41480/25046 (5%)]\tLoss: 0.988042\n",
            "Train epoch: 245 [62340/25046 (8%)]\tLoss: 0.355913\n",
            "Train epoch: 245 [79040/25046 (10%)]\tLoss: 0.810078\n",
            "Train epoch: 245 [98600/25046 (13%)]\tLoss: 0.553056\n",
            "Train epoch: 245 [123600/25046 (15%)]\tLoss: 1.111265\n",
            "Train epoch: 245 [141680/25046 (18%)]\tLoss: 0.560150\n",
            "Train epoch: 245 [164640/25046 (20%)]\tLoss: 1.262293\n",
            "Train epoch: 245 [179280/25046 (23%)]\tLoss: 0.996872\n",
            "Train epoch: 245 [213400/25046 (26%)]\tLoss: 1.555681\n",
            "Train epoch: 245 [223960/25046 (28%)]\tLoss: 0.825863\n",
            "Train epoch: 245 [253680/25046 (31%)]\tLoss: 0.828526\n",
            "Train epoch: 245 [266240/25046 (33%)]\tLoss: 0.576620\n",
            "Train epoch: 245 [279160/25046 (36%)]\tLoss: 0.605075\n",
            "Train epoch: 245 [308700/25046 (38%)]\tLoss: 0.988952\n",
            "Train epoch: 245 [340160/25046 (41%)]\tLoss: 0.683666\n",
            "Train epoch: 245 [362100/25046 (43%)]\tLoss: 0.747811\n",
            "Train epoch: 245 [379440/25046 (46%)]\tLoss: 1.145644\n",
            "Train epoch: 245 [392540/25046 (49%)]\tLoss: 0.289103\n",
            "Train epoch: 245 [422000/25046 (51%)]\tLoss: 1.533934\n",
            "Train epoch: 245 [447300/25046 (54%)]\tLoss: 2.498412\n",
            "Train epoch: 245 [447920/25046 (56%)]\tLoss: 0.357442\n",
            "Train epoch: 245 [491740/25046 (59%)]\tLoss: 0.592983\n",
            "Train epoch: 245 [471840/25046 (61%)]\tLoss: 1.141814\n",
            "Train epoch: 245 [520000/25046 (64%)]\tLoss: 0.651329\n",
            "Train epoch: 245 [501280/25046 (66%)]\tLoss: 0.541875\n",
            "Train epoch: 245 [537840/25046 (69%)]\tLoss: 0.853735\n",
            "Train epoch: 245 [580720/25046 (72%)]\tLoss: 0.357349\n",
            "Train epoch: 245 [585800/25046 (74%)]\tLoss: 1.553524\n",
            "Train epoch: 245 [604200/25046 (77%)]\tLoss: 1.220542\n",
            "Train epoch: 245 [643560/25046 (79%)]\tLoss: 0.918256\n",
            "Train epoch: 245 [695680/25046 (82%)]\tLoss: 1.294069\n",
            "Train epoch: 245 [687720/25046 (84%)]\tLoss: 1.358467\n",
            "Train epoch: 245 [718760/25046 (87%)]\tLoss: 1.488610\n",
            "Train epoch: 245 [646800/25046 (89%)]\tLoss: 0.860053\n",
            "Train epoch: 245 [717120/25046 (92%)]\tLoss: 0.713206\n",
            "Train epoch: 245 [807340/25046 (95%)]\tLoss: 1.063194\n",
            "Train epoch: 245 [817760/25046 (97%)]\tLoss: 0.765599\n",
            "Train epoch: 245 [755040/25046 (100%)]\tLoss: 0.403611\n",
            "Make prediction for 5010 samples...\n",
            "0.80177146 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 246 [0/25046 (0%)]\tLoss: 0.839518\n",
            "Train epoch: 246 [20380/25046 (3%)]\tLoss: 0.410412\n",
            "Train epoch: 246 [42320/25046 (5%)]\tLoss: 1.170928\n",
            "Train epoch: 246 [62040/25046 (8%)]\tLoss: 0.591592\n",
            "Train epoch: 246 [79120/25046 (10%)]\tLoss: 0.346274\n",
            "Train epoch: 246 [108300/25046 (13%)]\tLoss: 0.702111\n",
            "Train epoch: 246 [124080/25046 (15%)]\tLoss: 0.920517\n",
            "Train epoch: 246 [140840/25046 (18%)]\tLoss: 0.708746\n",
            "Train epoch: 246 [168480/25046 (20%)]\tLoss: 0.506403\n",
            "Train epoch: 246 [175680/25046 (23%)]\tLoss: 1.066545\n",
            "Train epoch: 246 [213000/25046 (26%)]\tLoss: 0.693513\n",
            "Train epoch: 246 [216260/25046 (28%)]\tLoss: 0.537064\n",
            "Train epoch: 246 [250320/25046 (31%)]\tLoss: 0.591394\n",
            "Train epoch: 246 [265980/25046 (33%)]\tLoss: 1.070882\n",
            "Train epoch: 246 [279160/25046 (36%)]\tLoss: 0.970674\n",
            "Train epoch: 246 [306000/25046 (38%)]\tLoss: 0.997747\n",
            "Train epoch: 246 [319040/25046 (41%)]\tLoss: 0.621858\n",
            "Train epoch: 246 [351560/25046 (43%)]\tLoss: 0.648688\n",
            "Train epoch: 246 [375120/25046 (46%)]\tLoss: 0.882850\n",
            "Train epoch: 246 [376200/25046 (49%)]\tLoss: 0.410529\n",
            "Train epoch: 246 [420800/25046 (51%)]\tLoss: 0.751775\n",
            "Train epoch: 246 [414120/25046 (54%)]\tLoss: 0.780888\n",
            "Train epoch: 246 [463760/25046 (56%)]\tLoss: 0.418766\n",
            "Train epoch: 246 [477020/25046 (59%)]\tLoss: 0.811543\n",
            "Train epoch: 246 [499680/25046 (61%)]\tLoss: 1.618599\n",
            "Train epoch: 246 [490500/25046 (64%)]\tLoss: 0.549860\n",
            "Train epoch: 246 [522080/25046 (66%)]\tLoss: 0.579705\n",
            "Train epoch: 246 [532440/25046 (69%)]\tLoss: 0.962793\n",
            "Train epoch: 246 [592480/25046 (72%)]\tLoss: 1.105074\n",
            "Train epoch: 246 [581160/25046 (74%)]\tLoss: 1.026938\n",
            "Train epoch: 246 [631800/25046 (77%)]\tLoss: 0.556327\n",
            "Train epoch: 246 [645420/25046 (79%)]\tLoss: 0.525419\n",
            "Train epoch: 246 [668800/25046 (82%)]\tLoss: 1.564949\n",
            "Train epoch: 246 [695640/25046 (84%)]\tLoss: 0.912786\n",
            "Train epoch: 246 [663000/25046 (87%)]\tLoss: 1.123300\n",
            "Train epoch: 246 [736400/25046 (89%)]\tLoss: 1.120350\n",
            "Train epoch: 246 [756720/25046 (92%)]\tLoss: 0.614823\n",
            "Train epoch: 246 [762200/25046 (95%)]\tLoss: 1.021247\n",
            "Train epoch: 246 [788880/25046 (97%)]\tLoss: 0.658994\n",
            "Train epoch: 246 [751920/25046 (100%)]\tLoss: 0.721150\n",
            "Make prediction for 5010 samples...\n",
            "0.80159396 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 247 [0/25046 (0%)]\tLoss: 0.614839\n",
            "Train epoch: 247 [19880/25046 (3%)]\tLoss: 0.757611\n",
            "Train epoch: 247 [41440/25046 (5%)]\tLoss: 1.023709\n",
            "Train epoch: 247 [59400/25046 (8%)]\tLoss: 0.666008\n",
            "Train epoch: 247 [79840/25046 (10%)]\tLoss: 0.917836\n",
            "Train epoch: 247 [107200/25046 (13%)]\tLoss: 0.536856\n",
            "Train epoch: 247 [131520/25046 (15%)]\tLoss: 0.696946\n",
            "Train epoch: 247 [143780/25046 (18%)]\tLoss: 0.601439\n",
            "Train epoch: 247 [154400/25046 (20%)]\tLoss: 0.885269\n",
            "Train epoch: 247 [184680/25046 (23%)]\tLoss: 1.560714\n",
            "Train epoch: 247 [209400/25046 (26%)]\tLoss: 1.067156\n",
            "Train epoch: 247 [223520/25046 (28%)]\tLoss: 0.346226\n",
            "Train epoch: 247 [231600/25046 (31%)]\tLoss: 0.297656\n",
            "Train epoch: 247 [275340/25046 (33%)]\tLoss: 0.340178\n",
            "Train epoch: 247 [288120/25046 (36%)]\tLoss: 0.605477\n",
            "Train epoch: 247 [294600/25046 (38%)]\tLoss: 1.321860\n",
            "Train epoch: 247 [322240/25046 (41%)]\tLoss: 1.170046\n",
            "Train epoch: 247 [352920/25046 (43%)]\tLoss: 0.586408\n",
            "Train epoch: 247 [354240/25046 (46%)]\tLoss: 0.532157\n",
            "Train epoch: 247 [397480/25046 (49%)]\tLoss: 0.646504\n",
            "Train epoch: 247 [414800/25046 (51%)]\tLoss: 0.231308\n",
            "Train epoch: 247 [445620/25046 (54%)]\tLoss: 0.626882\n",
            "Train epoch: 247 [465520/25046 (56%)]\tLoss: 0.721474\n",
            "Train epoch: 247 [468280/25046 (59%)]\tLoss: 0.833057\n",
            "Train epoch: 247 [494400/25046 (61%)]\tLoss: 0.941095\n",
            "Train epoch: 247 [533000/25046 (64%)]\tLoss: 0.524606\n",
            "Train epoch: 247 [529360/25046 (66%)]\tLoss: 0.351150\n",
            "Train epoch: 247 [572940/25046 (69%)]\tLoss: 1.229471\n",
            "Train epoch: 247 [581280/25046 (72%)]\tLoss: 0.722069\n",
            "Train epoch: 247 [613060/25046 (74%)]\tLoss: 0.940742\n",
            "Train epoch: 247 [621600/25046 (77%)]\tLoss: 1.600943\n",
            "Train epoch: 247 [625580/25046 (79%)]\tLoss: 1.034977\n",
            "Train epoch: 247 [675200/25046 (82%)]\tLoss: 0.484223\n",
            "Train epoch: 247 [648780/25046 (84%)]\tLoss: 0.592970\n",
            "Train epoch: 247 [673880/25046 (87%)]\tLoss: 1.027083\n",
            "Train epoch: 247 [705600/25046 (89%)]\tLoss: 0.207340\n",
            "Train epoch: 247 [711360/25046 (92%)]\tLoss: 0.650518\n",
            "Train epoch: 247 [782180/25046 (95%)]\tLoss: 0.445842\n",
            "Train epoch: 247 [801040/25046 (97%)]\tLoss: 0.839348\n",
            "Train epoch: 247 [826020/25046 (100%)]\tLoss: 0.269545\n",
            "Make prediction for 5010 samples...\n",
            "0.80159605 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 248 [0/25046 (0%)]\tLoss: 0.455173\n",
            "Train epoch: 248 [21020/25046 (3%)]\tLoss: 1.589555\n",
            "Train epoch: 248 [40880/25046 (5%)]\tLoss: 0.832056\n",
            "Train epoch: 248 [60840/25046 (8%)]\tLoss: 0.686052\n",
            "Train epoch: 248 [83520/25046 (10%)]\tLoss: 0.591302\n",
            "Train epoch: 248 [96000/25046 (13%)]\tLoss: 0.819970\n",
            "Train epoch: 248 [128520/25046 (15%)]\tLoss: 0.291072\n",
            "Train epoch: 248 [145880/25046 (18%)]\tLoss: 0.542466\n",
            "Train epoch: 248 [168480/25046 (20%)]\tLoss: 0.557948\n",
            "Train epoch: 248 [190800/25046 (23%)]\tLoss: 0.817538\n",
            "Train epoch: 248 [210000/25046 (26%)]\tLoss: 0.774587\n",
            "Train epoch: 248 [226160/25046 (28%)]\tLoss: 1.173282\n",
            "Train epoch: 248 [242640/25046 (31%)]\tLoss: 1.201083\n",
            "Train epoch: 248 [265460/25046 (33%)]\tLoss: 0.549941\n",
            "Train epoch: 248 [283360/25046 (36%)]\tLoss: 0.973835\n",
            "Train epoch: 248 [311700/25046 (38%)]\tLoss: 1.590150\n",
            "Train epoch: 248 [339520/25046 (41%)]\tLoss: 1.617790\n",
            "Train epoch: 248 [341020/25046 (43%)]\tLoss: 0.258783\n",
            "Train epoch: 248 [379440/25046 (46%)]\tLoss: 0.972026\n",
            "Train epoch: 248 [392540/25046 (49%)]\tLoss: 1.456744\n",
            "Train epoch: 248 [413200/25046 (51%)]\tLoss: 0.611022\n",
            "Train epoch: 248 [440580/25046 (54%)]\tLoss: 0.548260\n",
            "Train epoch: 248 [439560/25046 (56%)]\tLoss: 1.393459\n",
            "Train epoch: 248 [490360/25046 (59%)]\tLoss: 0.749112\n",
            "Train epoch: 248 [476160/25046 (61%)]\tLoss: 1.004787\n",
            "Train epoch: 248 [495500/25046 (64%)]\tLoss: 0.640258\n",
            "Train epoch: 248 [530920/25046 (66%)]\tLoss: 0.928812\n",
            "Train epoch: 248 [550260/25046 (69%)]\tLoss: 0.741044\n",
            "Train epoch: 248 [577360/25046 (72%)]\tLoss: 0.884480\n",
            "Train epoch: 248 [604940/25046 (74%)]\tLoss: 0.676901\n",
            "Train epoch: 248 [649800/25046 (77%)]\tLoss: 1.730278\n",
            "Train epoch: 248 [657200/25046 (79%)]\tLoss: 0.485902\n",
            "Train epoch: 248 [641920/25046 (82%)]\tLoss: 1.006589\n",
            "Train epoch: 248 [678480/25046 (84%)]\tLoss: 0.493482\n",
            "Train epoch: 248 [686800/25046 (87%)]\tLoss: 1.160348\n",
            "Train epoch: 248 [697200/25046 (89%)]\tLoss: 0.615462\n",
            "Train epoch: 248 [739440/25046 (92%)]\tLoss: 0.426083\n",
            "Train epoch: 248 [782180/25046 (95%)]\tLoss: 1.511654\n",
            "Train epoch: 248 [810920/25046 (97%)]\tLoss: 0.397499\n",
            "Train epoch: 248 [795600/25046 (100%)]\tLoss: 0.896096\n",
            "Make prediction for 5010 samples...\n",
            "0.80162174 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 249 [0/25046 (0%)]\tLoss: 0.641906\n",
            "Train epoch: 249 [20220/25046 (3%)]\tLoss: 0.748568\n",
            "Train epoch: 249 [41160/25046 (5%)]\tLoss: 0.729080\n",
            "Train epoch: 249 [64680/25046 (8%)]\tLoss: 1.394554\n",
            "Train epoch: 249 [76560/25046 (10%)]\tLoss: 0.227651\n",
            "Train epoch: 249 [103500/25046 (13%)]\tLoss: 1.654804\n",
            "Train epoch: 249 [125280/25046 (15%)]\tLoss: 1.145074\n",
            "Train epoch: 249 [146300/25046 (18%)]\tLoss: 0.680350\n",
            "Train epoch: 249 [167200/25046 (20%)]\tLoss: 1.587773\n",
            "Train epoch: 249 [187020/25046 (23%)]\tLoss: 0.406063\n",
            "Train epoch: 249 [195800/25046 (26%)]\tLoss: 0.877498\n",
            "Train epoch: 249 [218900/25046 (28%)]\tLoss: 0.264677\n",
            "Train epoch: 249 [252240/25046 (31%)]\tLoss: 0.664683\n",
            "Train epoch: 249 [257920/25046 (33%)]\tLoss: 0.806506\n",
            "Train epoch: 249 [277480/25046 (36%)]\tLoss: 0.800661\n",
            "Train epoch: 249 [317400/25046 (38%)]\tLoss: 0.456417\n",
            "Train epoch: 249 [306880/25046 (41%)]\tLoss: 0.560773\n",
            "Train epoch: 249 [362100/25046 (43%)]\tLoss: 0.813319\n",
            "Train epoch: 249 [383400/25046 (46%)]\tLoss: 0.838083\n",
            "Train epoch: 249 [392540/25046 (49%)]\tLoss: 1.022449\n",
            "Train epoch: 249 [408800/25046 (51%)]\tLoss: 0.719268\n",
            "Train epoch: 249 [429240/25046 (54%)]\tLoss: 1.047033\n",
            "Train epoch: 249 [483560/25046 (56%)]\tLoss: 1.994288\n",
            "Train epoch: 249 [457700/25046 (59%)]\tLoss: 0.256938\n",
            "Train epoch: 249 [490560/25046 (61%)]\tLoss: 0.936108\n",
            "Train epoch: 249 [523500/25046 (64%)]\tLoss: 0.535112\n",
            "Train epoch: 249 [535600/25046 (66%)]\tLoss: 0.551187\n",
            "Train epoch: 249 [541620/25046 (69%)]\tLoss: 0.297446\n",
            "Train epoch: 249 [581280/25046 (72%)]\tLoss: 0.244334\n",
            "Train epoch: 249 [581160/25046 (74%)]\tLoss: 0.344868\n",
            "Train epoch: 249 [622800/25046 (77%)]\tLoss: 1.131529\n",
            "Train epoch: 249 [623100/25046 (79%)]\tLoss: 0.579650\n",
            "Train epoch: 249 [648320/25046 (82%)]\tLoss: 0.555572\n",
            "Train epoch: 249 [661320/25046 (84%)]\tLoss: 0.962308\n",
            "Train epoch: 249 [711280/25046 (87%)]\tLoss: 0.509550\n",
            "Train epoch: 249 [692300/25046 (89%)]\tLoss: 0.271635\n",
            "Train epoch: 249 [745920/25046 (92%)]\tLoss: 0.803891\n",
            "Train epoch: 249 [764420/25046 (95%)]\tLoss: 1.004660\n",
            "Train epoch: 249 [791160/25046 (97%)]\tLoss: 1.136539\n",
            "Train epoch: 249 [790140/25046 (100%)]\tLoss: 1.553563\n",
            "Make prediction for 5010 samples...\n",
            "0.8015209 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 250 [0/25046 (0%)]\tLoss: 0.400616\n",
            "Train epoch: 250 [19180/25046 (3%)]\tLoss: 1.029545\n",
            "Train epoch: 250 [39760/25046 (5%)]\tLoss: 1.076768\n",
            "Train epoch: 250 [64620/25046 (8%)]\tLoss: 1.754635\n",
            "Train epoch: 250 [80320/25046 (10%)]\tLoss: 0.793501\n",
            "Train epoch: 250 [103400/25046 (13%)]\tLoss: 1.876812\n",
            "Train epoch: 250 [125160/25046 (15%)]\tLoss: 0.377865\n",
            "Train epoch: 250 [136920/25046 (18%)]\tLoss: 0.396967\n",
            "Train epoch: 250 [171200/25046 (20%)]\tLoss: 1.403267\n",
            "Train epoch: 250 [183600/25046 (23%)]\tLoss: 1.605152\n",
            "Train epoch: 250 [209200/25046 (26%)]\tLoss: 0.900324\n",
            "Train epoch: 250 [222420/25046 (28%)]\tLoss: 0.449958\n",
            "Train epoch: 250 [245760/25046 (31%)]\tLoss: 0.212801\n",
            "Train epoch: 250 [269880/25046 (33%)]\tLoss: 0.185812\n",
            "Train epoch: 250 [286720/25046 (36%)]\tLoss: 0.301836\n",
            "Train epoch: 250 [308400/25046 (38%)]\tLoss: 0.863439\n",
            "Train epoch: 250 [328960/25046 (41%)]\tLoss: 0.984666\n",
            "Train epoch: 250 [359720/25046 (43%)]\tLoss: 1.052904\n",
            "Train epoch: 250 [363600/25046 (46%)]\tLoss: 1.222720\n",
            "Train epoch: 250 [395960/25046 (49%)]\tLoss: 0.399813\n",
            "Train epoch: 250 [426000/25046 (51%)]\tLoss: 0.729304\n",
            "Train epoch: 250 [430080/25046 (54%)]\tLoss: 0.610406\n",
            "Train epoch: 250 [443080/25046 (56%)]\tLoss: 0.634490\n",
            "Train epoch: 250 [471960/25046 (59%)]\tLoss: 0.506929\n",
            "Train epoch: 250 [481920/25046 (61%)]\tLoss: 0.476852\n",
            "Train epoch: 250 [505500/25046 (64%)]\tLoss: 1.167855\n",
            "Train epoch: 250 [509600/25046 (66%)]\tLoss: 0.291697\n",
            "Train epoch: 250 [571320/25046 (69%)]\tLoss: 1.350487\n",
            "Train epoch: 250 [586880/25046 (72%)]\tLoss: 0.421606\n",
            "Train epoch: 250 [584060/25046 (74%)]\tLoss: 0.842167\n",
            "Train epoch: 250 [606000/25046 (77%)]\tLoss: 0.936941\n",
            "Train epoch: 250 [608220/25046 (79%)]\tLoss: 0.647195\n",
            "Train epoch: 250 [680320/25046 (82%)]\tLoss: 0.737440\n",
            "Train epoch: 250 [714780/25046 (84%)]\tLoss: 1.272941\n",
            "Train epoch: 250 [726920/25046 (87%)]\tLoss: 0.631497\n",
            "Train epoch: 250 [742700/25046 (89%)]\tLoss: 0.396254\n",
            "Train epoch: 250 [779760/25046 (92%)]\tLoss: 0.588243\n",
            "Train epoch: 250 [779220/25046 (95%)]\tLoss: 0.638787\n",
            "Train epoch: 250 [782040/25046 (97%)]\tLoss: 0.757008\n",
            "Train epoch: 250 [776880/25046 (100%)]\tLoss: 0.670189\n",
            "Make prediction for 5010 samples...\n",
            "0.8019386 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 251 [0/25046 (0%)]\tLoss: 0.506392\n",
            "Train epoch: 251 [20020/25046 (3%)]\tLoss: 0.412818\n",
            "Train epoch: 251 [39640/25046 (5%)]\tLoss: 0.521094\n",
            "Train epoch: 251 [61440/25046 (8%)]\tLoss: 0.552525\n",
            "Train epoch: 251 [81280/25046 (10%)]\tLoss: 1.243186\n",
            "Train epoch: 251 [101800/25046 (13%)]\tLoss: 0.721491\n",
            "Train epoch: 251 [123720/25046 (15%)]\tLoss: 0.658460\n",
            "Train epoch: 251 [129220/25046 (18%)]\tLoss: 0.181774\n",
            "Train epoch: 251 [171680/25046 (20%)]\tLoss: 1.043422\n",
            "Train epoch: 251 [196920/25046 (23%)]\tLoss: 0.775971\n",
            "Train epoch: 251 [201200/25046 (26%)]\tLoss: 0.816612\n",
            "Train epoch: 251 [212080/25046 (28%)]\tLoss: 0.501918\n",
            "Train epoch: 251 [251520/25046 (31%)]\tLoss: 1.057746\n",
            "Train epoch: 251 [264940/25046 (33%)]\tLoss: 0.204455\n",
            "Train epoch: 251 [299880/25046 (36%)]\tLoss: 1.828588\n",
            "Train epoch: 251 [321600/25046 (38%)]\tLoss: 0.805237\n",
            "Train epoch: 251 [329920/25046 (41%)]\tLoss: 0.926696\n",
            "Train epoch: 251 [347140/25046 (43%)]\tLoss: 0.957680\n",
            "Train epoch: 251 [375480/25046 (46%)]\tLoss: 0.685216\n",
            "Train epoch: 251 [411920/25046 (49%)]\tLoss: 1.544651\n",
            "Train epoch: 251 [415600/25046 (51%)]\tLoss: 1.132670\n",
            "Train epoch: 251 [422100/25046 (54%)]\tLoss: 0.344585\n",
            "Train epoch: 251 [454520/25046 (56%)]\tLoss: 1.320221\n",
            "Train epoch: 251 [458160/25046 (59%)]\tLoss: 1.060575\n",
            "Train epoch: 251 [487680/25046 (61%)]\tLoss: 0.957994\n",
            "Train epoch: 251 [481000/25046 (64%)]\tLoss: 1.040472\n",
            "Train epoch: 251 [581360/25046 (66%)]\tLoss: 0.678951\n",
            "Train epoch: 251 [573480/25046 (69%)]\tLoss: 0.638705\n",
            "Train epoch: 251 [576800/25046 (72%)]\tLoss: 0.454160\n",
            "Train epoch: 251 [610740/25046 (74%)]\tLoss: 1.018355\n",
            "Train epoch: 251 [637200/25046 (77%)]\tLoss: 1.062563\n",
            "Train epoch: 251 [582180/25046 (79%)]\tLoss: 0.544661\n",
            "Train epoch: 251 [639360/25046 (82%)]\tLoss: 1.489845\n",
            "Train epoch: 251 [669900/25046 (84%)]\tLoss: 0.668029\n",
            "Train epoch: 251 [692920/25046 (87%)]\tLoss: 0.258922\n",
            "Train epoch: 251 [691600/25046 (89%)]\tLoss: 0.551367\n",
            "Train epoch: 251 [689760/25046 (92%)]\tLoss: 0.465460\n",
            "Train epoch: 251 [759980/25046 (95%)]\tLoss: 1.051304\n",
            "Train epoch: 251 [753160/25046 (97%)]\tLoss: 0.630694\n",
            "Train epoch: 251 [783900/25046 (100%)]\tLoss: 1.012977\n",
            "Make prediction for 5010 samples...\n",
            "0.80460376 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 252 [0/25046 (0%)]\tLoss: 1.333427\n",
            "Train epoch: 252 [20680/25046 (3%)]\tLoss: 0.394484\n",
            "Train epoch: 252 [41280/25046 (5%)]\tLoss: 0.505542\n",
            "Train epoch: 252 [61620/25046 (8%)]\tLoss: 0.294787\n",
            "Train epoch: 252 [82400/25046 (10%)]\tLoss: 1.235726\n",
            "Train epoch: 252 [93900/25046 (13%)]\tLoss: 0.836540\n",
            "Train epoch: 252 [124920/25046 (15%)]\tLoss: 0.463888\n",
            "Train epoch: 252 [149940/25046 (18%)]\tLoss: 1.020076\n",
            "Train epoch: 252 [176640/25046 (20%)]\tLoss: 0.707675\n",
            "Train epoch: 252 [180360/25046 (23%)]\tLoss: 0.735226\n",
            "Train epoch: 252 [206200/25046 (26%)]\tLoss: 0.960265\n",
            "Train epoch: 252 [205700/25046 (28%)]\tLoss: 0.299350\n",
            "Train epoch: 252 [252480/25046 (31%)]\tLoss: 1.340331\n",
            "Train epoch: 252 [260780/25046 (33%)]\tLoss: 1.068776\n",
            "Train epoch: 252 [300160/25046 (36%)]\tLoss: 1.074043\n",
            "Train epoch: 252 [312600/25046 (38%)]\tLoss: 1.119329\n",
            "Train epoch: 252 [329920/25046 (41%)]\tLoss: 0.957702\n",
            "Train epoch: 252 [358020/25046 (43%)]\tLoss: 0.556163\n",
            "Train epoch: 252 [387000/25046 (46%)]\tLoss: 0.558500\n",
            "Train epoch: 252 [367840/25046 (49%)]\tLoss: 0.625178\n",
            "Train epoch: 252 [411200/25046 (51%)]\tLoss: 0.387720\n",
            "Train epoch: 252 [413280/25046 (54%)]\tLoss: 0.689944\n",
            "Train epoch: 252 [461120/25046 (56%)]\tLoss: 0.345936\n",
            "Train epoch: 252 [468280/25046 (59%)]\tLoss: 0.954762\n",
            "Train epoch: 252 [495840/25046 (61%)]\tLoss: 0.245334\n",
            "Train epoch: 252 [482000/25046 (64%)]\tLoss: 0.357408\n",
            "Train epoch: 252 [512200/25046 (66%)]\tLoss: 0.445714\n",
            "Train epoch: 252 [537300/25046 (69%)]\tLoss: 0.399428\n",
            "Train epoch: 252 [571200/25046 (72%)]\tLoss: 0.748384\n",
            "Train epoch: 252 [582900/25046 (74%)]\tLoss: 1.079558\n",
            "Train epoch: 252 [615000/25046 (77%)]\tLoss: 0.458948\n",
            "Train epoch: 252 [615040/25046 (79%)]\tLoss: 0.572457\n",
            "Train epoch: 252 [650240/25046 (82%)]\tLoss: 0.628538\n",
            "Train epoch: 252 [687060/25046 (84%)]\tLoss: 0.853616\n",
            "Train epoch: 252 [716040/25046 (87%)]\tLoss: 0.779667\n",
            "Train epoch: 252 [726600/25046 (89%)]\tLoss: 0.960691\n",
            "Train epoch: 252 [729360/25046 (92%)]\tLoss: 1.121611\n",
            "Train epoch: 252 [788100/25046 (95%)]\tLoss: 1.238407\n",
            "Train epoch: 252 [785840/25046 (97%)]\tLoss: 0.459017\n",
            "Train epoch: 252 [793260/25046 (100%)]\tLoss: 1.351909\n",
            "Make prediction for 5010 samples...\n",
            "0.802635 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 253 [0/25046 (0%)]\tLoss: 1.119844\n",
            "Train epoch: 253 [20300/25046 (3%)]\tLoss: 1.134009\n",
            "Train epoch: 253 [41520/25046 (5%)]\tLoss: 0.387535\n",
            "Train epoch: 253 [59460/25046 (8%)]\tLoss: 0.306328\n",
            "Train epoch: 253 [79120/25046 (10%)]\tLoss: 1.070447\n",
            "Train epoch: 253 [96700/25046 (13%)]\tLoss: 1.717391\n",
            "Train epoch: 253 [131760/25046 (15%)]\tLoss: 0.975361\n",
            "Train epoch: 253 [137340/25046 (18%)]\tLoss: 1.082424\n",
            "Train epoch: 253 [164000/25046 (20%)]\tLoss: 0.656680\n",
            "Train epoch: 253 [177660/25046 (23%)]\tLoss: 0.639695\n",
            "Train epoch: 253 [207000/25046 (26%)]\tLoss: 0.676001\n",
            "Train epoch: 253 [226600/25046 (28%)]\tLoss: 0.623073\n",
            "Train epoch: 253 [244560/25046 (31%)]\tLoss: 0.595744\n",
            "Train epoch: 253 [279500/25046 (33%)]\tLoss: 1.039696\n",
            "Train epoch: 253 [307440/25046 (36%)]\tLoss: 1.173636\n",
            "Train epoch: 253 [304200/25046 (38%)]\tLoss: 1.170965\n",
            "Train epoch: 253 [323520/25046 (41%)]\tLoss: 0.597021\n",
            "Train epoch: 253 [352240/25046 (43%)]\tLoss: 0.649030\n",
            "Train epoch: 253 [346680/25046 (46%)]\tLoss: 0.401566\n",
            "Train epoch: 253 [371640/25046 (49%)]\tLoss: 0.920107\n",
            "Train epoch: 253 [417200/25046 (51%)]\tLoss: 1.860258\n",
            "Train epoch: 253 [433020/25046 (54%)]\tLoss: 0.384451\n",
            "Train epoch: 253 [510400/25046 (56%)]\tLoss: 0.712260\n",
            "Train epoch: 253 [494500/25046 (59%)]\tLoss: 0.260728\n",
            "Train epoch: 253 [506400/25046 (61%)]\tLoss: 1.099761\n",
            "Train epoch: 253 [515000/25046 (64%)]\tLoss: 0.530517\n",
            "Train epoch: 253 [547560/25046 (66%)]\tLoss: 0.218308\n",
            "Train epoch: 253 [570780/25046 (69%)]\tLoss: 0.529626\n",
            "Train epoch: 253 [571200/25046 (72%)]\tLoss: 0.406414\n",
            "Train epoch: 253 [591020/25046 (74%)]\tLoss: 1.437287\n",
            "Train epoch: 253 [609600/25046 (77%)]\tLoss: 1.176709\n",
            "Train epoch: 253 [657200/25046 (79%)]\tLoss: 1.737720\n",
            "Train epoch: 253 [652160/25046 (82%)]\tLoss: 0.574006\n",
            "Train epoch: 253 [670560/25046 (84%)]\tLoss: 0.771145\n",
            "Train epoch: 253 [733720/25046 (87%)]\tLoss: 1.213780\n",
            "Train epoch: 253 [721700/25046 (89%)]\tLoss: 1.205921\n",
            "Train epoch: 253 [758160/25046 (92%)]\tLoss: 1.115801\n",
            "Train epoch: 253 [777000/25046 (95%)]\tLoss: 1.469284\n",
            "Train epoch: 253 [825360/25046 (97%)]\tLoss: 1.485106\n",
            "Train epoch: 253 [840060/25046 (100%)]\tLoss: 0.999599\n",
            "Make prediction for 5010 samples...\n",
            "0.8018084 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 254 [0/25046 (0%)]\tLoss: 0.498649\n",
            "Train epoch: 254 [21300/25046 (3%)]\tLoss: 1.807881\n",
            "Train epoch: 254 [37920/25046 (5%)]\tLoss: 0.553734\n",
            "Train epoch: 254 [58860/25046 (8%)]\tLoss: 1.232600\n",
            "Train epoch: 254 [81680/25046 (10%)]\tLoss: 0.286465\n",
            "Train epoch: 254 [104400/25046 (13%)]\tLoss: 0.658000\n",
            "Train epoch: 254 [122760/25046 (15%)]\tLoss: 0.833857\n",
            "Train epoch: 254 [142240/25046 (18%)]\tLoss: 0.686478\n",
            "Train epoch: 254 [163520/25046 (20%)]\tLoss: 1.160211\n",
            "Train epoch: 254 [185400/25046 (23%)]\tLoss: 0.587959\n",
            "Train epoch: 254 [198200/25046 (26%)]\tLoss: 0.875534\n",
            "Train epoch: 254 [222640/25046 (28%)]\tLoss: 1.252204\n",
            "Train epoch: 254 [243360/25046 (31%)]\tLoss: 0.388408\n",
            "Train epoch: 254 [245960/25046 (33%)]\tLoss: 0.961771\n",
            "Train epoch: 254 [294280/25046 (36%)]\tLoss: 0.365384\n",
            "Train epoch: 254 [307500/25046 (38%)]\tLoss: 0.727911\n",
            "Train epoch: 254 [341440/25046 (41%)]\tLoss: 0.241276\n",
            "Train epoch: 254 [371960/25046 (43%)]\tLoss: 0.684701\n",
            "Train epoch: 254 [358920/25046 (46%)]\tLoss: 0.528703\n",
            "Train epoch: 254 [389880/25046 (49%)]\tLoss: 0.954775\n",
            "Train epoch: 254 [405600/25046 (51%)]\tLoss: 0.366963\n",
            "Train epoch: 254 [451920/25046 (54%)]\tLoss: 1.038552\n",
            "Train epoch: 254 [433400/25046 (56%)]\tLoss: 0.594701\n",
            "Train epoch: 254 [438380/25046 (59%)]\tLoss: 0.706351\n",
            "Train epoch: 254 [480480/25046 (61%)]\tLoss: 1.451452\n",
            "Train epoch: 254 [506000/25046 (64%)]\tLoss: 0.925694\n",
            "Train epoch: 254 [559000/25046 (66%)]\tLoss: 0.881282\n",
            "Train epoch: 254 [572940/25046 (69%)]\tLoss: 1.111804\n",
            "Train epoch: 254 [595840/25046 (72%)]\tLoss: 1.149298\n",
            "Train epoch: 254 [548100/25046 (74%)]\tLoss: 0.319174\n",
            "Train epoch: 254 [597600/25046 (77%)]\tLoss: 0.704033\n",
            "Train epoch: 254 [636740/25046 (79%)]\tLoss: 0.573676\n",
            "Train epoch: 254 [657920/25046 (82%)]\tLoss: 0.850157\n",
            "Train epoch: 254 [666600/25046 (84%)]\tLoss: 0.787033\n",
            "Train epoch: 254 [686120/25046 (87%)]\tLoss: 0.451040\n",
            "Train epoch: 254 [674800/25046 (89%)]\tLoss: 0.667264\n",
            "Train epoch: 254 [762480/25046 (92%)]\tLoss: 0.531059\n",
            "Train epoch: 254 [754800/25046 (95%)]\tLoss: 0.713729\n",
            "Train epoch: 254 [725040/25046 (97%)]\tLoss: 1.072288\n",
            "Train epoch: 254 [807300/25046 (100%)]\tLoss: 0.686327\n",
            "Make prediction for 5010 samples...\n",
            "0.80171686 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 255 [0/25046 (0%)]\tLoss: 0.902629\n",
            "Train epoch: 255 [20500/25046 (3%)]\tLoss: 0.546509\n",
            "Train epoch: 255 [40480/25046 (5%)]\tLoss: 0.664773\n",
            "Train epoch: 255 [60720/25046 (8%)]\tLoss: 0.492375\n",
            "Train epoch: 255 [84240/25046 (10%)]\tLoss: 1.068745\n",
            "Train epoch: 255 [102400/25046 (13%)]\tLoss: 0.760450\n",
            "Train epoch: 255 [124320/25046 (15%)]\tLoss: 0.589633\n",
            "Train epoch: 255 [140420/25046 (18%)]\tLoss: 0.729553\n",
            "Train epoch: 255 [160960/25046 (20%)]\tLoss: 0.344669\n",
            "Train epoch: 255 [181620/25046 (23%)]\tLoss: 0.780874\n",
            "Train epoch: 255 [203800/25046 (26%)]\tLoss: 1.136368\n",
            "Train epoch: 255 [227040/25046 (28%)]\tLoss: 0.488475\n",
            "Train epoch: 255 [257760/25046 (31%)]\tLoss: 0.752062\n",
            "Train epoch: 255 [258700/25046 (33%)]\tLoss: 1.213154\n",
            "Train epoch: 255 [277760/25046 (36%)]\tLoss: 1.583946\n",
            "Train epoch: 255 [300300/25046 (38%)]\tLoss: 0.542475\n",
            "Train epoch: 255 [325760/25046 (41%)]\tLoss: 0.811086\n",
            "Train epoch: 255 [318240/25046 (43%)]\tLoss: 0.517931\n",
            "Train epoch: 255 [395280/25046 (46%)]\tLoss: 0.692639\n",
            "Train epoch: 255 [380760/25046 (49%)]\tLoss: 1.103982\n",
            "Train epoch: 255 [415600/25046 (51%)]\tLoss: 0.717015\n",
            "Train epoch: 255 [446040/25046 (54%)]\tLoss: 0.854250\n",
            "Train epoch: 255 [425920/25046 (56%)]\tLoss: 0.717425\n",
            "Train epoch: 255 [442060/25046 (59%)]\tLoss: 0.650026\n",
            "Train epoch: 255 [492000/25046 (61%)]\tLoss: 0.341282\n",
            "Train epoch: 255 [513500/25046 (64%)]\tLoss: 0.958942\n",
            "Train epoch: 255 [545480/25046 (66%)]\tLoss: 0.667297\n",
            "Train epoch: 255 [581580/25046 (69%)]\tLoss: 1.083200\n",
            "Train epoch: 255 [574000/25046 (72%)]\tLoss: 0.939394\n",
            "Train epoch: 255 [585220/25046 (74%)]\tLoss: 0.844611\n",
            "Train epoch: 255 [622800/25046 (77%)]\tLoss: 1.267239\n",
            "Train epoch: 255 [607600/25046 (79%)]\tLoss: 0.592374\n",
            "Train epoch: 255 [640000/25046 (82%)]\tLoss: 1.383104\n",
            "Train epoch: 255 [683760/25046 (84%)]\tLoss: 1.361839\n",
            "Train epoch: 255 [718080/25046 (87%)]\tLoss: 0.872527\n",
            "Train epoch: 255 [700000/25046 (89%)]\tLoss: 1.093277\n",
            "Train epoch: 255 [744480/25046 (92%)]\tLoss: 1.555061\n",
            "Train epoch: 255 [782180/25046 (95%)]\tLoss: 1.349696\n",
            "Train epoch: 255 [808640/25046 (97%)]\tLoss: 1.037480\n",
            "Train epoch: 255 [857220/25046 (100%)]\tLoss: 0.961460\n",
            "Make prediction for 5010 samples...\n",
            "0.80194795 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 256 [0/25046 (0%)]\tLoss: 0.708587\n",
            "Train epoch: 256 [21220/25046 (3%)]\tLoss: 0.817441\n",
            "Train epoch: 256 [41640/25046 (5%)]\tLoss: 1.021684\n",
            "Train epoch: 256 [64020/25046 (8%)]\tLoss: 0.594564\n",
            "Train epoch: 256 [82160/25046 (10%)]\tLoss: 0.799456\n",
            "Train epoch: 256 [104600/25046 (13%)]\tLoss: 1.023427\n",
            "Train epoch: 256 [126120/25046 (15%)]\tLoss: 0.387156\n",
            "Train epoch: 256 [145320/25046 (18%)]\tLoss: 0.748754\n",
            "Train epoch: 256 [162080/25046 (20%)]\tLoss: 0.871325\n",
            "Train epoch: 256 [193140/25046 (23%)]\tLoss: 0.788202\n",
            "Train epoch: 256 [203800/25046 (26%)]\tLoss: 1.421113\n",
            "Train epoch: 256 [220880/25046 (28%)]\tLoss: 0.211968\n",
            "Train epoch: 256 [256800/25046 (31%)]\tLoss: 1.479919\n",
            "Train epoch: 256 [262340/25046 (33%)]\tLoss: 0.767359\n",
            "Train epoch: 256 [267680/25046 (36%)]\tLoss: 0.842936\n",
            "Train epoch: 256 [302100/25046 (38%)]\tLoss: 0.699982\n",
            "Train epoch: 256 [337920/25046 (41%)]\tLoss: 0.362613\n",
            "Train epoch: 256 [351220/25046 (43%)]\tLoss: 0.387554\n",
            "Train epoch: 256 [379800/25046 (46%)]\tLoss: 0.652456\n",
            "Train epoch: 256 [395960/25046 (49%)]\tLoss: 1.149688\n",
            "Train epoch: 256 [417600/25046 (51%)]\tLoss: 1.351496\n",
            "Train epoch: 256 [436800/25046 (54%)]\tLoss: 1.580039\n",
            "Train epoch: 256 [465080/25046 (56%)]\tLoss: 1.711969\n",
            "Train epoch: 256 [446200/25046 (59%)]\tLoss: 0.914650\n",
            "Train epoch: 256 [519840/25046 (61%)]\tLoss: 0.719883\n",
            "Train epoch: 256 [523000/25046 (64%)]\tLoss: 1.029701\n",
            "Train epoch: 256 [554320/25046 (66%)]\tLoss: 0.532283\n",
            "Train epoch: 256 [517320/25046 (69%)]\tLoss: 0.594388\n",
            "Train epoch: 256 [574000/25046 (72%)]\tLoss: 0.332567\n",
            "Train epoch: 256 [603780/25046 (74%)]\tLoss: 1.240418\n",
            "Train epoch: 256 [626400/25046 (77%)]\tLoss: 0.970554\n",
            "Train epoch: 256 [574120/25046 (79%)]\tLoss: 0.602109\n",
            "Train epoch: 256 [636160/25046 (82%)]\tLoss: 0.928544\n",
            "Train epoch: 256 [672540/25046 (84%)]\tLoss: 1.528105\n",
            "Train epoch: 256 [708560/25046 (87%)]\tLoss: 0.558614\n",
            "Train epoch: 256 [728000/25046 (89%)]\tLoss: 1.198279\n",
            "Train epoch: 256 [766080/25046 (92%)]\tLoss: 1.454692\n",
            "Train epoch: 256 [796980/25046 (95%)]\tLoss: 0.731840\n",
            "Train epoch: 256 [746320/25046 (97%)]\tLoss: 0.272588\n",
            "Train epoch: 256 [828360/25046 (100%)]\tLoss: 1.278419\n",
            "Make prediction for 5010 samples...\n",
            "0.8048253 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 257 [0/25046 (0%)]\tLoss: 0.520097\n",
            "Train epoch: 257 [19020/25046 (3%)]\tLoss: 0.484872\n",
            "Train epoch: 257 [42160/25046 (5%)]\tLoss: 0.391916\n",
            "Train epoch: 257 [64140/25046 (8%)]\tLoss: 1.059610\n",
            "Train epoch: 257 [77920/25046 (10%)]\tLoss: 0.783782\n",
            "Train epoch: 257 [104600/25046 (13%)]\tLoss: 1.101571\n",
            "Train epoch: 257 [128040/25046 (15%)]\tLoss: 0.688329\n",
            "Train epoch: 257 [151060/25046 (18%)]\tLoss: 1.079647\n",
            "Train epoch: 257 [163040/25046 (20%)]\tLoss: 1.672266\n",
            "Train epoch: 257 [173880/25046 (23%)]\tLoss: 1.094048\n",
            "Train epoch: 257 [215600/25046 (26%)]\tLoss: 1.421280\n",
            "Train epoch: 257 [219560/25046 (28%)]\tLoss: 0.324050\n",
            "Train epoch: 257 [239760/25046 (31%)]\tLoss: 0.967067\n",
            "Train epoch: 257 [258960/25046 (33%)]\tLoss: 0.953721\n",
            "Train epoch: 257 [296800/25046 (36%)]\tLoss: 0.704883\n",
            "Train epoch: 257 [298200/25046 (38%)]\tLoss: 0.247219\n",
            "Train epoch: 257 [305600/25046 (41%)]\tLoss: 0.755101\n",
            "Train epoch: 257 [330140/25046 (43%)]\tLoss: 1.816682\n",
            "Train epoch: 257 [379080/25046 (46%)]\tLoss: 1.222106\n",
            "Train epoch: 257 [416480/25046 (49%)]\tLoss: 0.358623\n",
            "Train epoch: 257 [422000/25046 (51%)]\tLoss: 1.223387\n",
            "Train epoch: 257 [435960/25046 (54%)]\tLoss: 0.348492\n",
            "Train epoch: 257 [449240/25046 (56%)]\tLoss: 1.538594\n",
            "Train epoch: 257 [455860/25046 (59%)]\tLoss: 0.557986\n",
            "Train epoch: 257 [516960/25046 (61%)]\tLoss: 0.410935\n",
            "Train epoch: 257 [526500/25046 (64%)]\tLoss: 1.182163\n",
            "Train epoch: 257 [494000/25046 (66%)]\tLoss: 0.842883\n",
            "Train epoch: 257 [516780/25046 (69%)]\tLoss: 0.614726\n",
            "Train epoch: 257 [510720/25046 (72%)]\tLoss: 0.752173\n",
            "Train epoch: 257 [607260/25046 (74%)]\tLoss: 0.577348\n",
            "Train epoch: 257 [598800/25046 (77%)]\tLoss: 0.653118\n",
            "Train epoch: 257 [664020/25046 (79%)]\tLoss: 1.121138\n",
            "Train epoch: 257 [659840/25046 (82%)]\tLoss: 0.615115\n",
            "Train epoch: 257 [661320/25046 (84%)]\tLoss: 0.372725\n",
            "Train epoch: 257 [703800/25046 (87%)]\tLoss: 0.372645\n",
            "Train epoch: 257 [658000/25046 (89%)]\tLoss: 0.461660\n",
            "Train epoch: 257 [740880/25046 (92%)]\tLoss: 0.917068\n",
            "Train epoch: 257 [705960/25046 (95%)]\tLoss: 1.195780\n",
            "Train epoch: 257 [791920/25046 (97%)]\tLoss: 0.961768\n",
            "Train epoch: 257 [833040/25046 (100%)]\tLoss: 0.395094\n",
            "Make prediction for 5010 samples...\n",
            "0.8015577 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 258 [0/25046 (0%)]\tLoss: 0.949655\n",
            "Train epoch: 258 [19280/25046 (3%)]\tLoss: 1.006278\n",
            "Train epoch: 258 [41160/25046 (5%)]\tLoss: 0.456923\n",
            "Train epoch: 258 [64200/25046 (8%)]\tLoss: 1.464458\n",
            "Train epoch: 258 [81840/25046 (10%)]\tLoss: 1.700060\n",
            "Train epoch: 258 [103100/25046 (13%)]\tLoss: 0.734729\n",
            "Train epoch: 258 [117360/25046 (15%)]\tLoss: 1.265411\n",
            "Train epoch: 258 [151760/25046 (18%)]\tLoss: 0.306743\n",
            "Train epoch: 258 [160800/25046 (20%)]\tLoss: 1.046552\n",
            "Train epoch: 258 [183240/25046 (23%)]\tLoss: 1.496540\n",
            "Train epoch: 258 [215000/25046 (26%)]\tLoss: 0.429554\n",
            "Train epoch: 258 [229460/25046 (28%)]\tLoss: 0.545553\n",
            "Train epoch: 258 [249360/25046 (31%)]\tLoss: 0.798544\n",
            "Train epoch: 258 [255580/25046 (33%)]\tLoss: 2.046976\n",
            "Train epoch: 258 [285600/25046 (36%)]\tLoss: 0.589467\n",
            "Train epoch: 258 [310200/25046 (38%)]\tLoss: 0.868481\n",
            "Train epoch: 258 [344000/25046 (41%)]\tLoss: 0.716301\n",
            "Train epoch: 258 [345440/25046 (43%)]\tLoss: 0.502979\n",
            "Train epoch: 258 [365040/25046 (46%)]\tLoss: 0.720780\n",
            "Train epoch: 258 [403560/25046 (49%)]\tLoss: 0.538693\n",
            "Train epoch: 258 [398400/25046 (51%)]\tLoss: 0.505340\n",
            "Train epoch: 258 [435120/25046 (54%)]\tLoss: 0.709208\n",
            "Train epoch: 258 [436040/25046 (56%)]\tLoss: 1.511552\n",
            "Train epoch: 258 [494040/25046 (59%)]\tLoss: 0.768498\n",
            "Train epoch: 258 [515520/25046 (61%)]\tLoss: 0.954413\n",
            "Train epoch: 258 [518500/25046 (64%)]\tLoss: 1.660074\n",
            "Train epoch: 258 [528840/25046 (66%)]\tLoss: 0.328376\n",
            "Train epoch: 258 [549720/25046 (69%)]\tLoss: 1.507128\n",
            "Train epoch: 258 [578480/25046 (72%)]\tLoss: 0.651248\n",
            "Train epoch: 258 [610160/25046 (74%)]\tLoss: 0.305851\n",
            "Train epoch: 258 [605400/25046 (77%)]\tLoss: 0.498487\n",
            "Train epoch: 258 [621240/25046 (79%)]\tLoss: 0.298560\n",
            "Train epoch: 258 [671360/25046 (82%)]\tLoss: 1.970744\n",
            "Train epoch: 258 [630960/25046 (84%)]\tLoss: 0.707338\n",
            "Train epoch: 258 [707200/25046 (87%)]\tLoss: 0.260751\n",
            "Train epoch: 258 [726600/25046 (89%)]\tLoss: 1.266459\n",
            "Train epoch: 258 [738720/25046 (92%)]\tLoss: 1.592809\n",
            "Train epoch: 258 [790320/25046 (95%)]\tLoss: 0.856526\n",
            "Train epoch: 258 [794960/25046 (97%)]\tLoss: 1.182179\n",
            "Train epoch: 258 [821340/25046 (100%)]\tLoss: 0.339841\n",
            "Make prediction for 5010 samples...\n",
            "0.80151576 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 259 [0/25046 (0%)]\tLoss: 0.331021\n",
            "Train epoch: 259 [21680/25046 (3%)]\tLoss: 0.368134\n",
            "Train epoch: 259 [41120/25046 (5%)]\tLoss: 0.635197\n",
            "Train epoch: 259 [60240/25046 (8%)]\tLoss: 1.315977\n",
            "Train epoch: 259 [84960/25046 (10%)]\tLoss: 0.705146\n",
            "Train epoch: 259 [106700/25046 (13%)]\tLoss: 0.776319\n",
            "Train epoch: 259 [129840/25046 (15%)]\tLoss: 0.319880\n",
            "Train epoch: 259 [147280/25046 (18%)]\tLoss: 0.599216\n",
            "Train epoch: 259 [164320/25046 (20%)]\tLoss: 0.761994\n",
            "Train epoch: 259 [197460/25046 (23%)]\tLoss: 1.299542\n",
            "Train epoch: 259 [210000/25046 (26%)]\tLoss: 0.642182\n",
            "Train epoch: 259 [223960/25046 (28%)]\tLoss: 1.090595\n",
            "Train epoch: 259 [262320/25046 (31%)]\tLoss: 1.022935\n",
            "Train epoch: 259 [277680/25046 (33%)]\tLoss: 1.374044\n",
            "Train epoch: 259 [286160/25046 (36%)]\tLoss: 0.431471\n",
            "Train epoch: 259 [321300/25046 (38%)]\tLoss: 0.669715\n",
            "Train epoch: 259 [346880/25046 (41%)]\tLoss: 0.393270\n",
            "Train epoch: 259 [352240/25046 (43%)]\tLoss: 0.589536\n",
            "Train epoch: 259 [376560/25046 (46%)]\tLoss: 0.458493\n",
            "Train epoch: 259 [382660/25046 (49%)]\tLoss: 0.452184\n",
            "Train epoch: 259 [421600/25046 (51%)]\tLoss: 0.237163\n",
            "Train epoch: 259 [425040/25046 (54%)]\tLoss: 0.310225\n",
            "Train epoch: 259 [451000/25046 (56%)]\tLoss: 1.368149\n",
            "Train epoch: 259 [462300/25046 (59%)]\tLoss: 1.788667\n",
            "Train epoch: 259 [509760/25046 (61%)]\tLoss: 0.595051\n",
            "Train epoch: 259 [562500/25046 (64%)]\tLoss: 0.811709\n",
            "Train epoch: 259 [542880/25046 (66%)]\tLoss: 0.295495\n",
            "Train epoch: 259 [531360/25046 (69%)]\tLoss: 0.538340\n",
            "Train epoch: 259 [588560/25046 (72%)]\tLoss: 0.899425\n",
            "Train epoch: 259 [584060/25046 (74%)]\tLoss: 0.733722\n",
            "Train epoch: 259 [585000/25046 (77%)]\tLoss: 0.756623\n",
            "Train epoch: 259 [645420/25046 (79%)]\tLoss: 0.784588\n",
            "Train epoch: 259 [622080/25046 (82%)]\tLoss: 0.365001\n",
            "Train epoch: 259 [712140/25046 (84%)]\tLoss: 1.126886\n",
            "Train epoch: 259 [709920/25046 (87%)]\tLoss: 1.061926\n",
            "Train epoch: 259 [705600/25046 (89%)]\tLoss: 0.374567\n",
            "Train epoch: 259 [763920/25046 (92%)]\tLoss: 1.872941\n",
            "Train epoch: 259 [769600/25046 (95%)]\tLoss: 0.530971\n",
            "Train epoch: 259 [788120/25046 (97%)]\tLoss: 0.872362\n",
            "Train epoch: 259 [818220/25046 (100%)]\tLoss: 1.071287\n",
            "Make prediction for 5010 samples...\n",
            "0.8025088 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 260 [0/25046 (0%)]\tLoss: 0.784590\n",
            "Train epoch: 260 [20940/25046 (3%)]\tLoss: 0.476696\n",
            "Train epoch: 260 [39880/25046 (5%)]\tLoss: 1.579861\n",
            "Train epoch: 260 [60240/25046 (8%)]\tLoss: 1.283744\n",
            "Train epoch: 260 [80560/25046 (10%)]\tLoss: 0.663995\n",
            "Train epoch: 260 [102200/25046 (13%)]\tLoss: 0.905256\n",
            "Train epoch: 260 [110280/25046 (15%)]\tLoss: 0.971436\n",
            "Train epoch: 260 [141680/25046 (18%)]\tLoss: 0.496776\n",
            "Train epoch: 260 [155520/25046 (20%)]\tLoss: 0.511470\n",
            "Train epoch: 260 [185220/25046 (23%)]\tLoss: 0.822516\n",
            "Train epoch: 260 [204000/25046 (26%)]\tLoss: 0.474393\n",
            "Train epoch: 260 [229020/25046 (28%)]\tLoss: 0.349941\n",
            "Train epoch: 260 [258000/25046 (31%)]\tLoss: 1.755000\n",
            "Train epoch: 260 [272480/25046 (33%)]\tLoss: 0.394904\n",
            "Train epoch: 260 [297360/25046 (36%)]\tLoss: 0.279319\n",
            "Train epoch: 260 [288600/25046 (38%)]\tLoss: 0.493080\n",
            "Train epoch: 260 [326720/25046 (41%)]\tLoss: 0.277760\n",
            "Train epoch: 260 [320960/25046 (43%)]\tLoss: 1.226803\n",
            "Train epoch: 260 [365400/25046 (46%)]\tLoss: 0.567488\n",
            "Train epoch: 260 [378100/25046 (49%)]\tLoss: 0.520970\n",
            "Train epoch: 260 [410000/25046 (51%)]\tLoss: 0.753175\n",
            "Train epoch: 260 [436800/25046 (54%)]\tLoss: 1.258917\n",
            "Train epoch: 260 [454960/25046 (56%)]\tLoss: 1.663602\n",
            "Train epoch: 260 [440220/25046 (59%)]\tLoss: 1.157353\n",
            "Train epoch: 260 [476640/25046 (61%)]\tLoss: 0.725853\n",
            "Train epoch: 260 [528000/25046 (64%)]\tLoss: 1.033221\n",
            "Train epoch: 260 [527800/25046 (66%)]\tLoss: 0.883636\n",
            "Train epoch: 260 [569700/25046 (69%)]\tLoss: 1.342601\n",
            "Train epoch: 260 [558880/25046 (72%)]\tLoss: 0.923630\n",
            "Train epoch: 260 [592760/25046 (74%)]\tLoss: 0.570119\n",
            "Train epoch: 260 [598200/25046 (77%)]\tLoss: 1.095722\n",
            "Train epoch: 260 [615660/25046 (79%)]\tLoss: 1.087335\n",
            "Train epoch: 260 [650880/25046 (82%)]\tLoss: 1.009299\n",
            "Train epoch: 260 [703560/25046 (84%)]\tLoss: 0.562634\n",
            "Train epoch: 260 [697680/25046 (87%)]\tLoss: 1.516333\n",
            "Train epoch: 260 [671300/25046 (89%)]\tLoss: 1.043563\n",
            "Train epoch: 260 [735120/25046 (92%)]\tLoss: 1.240008\n",
            "Train epoch: 260 [760720/25046 (95%)]\tLoss: 0.557406\n",
            "Train epoch: 260 [829920/25046 (97%)]\tLoss: 0.636908\n",
            "Train epoch: 260 [795600/25046 (100%)]\tLoss: 1.174652\n",
            "Make prediction for 5010 samples...\n",
            "0.8017027 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 261 [0/25046 (0%)]\tLoss: 0.655458\n",
            "Train epoch: 261 [19040/25046 (3%)]\tLoss: 0.778129\n",
            "Train epoch: 261 [39360/25046 (5%)]\tLoss: 0.392904\n",
            "Train epoch: 261 [62880/25046 (8%)]\tLoss: 0.902766\n",
            "Train epoch: 261 [82400/25046 (10%)]\tLoss: 1.060831\n",
            "Train epoch: 261 [103000/25046 (13%)]\tLoss: 0.725290\n",
            "Train epoch: 261 [121560/25046 (15%)]\tLoss: 0.577840\n",
            "Train epoch: 261 [141400/25046 (18%)]\tLoss: 0.770343\n",
            "Train epoch: 261 [166080/25046 (20%)]\tLoss: 0.902564\n",
            "Train epoch: 261 [184680/25046 (23%)]\tLoss: 1.077984\n",
            "Train epoch: 261 [211800/25046 (26%)]\tLoss: 0.450891\n",
            "Train epoch: 261 [225280/25046 (28%)]\tLoss: 1.469733\n",
            "Train epoch: 261 [248400/25046 (31%)]\tLoss: 0.543557\n",
            "Train epoch: 261 [275860/25046 (33%)]\tLoss: 0.307871\n",
            "Train epoch: 261 [282520/25046 (36%)]\tLoss: 0.792441\n",
            "Train epoch: 261 [287100/25046 (38%)]\tLoss: 0.577228\n",
            "Train epoch: 261 [320000/25046 (41%)]\tLoss: 0.339789\n",
            "Train epoch: 261 [341360/25046 (43%)]\tLoss: 0.731894\n",
            "Train epoch: 261 [383040/25046 (46%)]\tLoss: 0.875677\n",
            "Train epoch: 261 [402800/25046 (49%)]\tLoss: 0.651938\n",
            "Train epoch: 261 [412800/25046 (51%)]\tLoss: 1.595075\n",
            "Train epoch: 261 [407820/25046 (54%)]\tLoss: 1.330190\n",
            "Train epoch: 261 [450120/25046 (56%)]\tLoss: 1.047264\n",
            "Train epoch: 261 [448500/25046 (59%)]\tLoss: 0.428771\n",
            "Train epoch: 261 [468960/25046 (61%)]\tLoss: 0.252618\n",
            "Train epoch: 261 [505500/25046 (64%)]\tLoss: 0.572676\n",
            "Train epoch: 261 [554320/25046 (66%)]\tLoss: 0.751182\n",
            "Train epoch: 261 [528120/25046 (69%)]\tLoss: 2.074413\n",
            "Train epoch: 261 [567840/25046 (72%)]\tLoss: 1.068197\n",
            "Train epoch: 261 [587540/25046 (74%)]\tLoss: 0.538095\n",
            "Train epoch: 261 [584400/25046 (77%)]\tLoss: 0.692188\n",
            "Train epoch: 261 [649140/25046 (79%)]\tLoss: 0.376554\n",
            "Train epoch: 261 [620800/25046 (82%)]\tLoss: 0.632570\n",
            "Train epoch: 261 [663300/25046 (84%)]\tLoss: 0.751324\n",
            "Train epoch: 261 [709240/25046 (87%)]\tLoss: 0.554365\n",
            "Train epoch: 261 [730100/25046 (89%)]\tLoss: 0.402676\n",
            "Train epoch: 261 [679680/25046 (92%)]\tLoss: 0.999785\n",
            "Train epoch: 261 [731120/25046 (95%)]\tLoss: 1.183830\n",
            "Train epoch: 261 [734160/25046 (97%)]\tLoss: 0.339593\n",
            "Train epoch: 261 [840060/25046 (100%)]\tLoss: 0.544726\n",
            "Make prediction for 5010 samples...\n",
            "0.8015333 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 262 [0/25046 (0%)]\tLoss: 1.582928\n",
            "Train epoch: 262 [20360/25046 (3%)]\tLoss: 1.104808\n",
            "Train epoch: 262 [41000/25046 (5%)]\tLoss: 0.574617\n",
            "Train epoch: 262 [58620/25046 (8%)]\tLoss: 0.470500\n",
            "Train epoch: 262 [78560/25046 (10%)]\tLoss: 1.174073\n",
            "Train epoch: 262 [97900/25046 (13%)]\tLoss: 0.683148\n",
            "Train epoch: 262 [125040/25046 (15%)]\tLoss: 0.652991\n",
            "Train epoch: 262 [138180/25046 (18%)]\tLoss: 0.972024\n",
            "Train epoch: 262 [170560/25046 (20%)]\tLoss: 0.812061\n",
            "Train epoch: 262 [178740/25046 (23%)]\tLoss: 0.671860\n",
            "Train epoch: 262 [204600/25046 (26%)]\tLoss: 0.869451\n",
            "Train epoch: 262 [217360/25046 (28%)]\tLoss: 1.328272\n",
            "Train epoch: 262 [247440/25046 (31%)]\tLoss: 0.356987\n",
            "Train epoch: 262 [280800/25046 (33%)]\tLoss: 0.491700\n",
            "Train epoch: 262 [280560/25046 (36%)]\tLoss: 1.120701\n",
            "Train epoch: 262 [296400/25046 (38%)]\tLoss: 0.734750\n",
            "Train epoch: 262 [320960/25046 (41%)]\tLoss: 1.424252\n",
            "Train epoch: 262 [340680/25046 (43%)]\tLoss: 0.746578\n",
            "Train epoch: 262 [372240/25046 (46%)]\tLoss: 0.479141\n",
            "Train epoch: 262 [388740/25046 (49%)]\tLoss: 1.078146\n",
            "Train epoch: 262 [412400/25046 (51%)]\tLoss: 0.343980\n",
            "Train epoch: 262 [433440/25046 (54%)]\tLoss: 0.938128\n",
            "Train epoch: 262 [447480/25046 (56%)]\tLoss: 0.589071\n",
            "Train epoch: 262 [469660/25046 (59%)]\tLoss: 0.301843\n",
            "Train epoch: 262 [505920/25046 (61%)]\tLoss: 0.326444\n",
            "Train epoch: 262 [496500/25046 (64%)]\tLoss: 0.702768\n",
            "Train epoch: 262 [521560/25046 (66%)]\tLoss: 1.075634\n",
            "Train epoch: 262 [544860/25046 (69%)]\tLoss: 0.569168\n",
            "Train epoch: 262 [539840/25046 (72%)]\tLoss: 0.644723\n",
            "Train epoch: 262 [636260/25046 (74%)]\tLoss: 0.748140\n",
            "Train epoch: 262 [607200/25046 (77%)]\tLoss: 0.587361\n",
            "Train epoch: 262 [599540/25046 (79%)]\tLoss: 1.349624\n",
            "Train epoch: 262 [650240/25046 (82%)]\tLoss: 1.101351\n",
            "Train epoch: 262 [665940/25046 (84%)]\tLoss: 0.669295\n",
            "Train epoch: 262 [680680/25046 (87%)]\tLoss: 0.901879\n",
            "Train epoch: 262 [705600/25046 (89%)]\tLoss: 1.128813\n",
            "Train epoch: 262 [728640/25046 (92%)]\tLoss: 0.540664\n",
            "Train epoch: 262 [768120/25046 (95%)]\tLoss: 0.545669\n",
            "Train epoch: 262 [769880/25046 (97%)]\tLoss: 1.600910\n",
            "Train epoch: 262 [796380/25046 (100%)]\tLoss: 0.565862\n",
            "Make prediction for 5010 samples...\n",
            "0.80454874 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 263 [0/25046 (0%)]\tLoss: 0.833314\n",
            "Train epoch: 263 [20440/25046 (3%)]\tLoss: 1.279966\n",
            "Train epoch: 263 [39160/25046 (5%)]\tLoss: 0.405585\n",
            "Train epoch: 263 [59760/25046 (8%)]\tLoss: 0.526704\n",
            "Train epoch: 263 [79520/25046 (10%)]\tLoss: 1.044085\n",
            "Train epoch: 263 [99200/25046 (13%)]\tLoss: 0.898508\n",
            "Train epoch: 263 [123600/25046 (15%)]\tLoss: 1.149472\n",
            "Train epoch: 263 [152460/25046 (18%)]\tLoss: 1.215605\n",
            "Train epoch: 263 [159520/25046 (20%)]\tLoss: 0.845345\n",
            "Train epoch: 263 [189900/25046 (23%)]\tLoss: 0.369651\n",
            "Train epoch: 263 [190400/25046 (26%)]\tLoss: 0.813435\n",
            "Train epoch: 263 [226160/25046 (28%)]\tLoss: 0.866829\n",
            "Train epoch: 263 [250560/25046 (31%)]\tLoss: 0.628924\n",
            "Train epoch: 263 [265460/25046 (33%)]\tLoss: 0.679379\n",
            "Train epoch: 263 [288120/25046 (36%)]\tLoss: 0.939021\n",
            "Train epoch: 263 [310500/25046 (38%)]\tLoss: 0.263618\n",
            "Train epoch: 263 [333440/25046 (41%)]\tLoss: 1.036161\n",
            "Train epoch: 263 [351220/25046 (43%)]\tLoss: 0.404826\n",
            "Train epoch: 263 [370800/25046 (46%)]\tLoss: 0.728472\n",
            "Train epoch: 263 [394060/25046 (49%)]\tLoss: 0.422832\n",
            "Train epoch: 263 [392800/25046 (51%)]\tLoss: 0.986668\n",
            "Train epoch: 263 [412440/25046 (54%)]\tLoss: 0.427906\n",
            "Train epoch: 263 [456720/25046 (56%)]\tLoss: 0.861658\n",
            "Train epoch: 263 [451260/25046 (59%)]\tLoss: 0.911209\n",
            "Train epoch: 263 [510240/25046 (61%)]\tLoss: 1.497191\n",
            "Train epoch: 263 [490500/25046 (64%)]\tLoss: 1.068914\n",
            "Train epoch: 263 [520000/25046 (66%)]\tLoss: 1.883471\n",
            "Train epoch: 263 [579420/25046 (69%)]\tLoss: 0.567405\n",
            "Train epoch: 263 [576800/25046 (72%)]\tLoss: 1.341364\n",
            "Train epoch: 263 [611900/25046 (74%)]\tLoss: 0.603985\n",
            "Train epoch: 263 [610200/25046 (77%)]\tLoss: 1.170363\n",
            "Train epoch: 263 [647900/25046 (79%)]\tLoss: 0.964494\n",
            "Train epoch: 263 [654720/25046 (82%)]\tLoss: 0.712372\n",
            "Train epoch: 263 [726660/25046 (84%)]\tLoss: 1.056747\n",
            "Train epoch: 263 [728280/25046 (87%)]\tLoss: 1.265020\n",
            "Train epoch: 263 [684600/25046 (89%)]\tLoss: 0.863043\n",
            "Train epoch: 263 [761040/25046 (92%)]\tLoss: 1.045705\n",
            "Train epoch: 263 [750360/25046 (95%)]\tLoss: 0.871677\n",
            "Train epoch: 263 [775200/25046 (97%)]\tLoss: 0.992001\n",
            "Train epoch: 263 [836940/25046 (100%)]\tLoss: 0.280335\n",
            "Make prediction for 5010 samples...\n",
            "0.80212873 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 264 [0/25046 (0%)]\tLoss: 0.522012\n",
            "Train epoch: 264 [22220/25046 (3%)]\tLoss: 0.300444\n",
            "Train epoch: 264 [40960/25046 (5%)]\tLoss: 0.988367\n",
            "Train epoch: 264 [60840/25046 (8%)]\tLoss: 0.777338\n",
            "Train epoch: 264 [85120/25046 (10%)]\tLoss: 0.327797\n",
            "Train epoch: 264 [99500/25046 (13%)]\tLoss: 0.562730\n",
            "Train epoch: 264 [122880/25046 (15%)]\tLoss: 0.702141\n",
            "Train epoch: 264 [148820/25046 (18%)]\tLoss: 1.345836\n",
            "Train epoch: 264 [162720/25046 (20%)]\tLoss: 0.966684\n",
            "Train epoch: 264 [180540/25046 (23%)]\tLoss: 0.405907\n",
            "Train epoch: 264 [205600/25046 (26%)]\tLoss: 0.882520\n",
            "Train epoch: 264 [223300/25046 (28%)]\tLoss: 0.519469\n",
            "Train epoch: 264 [249840/25046 (31%)]\tLoss: 0.465448\n",
            "Train epoch: 264 [272480/25046 (33%)]\tLoss: 1.163164\n",
            "Train epoch: 264 [290360/25046 (36%)]\tLoss: 1.021751\n",
            "Train epoch: 264 [321600/25046 (38%)]\tLoss: 0.751669\n",
            "Train epoch: 264 [321600/25046 (41%)]\tLoss: 0.596578\n",
            "Train epoch: 264 [357340/25046 (43%)]\tLoss: 0.749966\n",
            "Train epoch: 264 [370800/25046 (46%)]\tLoss: 0.852666\n",
            "Train epoch: 264 [372020/25046 (49%)]\tLoss: 0.376050\n",
            "Train epoch: 264 [406400/25046 (51%)]\tLoss: 0.534880\n",
            "Train epoch: 264 [433860/25046 (54%)]\tLoss: 0.334242\n",
            "Train epoch: 264 [462880/25046 (56%)]\tLoss: 0.533597\n",
            "Train epoch: 264 [455400/25046 (59%)]\tLoss: 0.703546\n",
            "Train epoch: 264 [497280/25046 (61%)]\tLoss: 1.032945\n",
            "Train epoch: 264 [535000/25046 (64%)]\tLoss: 0.816847\n",
            "Train epoch: 264 [532480/25046 (66%)]\tLoss: 0.658933\n",
            "Train epoch: 264 [527580/25046 (69%)]\tLoss: 0.842066\n",
            "Train epoch: 264 [594160/25046 (72%)]\tLoss: 1.075248\n",
            "Train epoch: 264 [587540/25046 (74%)]\tLoss: 0.466163\n",
            "Train epoch: 264 [610800/25046 (77%)]\tLoss: 0.776939\n",
            "Train epoch: 264 [626200/25046 (79%)]\tLoss: 0.655927\n",
            "Train epoch: 264 [702080/25046 (82%)]\tLoss: 0.757165\n",
            "Train epoch: 264 [674520/25046 (84%)]\tLoss: 1.186002\n",
            "Train epoch: 264 [692240/25046 (87%)]\tLoss: 0.719312\n",
            "Train epoch: 264 [711900/25046 (89%)]\tLoss: 0.859915\n",
            "Train epoch: 264 [767520/25046 (92%)]\tLoss: 0.298590\n",
            "Train epoch: 264 [791060/25046 (95%)]\tLoss: 0.824431\n",
            "Train epoch: 264 [791160/25046 (97%)]\tLoss: 0.777838\n",
            "Train epoch: 264 [815880/25046 (100%)]\tLoss: 0.696922\n",
            "Make prediction for 5010 samples...\n",
            "0.801938 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 265 [0/25046 (0%)]\tLoss: 0.685065\n",
            "Train epoch: 265 [20600/25046 (3%)]\tLoss: 0.329600\n",
            "Train epoch: 265 [40120/25046 (5%)]\tLoss: 0.597671\n",
            "Train epoch: 265 [62880/25046 (8%)]\tLoss: 0.472212\n",
            "Train epoch: 265 [80080/25046 (10%)]\tLoss: 1.594905\n",
            "Train epoch: 265 [103500/25046 (13%)]\tLoss: 0.376938\n",
            "Train epoch: 265 [132720/25046 (15%)]\tLoss: 1.158613\n",
            "Train epoch: 265 [136780/25046 (18%)]\tLoss: 0.273283\n",
            "Train epoch: 265 [173440/25046 (20%)]\tLoss: 1.650729\n",
            "Train epoch: 265 [186120/25046 (23%)]\tLoss: 0.646208\n",
            "Train epoch: 265 [197200/25046 (26%)]\tLoss: 0.327219\n",
            "Train epoch: 265 [229240/25046 (28%)]\tLoss: 0.910595\n",
            "Train epoch: 265 [248640/25046 (31%)]\tLoss: 1.007699\n",
            "Train epoch: 265 [263120/25046 (33%)]\tLoss: 0.767179\n",
            "Train epoch: 265 [278880/25046 (36%)]\tLoss: 0.519035\n",
            "Train epoch: 265 [298500/25046 (38%)]\tLoss: 0.767531\n",
            "Train epoch: 265 [330560/25046 (41%)]\tLoss: 0.345357\n",
            "Train epoch: 265 [360400/25046 (43%)]\tLoss: 0.418370\n",
            "Train epoch: 265 [369000/25046 (46%)]\tLoss: 0.360294\n",
            "Train epoch: 265 [418760/25046 (49%)]\tLoss: 0.703628\n",
            "Train epoch: 265 [410800/25046 (51%)]\tLoss: 0.864630\n",
            "Train epoch: 265 [445200/25046 (54%)]\tLoss: 0.542834\n",
            "Train epoch: 265 [455400/25046 (56%)]\tLoss: 0.405784\n",
            "Train epoch: 265 [454020/25046 (59%)]\tLoss: 1.130006\n",
            "Train epoch: 265 [456000/25046 (61%)]\tLoss: 0.384713\n",
            "Train epoch: 265 [508000/25046 (64%)]\tLoss: 0.679425\n",
            "Train epoch: 265 [540280/25046 (66%)]\tLoss: 1.200630\n",
            "Train epoch: 265 [516780/25046 (69%)]\tLoss: 0.318911\n",
            "Train epoch: 265 [562800/25046 (72%)]\tLoss: 1.237973\n",
            "Train epoch: 265 [591020/25046 (74%)]\tLoss: 0.518778\n",
            "Train epoch: 265 [621600/25046 (77%)]\tLoss: 1.500470\n",
            "Train epoch: 265 [664640/25046 (79%)]\tLoss: 1.780724\n",
            "Train epoch: 265 [677120/25046 (82%)]\tLoss: 0.594696\n",
            "Train epoch: 265 [667260/25046 (84%)]\tLoss: 1.487530\n",
            "Train epoch: 265 [670480/25046 (87%)]\tLoss: 0.478037\n",
            "Train epoch: 265 [699300/25046 (89%)]\tLoss: 0.649547\n",
            "Train epoch: 265 [760320/25046 (92%)]\tLoss: 0.282233\n",
            "Train epoch: 265 [728160/25046 (95%)]\tLoss: 1.705728\n",
            "Train epoch: 265 [785840/25046 (97%)]\tLoss: 0.971618\n",
            "Train epoch: 265 [818220/25046 (100%)]\tLoss: 0.707418\n",
            "Make prediction for 5010 samples...\n",
            "0.8029742 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 266 [0/25046 (0%)]\tLoss: 0.763211\n",
            "Train epoch: 266 [22260/25046 (3%)]\tLoss: 1.350429\n",
            "Train epoch: 266 [41880/25046 (5%)]\tLoss: 1.179466\n",
            "Train epoch: 266 [60720/25046 (8%)]\tLoss: 0.643258\n",
            "Train epoch: 266 [80880/25046 (10%)]\tLoss: 0.424828\n",
            "Train epoch: 266 [102100/25046 (13%)]\tLoss: 0.610184\n",
            "Train epoch: 266 [120960/25046 (15%)]\tLoss: 0.715546\n",
            "Train epoch: 266 [142240/25046 (18%)]\tLoss: 0.682913\n",
            "Train epoch: 266 [163200/25046 (20%)]\tLoss: 0.713447\n",
            "Train epoch: 266 [184500/25046 (23%)]\tLoss: 0.547133\n",
            "Train epoch: 266 [219400/25046 (26%)]\tLoss: 0.546138\n",
            "Train epoch: 266 [217800/25046 (28%)]\tLoss: 0.345062\n",
            "Train epoch: 266 [240240/25046 (31%)]\tLoss: 0.819753\n",
            "Train epoch: 266 [263380/25046 (33%)]\tLoss: 0.385228\n",
            "Train epoch: 266 [284480/25046 (36%)]\tLoss: 0.323153\n",
            "Train epoch: 266 [312900/25046 (38%)]\tLoss: 1.299714\n",
            "Train epoch: 266 [331840/25046 (41%)]\tLoss: 0.644500\n",
            "Train epoch: 266 [346120/25046 (43%)]\tLoss: 0.271030\n",
            "Train epoch: 266 [383040/25046 (46%)]\tLoss: 0.969716\n",
            "Train epoch: 266 [383420/25046 (49%)]\tLoss: 0.846885\n",
            "Train epoch: 266 [436000/25046 (51%)]\tLoss: 0.617239\n",
            "Train epoch: 266 [436800/25046 (54%)]\tLoss: 0.734473\n",
            "Train epoch: 266 [426360/25046 (56%)]\tLoss: 1.025430\n",
            "Train epoch: 266 [491280/25046 (59%)]\tLoss: 0.778813\n",
            "Train epoch: 266 [487680/25046 (61%)]\tLoss: 0.956146\n",
            "Train epoch: 266 [490000/25046 (64%)]\tLoss: 0.488129\n",
            "Train epoch: 266 [544960/25046 (66%)]\tLoss: 1.212620\n",
            "Train epoch: 266 [570240/25046 (69%)]\tLoss: 0.630839\n",
            "Train epoch: 266 [597520/25046 (72%)]\tLoss: 0.274262\n",
            "Train epoch: 266 [598560/25046 (74%)]\tLoss: 0.727870\n",
            "Train epoch: 266 [630000/25046 (77%)]\tLoss: 0.729315\n",
            "Train epoch: 266 [661540/25046 (79%)]\tLoss: 0.219376\n",
            "Train epoch: 266 [668160/25046 (82%)]\tLoss: 0.560395\n",
            "Train epoch: 266 [656040/25046 (84%)]\tLoss: 0.719719\n",
            "Train epoch: 266 [727600/25046 (87%)]\tLoss: 0.520876\n",
            "Train epoch: 266 [702100/25046 (89%)]\tLoss: 0.478561\n",
            "Train epoch: 266 [741600/25046 (92%)]\tLoss: 1.088883\n",
            "Train epoch: 266 [782920/25046 (95%)]\tLoss: 0.746637\n",
            "Train epoch: 266 [760000/25046 (97%)]\tLoss: 1.705256\n",
            "Train epoch: 266 [816660/25046 (100%)]\tLoss: 1.263644\n",
            "Make prediction for 5010 samples...\n",
            "0.80151796 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 267 [0/25046 (0%)]\tLoss: 0.689031\n",
            "Train epoch: 267 [20880/25046 (3%)]\tLoss: 0.825813\n",
            "Train epoch: 267 [41120/25046 (5%)]\tLoss: 1.035386\n",
            "Train epoch: 267 [64620/25046 (8%)]\tLoss: 0.856408\n",
            "Train epoch: 267 [81920/25046 (10%)]\tLoss: 0.342379\n",
            "Train epoch: 267 [101600/25046 (13%)]\tLoss: 0.460615\n",
            "Train epoch: 267 [121200/25046 (15%)]\tLoss: 0.284141\n",
            "Train epoch: 267 [149520/25046 (18%)]\tLoss: 1.342338\n",
            "Train epoch: 267 [156640/25046 (20%)]\tLoss: 0.409441\n",
            "Train epoch: 267 [188460/25046 (23%)]\tLoss: 0.941065\n",
            "Train epoch: 267 [201600/25046 (26%)]\tLoss: 1.081121\n",
            "Train epoch: 267 [225280/25046 (28%)]\tLoss: 0.464752\n",
            "Train epoch: 267 [241440/25046 (31%)]\tLoss: 1.173178\n",
            "Train epoch: 267 [269100/25046 (33%)]\tLoss: 0.743550\n",
            "Train epoch: 267 [301280/25046 (36%)]\tLoss: 0.930838\n",
            "Train epoch: 267 [315000/25046 (38%)]\tLoss: 2.159307\n",
            "Train epoch: 267 [313280/25046 (41%)]\tLoss: 0.641471\n",
            "Train epoch: 267 [353600/25046 (43%)]\tLoss: 0.721069\n",
            "Train epoch: 267 [364680/25046 (46%)]\tLoss: 1.317521\n",
            "Train epoch: 267 [375820/25046 (49%)]\tLoss: 0.414816\n",
            "Train epoch: 267 [388800/25046 (51%)]\tLoss: 0.436677\n",
            "Train epoch: 267 [441420/25046 (54%)]\tLoss: 0.630503\n",
            "Train epoch: 267 [480920/25046 (56%)]\tLoss: 0.222052\n",
            "Train epoch: 267 [463680/25046 (59%)]\tLoss: 0.552009\n",
            "Train epoch: 267 [491040/25046 (61%)]\tLoss: 0.763622\n",
            "Train epoch: 267 [521000/25046 (64%)]\tLoss: 0.954293\n",
            "Train epoch: 267 [526760/25046 (66%)]\tLoss: 0.382339\n",
            "Train epoch: 267 [564840/25046 (69%)]\tLoss: 0.381869\n",
            "Train epoch: 267 [562800/25046 (72%)]\tLoss: 0.814270\n",
            "Train epoch: 267 [621180/25046 (74%)]\tLoss: 0.959925\n",
            "Train epoch: 267 [630000/25046 (77%)]\tLoss: 0.332494\n",
            "Train epoch: 267 [627440/25046 (79%)]\tLoss: 1.338030\n",
            "Train epoch: 267 [654080/25046 (82%)]\tLoss: 0.804233\n",
            "Train epoch: 267 [691020/25046 (84%)]\tLoss: 0.397297\n",
            "Train epoch: 267 [701080/25046 (87%)]\tLoss: 0.677497\n",
            "Train epoch: 267 [757400/25046 (89%)]\tLoss: 0.535096\n",
            "Train epoch: 267 [717840/25046 (92%)]\tLoss: 1.251816\n",
            "Train epoch: 267 [735560/25046 (95%)]\tLoss: 0.809499\n",
            "Train epoch: 267 [750880/25046 (97%)]\tLoss: 1.180872\n",
            "Train epoch: 267 [802620/25046 (100%)]\tLoss: 0.632545\n",
            "Make prediction for 5010 samples...\n",
            "0.80211455 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 268 [0/25046 (0%)]\tLoss: 0.371107\n",
            "Train epoch: 268 [19940/25046 (3%)]\tLoss: 0.946022\n",
            "Train epoch: 268 [38760/25046 (5%)]\tLoss: 0.522237\n",
            "Train epoch: 268 [61200/25046 (8%)]\tLoss: 0.678219\n",
            "Train epoch: 268 [81440/25046 (10%)]\tLoss: 1.243766\n",
            "Train epoch: 268 [105700/25046 (13%)]\tLoss: 1.121588\n",
            "Train epoch: 268 [118560/25046 (15%)]\tLoss: 1.132756\n",
            "Train epoch: 268 [141680/25046 (18%)]\tLoss: 0.266069\n",
            "Train epoch: 268 [160480/25046 (20%)]\tLoss: 1.232281\n",
            "Train epoch: 268 [180000/25046 (23%)]\tLoss: 0.295503\n",
            "Train epoch: 268 [207000/25046 (26%)]\tLoss: 0.468362\n",
            "Train epoch: 268 [228140/25046 (28%)]\tLoss: 0.844438\n",
            "Train epoch: 268 [254640/25046 (31%)]\tLoss: 0.343049\n",
            "Train epoch: 268 [286260/25046 (33%)]\tLoss: 0.714227\n",
            "Train epoch: 268 [308280/25046 (36%)]\tLoss: 0.568920\n",
            "Train epoch: 268 [295200/25046 (38%)]\tLoss: 0.861017\n",
            "Train epoch: 268 [316480/25046 (41%)]\tLoss: 0.884304\n",
            "Train epoch: 268 [354280/25046 (43%)]\tLoss: 0.588243\n",
            "Train epoch: 268 [382320/25046 (46%)]\tLoss: 0.846745\n",
            "Train epoch: 268 [399380/25046 (49%)]\tLoss: 1.220307\n",
            "Train epoch: 268 [381200/25046 (51%)]\tLoss: 0.412520\n",
            "Train epoch: 268 [437640/25046 (54%)]\tLoss: 1.055567\n",
            "Train epoch: 268 [438240/25046 (56%)]\tLoss: 0.658345\n",
            "Train epoch: 268 [472880/25046 (59%)]\tLoss: 0.696043\n",
            "Train epoch: 268 [475680/25046 (61%)]\tLoss: 0.628589\n",
            "Train epoch: 268 [526500/25046 (64%)]\tLoss: 0.662732\n",
            "Train epoch: 268 [565240/25046 (66%)]\tLoss: 0.520901\n",
            "Train epoch: 268 [584820/25046 (69%)]\tLoss: 0.374226\n",
            "Train epoch: 268 [608720/25046 (72%)]\tLoss: 0.918769\n",
            "Train epoch: 268 [606680/25046 (74%)]\tLoss: 0.544924\n",
            "Train epoch: 268 [619200/25046 (77%)]\tLoss: 0.850792\n",
            "Train epoch: 268 [642320/25046 (79%)]\tLoss: 0.642281\n",
            "Train epoch: 268 [644480/25046 (82%)]\tLoss: 1.747101\n",
            "Train epoch: 268 [677820/25046 (84%)]\tLoss: 0.659113\n",
            "Train epoch: 268 [707880/25046 (87%)]\tLoss: 0.723217\n",
            "Train epoch: 268 [686700/25046 (89%)]\tLoss: 0.484280\n",
            "Train epoch: 268 [708480/25046 (92%)]\tLoss: 0.831606\n",
            "Train epoch: 268 [788840/25046 (95%)]\tLoss: 1.508937\n",
            "Train epoch: 268 [780520/25046 (97%)]\tLoss: 0.765150\n",
            "Train epoch: 268 [797940/25046 (100%)]\tLoss: 0.709614\n",
            "Make prediction for 5010 samples...\n",
            "0.8015546 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 269 [0/25046 (0%)]\tLoss: 0.586141\n",
            "Train epoch: 269 [19200/25046 (3%)]\tLoss: 1.463561\n",
            "Train epoch: 269 [43960/25046 (5%)]\tLoss: 0.401928\n",
            "Train epoch: 269 [58080/25046 (8%)]\tLoss: 1.157610\n",
            "Train epoch: 269 [81280/25046 (10%)]\tLoss: 0.175455\n",
            "Train epoch: 269 [105600/25046 (13%)]\tLoss: 0.603532\n",
            "Train epoch: 269 [126840/25046 (15%)]\tLoss: 0.985614\n",
            "Train epoch: 269 [154700/25046 (18%)]\tLoss: 0.380817\n",
            "Train epoch: 269 [157600/25046 (20%)]\tLoss: 0.922397\n",
            "Train epoch: 269 [192240/25046 (23%)]\tLoss: 1.474702\n",
            "Train epoch: 269 [206800/25046 (26%)]\tLoss: 1.247598\n",
            "Train epoch: 269 [230340/25046 (28%)]\tLoss: 0.286245\n",
            "Train epoch: 269 [255600/25046 (31%)]\tLoss: 1.541242\n",
            "Train epoch: 269 [261560/25046 (33%)]\tLoss: 1.497810\n",
            "Train epoch: 269 [290640/25046 (36%)]\tLoss: 0.871473\n",
            "Train epoch: 269 [311400/25046 (38%)]\tLoss: 1.156396\n",
            "Train epoch: 269 [331200/25046 (41%)]\tLoss: 1.120388\n",
            "Train epoch: 269 [355640/25046 (43%)]\tLoss: 0.377156\n",
            "Train epoch: 269 [356760/25046 (46%)]\tLoss: 0.340464\n",
            "Train epoch: 269 [391020/25046 (49%)]\tLoss: 0.516771\n",
            "Train epoch: 269 [411600/25046 (51%)]\tLoss: 0.441273\n",
            "Train epoch: 269 [449820/25046 (54%)]\tLoss: 1.637921\n",
            "Train epoch: 269 [432520/25046 (56%)]\tLoss: 0.490069\n",
            "Train epoch: 269 [452180/25046 (59%)]\tLoss: 0.753236\n",
            "Train epoch: 269 [511200/25046 (61%)]\tLoss: 1.282588\n",
            "Train epoch: 269 [490000/25046 (64%)]\tLoss: 0.401352\n",
            "Train epoch: 269 [564200/25046 (66%)]\tLoss: 0.765070\n",
            "Train epoch: 269 [531360/25046 (69%)]\tLoss: 0.792360\n",
            "Train epoch: 269 [574560/25046 (72%)]\tLoss: 0.618116\n",
            "Train epoch: 269 [564920/25046 (74%)]\tLoss: 0.603731\n",
            "Train epoch: 269 [666600/25046 (77%)]\tLoss: 0.832516\n",
            "Train epoch: 269 [623100/25046 (79%)]\tLoss: 0.961250\n",
            "Train epoch: 269 [676480/25046 (82%)]\tLoss: 1.240999\n",
            "Train epoch: 269 [696300/25046 (84%)]\tLoss: 1.281187\n",
            "Train epoch: 269 [709240/25046 (87%)]\tLoss: 1.159746\n",
            "Train epoch: 269 [719600/25046 (89%)]\tLoss: 0.659887\n",
            "Train epoch: 269 [738720/25046 (92%)]\tLoss: 0.474523\n",
            "Train epoch: 269 [780700/25046 (95%)]\tLoss: 0.526552\n",
            "Train epoch: 269 [776720/25046 (97%)]\tLoss: 0.863361\n",
            "Train epoch: 269 [800280/25046 (100%)]\tLoss: 0.765853\n",
            "Make prediction for 5010 samples...\n",
            "0.8024515 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 270 [0/25046 (0%)]\tLoss: 0.609888\n",
            "Train epoch: 270 [20720/25046 (3%)]\tLoss: 0.479898\n",
            "Train epoch: 270 [40680/25046 (5%)]\tLoss: 0.918145\n",
            "Train epoch: 270 [61380/25046 (8%)]\tLoss: 1.330436\n",
            "Train epoch: 270 [80720/25046 (10%)]\tLoss: 0.833262\n",
            "Train epoch: 270 [101500/25046 (13%)]\tLoss: 0.583645\n",
            "Train epoch: 270 [121200/25046 (15%)]\tLoss: 1.433766\n",
            "Train epoch: 270 [145600/25046 (18%)]\tLoss: 0.662982\n",
            "Train epoch: 270 [162880/25046 (20%)]\tLoss: 0.456641\n",
            "Train epoch: 270 [180540/25046 (23%)]\tLoss: 0.669054\n",
            "Train epoch: 270 [208200/25046 (26%)]\tLoss: 0.644784\n",
            "Train epoch: 270 [230340/25046 (28%)]\tLoss: 0.939887\n",
            "Train epoch: 270 [240960/25046 (31%)]\tLoss: 1.500778\n",
            "Train epoch: 270 [264420/25046 (33%)]\tLoss: 0.873473\n",
            "Train epoch: 270 [295960/25046 (36%)]\tLoss: 0.293064\n",
            "Train epoch: 270 [311100/25046 (38%)]\tLoss: 0.700252\n",
            "Train epoch: 270 [321600/25046 (41%)]\tLoss: 0.999682\n",
            "Train epoch: 270 [347480/25046 (43%)]\tLoss: 0.993392\n",
            "Train epoch: 270 [366120/25046 (46%)]\tLoss: 0.328922\n",
            "Train epoch: 270 [391020/25046 (49%)]\tLoss: 0.903047\n",
            "Train epoch: 270 [396800/25046 (51%)]\tLoss: 1.518099\n",
            "Train epoch: 270 [399420/25046 (54%)]\tLoss: 0.420291\n",
            "Train epoch: 270 [435160/25046 (56%)]\tLoss: 0.750056\n",
            "Train epoch: 270 [471960/25046 (59%)]\tLoss: 0.380484\n",
            "Train epoch: 270 [471840/25046 (61%)]\tLoss: 0.180694\n",
            "Train epoch: 270 [528500/25046 (64%)]\tLoss: 1.464070\n",
            "Train epoch: 270 [497640/25046 (66%)]\tLoss: 0.414216\n",
            "Train epoch: 270 [554580/25046 (69%)]\tLoss: 0.773060\n",
            "Train epoch: 270 [585760/25046 (72%)]\tLoss: 0.828971\n",
            "Train epoch: 270 [573040/25046 (74%)]\tLoss: 1.511516\n",
            "Train epoch: 270 [601800/25046 (77%)]\tLoss: 0.555999\n",
            "Train epoch: 270 [616280/25046 (79%)]\tLoss: 0.749894\n",
            "Train epoch: 270 [623360/25046 (82%)]\tLoss: 1.185852\n",
            "Train epoch: 270 [691680/25046 (84%)]\tLoss: 0.653299\n",
            "Train epoch: 270 [650080/25046 (87%)]\tLoss: 0.843779\n",
            "Train epoch: 270 [729400/25046 (89%)]\tLoss: 2.467882\n",
            "Train epoch: 270 [747360/25046 (92%)]\tLoss: 0.975908\n",
            "Train epoch: 270 [743700/25046 (95%)]\tLoss: 1.133984\n",
            "Train epoch: 270 [774440/25046 (97%)]\tLoss: 1.480019\n",
            "Train epoch: 270 [838500/25046 (100%)]\tLoss: 0.764181\n",
            "Make prediction for 5010 samples...\n",
            "\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training.py 0 2 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_NkLgojhYXl",
        "outputId": "29ada1da-0089-44cb-c41c-639074d5fdfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train epoch: 100 [0/25046 (0%)]\tLoss: 0.162615\n",
            "Train epoch: 100 [82760/25046 (10%)]\tLoss: 0.116393\n",
            "Train epoch: 100 [169520/25046 (20%)]\tLoss: 0.131716\n",
            "Train epoch: 100 [254400/25046 (31%)]\tLoss: 0.129486\n",
            "Train epoch: 100 [334800/25046 (41%)]\tLoss: 0.102472\n",
            "Train epoch: 100 [404300/25046 (51%)]\tLoss: 0.095708\n",
            "Train epoch: 100 [486960/25046 (61%)]\tLoss: 0.065528\n",
            "Train epoch: 100 [581000/25046 (71%)]\tLoss: 0.118937\n",
            "Train epoch: 100 [635680/25046 (82%)]\tLoss: 0.065618\n",
            "Train epoch: 100 [730800/25046 (92%)]\tLoss: 0.076272\n",
            "Make prediction for 5010 samples...\n",
            "0.27119195 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 101 [0/25046 (0%)]\tLoss: 0.083725\n",
            "Train epoch: 101 [81960/25046 (10%)]\tLoss: 0.070963\n",
            "Train epoch: 101 [165080/25046 (20%)]\tLoss: 0.082780\n",
            "Train epoch: 101 [243600/25046 (31%)]\tLoss: 0.117767\n",
            "Train epoch: 101 [326960/25046 (41%)]\tLoss: 0.086993\n",
            "Train epoch: 101 [412500/25046 (51%)]\tLoss: 0.120258\n",
            "Train epoch: 101 [487680/25046 (61%)]\tLoss: 0.143010\n",
            "Train epoch: 101 [563640/25046 (71%)]\tLoss: 0.080999\n",
            "Train epoch: 101 [655680/25046 (82%)]\tLoss: 0.172941\n",
            "Train epoch: 101 [762840/25046 (92%)]\tLoss: 0.071540\n",
            "Make prediction for 5010 samples...\n",
            "0.27661365 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 102 [0/25046 (0%)]\tLoss: 0.116729\n",
            "Train epoch: 102 [82320/25046 (10%)]\tLoss: 0.068555\n",
            "Train epoch: 102 [164800/25046 (20%)]\tLoss: 0.163981\n",
            "Train epoch: 102 [245100/25046 (31%)]\tLoss: 0.069140\n",
            "Train epoch: 102 [328480/25046 (41%)]\tLoss: 0.077402\n",
            "Train epoch: 102 [415500/25046 (51%)]\tLoss: 0.083769\n",
            "Train epoch: 102 [499200/25046 (61%)]\tLoss: 0.155939\n",
            "Train epoch: 102 [570080/25046 (71%)]\tLoss: 0.066529\n",
            "Train epoch: 102 [660800/25046 (82%)]\tLoss: 0.092211\n",
            "Train epoch: 102 [730800/25046 (92%)]\tLoss: 0.089158\n",
            "Make prediction for 5010 samples...\n",
            "0.2608695 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 103 [0/25046 (0%)]\tLoss: 0.090955\n",
            "Train epoch: 103 [82340/25046 (10%)]\tLoss: 0.169276\n",
            "Train epoch: 103 [163600/25046 (20%)]\tLoss: 0.102486\n",
            "Train epoch: 103 [242040/25046 (31%)]\tLoss: 0.072632\n",
            "Train epoch: 103 [328000/25046 (41%)]\tLoss: 0.156201\n",
            "Train epoch: 103 [414300/25046 (51%)]\tLoss: 0.127133\n",
            "Train epoch: 103 [490200/25046 (61%)]\tLoss: 0.076791\n",
            "Train epoch: 103 [582120/25046 (71%)]\tLoss: 0.091566\n",
            "Train epoch: 103 [634560/25046 (82%)]\tLoss: 0.066797\n",
            "Train epoch: 103 [751140/25046 (92%)]\tLoss: 0.092052\n",
            "Make prediction for 5010 samples...\n",
            "0.27001426 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 104 [0/25046 (0%)]\tLoss: 0.170730\n",
            "Train epoch: 104 [81140/25046 (10%)]\tLoss: 0.094772\n",
            "Train epoch: 104 [159080/25046 (20%)]\tLoss: 0.095137\n",
            "Train epoch: 104 [245280/25046 (31%)]\tLoss: 0.062211\n",
            "Train epoch: 104 [332240/25046 (41%)]\tLoss: 0.089839\n",
            "Train epoch: 104 [414100/25046 (51%)]\tLoss: 0.102020\n",
            "Train epoch: 104 [480720/25046 (61%)]\tLoss: 0.098784\n",
            "Train epoch: 104 [577640/25046 (71%)]\tLoss: 0.078310\n",
            "Train epoch: 104 [673600/25046 (82%)]\tLoss: 0.097218\n",
            "Train epoch: 104 [750600/25046 (92%)]\tLoss: 0.087116\n",
            "Make prediction for 5010 samples...\n",
            "0.26739225 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 105 [0/25046 (0%)]\tLoss: 0.107181\n",
            "Train epoch: 105 [80820/25046 (10%)]\tLoss: 0.078875\n",
            "Train epoch: 105 [164120/25046 (20%)]\tLoss: 0.097058\n",
            "Train epoch: 105 [244380/25046 (31%)]\tLoss: 0.068674\n",
            "Train epoch: 105 [326400/25046 (41%)]\tLoss: 0.109845\n",
            "Train epoch: 105 [417000/25046 (51%)]\tLoss: 0.083144\n",
            "Train epoch: 105 [505920/25046 (61%)]\tLoss: 0.181109\n",
            "Train epoch: 105 [577220/25046 (71%)]\tLoss: 0.079417\n",
            "Train epoch: 105 [669760/25046 (82%)]\tLoss: 0.102512\n",
            "Train epoch: 105 [727560/25046 (92%)]\tLoss: 0.113421\n",
            "Make prediction for 5010 samples...\n",
            "0.27479702 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 106 [0/25046 (0%)]\tLoss: 0.137971\n",
            "Train epoch: 106 [83760/25046 (10%)]\tLoss: 0.082766\n",
            "Train epoch: 106 [167160/25046 (20%)]\tLoss: 0.070728\n",
            "Train epoch: 106 [245280/25046 (31%)]\tLoss: 0.171455\n",
            "Train epoch: 106 [325840/25046 (41%)]\tLoss: 0.123692\n",
            "Train epoch: 106 [403700/25046 (51%)]\tLoss: 0.102702\n",
            "Train epoch: 106 [496800/25046 (61%)]\tLoss: 0.122170\n",
            "Train epoch: 106 [542360/25046 (71%)]\tLoss: 0.097224\n",
            "Train epoch: 106 [660480/25046 (82%)]\tLoss: 0.055491\n",
            "Train epoch: 106 [738540/25046 (92%)]\tLoss: 0.142097\n",
            "Make prediction for 5010 samples...\n",
            "0.29281408 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 107 [0/25046 (0%)]\tLoss: 0.122853\n",
            "Train epoch: 107 [83380/25046 (10%)]\tLoss: 0.100052\n",
            "Train epoch: 107 [164360/25046 (20%)]\tLoss: 0.080271\n",
            "Train epoch: 107 [240840/25046 (31%)]\tLoss: 0.114583\n",
            "Train epoch: 107 [330720/25046 (41%)]\tLoss: 0.102135\n",
            "Train epoch: 107 [424300/25046 (51%)]\tLoss: 0.090803\n",
            "Train epoch: 107 [499080/25046 (61%)]\tLoss: 0.044958\n",
            "Train epoch: 107 [580300/25046 (71%)]\tLoss: 0.146128\n",
            "Train epoch: 107 [664480/25046 (82%)]\tLoss: 0.083524\n",
            "Train epoch: 107 [759420/25046 (92%)]\tLoss: 0.121621\n",
            "Make prediction for 5010 samples...\n",
            "0.2669587 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 108 [0/25046 (0%)]\tLoss: 0.090210\n",
            "Train epoch: 108 [82480/25046 (10%)]\tLoss: 0.081409\n",
            "Train epoch: 108 [167800/25046 (20%)]\tLoss: 0.065321\n",
            "Train epoch: 108 [245220/25046 (31%)]\tLoss: 0.065163\n",
            "Train epoch: 108 [326320/25046 (41%)]\tLoss: 0.074147\n",
            "Train epoch: 108 [410600/25046 (51%)]\tLoss: 0.053592\n",
            "Train epoch: 108 [480840/25046 (61%)]\tLoss: 0.088671\n",
            "Train epoch: 108 [572600/25046 (71%)]\tLoss: 0.137026\n",
            "Train epoch: 108 [670400/25046 (82%)]\tLoss: 0.103227\n",
            "Train epoch: 108 [741060/25046 (92%)]\tLoss: 0.133096\n",
            "Make prediction for 5010 samples...\n",
            "0.26991263 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 109 [0/25046 (0%)]\tLoss: 0.068354\n",
            "Train epoch: 109 [84740/25046 (10%)]\tLoss: 0.084873\n",
            "Train epoch: 109 [165880/25046 (20%)]\tLoss: 0.140221\n",
            "Train epoch: 109 [252360/25046 (31%)]\tLoss: 0.100708\n",
            "Train epoch: 109 [324160/25046 (41%)]\tLoss: 0.070964\n",
            "Train epoch: 109 [411100/25046 (51%)]\tLoss: 0.075845\n",
            "Train epoch: 109 [497880/25046 (61%)]\tLoss: 0.156990\n",
            "Train epoch: 109 [572180/25046 (71%)]\tLoss: 0.110572\n",
            "Train epoch: 109 [660320/25046 (82%)]\tLoss: 0.053956\n",
            "Train epoch: 109 [760320/25046 (92%)]\tLoss: 0.096234\n",
            "Make prediction for 5010 samples...\n",
            "0.26451296 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 110 [0/25046 (0%)]\tLoss: 0.103993\n",
            "Train epoch: 110 [80380/25046 (10%)]\tLoss: 0.078674\n",
            "Train epoch: 110 [167080/25046 (20%)]\tLoss: 0.086863\n",
            "Train epoch: 110 [245580/25046 (31%)]\tLoss: 0.104297\n",
            "Train epoch: 110 [331360/25046 (41%)]\tLoss: 0.076895\n",
            "Train epoch: 110 [416100/25046 (51%)]\tLoss: 0.083955\n",
            "Train epoch: 110 [494880/25046 (61%)]\tLoss: 0.075482\n",
            "Train epoch: 110 [584360/25046 (71%)]\tLoss: 0.116447\n",
            "Train epoch: 110 [665920/25046 (82%)]\tLoss: 0.072987\n",
            "Train epoch: 110 [738360/25046 (92%)]\tLoss: 0.094969\n",
            "Make prediction for 5010 samples...\n",
            "0.26794803 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 111 [0/25046 (0%)]\tLoss: 0.076679\n",
            "Train epoch: 111 [85560/25046 (10%)]\tLoss: 0.070206\n",
            "Train epoch: 111 [158680/25046 (20%)]\tLoss: 0.067433\n",
            "Train epoch: 111 [239580/25046 (31%)]\tLoss: 0.104383\n",
            "Train epoch: 111 [324000/25046 (41%)]\tLoss: 0.077897\n",
            "Train epoch: 111 [416300/25046 (51%)]\tLoss: 0.039120\n",
            "Train epoch: 111 [491640/25046 (61%)]\tLoss: 0.108192\n",
            "Train epoch: 111 [574700/25046 (71%)]\tLoss: 0.150584\n",
            "Train epoch: 111 [647680/25046 (82%)]\tLoss: 0.128760\n",
            "Train epoch: 111 [755280/25046 (92%)]\tLoss: 0.091586\n",
            "Make prediction for 5010 samples...\n",
            "0.2717734 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 112 [0/25046 (0%)]\tLoss: 0.082434\n",
            "Train epoch: 112 [84100/25046 (10%)]\tLoss: 0.098621\n",
            "Train epoch: 112 [160320/25046 (20%)]\tLoss: 0.058370\n",
            "Train epoch: 112 [242100/25046 (31%)]\tLoss: 0.082916\n",
            "Train epoch: 112 [325440/25046 (41%)]\tLoss: 0.060170\n",
            "Train epoch: 112 [400700/25046 (51%)]\tLoss: 0.131724\n",
            "Train epoch: 112 [506400/25046 (61%)]\tLoss: 0.070717\n",
            "Train epoch: 112 [567000/25046 (71%)]\tLoss: 0.072140\n",
            "Train epoch: 112 [656320/25046 (82%)]\tLoss: 0.121476\n",
            "Train epoch: 112 [734400/25046 (92%)]\tLoss: 0.083884\n",
            "Make prediction for 5010 samples...\n",
            "0.28406918 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 113 [0/25046 (0%)]\tLoss: 0.085731\n",
            "Train epoch: 113 [81680/25046 (10%)]\tLoss: 0.109390\n",
            "Train epoch: 113 [162160/25046 (20%)]\tLoss: 0.074825\n",
            "Train epoch: 113 [244260/25046 (31%)]\tLoss: 0.077916\n",
            "Train epoch: 113 [328320/25046 (41%)]\tLoss: 0.118738\n",
            "Train epoch: 113 [400200/25046 (51%)]\tLoss: 0.057663\n",
            "Train epoch: 113 [494880/25046 (61%)]\tLoss: 0.142508\n",
            "Train epoch: 113 [572880/25046 (71%)]\tLoss: 0.109052\n",
            "Train epoch: 113 [668640/25046 (82%)]\tLoss: 0.120323\n",
            "Train epoch: 113 [725760/25046 (92%)]\tLoss: 0.125872\n",
            "Make prediction for 5010 samples...\n",
            "0.275522 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 114 [0/25046 (0%)]\tLoss: 0.088133\n",
            "Train epoch: 114 [82420/25046 (10%)]\tLoss: 0.097035\n",
            "Train epoch: 114 [164000/25046 (20%)]\tLoss: 0.067453\n",
            "Train epoch: 114 [248760/25046 (31%)]\tLoss: 0.098159\n",
            "Train epoch: 114 [325200/25046 (41%)]\tLoss: 0.071225\n",
            "Train epoch: 114 [424000/25046 (51%)]\tLoss: 0.081076\n",
            "Train epoch: 114 [485400/25046 (61%)]\tLoss: 0.090700\n",
            "Train epoch: 114 [577080/25046 (71%)]\tLoss: 0.085498\n",
            "Train epoch: 114 [649120/25046 (82%)]\tLoss: 0.189361\n",
            "Train epoch: 114 [753840/25046 (92%)]\tLoss: 0.089225\n",
            "Make prediction for 5010 samples...\n",
            "0.27048528 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 115 [0/25046 (0%)]\tLoss: 0.096888\n",
            "Train epoch: 115 [81320/25046 (10%)]\tLoss: 0.075906\n",
            "Train epoch: 115 [164840/25046 (20%)]\tLoss: 0.105664\n",
            "Train epoch: 115 [240540/25046 (31%)]\tLoss: 0.098896\n",
            "Train epoch: 115 [338160/25046 (41%)]\tLoss: 0.073728\n",
            "Train epoch: 115 [421100/25046 (51%)]\tLoss: 0.096472\n",
            "Train epoch: 115 [488640/25046 (61%)]\tLoss: 0.094250\n",
            "Train epoch: 115 [574420/25046 (71%)]\tLoss: 0.074770\n",
            "Train epoch: 115 [669600/25046 (82%)]\tLoss: 0.143755\n",
            "Train epoch: 115 [725400/25046 (92%)]\tLoss: 0.104648\n",
            "Make prediction for 5010 samples...\n",
            "0.27138072 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 116 [0/25046 (0%)]\tLoss: 0.131052\n",
            "Train epoch: 116 [82320/25046 (10%)]\tLoss: 0.109884\n",
            "Train epoch: 116 [172120/25046 (20%)]\tLoss: 0.093804\n",
            "Train epoch: 116 [240780/25046 (31%)]\tLoss: 0.102776\n",
            "Train epoch: 116 [329360/25046 (41%)]\tLoss: 0.059866\n",
            "Train epoch: 116 [409700/25046 (51%)]\tLoss: 0.070700\n",
            "Train epoch: 116 [484440/25046 (61%)]\tLoss: 0.230730\n",
            "Train epoch: 116 [569100/25046 (71%)]\tLoss: 0.145733\n",
            "Train epoch: 116 [648160/25046 (82%)]\tLoss: 0.075048\n",
            "Train epoch: 116 [743220/25046 (92%)]\tLoss: 0.075724\n",
            "Make prediction for 5010 samples...\n",
            "0.2855762 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 117 [0/25046 (0%)]\tLoss: 0.063070\n",
            "Train epoch: 117 [81580/25046 (10%)]\tLoss: 0.079352\n",
            "Train epoch: 117 [163920/25046 (20%)]\tLoss: 0.051332\n",
            "Train epoch: 117 [243480/25046 (31%)]\tLoss: 0.067717\n",
            "Train epoch: 117 [325040/25046 (41%)]\tLoss: 0.056020\n",
            "Train epoch: 117 [419100/25046 (51%)]\tLoss: 0.107739\n",
            "Train epoch: 117 [483840/25046 (61%)]\tLoss: 0.069150\n",
            "Train epoch: 117 [586600/25046 (71%)]\tLoss: 0.065161\n",
            "Train epoch: 117 [648960/25046 (82%)]\tLoss: 0.205277\n",
            "Train epoch: 117 [751140/25046 (92%)]\tLoss: 0.148791\n",
            "Make prediction for 5010 samples...\n",
            "0.2703162 No improvement since epoch  90 ; best_mse,best_ci: 0.25760257 0.8759062234040842 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 118 [0/25046 (0%)]\tLoss: 0.101954\n",
            "Train epoch: 118 [82660/25046 (10%)]\tLoss: 0.101246\n",
            "Train epoch: 118 [164600/25046 (20%)]\tLoss: 0.122390\n",
            "Train epoch: 118 [243120/25046 (31%)]\tLoss: 0.087370\n",
            "Train epoch: 118 [316960/25046 (41%)]\tLoss: 0.129953\n",
            "Train epoch: 118 [417300/25046 (51%)]\tLoss: 0.072839\n",
            "Train epoch: 118 [506400/25046 (61%)]\tLoss: 0.062390\n",
            "Train epoch: 118 [571760/25046 (71%)]\tLoss: 0.067557\n",
            "Train epoch: 118 [636800/25046 (82%)]\tLoss: 0.083018\n",
            "Train epoch: 118 [756360/25046 (92%)]\tLoss: 0.083859\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 119 [0/25046 (0%)]\tLoss: 0.093927\n",
            "Train epoch: 119 [81720/25046 (10%)]\tLoss: 0.057397\n",
            "Train epoch: 119 [160320/25046 (20%)]\tLoss: 0.220481\n",
            "Train epoch: 119 [251040/25046 (31%)]\tLoss: 0.063264\n",
            "Train epoch: 119 [323040/25046 (41%)]\tLoss: 0.074802\n",
            "Train epoch: 119 [405200/25046 (51%)]\tLoss: 0.101250\n",
            "Train epoch: 119 [497160/25046 (61%)]\tLoss: 0.053239\n",
            "Train epoch: 119 [563360/25046 (71%)]\tLoss: 0.095674\n",
            "Train epoch: 119 [674080/25046 (82%)]\tLoss: 0.135368\n",
            "Train epoch: 119 [764100/25046 (92%)]\tLoss: 0.119732\n",
            "Make prediction for 5010 samples...\n",
            "0.261888 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 120 [0/25046 (0%)]\tLoss: 0.075282\n",
            "Train epoch: 120 [81780/25046 (10%)]\tLoss: 0.062372\n",
            "Train epoch: 120 [161760/25046 (20%)]\tLoss: 0.095657\n",
            "Train epoch: 120 [251580/25046 (31%)]\tLoss: 0.114716\n",
            "Train epoch: 120 [326960/25046 (41%)]\tLoss: 0.074489\n",
            "Train epoch: 120 [405100/25046 (51%)]\tLoss: 0.089576\n",
            "Train epoch: 120 [490920/25046 (61%)]\tLoss: 0.081223\n",
            "Train epoch: 120 [575260/25046 (71%)]\tLoss: 0.108128\n",
            "Train epoch: 120 [639840/25046 (82%)]\tLoss: 0.154712\n",
            "Train epoch: 120 [729540/25046 (92%)]\tLoss: 0.063817\n",
            "Make prediction for 5010 samples...\n",
            "0.28347808 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 121 [0/25046 (0%)]\tLoss: 0.081538\n",
            "Train epoch: 121 [82640/25046 (10%)]\tLoss: 0.153579\n",
            "Train epoch: 121 [160240/25046 (20%)]\tLoss: 0.159058\n",
            "Train epoch: 121 [243060/25046 (31%)]\tLoss: 0.085698\n",
            "Train epoch: 121 [324800/25046 (41%)]\tLoss: 0.116491\n",
            "Train epoch: 121 [415900/25046 (51%)]\tLoss: 0.090423\n",
            "Train epoch: 121 [489360/25046 (61%)]\tLoss: 0.086493\n",
            "Train epoch: 121 [565040/25046 (71%)]\tLoss: 0.100409\n",
            "Train epoch: 121 [657920/25046 (82%)]\tLoss: 0.082565\n",
            "Train epoch: 121 [722340/25046 (92%)]\tLoss: 0.057923\n",
            "Make prediction for 5010 samples...\n",
            "0.2623783 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 122 [0/25046 (0%)]\tLoss: 0.232246\n",
            "Train epoch: 122 [82660/25046 (10%)]\tLoss: 0.066815\n",
            "Train epoch: 122 [163480/25046 (20%)]\tLoss: 0.092608\n",
            "Train epoch: 122 [247740/25046 (31%)]\tLoss: 0.110831\n",
            "Train epoch: 122 [330320/25046 (41%)]\tLoss: 0.066430\n",
            "Train epoch: 122 [405400/25046 (51%)]\tLoss: 0.092910\n",
            "Train epoch: 122 [490200/25046 (61%)]\tLoss: 0.108634\n",
            "Train epoch: 122 [591500/25046 (71%)]\tLoss: 0.061972\n",
            "Train epoch: 122 [687040/25046 (82%)]\tLoss: 0.073965\n",
            "Train epoch: 122 [736740/25046 (92%)]\tLoss: 0.076097\n",
            "Make prediction for 5010 samples...\n",
            "0.26988685 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 123 [0/25046 (0%)]\tLoss: 0.049343\n",
            "Train epoch: 123 [81680/25046 (10%)]\tLoss: 0.085076\n",
            "Train epoch: 123 [161000/25046 (20%)]\tLoss: 0.064562\n",
            "Train epoch: 123 [243660/25046 (31%)]\tLoss: 0.038850\n",
            "Train epoch: 123 [322400/25046 (41%)]\tLoss: 0.088853\n",
            "Train epoch: 123 [408700/25046 (51%)]\tLoss: 0.079392\n",
            "Train epoch: 123 [492000/25046 (61%)]\tLoss: 0.109018\n",
            "Train epoch: 123 [572880/25046 (71%)]\tLoss: 0.079871\n",
            "Train epoch: 123 [662880/25046 (82%)]\tLoss: 0.088758\n",
            "Train epoch: 123 [739800/25046 (92%)]\tLoss: 0.099534\n",
            "Make prediction for 5010 samples...\n",
            "0.2655409 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 124 [0/25046 (0%)]\tLoss: 0.077417\n",
            "Train epoch: 124 [81380/25046 (10%)]\tLoss: 0.070740\n",
            "Train epoch: 124 [164120/25046 (20%)]\tLoss: 0.104548\n",
            "Train epoch: 124 [245520/25046 (31%)]\tLoss: 0.098292\n",
            "Train epoch: 124 [331600/25046 (41%)]\tLoss: 0.167516\n",
            "Train epoch: 124 [402800/25046 (51%)]\tLoss: 0.104738\n",
            "Train epoch: 124 [496440/25046 (61%)]\tLoss: 0.193194\n",
            "Train epoch: 124 [568400/25046 (71%)]\tLoss: 0.064316\n",
            "Train epoch: 124 [652000/25046 (82%)]\tLoss: 0.083135\n",
            "Train epoch: 124 [750600/25046 (92%)]\tLoss: 0.138995\n",
            "Make prediction for 5010 samples...\n",
            "0.27282915 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 125 [0/25046 (0%)]\tLoss: 0.091621\n",
            "Train epoch: 125 [78900/25046 (10%)]\tLoss: 0.124615\n",
            "Train epoch: 125 [162400/25046 (20%)]\tLoss: 0.115904\n",
            "Train epoch: 125 [246420/25046 (31%)]\tLoss: 0.041970\n",
            "Train epoch: 125 [337600/25046 (41%)]\tLoss: 0.076725\n",
            "Train epoch: 125 [405300/25046 (51%)]\tLoss: 0.078235\n",
            "Train epoch: 125 [492480/25046 (61%)]\tLoss: 0.113204\n",
            "Train epoch: 125 [574280/25046 (71%)]\tLoss: 0.094712\n",
            "Train epoch: 125 [646720/25046 (82%)]\tLoss: 0.175510\n",
            "Train epoch: 125 [748080/25046 (92%)]\tLoss: 0.101000\n",
            "Make prediction for 5010 samples...\n",
            "0.2694674 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 126 [0/25046 (0%)]\tLoss: 0.157336\n",
            "Train epoch: 126 [85580/25046 (10%)]\tLoss: 0.108503\n",
            "Train epoch: 126 [161280/25046 (20%)]\tLoss: 0.114353\n",
            "Train epoch: 126 [250560/25046 (31%)]\tLoss: 0.268024\n",
            "Train epoch: 126 [334560/25046 (41%)]\tLoss: 0.101491\n",
            "Train epoch: 126 [409400/25046 (51%)]\tLoss: 0.139204\n",
            "Train epoch: 126 [508320/25046 (61%)]\tLoss: 0.093235\n",
            "Train epoch: 126 [588280/25046 (71%)]\tLoss: 0.138361\n",
            "Train epoch: 126 [669760/25046 (82%)]\tLoss: 0.098360\n",
            "Train epoch: 126 [736560/25046 (92%)]\tLoss: 0.079344\n",
            "Make prediction for 5010 samples...\n",
            "0.2626781 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 127 [0/25046 (0%)]\tLoss: 0.082486\n",
            "Train epoch: 127 [84040/25046 (10%)]\tLoss: 0.101705\n",
            "Train epoch: 127 [164600/25046 (20%)]\tLoss: 0.070237\n",
            "Train epoch: 127 [245100/25046 (31%)]\tLoss: 0.107049\n",
            "Train epoch: 127 [328160/25046 (41%)]\tLoss: 0.097520\n",
            "Train epoch: 127 [406600/25046 (51%)]\tLoss: 0.096657\n",
            "Train epoch: 127 [497880/25046 (61%)]\tLoss: 0.079074\n",
            "Train epoch: 127 [573020/25046 (71%)]\tLoss: 0.061057\n",
            "Train epoch: 127 [653280/25046 (82%)]\tLoss: 0.116560\n",
            "Train epoch: 127 [752040/25046 (92%)]\tLoss: 0.074123\n",
            "Make prediction for 5010 samples...\n",
            "0.2718185 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 128 [0/25046 (0%)]\tLoss: 0.094201\n",
            "Train epoch: 128 [81420/25046 (10%)]\tLoss: 0.082956\n",
            "Train epoch: 128 [156800/25046 (20%)]\tLoss: 0.070529\n",
            "Train epoch: 128 [243300/25046 (31%)]\tLoss: 0.083495\n",
            "Train epoch: 128 [324960/25046 (41%)]\tLoss: 0.094936\n",
            "Train epoch: 128 [410000/25046 (51%)]\tLoss: 0.074310\n",
            "Train epoch: 128 [502320/25046 (61%)]\tLoss: 0.095612\n",
            "Train epoch: 128 [581000/25046 (71%)]\tLoss: 0.076410\n",
            "Train epoch: 128 [653920/25046 (82%)]\tLoss: 0.074384\n",
            "Train epoch: 128 [729720/25046 (92%)]\tLoss: 0.102512\n",
            "Make prediction for 5010 samples...\n",
            "0.27579132 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 129 [0/25046 (0%)]\tLoss: 0.064895\n",
            "Train epoch: 129 [82840/25046 (10%)]\tLoss: 0.116666\n",
            "Train epoch: 129 [167160/25046 (20%)]\tLoss: 0.160955\n",
            "Train epoch: 129 [255300/25046 (31%)]\tLoss: 0.069653\n",
            "Train epoch: 129 [332080/25046 (41%)]\tLoss: 0.094546\n",
            "Train epoch: 129 [417600/25046 (51%)]\tLoss: 0.107288\n",
            "Train epoch: 129 [482760/25046 (61%)]\tLoss: 0.087187\n",
            "Train epoch: 129 [585060/25046 (71%)]\tLoss: 0.062927\n",
            "Train epoch: 129 [663680/25046 (82%)]\tLoss: 0.092135\n",
            "Train epoch: 129 [722520/25046 (92%)]\tLoss: 0.079273\n",
            "Make prediction for 5010 samples...\n",
            "0.27649227 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 130 [0/25046 (0%)]\tLoss: 0.108923\n",
            "Train epoch: 130 [81020/25046 (10%)]\tLoss: 0.107493\n",
            "Train epoch: 130 [164800/25046 (20%)]\tLoss: 0.071051\n",
            "Train epoch: 130 [242220/25046 (31%)]\tLoss: 0.078231\n",
            "Train epoch: 130 [329200/25046 (41%)]\tLoss: 0.107008\n",
            "Train epoch: 130 [418000/25046 (51%)]\tLoss: 0.059811\n",
            "Train epoch: 130 [484680/25046 (61%)]\tLoss: 0.091552\n",
            "Train epoch: 130 [576520/25046 (71%)]\tLoss: 0.054633\n",
            "Train epoch: 130 [646240/25046 (82%)]\tLoss: 0.095268\n",
            "Train epoch: 130 [730620/25046 (92%)]\tLoss: 0.065588\n",
            "Make prediction for 5010 samples...\n",
            "0.2813115 No improvement since epoch  118 ; best_mse,best_ci: 0.25747618 0.8789797674621977 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 131 [0/25046 (0%)]\tLoss: 0.098379\n",
            "Train epoch: 131 [81480/25046 (10%)]\tLoss: 0.178817\n",
            "Train epoch: 131 [162160/25046 (20%)]\tLoss: 0.070852\n",
            "Train epoch: 131 [245340/25046 (31%)]\tLoss: 0.059285\n",
            "Train epoch: 131 [324240/25046 (41%)]\tLoss: 0.066902\n",
            "Train epoch: 131 [415200/25046 (51%)]\tLoss: 0.109182\n",
            "Train epoch: 131 [474960/25046 (61%)]\tLoss: 0.090995\n",
            "Train epoch: 131 [570080/25046 (71%)]\tLoss: 0.105750\n",
            "Train epoch: 131 [654240/25046 (82%)]\tLoss: 0.043238\n",
            "Train epoch: 131 [740340/25046 (92%)]\tLoss: 0.071680\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 132 [0/25046 (0%)]\tLoss: 0.065976\n",
            "Train epoch: 132 [84720/25046 (10%)]\tLoss: 0.056589\n",
            "Train epoch: 132 [164120/25046 (20%)]\tLoss: 0.080678\n",
            "Train epoch: 132 [241860/25046 (31%)]\tLoss: 0.070250\n",
            "Train epoch: 132 [328000/25046 (41%)]\tLoss: 0.099270\n",
            "Train epoch: 132 [413600/25046 (51%)]\tLoss: 0.114015\n",
            "Train epoch: 132 [504240/25046 (61%)]\tLoss: 0.140531\n",
            "Train epoch: 132 [584220/25046 (71%)]\tLoss: 0.078659\n",
            "Train epoch: 132 [641120/25046 (82%)]\tLoss: 0.057518\n",
            "Train epoch: 132 [765360/25046 (92%)]\tLoss: 0.057875\n",
            "Make prediction for 5010 samples...\n",
            "0.2605437 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 133 [0/25046 (0%)]\tLoss: 0.107929\n",
            "Train epoch: 133 [81860/25046 (10%)]\tLoss: 0.125212\n",
            "Train epoch: 133 [162000/25046 (20%)]\tLoss: 0.085155\n",
            "Train epoch: 133 [247800/25046 (31%)]\tLoss: 0.067438\n",
            "Train epoch: 133 [328560/25046 (41%)]\tLoss: 0.081344\n",
            "Train epoch: 133 [412900/25046 (51%)]\tLoss: 0.106548\n",
            "Train epoch: 133 [501600/25046 (61%)]\tLoss: 0.107158\n",
            "Train epoch: 133 [567280/25046 (71%)]\tLoss: 0.087406\n",
            "Train epoch: 133 [662080/25046 (82%)]\tLoss: 0.070193\n",
            "Train epoch: 133 [751680/25046 (92%)]\tLoss: 0.057041\n",
            "Make prediction for 5010 samples...\n",
            "0.25983906 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 134 [0/25046 (0%)]\tLoss: 0.060801\n",
            "Train epoch: 134 [80020/25046 (10%)]\tLoss: 0.078394\n",
            "Train epoch: 134 [163000/25046 (20%)]\tLoss: 0.058393\n",
            "Train epoch: 134 [250620/25046 (31%)]\tLoss: 0.065199\n",
            "Train epoch: 134 [335840/25046 (41%)]\tLoss: 0.070885\n",
            "Train epoch: 134 [415500/25046 (51%)]\tLoss: 0.064429\n",
            "Train epoch: 134 [495360/25046 (61%)]\tLoss: 0.110270\n",
            "Train epoch: 134 [569240/25046 (71%)]\tLoss: 0.090977\n",
            "Train epoch: 134 [658720/25046 (82%)]\tLoss: 0.116180\n",
            "Train epoch: 134 [738540/25046 (92%)]\tLoss: 0.085656\n",
            "Make prediction for 5010 samples...\n",
            "0.28022933 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 135 [0/25046 (0%)]\tLoss: 0.095338\n",
            "Train epoch: 135 [83460/25046 (10%)]\tLoss: 0.154311\n",
            "Train epoch: 135 [167040/25046 (20%)]\tLoss: 0.076638\n",
            "Train epoch: 135 [240240/25046 (31%)]\tLoss: 0.065780\n",
            "Train epoch: 135 [335680/25046 (41%)]\tLoss: 0.099049\n",
            "Train epoch: 135 [415400/25046 (51%)]\tLoss: 0.112347\n",
            "Train epoch: 135 [489120/25046 (61%)]\tLoss: 0.056289\n",
            "Train epoch: 135 [562240/25046 (71%)]\tLoss: 0.066345\n",
            "Train epoch: 135 [667040/25046 (82%)]\tLoss: 0.057773\n",
            "Train epoch: 135 [747180/25046 (92%)]\tLoss: 0.100279\n",
            "Make prediction for 5010 samples...\n",
            "0.2687518 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 136 [0/25046 (0%)]\tLoss: 0.096949\n",
            "Train epoch: 136 [82880/25046 (10%)]\tLoss: 0.159624\n",
            "Train epoch: 136 [163800/25046 (20%)]\tLoss: 0.153530\n",
            "Train epoch: 136 [248640/25046 (31%)]\tLoss: 0.085888\n",
            "Train epoch: 136 [320720/25046 (41%)]\tLoss: 0.080561\n",
            "Train epoch: 136 [420800/25046 (51%)]\tLoss: 0.096213\n",
            "Train epoch: 136 [491160/25046 (61%)]\tLoss: 0.074062\n",
            "Train epoch: 136 [582260/25046 (71%)]\tLoss: 0.107939\n",
            "Train epoch: 136 [655360/25046 (82%)]\tLoss: 0.089518\n",
            "Train epoch: 136 [732600/25046 (92%)]\tLoss: 0.071238\n",
            "Make prediction for 5010 samples...\n",
            "0.26152217 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 137 [0/25046 (0%)]\tLoss: 0.094038\n",
            "Train epoch: 137 [82900/25046 (10%)]\tLoss: 0.066456\n",
            "Train epoch: 137 [166840/25046 (20%)]\tLoss: 0.063021\n",
            "Train epoch: 137 [250260/25046 (31%)]\tLoss: 0.101346\n",
            "Train epoch: 137 [340320/25046 (41%)]\tLoss: 0.107029\n",
            "Train epoch: 137 [414800/25046 (51%)]\tLoss: 0.070742\n",
            "Train epoch: 137 [489120/25046 (61%)]\tLoss: 0.111676\n",
            "Train epoch: 137 [570080/25046 (71%)]\tLoss: 0.115051\n",
            "Train epoch: 137 [679520/25046 (82%)]\tLoss: 0.104004\n",
            "Train epoch: 137 [727380/25046 (92%)]\tLoss: 0.110723\n",
            "Make prediction for 5010 samples...\n",
            "0.2633534 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 138 [0/25046 (0%)]\tLoss: 0.046114\n",
            "Train epoch: 138 [82820/25046 (10%)]\tLoss: 0.093135\n",
            "Train epoch: 138 [158840/25046 (20%)]\tLoss: 0.050504\n",
            "Train epoch: 138 [239820/25046 (31%)]\tLoss: 0.075585\n",
            "Train epoch: 138 [328480/25046 (41%)]\tLoss: 0.060892\n",
            "Train epoch: 138 [408700/25046 (51%)]\tLoss: 0.252545\n",
            "Train epoch: 138 [503760/25046 (61%)]\tLoss: 0.102505\n",
            "Train epoch: 138 [561260/25046 (71%)]\tLoss: 0.078902\n",
            "Train epoch: 138 [666400/25046 (82%)]\tLoss: 0.099358\n",
            "Train epoch: 138 [740700/25046 (92%)]\tLoss: 0.082343\n",
            "Make prediction for 5010 samples...\n",
            "0.28088474 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 139 [0/25046 (0%)]\tLoss: 0.110120\n",
            "Train epoch: 139 [81900/25046 (10%)]\tLoss: 0.060347\n",
            "Train epoch: 139 [160920/25046 (20%)]\tLoss: 0.106450\n",
            "Train epoch: 139 [243120/25046 (31%)]\tLoss: 0.074463\n",
            "Train epoch: 139 [327680/25046 (41%)]\tLoss: 0.063685\n",
            "Train epoch: 139 [412500/25046 (51%)]\tLoss: 0.112201\n",
            "Train epoch: 139 [486720/25046 (61%)]\tLoss: 0.146518\n",
            "Train epoch: 139 [592340/25046 (71%)]\tLoss: 0.065078\n",
            "Train epoch: 139 [663520/25046 (82%)]\tLoss: 0.068102\n",
            "Train epoch: 139 [741780/25046 (92%)]\tLoss: 0.099585\n",
            "Make prediction for 5010 samples...\n",
            "0.27202588 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 140 [0/25046 (0%)]\tLoss: 0.085657\n",
            "Train epoch: 140 [82100/25046 (10%)]\tLoss: 0.060917\n",
            "Train epoch: 140 [165960/25046 (20%)]\tLoss: 0.050552\n",
            "Train epoch: 140 [241380/25046 (31%)]\tLoss: 0.097085\n",
            "Train epoch: 140 [328960/25046 (41%)]\tLoss: 0.141403\n",
            "Train epoch: 140 [400100/25046 (51%)]\tLoss: 0.060306\n",
            "Train epoch: 140 [497160/25046 (61%)]\tLoss: 0.054553\n",
            "Train epoch: 140 [560420/25046 (71%)]\tLoss: 0.108961\n",
            "Train epoch: 140 [660480/25046 (82%)]\tLoss: 0.132098\n",
            "Train epoch: 140 [725760/25046 (92%)]\tLoss: 0.090861\n",
            "Make prediction for 5010 samples...\n",
            "0.26692274 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 141 [0/25046 (0%)]\tLoss: 0.075354\n",
            "Train epoch: 141 [82040/25046 (10%)]\tLoss: 0.139114\n",
            "Train epoch: 141 [165320/25046 (20%)]\tLoss: 0.060291\n",
            "Train epoch: 141 [245340/25046 (31%)]\tLoss: 0.137895\n",
            "Train epoch: 141 [340000/25046 (41%)]\tLoss: 0.136622\n",
            "Train epoch: 141 [415000/25046 (51%)]\tLoss: 0.181843\n",
            "Train epoch: 141 [479880/25046 (61%)]\tLoss: 0.088774\n",
            "Train epoch: 141 [589540/25046 (71%)]\tLoss: 0.062738\n",
            "Train epoch: 141 [658240/25046 (82%)]\tLoss: 0.073185\n",
            "Train epoch: 141 [732060/25046 (92%)]\tLoss: 0.138261\n",
            "Make prediction for 5010 samples...\n",
            "0.27495772 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 142 [0/25046 (0%)]\tLoss: 0.062325\n",
            "Train epoch: 142 [82120/25046 (10%)]\tLoss: 0.098999\n",
            "Train epoch: 142 [166920/25046 (20%)]\tLoss: 0.082998\n",
            "Train epoch: 142 [241620/25046 (31%)]\tLoss: 0.136433\n",
            "Train epoch: 142 [328400/25046 (41%)]\tLoss: 0.190591\n",
            "Train epoch: 142 [409100/25046 (51%)]\tLoss: 0.073717\n",
            "Train epoch: 142 [489840/25046 (61%)]\tLoss: 0.090702\n",
            "Train epoch: 142 [586600/25046 (71%)]\tLoss: 0.088735\n",
            "Train epoch: 142 [663040/25046 (82%)]\tLoss: 0.070669\n",
            "Train epoch: 142 [719640/25046 (92%)]\tLoss: 0.072090\n",
            "Make prediction for 5010 samples...\n",
            "0.2685554 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 143 [0/25046 (0%)]\tLoss: 0.108131\n",
            "Train epoch: 143 [81860/25046 (10%)]\tLoss: 0.071335\n",
            "Train epoch: 143 [163560/25046 (20%)]\tLoss: 0.204196\n",
            "Train epoch: 143 [244200/25046 (31%)]\tLoss: 0.057899\n",
            "Train epoch: 143 [331920/25046 (41%)]\tLoss: 0.090369\n",
            "Train epoch: 143 [413300/25046 (51%)]\tLoss: 0.078182\n",
            "Train epoch: 143 [496440/25046 (61%)]\tLoss: 0.063144\n",
            "Train epoch: 143 [576940/25046 (71%)]\tLoss: 0.053616\n",
            "Train epoch: 143 [655520/25046 (82%)]\tLoss: 0.068497\n",
            "Train epoch: 143 [721440/25046 (92%)]\tLoss: 0.049655\n",
            "Make prediction for 5010 samples...\n",
            "0.27963015 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 144 [0/25046 (0%)]\tLoss: 0.093322\n",
            "Train epoch: 144 [82700/25046 (10%)]\tLoss: 0.059017\n",
            "Train epoch: 144 [169160/25046 (20%)]\tLoss: 0.092183\n",
            "Train epoch: 144 [239940/25046 (31%)]\tLoss: 0.039959\n",
            "Train epoch: 144 [325680/25046 (41%)]\tLoss: 0.101453\n",
            "Train epoch: 144 [413300/25046 (51%)]\tLoss: 0.046392\n",
            "Train epoch: 144 [496920/25046 (61%)]\tLoss: 0.126933\n",
            "Train epoch: 144 [599480/25046 (71%)]\tLoss: 0.082499\n",
            "Train epoch: 144 [648320/25046 (82%)]\tLoss: 0.151293\n",
            "Train epoch: 144 [742320/25046 (92%)]\tLoss: 0.097231\n",
            "Make prediction for 5010 samples...\n",
            "0.26945925 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 145 [0/25046 (0%)]\tLoss: 0.070524\n",
            "Train epoch: 145 [81080/25046 (10%)]\tLoss: 0.125486\n",
            "Train epoch: 145 [162200/25046 (20%)]\tLoss: 0.088807\n",
            "Train epoch: 145 [245400/25046 (31%)]\tLoss: 0.173653\n",
            "Train epoch: 145 [333760/25046 (41%)]\tLoss: 0.065259\n",
            "Train epoch: 145 [413600/25046 (51%)]\tLoss: 0.098893\n",
            "Train epoch: 145 [486720/25046 (61%)]\tLoss: 0.096038\n",
            "Train epoch: 145 [586600/25046 (71%)]\tLoss: 0.124475\n",
            "Train epoch: 145 [684640/25046 (82%)]\tLoss: 0.101691\n",
            "Train epoch: 145 [733320/25046 (92%)]\tLoss: 0.068857\n",
            "Make prediction for 5010 samples...\n",
            "0.2610315 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 146 [0/25046 (0%)]\tLoss: 0.062192\n",
            "Train epoch: 146 [82620/25046 (10%)]\tLoss: 0.078464\n",
            "Train epoch: 146 [162760/25046 (20%)]\tLoss: 0.049101\n",
            "Train epoch: 146 [238320/25046 (31%)]\tLoss: 0.093497\n",
            "Train epoch: 146 [329680/25046 (41%)]\tLoss: 0.115805\n",
            "Train epoch: 146 [417200/25046 (51%)]\tLoss: 0.056576\n",
            "Train epoch: 146 [490440/25046 (61%)]\tLoss: 0.086809\n",
            "Train epoch: 146 [557760/25046 (71%)]\tLoss: 0.055473\n",
            "Train epoch: 146 [661920/25046 (82%)]\tLoss: 0.051547\n",
            "Train epoch: 146 [751860/25046 (92%)]\tLoss: 0.126014\n",
            "Make prediction for 5010 samples...\n",
            "0.25456643 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 147 [0/25046 (0%)]\tLoss: 0.064193\n",
            "Train epoch: 147 [83380/25046 (10%)]\tLoss: 0.072060\n",
            "Train epoch: 147 [168240/25046 (20%)]\tLoss: 0.098671\n",
            "Train epoch: 147 [248100/25046 (31%)]\tLoss: 0.065134\n",
            "Train epoch: 147 [320160/25046 (41%)]\tLoss: 0.038633\n",
            "Train epoch: 147 [411700/25046 (51%)]\tLoss: 0.057327\n",
            "Train epoch: 147 [489600/25046 (61%)]\tLoss: 0.039320\n",
            "Train epoch: 147 [577780/25046 (71%)]\tLoss: 0.055551\n",
            "Train epoch: 147 [628960/25046 (82%)]\tLoss: 0.089826\n",
            "Train epoch: 147 [735660/25046 (92%)]\tLoss: 0.104882\n",
            "Make prediction for 5010 samples...\n",
            "0.26614925 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 148 [0/25046 (0%)]\tLoss: 0.075577\n",
            "Train epoch: 148 [80660/25046 (10%)]\tLoss: 0.063138\n",
            "Train epoch: 148 [169680/25046 (20%)]\tLoss: 0.068117\n",
            "Train epoch: 148 [242280/25046 (31%)]\tLoss: 0.072565\n",
            "Train epoch: 148 [328880/25046 (41%)]\tLoss: 0.115393\n",
            "Train epoch: 148 [412500/25046 (51%)]\tLoss: 0.049225\n",
            "Train epoch: 148 [496920/25046 (61%)]\tLoss: 0.109209\n",
            "Train epoch: 148 [566580/25046 (71%)]\tLoss: 0.067511\n",
            "Train epoch: 148 [653440/25046 (82%)]\tLoss: 0.059419\n",
            "Train epoch: 148 [736920/25046 (92%)]\tLoss: 0.066580\n",
            "Make prediction for 5010 samples...\n",
            "0.26503915 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 149 [0/25046 (0%)]\tLoss: 0.140003\n",
            "Train epoch: 149 [82640/25046 (10%)]\tLoss: 0.071152\n",
            "Train epoch: 149 [168640/25046 (20%)]\tLoss: 0.076709\n",
            "Train epoch: 149 [249720/25046 (31%)]\tLoss: 0.092609\n",
            "Train epoch: 149 [329040/25046 (41%)]\tLoss: 0.099787\n",
            "Train epoch: 149 [417400/25046 (51%)]\tLoss: 0.118779\n",
            "Train epoch: 149 [493680/25046 (61%)]\tLoss: 0.126854\n",
            "Train epoch: 149 [592620/25046 (71%)]\tLoss: 0.095667\n",
            "Train epoch: 149 [659040/25046 (82%)]\tLoss: 0.075567\n",
            "Train epoch: 149 [723240/25046 (92%)]\tLoss: 0.087788\n",
            "Make prediction for 5010 samples...\n",
            "0.25397775 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 150 [0/25046 (0%)]\tLoss: 0.077385\n",
            "Train epoch: 150 [82080/25046 (10%)]\tLoss: 0.063908\n",
            "Train epoch: 150 [165640/25046 (20%)]\tLoss: 0.061651\n",
            "Train epoch: 150 [247500/25046 (31%)]\tLoss: 0.156489\n",
            "Train epoch: 150 [333680/25046 (41%)]\tLoss: 0.043189\n",
            "Train epoch: 150 [402400/25046 (51%)]\tLoss: 0.040130\n",
            "Train epoch: 150 [491400/25046 (61%)]\tLoss: 0.098859\n",
            "Train epoch: 150 [562940/25046 (71%)]\tLoss: 0.110588\n",
            "Train epoch: 150 [643520/25046 (82%)]\tLoss: 0.068644\n",
            "Train epoch: 150 [745740/25046 (92%)]\tLoss: 0.064080\n",
            "Make prediction for 5010 samples...\n",
            "0.25768396 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 151 [0/25046 (0%)]\tLoss: 0.106178\n",
            "Train epoch: 151 [83560/25046 (10%)]\tLoss: 0.161899\n",
            "Train epoch: 151 [166280/25046 (20%)]\tLoss: 0.080201\n",
            "Train epoch: 151 [246000/25046 (31%)]\tLoss: 0.088500\n",
            "Train epoch: 151 [326720/25046 (41%)]\tLoss: 0.064119\n",
            "Train epoch: 151 [405200/25046 (51%)]\tLoss: 0.071415\n",
            "Train epoch: 151 [478800/25046 (61%)]\tLoss: 0.099043\n",
            "Train epoch: 151 [552300/25046 (71%)]\tLoss: 0.069612\n",
            "Train epoch: 151 [658080/25046 (82%)]\tLoss: 0.065817\n",
            "Train epoch: 151 [728100/25046 (92%)]\tLoss: 0.102457\n",
            "Make prediction for 5010 samples...\n",
            "0.2736009 No improvement since epoch  131 ; best_mse,best_ci: 0.2538591 0.8803200829229736 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 152 [0/25046 (0%)]\tLoss: 0.066643\n",
            "Train epoch: 152 [81180/25046 (10%)]\tLoss: 0.065216\n",
            "Train epoch: 152 [160960/25046 (20%)]\tLoss: 0.076350\n",
            "Train epoch: 152 [252420/25046 (31%)]\tLoss: 0.114196\n",
            "Train epoch: 152 [319360/25046 (41%)]\tLoss: 0.066941\n",
            "Train epoch: 152 [387500/25046 (51%)]\tLoss: 0.072893\n",
            "Train epoch: 152 [495120/25046 (61%)]\tLoss: 0.074905\n",
            "Train epoch: 152 [585760/25046 (71%)]\tLoss: 0.147805\n",
            "Train epoch: 152 [650080/25046 (82%)]\tLoss: 0.059360\n",
            "Train epoch: 152 [735120/25046 (92%)]\tLoss: 0.170587\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 153 [0/25046 (0%)]\tLoss: 0.053002\n",
            "Train epoch: 153 [83100/25046 (10%)]\tLoss: 0.136328\n",
            "Train epoch: 153 [165880/25046 (20%)]\tLoss: 0.113761\n",
            "Train epoch: 153 [245460/25046 (31%)]\tLoss: 0.065629\n",
            "Train epoch: 153 [323280/25046 (41%)]\tLoss: 0.103168\n",
            "Train epoch: 153 [395200/25046 (51%)]\tLoss: 0.047056\n",
            "Train epoch: 153 [492600/25046 (61%)]\tLoss: 0.065803\n",
            "Train epoch: 153 [583240/25046 (71%)]\tLoss: 0.103079\n",
            "Train epoch: 153 [661120/25046 (82%)]\tLoss: 0.076574\n",
            "Train epoch: 153 [749880/25046 (92%)]\tLoss: 0.080888\n",
            "Make prediction for 5010 samples...\n",
            "0.26144576 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 154 [0/25046 (0%)]\tLoss: 0.068127\n",
            "Train epoch: 154 [82860/25046 (10%)]\tLoss: 0.061259\n",
            "Train epoch: 154 [169760/25046 (20%)]\tLoss: 0.094822\n",
            "Train epoch: 154 [251340/25046 (31%)]\tLoss: 0.066114\n",
            "Train epoch: 154 [322160/25046 (41%)]\tLoss: 0.054603\n",
            "Train epoch: 154 [397500/25046 (51%)]\tLoss: 0.095560\n",
            "Train epoch: 154 [484440/25046 (61%)]\tLoss: 0.083543\n",
            "Train epoch: 154 [573300/25046 (71%)]\tLoss: 0.070705\n",
            "Train epoch: 154 [644160/25046 (82%)]\tLoss: 0.174271\n",
            "Train epoch: 154 [735300/25046 (92%)]\tLoss: 0.110399\n",
            "Make prediction for 5010 samples...\n",
            "0.26249582 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 155 [0/25046 (0%)]\tLoss: 0.171310\n",
            "Train epoch: 155 [79980/25046 (10%)]\tLoss: 0.095205\n",
            "Train epoch: 155 [167280/25046 (20%)]\tLoss: 0.070118\n",
            "Train epoch: 155 [237480/25046 (31%)]\tLoss: 0.079016\n",
            "Train epoch: 155 [323680/25046 (41%)]\tLoss: 0.085299\n",
            "Train epoch: 155 [420100/25046 (51%)]\tLoss: 0.069495\n",
            "Train epoch: 155 [492720/25046 (61%)]\tLoss: 0.070426\n",
            "Train epoch: 155 [573300/25046 (71%)]\tLoss: 0.062859\n",
            "Train epoch: 155 [651520/25046 (82%)]\tLoss: 0.102743\n",
            "Train epoch: 155 [715140/25046 (92%)]\tLoss: 0.070100\n",
            "Make prediction for 5010 samples...\n",
            "0.27389514 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 156 [0/25046 (0%)]\tLoss: 0.060423\n",
            "Train epoch: 156 [79880/25046 (10%)]\tLoss: 0.100641\n",
            "Train epoch: 156 [164840/25046 (20%)]\tLoss: 0.062320\n",
            "Train epoch: 156 [245460/25046 (31%)]\tLoss: 0.053556\n",
            "Train epoch: 156 [328000/25046 (41%)]\tLoss: 0.124975\n",
            "Train epoch: 156 [402500/25046 (51%)]\tLoss: 0.146918\n",
            "Train epoch: 156 [488400/25046 (61%)]\tLoss: 0.069670\n",
            "Train epoch: 156 [576660/25046 (71%)]\tLoss: 0.104075\n",
            "Train epoch: 156 [654240/25046 (82%)]\tLoss: 0.066082\n",
            "Train epoch: 156 [734760/25046 (92%)]\tLoss: 0.052659\n",
            "Make prediction for 5010 samples...\n",
            "0.25210077 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 157 [0/25046 (0%)]\tLoss: 0.097575\n",
            "Train epoch: 157 [81060/25046 (10%)]\tLoss: 0.043264\n",
            "Train epoch: 157 [163400/25046 (20%)]\tLoss: 0.064264\n",
            "Train epoch: 157 [246420/25046 (31%)]\tLoss: 0.104563\n",
            "Train epoch: 157 [333440/25046 (41%)]\tLoss: 0.114391\n",
            "Train epoch: 157 [400200/25046 (51%)]\tLoss: 0.073169\n",
            "Train epoch: 157 [493200/25046 (61%)]\tLoss: 0.052113\n",
            "Train epoch: 157 [560560/25046 (71%)]\tLoss: 0.072559\n",
            "Train epoch: 157 [654240/25046 (82%)]\tLoss: 0.072119\n",
            "Train epoch: 157 [732420/25046 (92%)]\tLoss: 0.059261\n",
            "Make prediction for 5010 samples...\n",
            "0.25692034 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 158 [0/25046 (0%)]\tLoss: 0.105271\n",
            "Train epoch: 158 [82760/25046 (10%)]\tLoss: 0.073568\n",
            "Train epoch: 158 [159960/25046 (20%)]\tLoss: 0.095268\n",
            "Train epoch: 158 [246480/25046 (31%)]\tLoss: 0.097356\n",
            "Train epoch: 158 [329760/25046 (41%)]\tLoss: 0.045653\n",
            "Train epoch: 158 [414900/25046 (51%)]\tLoss: 0.052390\n",
            "Train epoch: 158 [491880/25046 (61%)]\tLoss: 0.076665\n",
            "Train epoch: 158 [573860/25046 (71%)]\tLoss: 0.067171\n",
            "Train epoch: 158 [663040/25046 (82%)]\tLoss: 0.105172\n",
            "Train epoch: 158 [762480/25046 (92%)]\tLoss: 0.063754\n",
            "Make prediction for 5010 samples...\n",
            "0.25375727 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 159 [0/25046 (0%)]\tLoss: 0.059868\n",
            "Train epoch: 159 [80260/25046 (10%)]\tLoss: 0.066086\n",
            "Train epoch: 159 [163640/25046 (20%)]\tLoss: 0.059453\n",
            "Train epoch: 159 [247920/25046 (31%)]\tLoss: 0.065681\n",
            "Train epoch: 159 [311040/25046 (41%)]\tLoss: 0.075649\n",
            "Train epoch: 159 [411400/25046 (51%)]\tLoss: 0.061002\n",
            "Train epoch: 159 [504240/25046 (61%)]\tLoss: 0.116146\n",
            "Train epoch: 159 [567560/25046 (71%)]\tLoss: 0.089728\n",
            "Train epoch: 159 [644000/25046 (82%)]\tLoss: 0.189835\n",
            "Train epoch: 159 [772200/25046 (92%)]\tLoss: 0.115367\n",
            "Make prediction for 5010 samples...\n",
            "0.2580121 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 160 [0/25046 (0%)]\tLoss: 0.067966\n",
            "Train epoch: 160 [82700/25046 (10%)]\tLoss: 0.062210\n",
            "Train epoch: 160 [165840/25046 (20%)]\tLoss: 0.052664\n",
            "Train epoch: 160 [247860/25046 (31%)]\tLoss: 0.064544\n",
            "Train epoch: 160 [326000/25046 (41%)]\tLoss: 0.106428\n",
            "Train epoch: 160 [405500/25046 (51%)]\tLoss: 0.127284\n",
            "Train epoch: 160 [481560/25046 (61%)]\tLoss: 0.122247\n",
            "Train epoch: 160 [563220/25046 (71%)]\tLoss: 0.048475\n",
            "Train epoch: 160 [641120/25046 (82%)]\tLoss: 0.083908\n",
            "Train epoch: 160 [737460/25046 (92%)]\tLoss: 0.092848\n",
            "Make prediction for 5010 samples...\n",
            "0.2604479 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 161 [0/25046 (0%)]\tLoss: 0.083387\n",
            "Train epoch: 161 [82020/25046 (10%)]\tLoss: 0.127372\n",
            "Train epoch: 161 [173440/25046 (20%)]\tLoss: 0.054134\n",
            "Train epoch: 161 [246060/25046 (31%)]\tLoss: 0.093576\n",
            "Train epoch: 161 [324800/25046 (41%)]\tLoss: 0.088634\n",
            "Train epoch: 161 [410100/25046 (51%)]\tLoss: 0.160686\n",
            "Train epoch: 161 [506880/25046 (61%)]\tLoss: 0.080786\n",
            "Train epoch: 161 [553420/25046 (71%)]\tLoss: 0.125198\n",
            "Train epoch: 161 [675040/25046 (82%)]\tLoss: 0.109592\n",
            "Train epoch: 161 [729000/25046 (92%)]\tLoss: 0.063917\n",
            "Make prediction for 5010 samples...\n",
            "0.2599357 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 162 [0/25046 (0%)]\tLoss: 0.060363\n",
            "Train epoch: 162 [82540/25046 (10%)]\tLoss: 0.053143\n",
            "Train epoch: 162 [166720/25046 (20%)]\tLoss: 0.064304\n",
            "Train epoch: 162 [240540/25046 (31%)]\tLoss: 0.077593\n",
            "Train epoch: 162 [330640/25046 (41%)]\tLoss: 0.088451\n",
            "Train epoch: 162 [394900/25046 (51%)]\tLoss: 0.082655\n",
            "Train epoch: 162 [495360/25046 (61%)]\tLoss: 0.085919\n",
            "Train epoch: 162 [571340/25046 (71%)]\tLoss: 0.105312\n",
            "Train epoch: 162 [660320/25046 (82%)]\tLoss: 0.062557\n",
            "Train epoch: 162 [732600/25046 (92%)]\tLoss: 0.090541\n",
            "Make prediction for 5010 samples...\n",
            "0.25386304 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 163 [0/25046 (0%)]\tLoss: 0.116858\n",
            "Train epoch: 163 [80980/25046 (10%)]\tLoss: 0.098078\n",
            "Train epoch: 163 [160560/25046 (20%)]\tLoss: 0.100842\n",
            "Train epoch: 163 [243540/25046 (31%)]\tLoss: 0.090259\n",
            "Train epoch: 163 [326800/25046 (41%)]\tLoss: 0.040406\n",
            "Train epoch: 163 [414600/25046 (51%)]\tLoss: 0.076973\n",
            "Train epoch: 163 [501480/25046 (61%)]\tLoss: 0.165894\n",
            "Train epoch: 163 [577500/25046 (71%)]\tLoss: 0.100872\n",
            "Train epoch: 163 [645760/25046 (82%)]\tLoss: 0.077788\n",
            "Train epoch: 163 [730620/25046 (92%)]\tLoss: 0.063652\n",
            "Make prediction for 5010 samples...\n",
            "0.26582202 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 164 [0/25046 (0%)]\tLoss: 0.079590\n",
            "Train epoch: 164 [80720/25046 (10%)]\tLoss: 0.056690\n",
            "Train epoch: 164 [168120/25046 (20%)]\tLoss: 0.181034\n",
            "Train epoch: 164 [246060/25046 (31%)]\tLoss: 0.125789\n",
            "Train epoch: 164 [327600/25046 (41%)]\tLoss: 0.091629\n",
            "Train epoch: 164 [406900/25046 (51%)]\tLoss: 0.055930\n",
            "Train epoch: 164 [501000/25046 (61%)]\tLoss: 0.062911\n",
            "Train epoch: 164 [568820/25046 (71%)]\tLoss: 0.065757\n",
            "Train epoch: 164 [659520/25046 (82%)]\tLoss: 0.088611\n",
            "Train epoch: 164 [745380/25046 (92%)]\tLoss: 0.114976\n",
            "Make prediction for 5010 samples...\n",
            "0.2602941 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 165 [0/25046 (0%)]\tLoss: 0.054064\n",
            "Train epoch: 165 [81040/25046 (10%)]\tLoss: 0.058629\n",
            "Train epoch: 165 [162640/25046 (20%)]\tLoss: 0.063767\n",
            "Train epoch: 165 [243420/25046 (31%)]\tLoss: 0.142552\n",
            "Train epoch: 165 [325680/25046 (41%)]\tLoss: 0.061360\n",
            "Train epoch: 165 [412800/25046 (51%)]\tLoss: 0.061582\n",
            "Train epoch: 165 [484440/25046 (61%)]\tLoss: 0.104365\n",
            "Train epoch: 165 [579600/25046 (71%)]\tLoss: 0.089168\n",
            "Train epoch: 165 [657440/25046 (82%)]\tLoss: 0.041460\n",
            "Train epoch: 165 [749340/25046 (92%)]\tLoss: 0.067045\n",
            "Make prediction for 5010 samples...\n",
            "0.26142314 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 166 [0/25046 (0%)]\tLoss: 0.105114\n",
            "Train epoch: 166 [81220/25046 (10%)]\tLoss: 0.075349\n",
            "Train epoch: 166 [161240/25046 (20%)]\tLoss: 0.119238\n",
            "Train epoch: 166 [248760/25046 (31%)]\tLoss: 0.060908\n",
            "Train epoch: 166 [327520/25046 (41%)]\tLoss: 0.089443\n",
            "Train epoch: 166 [423500/25046 (51%)]\tLoss: 0.071344\n",
            "Train epoch: 166 [489480/25046 (61%)]\tLoss: 0.071977\n",
            "Train epoch: 166 [579880/25046 (71%)]\tLoss: 0.202461\n",
            "Train epoch: 166 [663840/25046 (82%)]\tLoss: 0.059487\n",
            "Train epoch: 166 [715140/25046 (92%)]\tLoss: 0.074935\n",
            "Make prediction for 5010 samples...\n",
            "0.27281076 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 167 [0/25046 (0%)]\tLoss: 0.056488\n",
            "Train epoch: 167 [83760/25046 (10%)]\tLoss: 0.074094\n",
            "Train epoch: 167 [161320/25046 (20%)]\tLoss: 0.061350\n",
            "Train epoch: 167 [240960/25046 (31%)]\tLoss: 0.064530\n",
            "Train epoch: 167 [328640/25046 (41%)]\tLoss: 0.124937\n",
            "Train epoch: 167 [414400/25046 (51%)]\tLoss: 0.114230\n",
            "Train epoch: 167 [499560/25046 (61%)]\tLoss: 0.069820\n",
            "Train epoch: 167 [558880/25046 (71%)]\tLoss: 0.058959\n",
            "Train epoch: 167 [677440/25046 (82%)]\tLoss: 0.065779\n",
            "Train epoch: 167 [727560/25046 (92%)]\tLoss: 0.037240\n",
            "Make prediction for 5010 samples...\n",
            "0.2697103 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 168 [0/25046 (0%)]\tLoss: 0.076287\n",
            "Train epoch: 168 [80340/25046 (10%)]\tLoss: 0.079182\n",
            "Train epoch: 168 [159240/25046 (20%)]\tLoss: 0.085894\n",
            "Train epoch: 168 [245520/25046 (31%)]\tLoss: 0.047288\n",
            "Train epoch: 168 [335920/25046 (41%)]\tLoss: 0.112704\n",
            "Train epoch: 168 [409000/25046 (51%)]\tLoss: 0.078890\n",
            "Train epoch: 168 [487200/25046 (61%)]\tLoss: 0.047841\n",
            "Train epoch: 168 [590520/25046 (71%)]\tLoss: 0.094064\n",
            "Train epoch: 168 [648800/25046 (82%)]\tLoss: 0.121869\n",
            "Train epoch: 168 [747180/25046 (92%)]\tLoss: 0.122254\n",
            "Make prediction for 5010 samples...\n",
            "0.26383108 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 169 [0/25046 (0%)]\tLoss: 0.056539\n",
            "Train epoch: 169 [81220/25046 (10%)]\tLoss: 0.044641\n",
            "Train epoch: 169 [166440/25046 (20%)]\tLoss: 0.074475\n",
            "Train epoch: 169 [242040/25046 (31%)]\tLoss: 0.052696\n",
            "Train epoch: 169 [330160/25046 (41%)]\tLoss: 0.103420\n",
            "Train epoch: 169 [411100/25046 (51%)]\tLoss: 0.067988\n",
            "Train epoch: 169 [474000/25046 (61%)]\tLoss: 0.064202\n",
            "Train epoch: 169 [576240/25046 (71%)]\tLoss: 0.107719\n",
            "Train epoch: 169 [649920/25046 (82%)]\tLoss: 0.078681\n",
            "Train epoch: 169 [745560/25046 (92%)]\tLoss: 0.084249\n",
            "Make prediction for 5010 samples...\n",
            "0.25656015 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 170 [0/25046 (0%)]\tLoss: 0.143014\n",
            "Train epoch: 170 [81500/25046 (10%)]\tLoss: 0.155402\n",
            "Train epoch: 170 [169280/25046 (20%)]\tLoss: 0.075994\n",
            "Train epoch: 170 [247380/25046 (31%)]\tLoss: 0.067435\n",
            "Train epoch: 170 [327760/25046 (41%)]\tLoss: 0.071969\n",
            "Train epoch: 170 [413800/25046 (51%)]\tLoss: 0.050593\n",
            "Train epoch: 170 [495840/25046 (61%)]\tLoss: 0.038081\n",
            "Train epoch: 170 [559720/25046 (71%)]\tLoss: 0.048569\n",
            "Train epoch: 170 [662400/25046 (82%)]\tLoss: 0.050026\n",
            "Train epoch: 170 [729900/25046 (92%)]\tLoss: 0.089590\n",
            "Make prediction for 5010 samples...\n",
            "0.2558891 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 171 [0/25046 (0%)]\tLoss: 0.095798\n",
            "Train epoch: 171 [81180/25046 (10%)]\tLoss: 0.099272\n",
            "Train epoch: 171 [163000/25046 (20%)]\tLoss: 0.127955\n",
            "Train epoch: 171 [251280/25046 (31%)]\tLoss: 0.119193\n",
            "Train epoch: 171 [327520/25046 (41%)]\tLoss: 0.075828\n",
            "Train epoch: 171 [404700/25046 (51%)]\tLoss: 0.098156\n",
            "Train epoch: 171 [498720/25046 (61%)]\tLoss: 0.065992\n",
            "Train epoch: 171 [573860/25046 (71%)]\tLoss: 0.052242\n",
            "Train epoch: 171 [652640/25046 (82%)]\tLoss: 0.052483\n",
            "Train epoch: 171 [730980/25046 (92%)]\tLoss: 0.105971\n",
            "Make prediction for 5010 samples...\n",
            "0.2553757 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 172 [0/25046 (0%)]\tLoss: 0.084894\n",
            "Train epoch: 172 [83300/25046 (10%)]\tLoss: 0.054755\n",
            "Train epoch: 172 [169640/25046 (20%)]\tLoss: 0.103508\n",
            "Train epoch: 172 [243540/25046 (31%)]\tLoss: 0.088321\n",
            "Train epoch: 172 [329120/25046 (41%)]\tLoss: 0.056627\n",
            "Train epoch: 172 [418900/25046 (51%)]\tLoss: 0.140212\n",
            "Train epoch: 172 [503760/25046 (61%)]\tLoss: 0.072191\n",
            "Train epoch: 172 [571760/25046 (71%)]\tLoss: 0.102064\n",
            "Train epoch: 172 [647040/25046 (82%)]\tLoss: 0.083933\n",
            "Train epoch: 172 [728640/25046 (92%)]\tLoss: 0.044620\n",
            "Make prediction for 5010 samples...\n",
            "0.2660209 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 173 [0/25046 (0%)]\tLoss: 0.040256\n",
            "Train epoch: 173 [82440/25046 (10%)]\tLoss: 0.069400\n",
            "Train epoch: 173 [161640/25046 (20%)]\tLoss: 0.094978\n",
            "Train epoch: 173 [245520/25046 (31%)]\tLoss: 0.062635\n",
            "Train epoch: 173 [326320/25046 (41%)]\tLoss: 0.093690\n",
            "Train epoch: 173 [400500/25046 (51%)]\tLoss: 0.092517\n",
            "Train epoch: 173 [498120/25046 (61%)]\tLoss: 0.085930\n",
            "Train epoch: 173 [578340/25046 (71%)]\tLoss: 0.046516\n",
            "Train epoch: 173 [657920/25046 (82%)]\tLoss: 0.095107\n",
            "Train epoch: 173 [732060/25046 (92%)]\tLoss: 0.045582\n",
            "Make prediction for 5010 samples...\n",
            "0.26138842 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 174 [0/25046 (0%)]\tLoss: 0.089355\n",
            "Train epoch: 174 [80800/25046 (10%)]\tLoss: 0.078075\n",
            "Train epoch: 174 [164360/25046 (20%)]\tLoss: 0.100576\n",
            "Train epoch: 174 [244980/25046 (31%)]\tLoss: 0.110405\n",
            "Train epoch: 174 [324960/25046 (41%)]\tLoss: 0.092312\n",
            "Train epoch: 174 [399800/25046 (51%)]\tLoss: 0.126883\n",
            "Train epoch: 174 [505800/25046 (61%)]\tLoss: 0.080011\n",
            "Train epoch: 174 [557480/25046 (71%)]\tLoss: 0.080872\n",
            "Train epoch: 174 [663520/25046 (82%)]\tLoss: 0.059841\n",
            "Train epoch: 174 [724320/25046 (92%)]\tLoss: 0.084139\n",
            "Make prediction for 5010 samples...\n",
            "0.2620903 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 175 [0/25046 (0%)]\tLoss: 0.092271\n",
            "Train epoch: 175 [80620/25046 (10%)]\tLoss: 0.036766\n",
            "Train epoch: 175 [164680/25046 (20%)]\tLoss: 0.069349\n",
            "Train epoch: 175 [252600/25046 (31%)]\tLoss: 0.070392\n",
            "Train epoch: 175 [335920/25046 (41%)]\tLoss: 0.081332\n",
            "Train epoch: 175 [411500/25046 (51%)]\tLoss: 0.051906\n",
            "Train epoch: 175 [486120/25046 (61%)]\tLoss: 0.042393\n",
            "Train epoch: 175 [590800/25046 (71%)]\tLoss: 0.046305\n",
            "Train epoch: 175 [661920/25046 (82%)]\tLoss: 0.114826\n",
            "Train epoch: 175 [747900/25046 (92%)]\tLoss: 0.071965\n",
            "Make prediction for 5010 samples...\n",
            "0.26607662 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 176 [0/25046 (0%)]\tLoss: 0.070550\n",
            "Train epoch: 176 [81940/25046 (10%)]\tLoss: 0.055492\n",
            "Train epoch: 176 [163120/25046 (20%)]\tLoss: 0.083862\n",
            "Train epoch: 176 [244260/25046 (31%)]\tLoss: 0.091570\n",
            "Train epoch: 176 [329520/25046 (41%)]\tLoss: 0.025819\n",
            "Train epoch: 176 [413800/25046 (51%)]\tLoss: 0.072160\n",
            "Train epoch: 176 [486840/25046 (61%)]\tLoss: 0.184242\n",
            "Train epoch: 176 [565600/25046 (71%)]\tLoss: 0.062703\n",
            "Train epoch: 176 [663680/25046 (82%)]\tLoss: 0.053118\n",
            "Train epoch: 176 [759060/25046 (92%)]\tLoss: 0.091482\n",
            "Make prediction for 5010 samples...\n",
            "0.2638705 No improvement since epoch  152 ; best_mse,best_ci: 0.25107798 0.869165285867854 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 177 [0/25046 (0%)]\tLoss: 0.095020\n",
            "Train epoch: 177 [80220/25046 (10%)]\tLoss: 0.065138\n",
            "Train epoch: 177 [158480/25046 (20%)]\tLoss: 0.067729\n",
            "Train epoch: 177 [253080/25046 (31%)]\tLoss: 0.067378\n",
            "Train epoch: 177 [320240/25046 (41%)]\tLoss: 0.060082\n",
            "Train epoch: 177 [416900/25046 (51%)]\tLoss: 0.087559\n",
            "Train epoch: 177 [490440/25046 (61%)]\tLoss: 0.105433\n",
            "Train epoch: 177 [562380/25046 (71%)]\tLoss: 0.097943\n",
            "Train epoch: 177 [668480/25046 (82%)]\tLoss: 0.168870\n",
            "Train epoch: 177 [721620/25046 (92%)]\tLoss: 0.142057\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 178 [0/25046 (0%)]\tLoss: 0.085005\n",
            "Train epoch: 178 [82680/25046 (10%)]\tLoss: 0.090427\n",
            "Train epoch: 178 [166080/25046 (20%)]\tLoss: 0.106847\n",
            "Train epoch: 178 [244860/25046 (31%)]\tLoss: 0.078656\n",
            "Train epoch: 178 [330960/25046 (41%)]\tLoss: 0.075289\n",
            "Train epoch: 178 [412600/25046 (51%)]\tLoss: 0.114444\n",
            "Train epoch: 178 [488160/25046 (61%)]\tLoss: 0.104024\n",
            "Train epoch: 178 [584220/25046 (71%)]\tLoss: 0.048262\n",
            "Train epoch: 178 [680000/25046 (82%)]\tLoss: 0.067621\n",
            "Train epoch: 178 [714600/25046 (92%)]\tLoss: 0.052852\n",
            "Make prediction for 5010 samples...\n",
            "0.26774296 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 179 [0/25046 (0%)]\tLoss: 0.165980\n",
            "Train epoch: 179 [79420/25046 (10%)]\tLoss: 0.078219\n",
            "Train epoch: 179 [166600/25046 (20%)]\tLoss: 0.215460\n",
            "Train epoch: 179 [246840/25046 (31%)]\tLoss: 0.068979\n",
            "Train epoch: 179 [320160/25046 (41%)]\tLoss: 0.075240\n",
            "Train epoch: 179 [427700/25046 (51%)]\tLoss: 0.068915\n",
            "Train epoch: 179 [496800/25046 (61%)]\tLoss: 0.058439\n",
            "Train epoch: 179 [584920/25046 (71%)]\tLoss: 0.085320\n",
            "Train epoch: 179 [645760/25046 (82%)]\tLoss: 0.074472\n",
            "Train epoch: 179 [752940/25046 (92%)]\tLoss: 0.056480\n",
            "Make prediction for 5010 samples...\n",
            "0.27359217 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 180 [0/25046 (0%)]\tLoss: 0.049633\n",
            "Train epoch: 180 [83500/25046 (10%)]\tLoss: 0.026625\n",
            "Train epoch: 180 [159840/25046 (20%)]\tLoss: 0.185600\n",
            "Train epoch: 180 [246780/25046 (31%)]\tLoss: 0.064827\n",
            "Train epoch: 180 [333760/25046 (41%)]\tLoss: 0.067739\n",
            "Train epoch: 180 [401800/25046 (51%)]\tLoss: 0.083404\n",
            "Train epoch: 180 [496080/25046 (61%)]\tLoss: 0.065748\n",
            "Train epoch: 180 [578900/25046 (71%)]\tLoss: 0.049231\n",
            "Train epoch: 180 [650080/25046 (82%)]\tLoss: 0.098274\n",
            "Train epoch: 180 [742860/25046 (92%)]\tLoss: 0.056951\n",
            "Make prediction for 5010 samples...\n",
            "0.26371202 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 181 [0/25046 (0%)]\tLoss: 0.064981\n",
            "Train epoch: 181 [84920/25046 (10%)]\tLoss: 0.042333\n",
            "Train epoch: 181 [167760/25046 (20%)]\tLoss: 0.105978\n",
            "Train epoch: 181 [254100/25046 (31%)]\tLoss: 0.077919\n",
            "Train epoch: 181 [328640/25046 (41%)]\tLoss: 0.119817\n",
            "Train epoch: 181 [406700/25046 (51%)]\tLoss: 0.084303\n",
            "Train epoch: 181 [495480/25046 (61%)]\tLoss: 0.096424\n",
            "Train epoch: 181 [576240/25046 (71%)]\tLoss: 0.098905\n",
            "Train epoch: 181 [653120/25046 (82%)]\tLoss: 0.139263\n",
            "Train epoch: 181 [759420/25046 (92%)]\tLoss: 0.099882\n",
            "Make prediction for 5010 samples...\n",
            "0.2632941 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 182 [0/25046 (0%)]\tLoss: 0.093755\n",
            "Train epoch: 182 [81160/25046 (10%)]\tLoss: 0.073063\n",
            "Train epoch: 182 [157800/25046 (20%)]\tLoss: 0.091644\n",
            "Train epoch: 182 [241080/25046 (31%)]\tLoss: 0.036728\n",
            "Train epoch: 182 [330400/25046 (41%)]\tLoss: 0.044773\n",
            "Train epoch: 182 [400500/25046 (51%)]\tLoss: 0.073726\n",
            "Train epoch: 182 [477600/25046 (61%)]\tLoss: 0.101010\n",
            "Train epoch: 182 [568120/25046 (71%)]\tLoss: 0.068238\n",
            "Train epoch: 182 [662880/25046 (82%)]\tLoss: 0.108595\n",
            "Train epoch: 182 [741600/25046 (92%)]\tLoss: 0.073187\n",
            "Make prediction for 5010 samples...\n",
            "0.26570985 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 183 [0/25046 (0%)]\tLoss: 0.052471\n",
            "Train epoch: 183 [82340/25046 (10%)]\tLoss: 0.056897\n",
            "Train epoch: 183 [165400/25046 (20%)]\tLoss: 0.234020\n",
            "Train epoch: 183 [246480/25046 (31%)]\tLoss: 0.092544\n",
            "Train epoch: 183 [330000/25046 (41%)]\tLoss: 0.214842\n",
            "Train epoch: 183 [413800/25046 (51%)]\tLoss: 0.082750\n",
            "Train epoch: 183 [485640/25046 (61%)]\tLoss: 0.076771\n",
            "Train epoch: 183 [587580/25046 (71%)]\tLoss: 0.060634\n",
            "Train epoch: 183 [666880/25046 (82%)]\tLoss: 0.064517\n",
            "Train epoch: 183 [760860/25046 (92%)]\tLoss: 0.064355\n",
            "Make prediction for 5010 samples...\n",
            "0.25756797 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 184 [0/25046 (0%)]\tLoss: 0.081718\n",
            "Train epoch: 184 [83140/25046 (10%)]\tLoss: 0.050427\n",
            "Train epoch: 184 [166840/25046 (20%)]\tLoss: 0.038412\n",
            "Train epoch: 184 [244380/25046 (31%)]\tLoss: 0.068609\n",
            "Train epoch: 184 [328880/25046 (41%)]\tLoss: 0.160879\n",
            "Train epoch: 184 [400400/25046 (51%)]\tLoss: 0.096525\n",
            "Train epoch: 184 [482280/25046 (61%)]\tLoss: 0.069813\n",
            "Train epoch: 184 [563080/25046 (71%)]\tLoss: 0.049745\n",
            "Train epoch: 184 [646720/25046 (82%)]\tLoss: 0.066628\n",
            "Train epoch: 184 [749880/25046 (92%)]\tLoss: 0.063115\n",
            "Make prediction for 5010 samples...\n",
            "0.25568897 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 185 [0/25046 (0%)]\tLoss: 0.045376\n",
            "Train epoch: 185 [80520/25046 (10%)]\tLoss: 0.058369\n",
            "Train epoch: 185 [163200/25046 (20%)]\tLoss: 0.023543\n",
            "Train epoch: 185 [243240/25046 (31%)]\tLoss: 0.071634\n",
            "Train epoch: 185 [336960/25046 (41%)]\tLoss: 0.073628\n",
            "Train epoch: 185 [409100/25046 (51%)]\tLoss: 0.074618\n",
            "Train epoch: 185 [497520/25046 (61%)]\tLoss: 0.064768\n",
            "Train epoch: 185 [566580/25046 (71%)]\tLoss: 0.085351\n",
            "Train epoch: 185 [662080/25046 (82%)]\tLoss: 0.074553\n",
            "Train epoch: 185 [753300/25046 (92%)]\tLoss: 0.072300\n",
            "Make prediction for 5010 samples...\n",
            "0.26472104 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 186 [0/25046 (0%)]\tLoss: 0.046791\n",
            "Train epoch: 186 [83720/25046 (10%)]\tLoss: 0.054647\n",
            "Train epoch: 186 [163720/25046 (20%)]\tLoss: 0.058661\n",
            "Train epoch: 186 [250500/25046 (31%)]\tLoss: 0.058617\n",
            "Train epoch: 186 [326080/25046 (41%)]\tLoss: 0.054131\n",
            "Train epoch: 186 [410500/25046 (51%)]\tLoss: 0.043530\n",
            "Train epoch: 186 [510960/25046 (61%)]\tLoss: 0.121011\n",
            "Train epoch: 186 [582960/25046 (71%)]\tLoss: 0.073970\n",
            "Train epoch: 186 [654880/25046 (82%)]\tLoss: 0.065623\n",
            "Train epoch: 186 [729900/25046 (92%)]\tLoss: 0.069875\n",
            "Make prediction for 5010 samples...\n",
            "0.25636515 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 187 [0/25046 (0%)]\tLoss: 0.045276\n",
            "Train epoch: 187 [81540/25046 (10%)]\tLoss: 0.055465\n",
            "Train epoch: 187 [164480/25046 (20%)]\tLoss: 0.088874\n",
            "Train epoch: 187 [255780/25046 (31%)]\tLoss: 0.079261\n",
            "Train epoch: 187 [327120/25046 (41%)]\tLoss: 0.077816\n",
            "Train epoch: 187 [417500/25046 (51%)]\tLoss: 0.108362\n",
            "Train epoch: 187 [501840/25046 (61%)]\tLoss: 0.046921\n",
            "Train epoch: 187 [575120/25046 (71%)]\tLoss: 0.070002\n",
            "Train epoch: 187 [660000/25046 (82%)]\tLoss: 0.046628\n",
            "Train epoch: 187 [736380/25046 (92%)]\tLoss: 0.107105\n",
            "Make prediction for 5010 samples...\n",
            "0.25738168 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 188 [0/25046 (0%)]\tLoss: 0.053914\n",
            "Train epoch: 188 [81340/25046 (10%)]\tLoss: 0.044339\n",
            "Train epoch: 188 [161640/25046 (20%)]\tLoss: 0.056965\n",
            "Train epoch: 188 [244500/25046 (31%)]\tLoss: 0.057453\n",
            "Train epoch: 188 [329040/25046 (41%)]\tLoss: 0.155998\n",
            "Train epoch: 188 [403400/25046 (51%)]\tLoss: 0.049034\n",
            "Train epoch: 188 [498240/25046 (61%)]\tLoss: 0.057276\n",
            "Train epoch: 188 [578340/25046 (71%)]\tLoss: 0.053682\n",
            "Train epoch: 188 [649600/25046 (82%)]\tLoss: 0.069975\n",
            "Train epoch: 188 [738000/25046 (92%)]\tLoss: 0.056119\n",
            "Make prediction for 5010 samples...\n",
            "0.25863728 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 189 [0/25046 (0%)]\tLoss: 0.036893\n",
            "Train epoch: 189 [81540/25046 (10%)]\tLoss: 0.087679\n",
            "Train epoch: 189 [163120/25046 (20%)]\tLoss: 0.053556\n",
            "Train epoch: 189 [243420/25046 (31%)]\tLoss: 0.120230\n",
            "Train epoch: 189 [332800/25046 (41%)]\tLoss: 0.056206\n",
            "Train epoch: 189 [411100/25046 (51%)]\tLoss: 0.092302\n",
            "Train epoch: 189 [499560/25046 (61%)]\tLoss: 0.121422\n",
            "Train epoch: 189 [575680/25046 (71%)]\tLoss: 0.053625\n",
            "Train epoch: 189 [630880/25046 (82%)]\tLoss: 0.107145\n",
            "Train epoch: 189 [757980/25046 (92%)]\tLoss: 0.057890\n",
            "Make prediction for 5010 samples...\n",
            "0.2575476 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 190 [0/25046 (0%)]\tLoss: 0.099032\n",
            "Train epoch: 190 [79960/25046 (10%)]\tLoss: 0.123269\n",
            "Train epoch: 190 [155760/25046 (20%)]\tLoss: 0.034193\n",
            "Train epoch: 190 [259800/25046 (31%)]\tLoss: 0.060186\n",
            "Train epoch: 190 [334960/25046 (41%)]\tLoss: 0.113622\n",
            "Train epoch: 190 [407500/25046 (51%)]\tLoss: 0.033732\n",
            "Train epoch: 190 [492120/25046 (61%)]\tLoss: 0.043827\n",
            "Train epoch: 190 [576660/25046 (71%)]\tLoss: 0.094608\n",
            "Train epoch: 190 [651520/25046 (82%)]\tLoss: 0.097760\n",
            "Train epoch: 190 [733320/25046 (92%)]\tLoss: 0.053780\n",
            "Make prediction for 5010 samples...\n",
            "0.25415298 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 191 [0/25046 (0%)]\tLoss: 0.066168\n",
            "Train epoch: 191 [79800/25046 (10%)]\tLoss: 0.051523\n",
            "Train epoch: 191 [168200/25046 (20%)]\tLoss: 0.060633\n",
            "Train epoch: 191 [247980/25046 (31%)]\tLoss: 0.046113\n",
            "Train epoch: 191 [320080/25046 (41%)]\tLoss: 0.088112\n",
            "Train epoch: 191 [404500/25046 (51%)]\tLoss: 0.098535\n",
            "Train epoch: 191 [492720/25046 (61%)]\tLoss: 0.109092\n",
            "Train epoch: 191 [569660/25046 (71%)]\tLoss: 0.086381\n",
            "Train epoch: 191 [675520/25046 (82%)]\tLoss: 0.045511\n",
            "Train epoch: 191 [739440/25046 (92%)]\tLoss: 0.108205\n",
            "Make prediction for 5010 samples...\n",
            "0.2556314 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 192 [0/25046 (0%)]\tLoss: 0.036328\n",
            "Train epoch: 192 [83860/25046 (10%)]\tLoss: 0.085756\n",
            "Train epoch: 192 [163000/25046 (20%)]\tLoss: 0.172362\n",
            "Train epoch: 192 [246960/25046 (31%)]\tLoss: 0.091545\n",
            "Train epoch: 192 [338160/25046 (41%)]\tLoss: 0.081406\n",
            "Train epoch: 192 [424400/25046 (51%)]\tLoss: 0.041590\n",
            "Train epoch: 192 [496920/25046 (61%)]\tLoss: 0.047369\n",
            "Train epoch: 192 [560280/25046 (71%)]\tLoss: 0.029086\n",
            "Train epoch: 192 [664640/25046 (82%)]\tLoss: 0.065746\n",
            "Train epoch: 192 [724500/25046 (92%)]\tLoss: 0.071264\n",
            "Make prediction for 5010 samples...\n",
            "0.25678504 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 193 [0/25046 (0%)]\tLoss: 0.065447\n",
            "Train epoch: 193 [81180/25046 (10%)]\tLoss: 0.067487\n",
            "Train epoch: 193 [165120/25046 (20%)]\tLoss: 0.077172\n",
            "Train epoch: 193 [243960/25046 (31%)]\tLoss: 0.053819\n",
            "Train epoch: 193 [321600/25046 (41%)]\tLoss: 0.095380\n",
            "Train epoch: 193 [416500/25046 (51%)]\tLoss: 0.074366\n",
            "Train epoch: 193 [488040/25046 (61%)]\tLoss: 0.066040\n",
            "Train epoch: 193 [555520/25046 (71%)]\tLoss: 0.048983\n",
            "Train epoch: 193 [676160/25046 (82%)]\tLoss: 0.067554\n",
            "Train epoch: 193 [756900/25046 (92%)]\tLoss: 0.153303\n",
            "Make prediction for 5010 samples...\n",
            "0.27402973 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 194 [0/25046 (0%)]\tLoss: 0.050430\n",
            "Train epoch: 194 [83260/25046 (10%)]\tLoss: 0.036137\n",
            "Train epoch: 194 [168040/25046 (20%)]\tLoss: 0.045064\n",
            "Train epoch: 194 [244860/25046 (31%)]\tLoss: 0.144338\n",
            "Train epoch: 194 [325840/25046 (41%)]\tLoss: 0.102003\n",
            "Train epoch: 194 [401600/25046 (51%)]\tLoss: 0.033740\n",
            "Train epoch: 194 [484680/25046 (61%)]\tLoss: 0.110499\n",
            "Train epoch: 194 [578900/25046 (71%)]\tLoss: 0.081106\n",
            "Train epoch: 194 [659040/25046 (82%)]\tLoss: 0.085210\n",
            "Train epoch: 194 [734400/25046 (92%)]\tLoss: 0.108689\n",
            "Make prediction for 5010 samples...\n",
            "0.25901112 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 195 [0/25046 (0%)]\tLoss: 0.050268\n",
            "Train epoch: 195 [81760/25046 (10%)]\tLoss: 0.055927\n",
            "Train epoch: 195 [165680/25046 (20%)]\tLoss: 0.074607\n",
            "Train epoch: 195 [251220/25046 (31%)]\tLoss: 0.050176\n",
            "Train epoch: 195 [321440/25046 (41%)]\tLoss: 0.105098\n",
            "Train epoch: 195 [421800/25046 (51%)]\tLoss: 0.119848\n",
            "Train epoch: 195 [486480/25046 (61%)]\tLoss: 0.103550\n",
            "Train epoch: 195 [580580/25046 (71%)]\tLoss: 0.133834\n",
            "Train epoch: 195 [686080/25046 (82%)]\tLoss: 0.067192\n",
            "Train epoch: 195 [729540/25046 (92%)]\tLoss: 0.059101\n",
            "Make prediction for 5010 samples...\n",
            "0.26479995 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 196 [0/25046 (0%)]\tLoss: 0.092698\n",
            "Train epoch: 196 [80900/25046 (10%)]\tLoss: 0.034719\n",
            "Train epoch: 196 [155920/25046 (20%)]\tLoss: 0.063602\n",
            "Train epoch: 196 [247200/25046 (31%)]\tLoss: 0.186137\n",
            "Train epoch: 196 [331920/25046 (41%)]\tLoss: 0.027739\n",
            "Train epoch: 196 [402600/25046 (51%)]\tLoss: 0.085645\n",
            "Train epoch: 196 [485760/25046 (61%)]\tLoss: 0.059640\n",
            "Train epoch: 196 [581000/25046 (71%)]\tLoss: 0.089925\n",
            "Train epoch: 196 [669600/25046 (82%)]\tLoss: 0.086936\n",
            "Train epoch: 196 [740700/25046 (92%)]\tLoss: 0.063574\n",
            "Make prediction for 5010 samples...\n",
            "0.2630732 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 197 [0/25046 (0%)]\tLoss: 0.034330\n",
            "Train epoch: 197 [80960/25046 (10%)]\tLoss: 0.124893\n",
            "Train epoch: 197 [166360/25046 (20%)]\tLoss: 0.115047\n",
            "Train epoch: 197 [248160/25046 (31%)]\tLoss: 0.061645\n",
            "Train epoch: 197 [326480/25046 (41%)]\tLoss: 0.089894\n",
            "Train epoch: 197 [407000/25046 (51%)]\tLoss: 0.067405\n",
            "Train epoch: 197 [488640/25046 (61%)]\tLoss: 0.103177\n",
            "Train epoch: 197 [563360/25046 (71%)]\tLoss: 0.093238\n",
            "Train epoch: 197 [648480/25046 (82%)]\tLoss: 0.080443\n",
            "Train epoch: 197 [722700/25046 (92%)]\tLoss: 0.175427\n",
            "Make prediction for 5010 samples...\n",
            "0.25994387 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 198 [0/25046 (0%)]\tLoss: 0.088935\n",
            "Train epoch: 198 [81720/25046 (10%)]\tLoss: 0.072547\n",
            "Train epoch: 198 [164520/25046 (20%)]\tLoss: 0.037574\n",
            "Train epoch: 198 [254580/25046 (31%)]\tLoss: 0.063408\n",
            "Train epoch: 198 [324720/25046 (41%)]\tLoss: 0.074816\n",
            "Train epoch: 198 [414600/25046 (51%)]\tLoss: 0.044629\n",
            "Train epoch: 198 [485040/25046 (61%)]\tLoss: 0.044681\n",
            "Train epoch: 198 [582960/25046 (71%)]\tLoss: 0.041992\n",
            "Train epoch: 198 [653120/25046 (82%)]\tLoss: 0.126073\n",
            "Train epoch: 198 [723600/25046 (92%)]\tLoss: 0.072143\n",
            "Make prediction for 5010 samples...\n",
            "0.2672248 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 199 [0/25046 (0%)]\tLoss: 0.073009\n",
            "Train epoch: 199 [81660/25046 (10%)]\tLoss: 0.047162\n",
            "Train epoch: 199 [163360/25046 (20%)]\tLoss: 0.072799\n",
            "Train epoch: 199 [247020/25046 (31%)]\tLoss: 0.065848\n",
            "Train epoch: 199 [344560/25046 (41%)]\tLoss: 0.082770\n",
            "Train epoch: 199 [409700/25046 (51%)]\tLoss: 0.079989\n",
            "Train epoch: 199 [503760/25046 (61%)]\tLoss: 0.071893\n",
            "Train epoch: 199 [551600/25046 (71%)]\tLoss: 0.053864\n",
            "Train epoch: 199 [650720/25046 (82%)]\tLoss: 0.053663\n",
            "Train epoch: 199 [732960/25046 (92%)]\tLoss: 0.030630\n",
            "Make prediction for 5010 samples...\n",
            "0.25948742 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 200 [0/25046 (0%)]\tLoss: 0.090402\n",
            "Train epoch: 200 [81480/25046 (10%)]\tLoss: 0.054795\n",
            "Train epoch: 200 [156840/25046 (20%)]\tLoss: 0.103930\n",
            "Train epoch: 200 [244740/25046 (31%)]\tLoss: 0.038166\n",
            "Train epoch: 200 [325600/25046 (41%)]\tLoss: 0.073933\n",
            "Train epoch: 200 [406900/25046 (51%)]\tLoss: 0.088415\n",
            "Train epoch: 200 [497400/25046 (61%)]\tLoss: 0.068664\n",
            "Train epoch: 200 [585060/25046 (71%)]\tLoss: 0.056009\n",
            "Train epoch: 200 [666720/25046 (82%)]\tLoss: 0.057309\n",
            "Train epoch: 200 [726120/25046 (92%)]\tLoss: 0.056432\n",
            "Make prediction for 5010 samples...\n",
            "0.2598879 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 201 [0/25046 (0%)]\tLoss: 0.050782\n",
            "Train epoch: 201 [81280/25046 (10%)]\tLoss: 0.090739\n",
            "Train epoch: 201 [162720/25046 (20%)]\tLoss: 0.055128\n",
            "Train epoch: 201 [244500/25046 (31%)]\tLoss: 0.063646\n",
            "Train epoch: 201 [323120/25046 (41%)]\tLoss: 0.098792\n",
            "Train epoch: 201 [408200/25046 (51%)]\tLoss: 0.050867\n",
            "Train epoch: 201 [478680/25046 (61%)]\tLoss: 0.047759\n",
            "Train epoch: 201 [578480/25046 (71%)]\tLoss: 0.064840\n",
            "Train epoch: 201 [689120/25046 (82%)]\tLoss: 0.080551\n",
            "Train epoch: 201 [753120/25046 (92%)]\tLoss: 0.051285\n",
            "Make prediction for 5010 samples...\n",
            "0.25236198 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 202 [0/25046 (0%)]\tLoss: 0.065431\n",
            "Train epoch: 202 [80580/25046 (10%)]\tLoss: 0.093261\n",
            "Train epoch: 202 [163840/25046 (20%)]\tLoss: 0.044755\n",
            "Train epoch: 202 [246180/25046 (31%)]\tLoss: 0.095855\n",
            "Train epoch: 202 [327840/25046 (41%)]\tLoss: 0.073645\n",
            "Train epoch: 202 [401100/25046 (51%)]\tLoss: 0.050747\n",
            "Train epoch: 202 [500280/25046 (61%)]\tLoss: 0.093982\n",
            "Train epoch: 202 [571760/25046 (71%)]\tLoss: 0.076983\n",
            "Train epoch: 202 [646240/25046 (82%)]\tLoss: 0.045896\n",
            "Train epoch: 202 [750240/25046 (92%)]\tLoss: 0.063428\n",
            "Make prediction for 5010 samples...\n",
            "0.25216997 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 203 [0/25046 (0%)]\tLoss: 0.072781\n",
            "Train epoch: 203 [82360/25046 (10%)]\tLoss: 0.149317\n",
            "Train epoch: 203 [158960/25046 (20%)]\tLoss: 0.051117\n",
            "Train epoch: 203 [243960/25046 (31%)]\tLoss: 0.078171\n",
            "Train epoch: 203 [323280/25046 (41%)]\tLoss: 0.089304\n",
            "Train epoch: 203 [411400/25046 (51%)]\tLoss: 0.081970\n",
            "Train epoch: 203 [508560/25046 (61%)]\tLoss: 0.068498\n",
            "Train epoch: 203 [574000/25046 (71%)]\tLoss: 0.088387\n",
            "Train epoch: 203 [663040/25046 (82%)]\tLoss: 0.039408\n",
            "Train epoch: 203 [763200/25046 (92%)]\tLoss: 0.065147\n",
            "Make prediction for 5010 samples...\n",
            "0.2672171 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 204 [0/25046 (0%)]\tLoss: 0.145594\n",
            "Train epoch: 204 [83200/25046 (10%)]\tLoss: 0.049246\n",
            "Train epoch: 204 [162960/25046 (20%)]\tLoss: 0.085366\n",
            "Train epoch: 204 [247260/25046 (31%)]\tLoss: 0.064032\n",
            "Train epoch: 204 [329120/25046 (41%)]\tLoss: 0.072666\n",
            "Train epoch: 204 [409800/25046 (51%)]\tLoss: 0.066748\n",
            "Train epoch: 204 [492000/25046 (61%)]\tLoss: 0.062514\n",
            "Train epoch: 204 [572040/25046 (71%)]\tLoss: 0.064209\n",
            "Train epoch: 204 [650400/25046 (82%)]\tLoss: 0.048799\n",
            "Train epoch: 204 [735840/25046 (92%)]\tLoss: 0.049306\n",
            "Make prediction for 5010 samples...\n",
            "0.26271072 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 205 [0/25046 (0%)]\tLoss: 0.052260\n",
            "Train epoch: 205 [81660/25046 (10%)]\tLoss: 0.060114\n",
            "Train epoch: 205 [164800/25046 (20%)]\tLoss: 0.040646\n",
            "Train epoch: 205 [245100/25046 (31%)]\tLoss: 0.114889\n",
            "Train epoch: 205 [327680/25046 (41%)]\tLoss: 0.197827\n",
            "Train epoch: 205 [393800/25046 (51%)]\tLoss: 0.071212\n",
            "Train epoch: 205 [497880/25046 (61%)]\tLoss: 0.060102\n",
            "Train epoch: 205 [586600/25046 (71%)]\tLoss: 0.129702\n",
            "Train epoch: 205 [659520/25046 (82%)]\tLoss: 0.088902\n",
            "Train epoch: 205 [745560/25046 (92%)]\tLoss: 0.087484\n",
            "Make prediction for 5010 samples...\n",
            "0.26187134 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 206 [0/25046 (0%)]\tLoss: 0.055681\n",
            "Train epoch: 206 [80920/25046 (10%)]\tLoss: 0.033106\n",
            "Train epoch: 206 [165800/25046 (20%)]\tLoss: 0.062085\n",
            "Train epoch: 206 [251580/25046 (31%)]\tLoss: 0.052577\n",
            "Train epoch: 206 [322080/25046 (41%)]\tLoss: 0.046416\n",
            "Train epoch: 206 [414600/25046 (51%)]\tLoss: 0.027664\n",
            "Train epoch: 206 [490800/25046 (61%)]\tLoss: 0.071643\n",
            "Train epoch: 206 [583100/25046 (71%)]\tLoss: 0.118702\n",
            "Train epoch: 206 [669760/25046 (82%)]\tLoss: 0.121005\n",
            "Train epoch: 206 [734040/25046 (92%)]\tLoss: 0.067654\n",
            "Make prediction for 5010 samples...\n",
            "0.2576397 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 207 [0/25046 (0%)]\tLoss: 0.067863\n",
            "Train epoch: 207 [83180/25046 (10%)]\tLoss: 0.067321\n",
            "Train epoch: 207 [161280/25046 (20%)]\tLoss: 0.087291\n",
            "Train epoch: 207 [244920/25046 (31%)]\tLoss: 0.123738\n",
            "Train epoch: 207 [337280/25046 (41%)]\tLoss: 0.089465\n",
            "Train epoch: 207 [407700/25046 (51%)]\tLoss: 0.068518\n",
            "Train epoch: 207 [491400/25046 (61%)]\tLoss: 0.067478\n",
            "Train epoch: 207 [595420/25046 (71%)]\tLoss: 0.081545\n",
            "Train epoch: 207 [682720/25046 (82%)]\tLoss: 0.051118\n",
            "Train epoch: 207 [736380/25046 (92%)]\tLoss: 0.092381\n",
            "Make prediction for 5010 samples...\n",
            "0.27077603 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 208 [0/25046 (0%)]\tLoss: 0.069267\n",
            "Train epoch: 208 [81640/25046 (10%)]\tLoss: 0.034296\n",
            "Train epoch: 208 [168480/25046 (20%)]\tLoss: 0.075592\n",
            "Train epoch: 208 [238620/25046 (31%)]\tLoss: 0.049884\n",
            "Train epoch: 208 [318560/25046 (41%)]\tLoss: 0.073912\n",
            "Train epoch: 208 [400500/25046 (51%)]\tLoss: 0.060307\n",
            "Train epoch: 208 [499200/25046 (61%)]\tLoss: 0.049677\n",
            "Train epoch: 208 [562800/25046 (71%)]\tLoss: 0.055095\n",
            "Train epoch: 208 [671200/25046 (82%)]\tLoss: 0.093160\n",
            "Train epoch: 208 [749340/25046 (92%)]\tLoss: 0.073031\n",
            "Make prediction for 5010 samples...\n",
            "0.26192537 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 209 [0/25046 (0%)]\tLoss: 0.087955\n",
            "Train epoch: 209 [81740/25046 (10%)]\tLoss: 0.049669\n",
            "Train epoch: 209 [165840/25046 (20%)]\tLoss: 0.070328\n",
            "Train epoch: 209 [250020/25046 (31%)]\tLoss: 0.065261\n",
            "Train epoch: 209 [330800/25046 (41%)]\tLoss: 0.091691\n",
            "Train epoch: 209 [414300/25046 (51%)]\tLoss: 0.082105\n",
            "Train epoch: 209 [500280/25046 (61%)]\tLoss: 0.075913\n",
            "Train epoch: 209 [552020/25046 (71%)]\tLoss: 0.117460\n",
            "Train epoch: 209 [654240/25046 (82%)]\tLoss: 0.067726\n",
            "Train epoch: 209 [723600/25046 (92%)]\tLoss: 0.164364\n",
            "Make prediction for 5010 samples...\n",
            "0.26153067 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 210 [0/25046 (0%)]\tLoss: 0.097400\n",
            "Train epoch: 210 [85540/25046 (10%)]\tLoss: 0.048635\n",
            "Train epoch: 210 [165440/25046 (20%)]\tLoss: 0.139984\n",
            "Train epoch: 210 [243840/25046 (31%)]\tLoss: 0.066043\n",
            "Train epoch: 210 [328000/25046 (41%)]\tLoss: 0.032370\n",
            "Train epoch: 210 [415400/25046 (51%)]\tLoss: 0.066774\n",
            "Train epoch: 210 [486480/25046 (61%)]\tLoss: 0.056406\n",
            "Train epoch: 210 [587440/25046 (71%)]\tLoss: 0.043097\n",
            "Train epoch: 210 [668640/25046 (82%)]\tLoss: 0.080260\n",
            "Train epoch: 210 [732600/25046 (92%)]\tLoss: 0.094298\n",
            "Make prediction for 5010 samples...\n",
            "0.25616136 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 211 [0/25046 (0%)]\tLoss: 0.059896\n",
            "Train epoch: 211 [82260/25046 (10%)]\tLoss: 0.059875\n",
            "Train epoch: 211 [161960/25046 (20%)]\tLoss: 0.079877\n",
            "Train epoch: 211 [245100/25046 (31%)]\tLoss: 0.068487\n",
            "Train epoch: 211 [328560/25046 (41%)]\tLoss: 0.054777\n",
            "Train epoch: 211 [419000/25046 (51%)]\tLoss: 0.079245\n",
            "Train epoch: 211 [480600/25046 (61%)]\tLoss: 0.055688\n",
            "Train epoch: 211 [572040/25046 (71%)]\tLoss: 0.071305\n",
            "Train epoch: 211 [663840/25046 (82%)]\tLoss: 0.107597\n",
            "Train epoch: 211 [746820/25046 (92%)]\tLoss: 0.077059\n",
            "Make prediction for 5010 samples...\n",
            "0.26309627 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 212 [0/25046 (0%)]\tLoss: 0.047571\n",
            "Train epoch: 212 [81760/25046 (10%)]\tLoss: 0.103719\n",
            "Train epoch: 212 [161720/25046 (20%)]\tLoss: 0.042547\n",
            "Train epoch: 212 [247500/25046 (31%)]\tLoss: 0.061258\n",
            "Train epoch: 212 [324720/25046 (41%)]\tLoss: 0.069238\n",
            "Train epoch: 212 [403400/25046 (51%)]\tLoss: 0.054556\n",
            "Train epoch: 212 [470520/25046 (61%)]\tLoss: 0.074598\n",
            "Train epoch: 212 [594160/25046 (71%)]\tLoss: 0.073650\n",
            "Train epoch: 212 [653120/25046 (82%)]\tLoss: 0.061072\n",
            "Train epoch: 212 [729900/25046 (92%)]\tLoss: 0.075813\n",
            "Make prediction for 5010 samples...\n",
            "0.2623349 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 213 [0/25046 (0%)]\tLoss: 0.117937\n",
            "Train epoch: 213 [80500/25046 (10%)]\tLoss: 0.080668\n",
            "Train epoch: 213 [163640/25046 (20%)]\tLoss: 0.071610\n",
            "Train epoch: 213 [249840/25046 (31%)]\tLoss: 0.082825\n",
            "Train epoch: 213 [323760/25046 (41%)]\tLoss: 0.060322\n",
            "Train epoch: 213 [412300/25046 (51%)]\tLoss: 0.057074\n",
            "Train epoch: 213 [495600/25046 (61%)]\tLoss: 0.048526\n",
            "Train epoch: 213 [570360/25046 (71%)]\tLoss: 0.093269\n",
            "Train epoch: 213 [651840/25046 (82%)]\tLoss: 0.102820\n",
            "Train epoch: 213 [735660/25046 (92%)]\tLoss: 0.058751\n",
            "Make prediction for 5010 samples...\n",
            "0.25540477 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 214 [0/25046 (0%)]\tLoss: 0.044778\n",
            "Train epoch: 214 [82080/25046 (10%)]\tLoss: 0.071866\n",
            "Train epoch: 214 [162480/25046 (20%)]\tLoss: 0.128684\n",
            "Train epoch: 214 [247980/25046 (31%)]\tLoss: 0.076507\n",
            "Train epoch: 214 [319840/25046 (41%)]\tLoss: 0.067848\n",
            "Train epoch: 214 [409800/25046 (51%)]\tLoss: 0.057931\n",
            "Train epoch: 214 [493080/25046 (61%)]\tLoss: 0.050498\n",
            "Train epoch: 214 [568260/25046 (71%)]\tLoss: 0.073413\n",
            "Train epoch: 214 [652320/25046 (82%)]\tLoss: 0.055441\n",
            "Train epoch: 214 [758880/25046 (92%)]\tLoss: 0.089333\n",
            "Make prediction for 5010 samples...\n",
            "0.25509483 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 215 [0/25046 (0%)]\tLoss: 0.050003\n",
            "Train epoch: 215 [81960/25046 (10%)]\tLoss: 0.042177\n",
            "Train epoch: 215 [161120/25046 (20%)]\tLoss: 0.072005\n",
            "Train epoch: 215 [240720/25046 (31%)]\tLoss: 0.092285\n",
            "Train epoch: 215 [328080/25046 (41%)]\tLoss: 0.086778\n",
            "Train epoch: 215 [411900/25046 (51%)]\tLoss: 0.053609\n",
            "Train epoch: 215 [500520/25046 (61%)]\tLoss: 0.082076\n",
            "Train epoch: 215 [581140/25046 (71%)]\tLoss: 0.034041\n",
            "Train epoch: 215 [661600/25046 (82%)]\tLoss: 0.061531\n",
            "Train epoch: 215 [725220/25046 (92%)]\tLoss: 0.039161\n",
            "Make prediction for 5010 samples...\n",
            "0.2604006 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 216 [0/25046 (0%)]\tLoss: 0.065843\n",
            "Train epoch: 216 [81760/25046 (10%)]\tLoss: 0.042342\n",
            "Train epoch: 216 [164720/25046 (20%)]\tLoss: 0.064189\n",
            "Train epoch: 216 [241980/25046 (31%)]\tLoss: 0.080157\n",
            "Train epoch: 216 [332160/25046 (41%)]\tLoss: 0.064360\n",
            "Train epoch: 216 [407800/25046 (51%)]\tLoss: 0.078161\n",
            "Train epoch: 216 [481200/25046 (61%)]\tLoss: 0.060273\n",
            "Train epoch: 216 [585060/25046 (71%)]\tLoss: 0.070996\n",
            "Train epoch: 216 [646880/25046 (82%)]\tLoss: 0.059462\n",
            "Train epoch: 216 [715860/25046 (92%)]\tLoss: 0.037031\n",
            "Make prediction for 5010 samples...\n",
            "0.25956374 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 217 [0/25046 (0%)]\tLoss: 0.076969\n",
            "Train epoch: 217 [78740/25046 (10%)]\tLoss: 0.051862\n",
            "Train epoch: 217 [163160/25046 (20%)]\tLoss: 0.036733\n",
            "Train epoch: 217 [241080/25046 (31%)]\tLoss: 0.111802\n",
            "Train epoch: 217 [333600/25046 (41%)]\tLoss: 0.051426\n",
            "Train epoch: 217 [410800/25046 (51%)]\tLoss: 0.089167\n",
            "Train epoch: 217 [481200/25046 (61%)]\tLoss: 0.047932\n",
            "Train epoch: 217 [559720/25046 (71%)]\tLoss: 0.069503\n",
            "Train epoch: 217 [660480/25046 (82%)]\tLoss: 0.068909\n",
            "Train epoch: 217 [731160/25046 (92%)]\tLoss: 0.050310\n",
            "Make prediction for 5010 samples...\n",
            "0.2644774 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 218 [0/25046 (0%)]\tLoss: 0.061650\n",
            "Train epoch: 218 [81760/25046 (10%)]\tLoss: 0.054722\n",
            "Train epoch: 218 [163800/25046 (20%)]\tLoss: 0.076564\n",
            "Train epoch: 218 [248520/25046 (31%)]\tLoss: 0.049035\n",
            "Train epoch: 218 [332240/25046 (41%)]\tLoss: 0.058345\n",
            "Train epoch: 218 [406900/25046 (51%)]\tLoss: 0.068417\n",
            "Train epoch: 218 [490080/25046 (61%)]\tLoss: 0.074971\n",
            "Train epoch: 218 [588420/25046 (71%)]\tLoss: 0.090565\n",
            "Train epoch: 218 [659040/25046 (82%)]\tLoss: 0.056740\n",
            "Train epoch: 218 [710280/25046 (92%)]\tLoss: 0.043330\n",
            "Make prediction for 5010 samples...\n",
            "0.26275548 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 219 [0/25046 (0%)]\tLoss: 0.077616\n",
            "Train epoch: 219 [81900/25046 (10%)]\tLoss: 0.096881\n",
            "Train epoch: 219 [162320/25046 (20%)]\tLoss: 0.083578\n",
            "Train epoch: 219 [238800/25046 (31%)]\tLoss: 0.069143\n",
            "Train epoch: 219 [325840/25046 (41%)]\tLoss: 0.128483\n",
            "Train epoch: 219 [419300/25046 (51%)]\tLoss: 0.097706\n",
            "Train epoch: 219 [501840/25046 (61%)]\tLoss: 0.085567\n",
            "Train epoch: 219 [570920/25046 (71%)]\tLoss: 0.067274\n",
            "Train epoch: 219 [648800/25046 (82%)]\tLoss: 0.075069\n",
            "Train epoch: 219 [724680/25046 (92%)]\tLoss: 0.115421\n",
            "Make prediction for 5010 samples...\n",
            "0.27003118 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 220 [0/25046 (0%)]\tLoss: 0.044857\n",
            "Train epoch: 220 [81200/25046 (10%)]\tLoss: 0.086865\n",
            "Train epoch: 220 [167760/25046 (20%)]\tLoss: 0.047397\n",
            "Train epoch: 220 [253920/25046 (31%)]\tLoss: 0.143020\n",
            "Train epoch: 220 [324560/25046 (41%)]\tLoss: 0.051231\n",
            "Train epoch: 220 [411500/25046 (51%)]\tLoss: 0.062985\n",
            "Train epoch: 220 [497280/25046 (61%)]\tLoss: 0.097490\n",
            "Train epoch: 220 [580020/25046 (71%)]\tLoss: 0.072079\n",
            "Train epoch: 220 [635840/25046 (82%)]\tLoss: 0.070553\n",
            "Train epoch: 220 [737100/25046 (92%)]\tLoss: 0.058323\n",
            "Make prediction for 5010 samples...\n",
            "0.2583874 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 221 [0/25046 (0%)]\tLoss: 0.062254\n",
            "Train epoch: 221 [79740/25046 (10%)]\tLoss: 0.037003\n",
            "Train epoch: 221 [161120/25046 (20%)]\tLoss: 0.078721\n",
            "Train epoch: 221 [255840/25046 (31%)]\tLoss: 0.063814\n",
            "Train epoch: 221 [327440/25046 (41%)]\tLoss: 0.059116\n",
            "Train epoch: 221 [412900/25046 (51%)]\tLoss: 0.063607\n",
            "Train epoch: 221 [485160/25046 (61%)]\tLoss: 0.024062\n",
            "Train epoch: 221 [557480/25046 (71%)]\tLoss: 0.072456\n",
            "Train epoch: 221 [656480/25046 (82%)]\tLoss: 0.107802\n",
            "Train epoch: 221 [746100/25046 (92%)]\tLoss: 0.182602\n",
            "Make prediction for 5010 samples...\n",
            "0.25989217 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 222 [0/25046 (0%)]\tLoss: 0.055561\n",
            "Train epoch: 222 [80700/25046 (10%)]\tLoss: 0.040674\n",
            "Train epoch: 222 [161600/25046 (20%)]\tLoss: 0.051653\n",
            "Train epoch: 222 [250140/25046 (31%)]\tLoss: 0.080443\n",
            "Train epoch: 222 [329760/25046 (41%)]\tLoss: 0.079780\n",
            "Train epoch: 222 [407000/25046 (51%)]\tLoss: 0.154593\n",
            "Train epoch: 222 [489480/25046 (61%)]\tLoss: 0.059304\n",
            "Train epoch: 222 [568820/25046 (71%)]\tLoss: 0.036685\n",
            "Train epoch: 222 [672480/25046 (82%)]\tLoss: 0.049178\n",
            "Train epoch: 222 [737280/25046 (92%)]\tLoss: 0.074477\n",
            "Make prediction for 5010 samples...\n",
            "0.26524457 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 223 [0/25046 (0%)]\tLoss: 0.111040\n",
            "Train epoch: 223 [81340/25046 (10%)]\tLoss: 0.092274\n",
            "Train epoch: 223 [165560/25046 (20%)]\tLoss: 0.033384\n",
            "Train epoch: 223 [249000/25046 (31%)]\tLoss: 0.076109\n",
            "Train epoch: 223 [330720/25046 (41%)]\tLoss: 0.050336\n",
            "Train epoch: 223 [411400/25046 (51%)]\tLoss: 0.072205\n",
            "Train epoch: 223 [494760/25046 (61%)]\tLoss: 0.062727\n",
            "Train epoch: 223 [570080/25046 (71%)]\tLoss: 0.053742\n",
            "Train epoch: 223 [646560/25046 (82%)]\tLoss: 0.046593\n",
            "Train epoch: 223 [713520/25046 (92%)]\tLoss: 0.054701\n",
            "Make prediction for 5010 samples...\n",
            "0.25979856 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 224 [0/25046 (0%)]\tLoss: 0.014910\n",
            "Train epoch: 224 [79560/25046 (10%)]\tLoss: 0.054145\n",
            "Train epoch: 224 [161040/25046 (20%)]\tLoss: 0.044377\n",
            "Train epoch: 224 [250380/25046 (31%)]\tLoss: 0.084717\n",
            "Train epoch: 224 [321280/25046 (41%)]\tLoss: 0.074963\n",
            "Train epoch: 224 [406200/25046 (51%)]\tLoss: 0.109128\n",
            "Train epoch: 224 [482640/25046 (61%)]\tLoss: 0.057490\n",
            "Train epoch: 224 [573580/25046 (71%)]\tLoss: 0.134311\n",
            "Train epoch: 224 [637120/25046 (82%)]\tLoss: 0.051305\n",
            "Train epoch: 224 [742320/25046 (92%)]\tLoss: 0.043827\n",
            "Make prediction for 5010 samples...\n",
            "0.26017284 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 225 [0/25046 (0%)]\tLoss: 0.040044\n",
            "Train epoch: 225 [82120/25046 (10%)]\tLoss: 0.079426\n",
            "Train epoch: 225 [162000/25046 (20%)]\tLoss: 0.046222\n",
            "Train epoch: 225 [253980/25046 (31%)]\tLoss: 0.057516\n",
            "Train epoch: 225 [323600/25046 (41%)]\tLoss: 0.048664\n",
            "Train epoch: 225 [409000/25046 (51%)]\tLoss: 0.047731\n",
            "Train epoch: 225 [498360/25046 (61%)]\tLoss: 0.112657\n",
            "Train epoch: 225 [575820/25046 (71%)]\tLoss: 0.058357\n",
            "Train epoch: 225 [645920/25046 (82%)]\tLoss: 0.080975\n",
            "Train epoch: 225 [729540/25046 (92%)]\tLoss: 0.070406\n",
            "Make prediction for 5010 samples...\n",
            "0.26307797 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 226 [0/25046 (0%)]\tLoss: 0.044528\n",
            "Train epoch: 226 [82180/25046 (10%)]\tLoss: 0.049360\n",
            "Train epoch: 226 [163000/25046 (20%)]\tLoss: 0.051505\n",
            "Train epoch: 226 [253620/25046 (31%)]\tLoss: 0.058342\n",
            "Train epoch: 226 [336000/25046 (41%)]\tLoss: 0.078914\n",
            "Train epoch: 226 [406500/25046 (51%)]\tLoss: 0.074530\n",
            "Train epoch: 226 [483840/25046 (61%)]\tLoss: 0.069517\n",
            "Train epoch: 226 [579880/25046 (71%)]\tLoss: 0.073253\n",
            "Train epoch: 226 [680000/25046 (82%)]\tLoss: 0.076958\n",
            "Train epoch: 226 [738180/25046 (92%)]\tLoss: 0.074517\n",
            "Make prediction for 5010 samples...\n",
            "0.25874406 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 227 [0/25046 (0%)]\tLoss: 0.045453\n",
            "Train epoch: 227 [82820/25046 (10%)]\tLoss: 0.096956\n",
            "Train epoch: 227 [164280/25046 (20%)]\tLoss: 0.052650\n",
            "Train epoch: 227 [244020/25046 (31%)]\tLoss: 0.109653\n",
            "Train epoch: 227 [328160/25046 (41%)]\tLoss: 0.068253\n",
            "Train epoch: 227 [408600/25046 (51%)]\tLoss: 0.062541\n",
            "Train epoch: 227 [489000/25046 (61%)]\tLoss: 0.067500\n",
            "Train epoch: 227 [582540/25046 (71%)]\tLoss: 0.040278\n",
            "Train epoch: 227 [650560/25046 (82%)]\tLoss: 0.039655\n",
            "Train epoch: 227 [757800/25046 (92%)]\tLoss: 0.102560\n",
            "Make prediction for 5010 samples...\n",
            "0.25677004 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 228 [0/25046 (0%)]\tLoss: 0.062866\n",
            "Train epoch: 228 [81080/25046 (10%)]\tLoss: 0.070023\n",
            "Train epoch: 228 [161480/25046 (20%)]\tLoss: 0.062062\n",
            "Train epoch: 228 [250080/25046 (31%)]\tLoss: 0.031370\n",
            "Train epoch: 228 [335360/25046 (41%)]\tLoss: 0.055882\n",
            "Train epoch: 228 [408100/25046 (51%)]\tLoss: 0.088578\n",
            "Train epoch: 228 [494160/25046 (61%)]\tLoss: 0.133115\n",
            "Train epoch: 228 [563220/25046 (71%)]\tLoss: 0.063564\n",
            "Train epoch: 228 [665600/25046 (82%)]\tLoss: 0.039979\n",
            "Train epoch: 228 [745560/25046 (92%)]\tLoss: 0.080648\n",
            "Make prediction for 5010 samples...\n",
            "0.2596517 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 229 [0/25046 (0%)]\tLoss: 0.053424\n",
            "Train epoch: 229 [83920/25046 (10%)]\tLoss: 0.055806\n",
            "Train epoch: 229 [166280/25046 (20%)]\tLoss: 0.062188\n",
            "Train epoch: 229 [240480/25046 (31%)]\tLoss: 0.097159\n",
            "Train epoch: 229 [327840/25046 (41%)]\tLoss: 0.077210\n",
            "Train epoch: 229 [410800/25046 (51%)]\tLoss: 0.052894\n",
            "Train epoch: 229 [502920/25046 (61%)]\tLoss: 0.043627\n",
            "Train epoch: 229 [568960/25046 (71%)]\tLoss: 0.061086\n",
            "Train epoch: 229 [676320/25046 (82%)]\tLoss: 0.075993\n",
            "Train epoch: 229 [723960/25046 (92%)]\tLoss: 0.079709\n",
            "Make prediction for 5010 samples...\n",
            "0.25677454 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 230 [0/25046 (0%)]\tLoss: 0.037382\n",
            "Train epoch: 230 [83680/25046 (10%)]\tLoss: 0.113803\n",
            "Train epoch: 230 [162800/25046 (20%)]\tLoss: 0.123792\n",
            "Train epoch: 230 [245400/25046 (31%)]\tLoss: 0.138085\n",
            "Train epoch: 230 [335840/25046 (41%)]\tLoss: 0.053244\n",
            "Train epoch: 230 [417000/25046 (51%)]\tLoss: 0.052037\n",
            "Train epoch: 230 [488400/25046 (61%)]\tLoss: 0.100255\n",
            "Train epoch: 230 [584080/25046 (71%)]\tLoss: 0.032290\n",
            "Train epoch: 230 [652160/25046 (82%)]\tLoss: 0.057070\n",
            "Train epoch: 230 [739980/25046 (92%)]\tLoss: 0.117278\n",
            "Make prediction for 5010 samples...\n",
            "0.2684079 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 231 [0/25046 (0%)]\tLoss: 0.064813\n",
            "Train epoch: 231 [81880/25046 (10%)]\tLoss: 0.036499\n",
            "Train epoch: 231 [167800/25046 (20%)]\tLoss: 0.049286\n",
            "Train epoch: 231 [248400/25046 (31%)]\tLoss: 0.065526\n",
            "Train epoch: 231 [327280/25046 (41%)]\tLoss: 0.057622\n",
            "Train epoch: 231 [417500/25046 (51%)]\tLoss: 0.091869\n",
            "Train epoch: 231 [487560/25046 (61%)]\tLoss: 0.051536\n",
            "Train epoch: 231 [582260/25046 (71%)]\tLoss: 0.038674\n",
            "Train epoch: 231 [651680/25046 (82%)]\tLoss: 0.036677\n",
            "Train epoch: 231 [719280/25046 (92%)]\tLoss: 0.048833\n",
            "Make prediction for 5010 samples...\n",
            "0.25648835 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 232 [0/25046 (0%)]\tLoss: 0.056018\n",
            "Train epoch: 232 [83000/25046 (10%)]\tLoss: 0.030070\n",
            "Train epoch: 232 [166680/25046 (20%)]\tLoss: 0.084466\n",
            "Train epoch: 232 [245520/25046 (31%)]\tLoss: 0.055724\n",
            "Train epoch: 232 [328000/25046 (41%)]\tLoss: 0.064765\n",
            "Train epoch: 232 [406000/25046 (51%)]\tLoss: 0.088513\n",
            "Train epoch: 232 [489360/25046 (61%)]\tLoss: 0.072001\n",
            "Train epoch: 232 [572320/25046 (71%)]\tLoss: 0.078413\n",
            "Train epoch: 232 [660160/25046 (82%)]\tLoss: 0.066833\n",
            "Train epoch: 232 [730800/25046 (92%)]\tLoss: 0.078232\n",
            "Make prediction for 5010 samples...\n",
            "0.25631848 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 233 [0/25046 (0%)]\tLoss: 0.087221\n",
            "Train epoch: 233 [82900/25046 (10%)]\tLoss: 0.068082\n",
            "Train epoch: 233 [166240/25046 (20%)]\tLoss: 0.073640\n",
            "Train epoch: 233 [237360/25046 (31%)]\tLoss: 0.049531\n",
            "Train epoch: 233 [322160/25046 (41%)]\tLoss: 0.140451\n",
            "Train epoch: 233 [403200/25046 (51%)]\tLoss: 0.063694\n",
            "Train epoch: 233 [484800/25046 (61%)]\tLoss: 0.037231\n",
            "Train epoch: 233 [572880/25046 (71%)]\tLoss: 0.034270\n",
            "Train epoch: 233 [683680/25046 (82%)]\tLoss: 0.045448\n",
            "Train epoch: 233 [754920/25046 (92%)]\tLoss: 0.039594\n",
            "Make prediction for 5010 samples...\n",
            "0.25488243 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 234 [0/25046 (0%)]\tLoss: 0.052523\n",
            "Train epoch: 234 [82760/25046 (10%)]\tLoss: 0.138155\n",
            "Train epoch: 234 [167400/25046 (20%)]\tLoss: 0.046615\n",
            "Train epoch: 234 [238980/25046 (31%)]\tLoss: 0.042525\n",
            "Train epoch: 234 [330400/25046 (41%)]\tLoss: 0.099128\n",
            "Train epoch: 234 [407900/25046 (51%)]\tLoss: 0.059240\n",
            "Train epoch: 234 [486720/25046 (61%)]\tLoss: 0.056275\n",
            "Train epoch: 234 [582960/25046 (71%)]\tLoss: 0.045020\n",
            "Train epoch: 234 [655040/25046 (82%)]\tLoss: 0.034422\n",
            "Train epoch: 234 [768960/25046 (92%)]\tLoss: 0.052153\n",
            "Make prediction for 5010 samples...\n",
            "0.25880525 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 235 [0/25046 (0%)]\tLoss: 0.077174\n",
            "Train epoch: 235 [80680/25046 (10%)]\tLoss: 0.050327\n",
            "Train epoch: 235 [161320/25046 (20%)]\tLoss: 0.056850\n",
            "Train epoch: 235 [243300/25046 (31%)]\tLoss: 0.100918\n",
            "Train epoch: 235 [325200/25046 (41%)]\tLoss: 0.046826\n",
            "Train epoch: 235 [418000/25046 (51%)]\tLoss: 0.035574\n",
            "Train epoch: 235 [495600/25046 (61%)]\tLoss: 0.060257\n",
            "Train epoch: 235 [574840/25046 (71%)]\tLoss: 0.093544\n",
            "Train epoch: 235 [675520/25046 (82%)]\tLoss: 0.088350\n",
            "Train epoch: 235 [740340/25046 (92%)]\tLoss: 0.045054\n",
            "Make prediction for 5010 samples...\n",
            "0.2676155 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 236 [0/25046 (0%)]\tLoss: 0.112227\n",
            "Train epoch: 236 [83680/25046 (10%)]\tLoss: 0.036766\n",
            "Train epoch: 236 [163840/25046 (20%)]\tLoss: 0.045323\n",
            "Train epoch: 236 [249060/25046 (31%)]\tLoss: 0.065590\n",
            "Train epoch: 236 [331280/25046 (41%)]\tLoss: 0.048905\n",
            "Train epoch: 236 [412600/25046 (51%)]\tLoss: 0.042355\n",
            "Train epoch: 236 [492000/25046 (61%)]\tLoss: 0.048980\n",
            "Train epoch: 236 [585200/25046 (71%)]\tLoss: 0.073365\n",
            "Train epoch: 236 [638880/25046 (82%)]\tLoss: 0.051731\n",
            "Train epoch: 236 [718200/25046 (92%)]\tLoss: 0.054612\n",
            "Make prediction for 5010 samples...\n",
            "0.25419107 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 237 [0/25046 (0%)]\tLoss: 0.137364\n",
            "Train epoch: 237 [82680/25046 (10%)]\tLoss: 0.076639\n",
            "Train epoch: 237 [167320/25046 (20%)]\tLoss: 0.057974\n",
            "Train epoch: 237 [252480/25046 (31%)]\tLoss: 0.060914\n",
            "Train epoch: 237 [327120/25046 (41%)]\tLoss: 0.099615\n",
            "Train epoch: 237 [408000/25046 (51%)]\tLoss: 0.138633\n",
            "Train epoch: 237 [487560/25046 (61%)]\tLoss: 0.047793\n",
            "Train epoch: 237 [598500/25046 (71%)]\tLoss: 0.049644\n",
            "Train epoch: 237 [658240/25046 (82%)]\tLoss: 0.057073\n",
            "Train epoch: 237 [729000/25046 (92%)]\tLoss: 0.078690\n",
            "Make prediction for 5010 samples...\n",
            "0.2737951 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 238 [0/25046 (0%)]\tLoss: 0.104549\n",
            "Train epoch: 238 [81920/25046 (10%)]\tLoss: 0.058924\n",
            "Train epoch: 238 [165120/25046 (20%)]\tLoss: 0.038652\n",
            "Train epoch: 238 [246180/25046 (31%)]\tLoss: 0.126938\n",
            "Train epoch: 238 [316960/25046 (41%)]\tLoss: 0.073752\n",
            "Train epoch: 238 [427500/25046 (51%)]\tLoss: 0.182757\n",
            "Train epoch: 238 [493560/25046 (61%)]\tLoss: 0.140742\n",
            "Train epoch: 238 [569660/25046 (71%)]\tLoss: 0.049715\n",
            "Train epoch: 238 [647200/25046 (82%)]\tLoss: 0.139865\n",
            "Train epoch: 238 [732960/25046 (92%)]\tLoss: 0.035998\n",
            "Make prediction for 5010 samples...\n",
            "0.26317188 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 239 [0/25046 (0%)]\tLoss: 0.064666\n",
            "Train epoch: 239 [84960/25046 (10%)]\tLoss: 0.080652\n",
            "Train epoch: 239 [166200/25046 (20%)]\tLoss: 0.119075\n",
            "Train epoch: 239 [250380/25046 (31%)]\tLoss: 0.043600\n",
            "Train epoch: 239 [336000/25046 (41%)]\tLoss: 0.099308\n",
            "Train epoch: 239 [414300/25046 (51%)]\tLoss: 0.080045\n",
            "Train epoch: 239 [470640/25046 (61%)]\tLoss: 0.047877\n",
            "Train epoch: 239 [579040/25046 (71%)]\tLoss: 0.107592\n",
            "Train epoch: 239 [659040/25046 (82%)]\tLoss: 0.034565\n",
            "Train epoch: 239 [746640/25046 (92%)]\tLoss: 0.052139\n",
            "Make prediction for 5010 samples...\n",
            "0.27269852 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 240 [0/25046 (0%)]\tLoss: 0.071703\n",
            "Train epoch: 240 [79960/25046 (10%)]\tLoss: 0.054086\n",
            "Train epoch: 240 [167720/25046 (20%)]\tLoss: 0.052717\n",
            "Train epoch: 240 [245280/25046 (31%)]\tLoss: 0.043390\n",
            "Train epoch: 240 [331760/25046 (41%)]\tLoss: 0.065526\n",
            "Train epoch: 240 [424700/25046 (51%)]\tLoss: 0.085001\n",
            "Train epoch: 240 [501120/25046 (61%)]\tLoss: 0.072951\n",
            "Train epoch: 240 [577500/25046 (71%)]\tLoss: 0.090161\n",
            "Train epoch: 240 [664640/25046 (82%)]\tLoss: 0.083367\n",
            "Train epoch: 240 [738180/25046 (92%)]\tLoss: 0.072831\n",
            "Make prediction for 5010 samples...\n",
            "0.26280084 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 241 [0/25046 (0%)]\tLoss: 0.065656\n",
            "Train epoch: 241 [81620/25046 (10%)]\tLoss: 0.054556\n",
            "Train epoch: 241 [163520/25046 (20%)]\tLoss: 0.054029\n",
            "Train epoch: 241 [246180/25046 (31%)]\tLoss: 0.100720\n",
            "Train epoch: 241 [341200/25046 (41%)]\tLoss: 0.068521\n",
            "Train epoch: 241 [410800/25046 (51%)]\tLoss: 0.083431\n",
            "Train epoch: 241 [485640/25046 (61%)]\tLoss: 0.082003\n",
            "Train epoch: 241 [570500/25046 (71%)]\tLoss: 0.031118\n",
            "Train epoch: 241 [651040/25046 (82%)]\tLoss: 0.102706\n",
            "Train epoch: 241 [757260/25046 (92%)]\tLoss: 0.083161\n",
            "Make prediction for 5010 samples...\n",
            "0.2658933 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 242 [0/25046 (0%)]\tLoss: 0.045829\n",
            "Train epoch: 242 [82400/25046 (10%)]\tLoss: 0.047369\n",
            "Train epoch: 242 [163880/25046 (20%)]\tLoss: 0.042036\n",
            "Train epoch: 242 [247140/25046 (31%)]\tLoss: 0.051375\n",
            "Train epoch: 242 [327040/25046 (41%)]\tLoss: 0.077737\n",
            "Train epoch: 242 [417300/25046 (51%)]\tLoss: 0.089278\n",
            "Train epoch: 242 [499680/25046 (61%)]\tLoss: 0.068085\n",
            "Train epoch: 242 [556500/25046 (71%)]\tLoss: 0.033135\n",
            "Train epoch: 242 [652320/25046 (82%)]\tLoss: 0.062293\n",
            "Train epoch: 242 [744300/25046 (92%)]\tLoss: 0.069164\n",
            "Make prediction for 5010 samples...\n",
            "0.25193122 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 243 [0/25046 (0%)]\tLoss: 0.048055\n",
            "Train epoch: 243 [81540/25046 (10%)]\tLoss: 0.141793\n",
            "Train epoch: 243 [166680/25046 (20%)]\tLoss: 0.035755\n",
            "Train epoch: 243 [247920/25046 (31%)]\tLoss: 0.065427\n",
            "Train epoch: 243 [318480/25046 (41%)]\tLoss: 0.066471\n",
            "Train epoch: 243 [407400/25046 (51%)]\tLoss: 0.061827\n",
            "Train epoch: 243 [494160/25046 (61%)]\tLoss: 0.062464\n",
            "Train epoch: 243 [560140/25046 (71%)]\tLoss: 0.039927\n",
            "Train epoch: 243 [668640/25046 (82%)]\tLoss: 0.048764\n",
            "Train epoch: 243 [735840/25046 (92%)]\tLoss: 0.060165\n",
            "Make prediction for 5010 samples...\n",
            "0.26364866 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 244 [0/25046 (0%)]\tLoss: 0.107239\n",
            "Train epoch: 244 [80680/25046 (10%)]\tLoss: 0.051558\n",
            "Train epoch: 244 [165080/25046 (20%)]\tLoss: 0.087722\n",
            "Train epoch: 244 [242220/25046 (31%)]\tLoss: 0.056176\n",
            "Train epoch: 244 [331280/25046 (41%)]\tLoss: 0.088083\n",
            "Train epoch: 244 [407700/25046 (51%)]\tLoss: 0.134195\n",
            "Train epoch: 244 [488160/25046 (61%)]\tLoss: 0.099961\n",
            "Train epoch: 244 [571620/25046 (71%)]\tLoss: 0.073318\n",
            "Train epoch: 244 [666240/25046 (82%)]\tLoss: 0.065700\n",
            "Train epoch: 244 [716580/25046 (92%)]\tLoss: 0.126960\n",
            "Make prediction for 5010 samples...\n",
            "0.26248777 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 245 [0/25046 (0%)]\tLoss: 0.043861\n",
            "Train epoch: 245 [84140/25046 (10%)]\tLoss: 0.038575\n",
            "Train epoch: 245 [167640/25046 (20%)]\tLoss: 0.058852\n",
            "Train epoch: 245 [253020/25046 (31%)]\tLoss: 0.050048\n",
            "Train epoch: 245 [322960/25046 (41%)]\tLoss: 0.064273\n",
            "Train epoch: 245 [426300/25046 (51%)]\tLoss: 0.047908\n",
            "Train epoch: 245 [484680/25046 (61%)]\tLoss: 0.067271\n",
            "Train epoch: 245 [566440/25046 (71%)]\tLoss: 0.135349\n",
            "Train epoch: 245 [636000/25046 (82%)]\tLoss: 0.085468\n",
            "Train epoch: 245 [720900/25046 (92%)]\tLoss: 0.121266\n",
            "Make prediction for 5010 samples...\n",
            "0.25553143 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 246 [0/25046 (0%)]\tLoss: 0.040406\n",
            "Train epoch: 246 [81420/25046 (10%)]\tLoss: 0.055293\n",
            "Train epoch: 246 [168480/25046 (20%)]\tLoss: 0.045421\n",
            "Train epoch: 246 [251160/25046 (31%)]\tLoss: 0.049902\n",
            "Train epoch: 246 [331840/25046 (41%)]\tLoss: 0.104700\n",
            "Train epoch: 246 [429900/25046 (51%)]\tLoss: 0.049982\n",
            "Train epoch: 246 [485760/25046 (61%)]\tLoss: 0.051887\n",
            "Train epoch: 246 [576100/25046 (71%)]\tLoss: 0.039789\n",
            "Train epoch: 246 [652000/25046 (82%)]\tLoss: 0.086971\n",
            "Train epoch: 246 [724140/25046 (92%)]\tLoss: 0.044716\n",
            "Make prediction for 5010 samples...\n",
            "0.2521358 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 247 [0/25046 (0%)]\tLoss: 0.036323\n",
            "Train epoch: 247 [81040/25046 (10%)]\tLoss: 0.049318\n",
            "Train epoch: 247 [160920/25046 (20%)]\tLoss: 0.049984\n",
            "Train epoch: 247 [242760/25046 (31%)]\tLoss: 0.086426\n",
            "Train epoch: 247 [329600/25046 (41%)]\tLoss: 0.058256\n",
            "Train epoch: 247 [412900/25046 (51%)]\tLoss: 0.066708\n",
            "Train epoch: 247 [496920/25046 (61%)]\tLoss: 0.045919\n",
            "Train epoch: 247 [576940/25046 (71%)]\tLoss: 0.087211\n",
            "Train epoch: 247 [661760/25046 (82%)]\tLoss: 0.071334\n",
            "Train epoch: 247 [750240/25046 (92%)]\tLoss: 0.050344\n",
            "Make prediction for 5010 samples...\n",
            "0.25801158 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 248 [0/25046 (0%)]\tLoss: 0.029471\n",
            "Train epoch: 248 [82960/25046 (10%)]\tLoss: 0.033808\n",
            "Train epoch: 248 [166880/25046 (20%)]\tLoss: 0.061047\n",
            "Train epoch: 248 [240660/25046 (31%)]\tLoss: 0.051080\n",
            "Train epoch: 248 [326720/25046 (41%)]\tLoss: 0.038720\n",
            "Train epoch: 248 [405600/25046 (51%)]\tLoss: 0.105255\n",
            "Train epoch: 248 [488040/25046 (61%)]\tLoss: 0.077913\n",
            "Train epoch: 248 [554540/25046 (71%)]\tLoss: 0.060764\n",
            "Train epoch: 248 [650080/25046 (82%)]\tLoss: 0.196561\n",
            "Train epoch: 248 [738000/25046 (92%)]\tLoss: 0.054036\n",
            "Make prediction for 5010 samples...\n",
            "0.26062876 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 249 [0/25046 (0%)]\tLoss: 0.097421\n",
            "Train epoch: 249 [80780/25046 (10%)]\tLoss: 0.099293\n",
            "Train epoch: 249 [159880/25046 (20%)]\tLoss: 0.036034\n",
            "Train epoch: 249 [254160/25046 (31%)]\tLoss: 0.072364\n",
            "Train epoch: 249 [318800/25046 (41%)]\tLoss: 0.032423\n",
            "Train epoch: 249 [427200/25046 (51%)]\tLoss: 0.081456\n",
            "Train epoch: 249 [495240/25046 (61%)]\tLoss: 0.075537\n",
            "Train epoch: 249 [572880/25046 (71%)]\tLoss: 0.145707\n",
            "Train epoch: 249 [660960/25046 (82%)]\tLoss: 0.033439\n",
            "Train epoch: 249 [749160/25046 (92%)]\tLoss: 0.058228\n",
            "Make prediction for 5010 samples...\n",
            "0.26615757 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 250 [0/25046 (0%)]\tLoss: 0.075034\n",
            "Train epoch: 250 [81060/25046 (10%)]\tLoss: 0.074487\n",
            "Train epoch: 250 [165280/25046 (20%)]\tLoss: 0.049707\n",
            "Train epoch: 250 [248100/25046 (31%)]\tLoss: 0.047211\n",
            "Train epoch: 250 [319760/25046 (41%)]\tLoss: 0.049171\n",
            "Train epoch: 250 [412200/25046 (51%)]\tLoss: 0.082820\n",
            "Train epoch: 250 [481200/25046 (61%)]\tLoss: 0.120481\n",
            "Train epoch: 250 [576240/25046 (71%)]\tLoss: 0.047498\n",
            "Train epoch: 250 [667840/25046 (82%)]\tLoss: 0.041161\n",
            "Train epoch: 250 [751320/25046 (92%)]\tLoss: 0.058582\n",
            "Make prediction for 5010 samples...\n",
            "0.2644533 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 251 [0/25046 (0%)]\tLoss: 0.070394\n",
            "Train epoch: 251 [82540/25046 (10%)]\tLoss: 0.043696\n",
            "Train epoch: 251 [161920/25046 (20%)]\tLoss: 0.144725\n",
            "Train epoch: 251 [250320/25046 (31%)]\tLoss: 0.072168\n",
            "Train epoch: 251 [330800/25046 (41%)]\tLoss: 0.078194\n",
            "Train epoch: 251 [404900/25046 (51%)]\tLoss: 0.062140\n",
            "Train epoch: 251 [495600/25046 (61%)]\tLoss: 0.079600\n",
            "Train epoch: 251 [584780/25046 (71%)]\tLoss: 0.058161\n",
            "Train epoch: 251 [650240/25046 (82%)]\tLoss: 0.070064\n",
            "Train epoch: 251 [742140/25046 (92%)]\tLoss: 0.107353\n",
            "Make prediction for 5010 samples...\n",
            "0.26367766 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 252 [0/25046 (0%)]\tLoss: 0.081890\n",
            "Train epoch: 252 [82480/25046 (10%)]\tLoss: 0.117301\n",
            "Train epoch: 252 [162640/25046 (20%)]\tLoss: 0.044103\n",
            "Train epoch: 252 [247680/25046 (31%)]\tLoss: 0.066579\n",
            "Train epoch: 252 [334800/25046 (41%)]\tLoss: 0.041243\n",
            "Train epoch: 252 [412400/25046 (51%)]\tLoss: 0.095092\n",
            "Train epoch: 252 [504480/25046 (61%)]\tLoss: 0.049977\n",
            "Train epoch: 252 [565600/25046 (71%)]\tLoss: 0.060341\n",
            "Train epoch: 252 [667840/25046 (82%)]\tLoss: 0.062229\n",
            "Train epoch: 252 [743400/25046 (92%)]\tLoss: 0.114031\n",
            "Make prediction for 5010 samples...\n",
            "0.26509577 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 253 [0/25046 (0%)]\tLoss: 0.052280\n",
            "Train epoch: 253 [81460/25046 (10%)]\tLoss: 0.084594\n",
            "Train epoch: 253 [167680/25046 (20%)]\tLoss: 0.080033\n",
            "Train epoch: 253 [241980/25046 (31%)]\tLoss: 0.055998\n",
            "Train epoch: 253 [328160/25046 (41%)]\tLoss: 0.084394\n",
            "Train epoch: 253 [407800/25046 (51%)]\tLoss: 0.066041\n",
            "Train epoch: 253 [494280/25046 (61%)]\tLoss: 0.092859\n",
            "Train epoch: 253 [578200/25046 (71%)]\tLoss: 0.093305\n",
            "Train epoch: 253 [663200/25046 (82%)]\tLoss: 0.079662\n",
            "Train epoch: 253 [727380/25046 (92%)]\tLoss: 0.083233\n",
            "Make prediction for 5010 samples...\n",
            "0.2680341 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 254 [0/25046 (0%)]\tLoss: 0.086743\n",
            "Train epoch: 254 [82460/25046 (10%)]\tLoss: 0.042535\n",
            "Train epoch: 254 [164240/25046 (20%)]\tLoss: 0.140502\n",
            "Train epoch: 254 [246600/25046 (31%)]\tLoss: 0.073408\n",
            "Train epoch: 254 [323520/25046 (41%)]\tLoss: 0.057556\n",
            "Train epoch: 254 [414200/25046 (51%)]\tLoss: 0.069995\n",
            "Train epoch: 254 [498840/25046 (61%)]\tLoss: 0.046697\n",
            "Train epoch: 254 [575120/25046 (71%)]\tLoss: 0.117902\n",
            "Train epoch: 254 [673280/25046 (82%)]\tLoss: 0.099313\n",
            "Train epoch: 254 [728100/25046 (92%)]\tLoss: 0.035057\n",
            "Make prediction for 5010 samples...\n",
            "0.27380642 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 255 [0/25046 (0%)]\tLoss: 0.046875\n",
            "Train epoch: 255 [82300/25046 (10%)]\tLoss: 0.045735\n",
            "Train epoch: 255 [165360/25046 (20%)]\tLoss: 0.058747\n",
            "Train epoch: 255 [253800/25046 (31%)]\tLoss: 0.032268\n",
            "Train epoch: 255 [321440/25046 (41%)]\tLoss: 0.060412\n",
            "Train epoch: 255 [405200/25046 (51%)]\tLoss: 0.033717\n",
            "Train epoch: 255 [481440/25046 (61%)]\tLoss: 0.032670\n",
            "Train epoch: 255 [570640/25046 (71%)]\tLoss: 0.084650\n",
            "Train epoch: 255 [655680/25046 (82%)]\tLoss: 0.044523\n",
            "Train epoch: 255 [746460/25046 (92%)]\tLoss: 0.041975\n",
            "Make prediction for 5010 samples...\n",
            "0.2567829 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 256 [0/25046 (0%)]\tLoss: 0.047288\n",
            "Train epoch: 256 [85920/25046 (10%)]\tLoss: 0.048475\n",
            "Train epoch: 256 [164800/25046 (20%)]\tLoss: 0.046892\n",
            "Train epoch: 256 [245760/25046 (31%)]\tLoss: 0.050411\n",
            "Train epoch: 256 [331600/25046 (41%)]\tLoss: 0.060504\n",
            "Train epoch: 256 [399900/25046 (51%)]\tLoss: 0.067048\n",
            "Train epoch: 256 [487320/25046 (61%)]\tLoss: 0.039787\n",
            "Train epoch: 256 [560280/25046 (71%)]\tLoss: 0.038068\n",
            "Train epoch: 256 [646240/25046 (82%)]\tLoss: 0.089007\n",
            "Train epoch: 256 [728460/25046 (92%)]\tLoss: 0.036928\n",
            "Make prediction for 5010 samples...\n",
            "0.25226423 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 257 [0/25046 (0%)]\tLoss: 0.026474\n",
            "Train epoch: 257 [80880/25046 (10%)]\tLoss: 0.033170\n",
            "Train epoch: 257 [162200/25046 (20%)]\tLoss: 0.046458\n",
            "Train epoch: 257 [247680/25046 (31%)]\tLoss: 0.041616\n",
            "Train epoch: 257 [338480/25046 (41%)]\tLoss: 0.060142\n",
            "Train epoch: 257 [414900/25046 (51%)]\tLoss: 0.046691\n",
            "Train epoch: 257 [494880/25046 (61%)]\tLoss: 0.068767\n",
            "Train epoch: 257 [583940/25046 (71%)]\tLoss: 0.158575\n",
            "Train epoch: 257 [670720/25046 (82%)]\tLoss: 0.057087\n",
            "Train epoch: 257 [740880/25046 (92%)]\tLoss: 0.030908\n",
            "Make prediction for 5010 samples...\n",
            "0.26247957 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 258 [0/25046 (0%)]\tLoss: 0.126965\n",
            "Train epoch: 258 [80040/25046 (10%)]\tLoss: 0.093676\n",
            "Train epoch: 258 [165400/25046 (20%)]\tLoss: 0.033815\n",
            "Train epoch: 258 [244860/25046 (31%)]\tLoss: 0.047931\n",
            "Train epoch: 258 [331520/25046 (41%)]\tLoss: 0.047732\n",
            "Train epoch: 258 [415700/25046 (51%)]\tLoss: 0.050014\n",
            "Train epoch: 258 [489480/25046 (61%)]\tLoss: 0.078962\n",
            "Train epoch: 258 [585620/25046 (71%)]\tLoss: 0.043243\n",
            "Train epoch: 258 [659680/25046 (82%)]\tLoss: 0.048137\n",
            "Train epoch: 258 [737820/25046 (92%)]\tLoss: 0.050831\n",
            "Make prediction for 5010 samples...\n",
            "0.2579497 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 259 [0/25046 (0%)]\tLoss: 0.040494\n",
            "Train epoch: 259 [83640/25046 (10%)]\tLoss: 0.057438\n",
            "Train epoch: 259 [163160/25046 (20%)]\tLoss: 0.076679\n",
            "Train epoch: 259 [244980/25046 (31%)]\tLoss: 0.067510\n",
            "Train epoch: 259 [324000/25046 (41%)]\tLoss: 0.114283\n",
            "Train epoch: 259 [407700/25046 (51%)]\tLoss: 0.066856\n",
            "Train epoch: 259 [498240/25046 (61%)]\tLoss: 0.103894\n",
            "Train epoch: 259 [570360/25046 (71%)]\tLoss: 0.063558\n",
            "Train epoch: 259 [671520/25046 (82%)]\tLoss: 0.058812\n",
            "Train epoch: 259 [736920/25046 (92%)]\tLoss: 0.051175\n",
            "Make prediction for 5010 samples...\n",
            "0.25690785 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 260 [0/25046 (0%)]\tLoss: 0.037737\n",
            "Train epoch: 260 [82420/25046 (10%)]\tLoss: 0.079502\n",
            "Train epoch: 260 [166680/25046 (20%)]\tLoss: 0.087269\n",
            "Train epoch: 260 [238320/25046 (31%)]\tLoss: 0.055436\n",
            "Train epoch: 260 [329520/25046 (41%)]\tLoss: 0.039350\n",
            "Train epoch: 260 [421700/25046 (51%)]\tLoss: 0.039172\n",
            "Train epoch: 260 [489240/25046 (61%)]\tLoss: 0.094282\n",
            "Train epoch: 260 [562520/25046 (71%)]\tLoss: 0.053174\n",
            "Train epoch: 260 [673760/25046 (82%)]\tLoss: 0.066620\n",
            "Train epoch: 260 [723060/25046 (92%)]\tLoss: 0.045783\n",
            "Make prediction for 5010 samples...\n",
            "0.25523552 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 261 [0/25046 (0%)]\tLoss: 0.048361\n",
            "Train epoch: 261 [81860/25046 (10%)]\tLoss: 0.080461\n",
            "Train epoch: 261 [164520/25046 (20%)]\tLoss: 0.040133\n",
            "Train epoch: 261 [248640/25046 (31%)]\tLoss: 0.058591\n",
            "Train epoch: 261 [321200/25046 (41%)]\tLoss: 0.057719\n",
            "Train epoch: 261 [419100/25046 (51%)]\tLoss: 0.053970\n",
            "Train epoch: 261 [494400/25046 (61%)]\tLoss: 0.037548\n",
            "Train epoch: 261 [580300/25046 (71%)]\tLoss: 0.056879\n",
            "Train epoch: 261 [660160/25046 (82%)]\tLoss: 0.040874\n",
            "Train epoch: 261 [736200/25046 (92%)]\tLoss: 0.077207\n",
            "Make prediction for 5010 samples...\n",
            "0.25895128 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 262 [0/25046 (0%)]\tLoss: 0.073229\n",
            "Train epoch: 262 [81920/25046 (10%)]\tLoss: 0.061803\n",
            "Train epoch: 262 [163800/25046 (20%)]\tLoss: 0.053359\n",
            "Train epoch: 262 [241980/25046 (31%)]\tLoss: 0.063674\n",
            "Train epoch: 262 [327840/25046 (41%)]\tLoss: 0.036948\n",
            "Train epoch: 262 [414400/25046 (51%)]\tLoss: 0.053924\n",
            "Train epoch: 262 [482040/25046 (61%)]\tLoss: 0.073485\n",
            "Train epoch: 262 [575120/25046 (71%)]\tLoss: 0.067335\n",
            "Train epoch: 262 [633280/25046 (82%)]\tLoss: 0.096900\n",
            "Train epoch: 262 [730980/25046 (92%)]\tLoss: 0.051107\n",
            "Make prediction for 5010 samples...\n",
            "0.2555035 No improvement since epoch  177 ; best_mse,best_ci: 0.2503633 0.872553405479465 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 263 [0/25046 (0%)]\tLoss: 0.050391\n",
            "Train epoch: 263 [81680/25046 (10%)]\tLoss: 0.046710\n",
            "Train epoch: 263 [162720/25046 (20%)]\tLoss: 0.045059\n",
            "Train epoch: 263 [246720/25046 (31%)]\tLoss: 0.044116\n",
            "Train epoch: 263 [330800/25046 (41%)]\tLoss: 0.047376\n",
            "Train epoch: 263 [415000/25046 (51%)]\tLoss: 0.052467\n",
            "Train epoch: 263 [487800/25046 (61%)]\tLoss: 0.053432\n",
            "Train epoch: 263 [579740/25046 (71%)]\tLoss: 0.065247\n",
            "Train epoch: 263 [638400/25046 (82%)]\tLoss: 0.021191\n",
            "Train epoch: 263 [732600/25046 (92%)]\tLoss: 0.039309\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  263 ; best_mse,best_ci: 0.2502461 0.8733899252814141 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 264 [0/25046 (0%)]\tLoss: 0.067479\n",
            "Train epoch: 264 [81860/25046 (10%)]\tLoss: 0.053323\n",
            "Train epoch: 264 [164680/25046 (20%)]\tLoss: 0.078026\n",
            "Train epoch: 264 [242760/25046 (31%)]\tLoss: 0.034212\n",
            "Train epoch: 264 [321040/25046 (41%)]\tLoss: 0.046171\n",
            "Train epoch: 264 [405400/25046 (51%)]\tLoss: 0.084230\n",
            "Train epoch: 264 [488040/25046 (61%)]\tLoss: 0.041574\n",
            "Train epoch: 264 [558600/25046 (71%)]\tLoss: 0.047131\n",
            "Train epoch: 264 [642080/25046 (82%)]\tLoss: 0.038066\n",
            "Train epoch: 264 [742500/25046 (92%)]\tLoss: 0.045719\n",
            "Make prediction for 5010 samples...\n",
            "0.25522453 No improvement since epoch  263 ; best_mse,best_ci: 0.2502461 0.8733899252814141 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 265 [0/25046 (0%)]\tLoss: 0.080124\n",
            "Train epoch: 265 [81180/25046 (10%)]\tLoss: 0.038954\n",
            "Train epoch: 265 [162360/25046 (20%)]\tLoss: 0.046162\n",
            "Train epoch: 265 [240120/25046 (31%)]\tLoss: 0.038089\n",
            "Train epoch: 265 [325680/25046 (41%)]\tLoss: 0.080236\n",
            "Train epoch: 265 [415900/25046 (51%)]\tLoss: 0.046250\n",
            "Train epoch: 265 [492480/25046 (61%)]\tLoss: 0.045821\n",
            "Train epoch: 265 [564200/25046 (71%)]\tLoss: 0.025968\n",
            "Train epoch: 265 [639040/25046 (82%)]\tLoss: 0.048465\n",
            "Train epoch: 265 [739440/25046 (92%)]\tLoss: 0.048669\n",
            "Make prediction for 5010 samples...\n",
            "0.25912756 No improvement since epoch  263 ; best_mse,best_ci: 0.2502461 0.8733899252814141 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 266 [0/25046 (0%)]\tLoss: 0.058859\n",
            "Train epoch: 266 [82340/25046 (10%)]\tLoss: 0.064413\n",
            "Train epoch: 266 [163600/25046 (20%)]\tLoss: 0.026855\n",
            "Train epoch: 266 [249600/25046 (31%)]\tLoss: 0.034243\n",
            "Train epoch: 266 [331360/25046 (41%)]\tLoss: 0.115639\n",
            "Train epoch: 266 [409700/25046 (51%)]\tLoss: 0.066216\n",
            "Train epoch: 266 [492120/25046 (61%)]\tLoss: 0.065921\n",
            "Train epoch: 266 [576240/25046 (71%)]\tLoss: 0.053449\n",
            "Train epoch: 266 [657920/25046 (82%)]\tLoss: 0.180960\n",
            "Train epoch: 266 [735300/25046 (92%)]\tLoss: 0.047056\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 267 [0/25046 (0%)]\tLoss: 0.048537\n",
            "Train epoch: 267 [81400/25046 (10%)]\tLoss: 0.070376\n",
            "Train epoch: 267 [163480/25046 (20%)]\tLoss: 0.086534\n",
            "Train epoch: 267 [242340/25046 (31%)]\tLoss: 0.056909\n",
            "Train epoch: 267 [321280/25046 (41%)]\tLoss: 0.068936\n",
            "Train epoch: 267 [408400/25046 (51%)]\tLoss: 0.051558\n",
            "Train epoch: 267 [500280/25046 (61%)]\tLoss: 0.097304\n",
            "Train epoch: 267 [569100/25046 (71%)]\tLoss: 0.047548\n",
            "Train epoch: 267 [668320/25046 (82%)]\tLoss: 0.057810\n",
            "Train epoch: 267 [746460/25046 (92%)]\tLoss: 0.059500\n",
            "Make prediction for 5010 samples...\n",
            "0.26758665 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 268 [0/25046 (0%)]\tLoss: 0.036258\n",
            "Train epoch: 268 [83480/25046 (10%)]\tLoss: 0.058972\n",
            "Train epoch: 268 [163680/25046 (20%)]\tLoss: 0.077364\n",
            "Train epoch: 268 [247740/25046 (31%)]\tLoss: 0.031932\n",
            "Train epoch: 268 [337760/25046 (41%)]\tLoss: 0.036456\n",
            "Train epoch: 268 [414200/25046 (51%)]\tLoss: 0.060748\n",
            "Train epoch: 268 [506640/25046 (61%)]\tLoss: 0.081669\n",
            "Train epoch: 268 [579740/25046 (71%)]\tLoss: 0.076439\n",
            "Train epoch: 268 [662400/25046 (82%)]\tLoss: 0.089061\n",
            "Train epoch: 268 [728460/25046 (92%)]\tLoss: 0.064486\n",
            "Make prediction for 5010 samples...\n",
            "0.2559521 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 269 [0/25046 (0%)]\tLoss: 0.071431\n",
            "Train epoch: 269 [83060/25046 (10%)]\tLoss: 0.035987\n",
            "Train epoch: 269 [162440/25046 (20%)]\tLoss: 0.065392\n",
            "Train epoch: 269 [241500/25046 (31%)]\tLoss: 0.074871\n",
            "Train epoch: 269 [328400/25046 (41%)]\tLoss: 0.037726\n",
            "Train epoch: 269 [409600/25046 (51%)]\tLoss: 0.071129\n",
            "Train epoch: 269 [493560/25046 (61%)]\tLoss: 0.069172\n",
            "Train epoch: 269 [569940/25046 (71%)]\tLoss: 0.080061\n",
            "Train epoch: 269 [648160/25046 (82%)]\tLoss: 0.051821\n",
            "Train epoch: 269 [746280/25046 (92%)]\tLoss: 0.065066\n",
            "Make prediction for 5010 samples...\n",
            "0.25954017 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 270 [0/25046 (0%)]\tLoss: 0.115525\n",
            "Train epoch: 270 [81100/25046 (10%)]\tLoss: 0.097814\n",
            "Train epoch: 270 [162240/25046 (20%)]\tLoss: 0.077409\n",
            "Train epoch: 270 [242040/25046 (31%)]\tLoss: 0.054257\n",
            "Train epoch: 270 [330960/25046 (41%)]\tLoss: 0.100115\n",
            "Train epoch: 270 [424300/25046 (51%)]\tLoss: 0.061753\n",
            "Train epoch: 270 [481440/25046 (61%)]\tLoss: 0.037443\n",
            "Train epoch: 270 [555240/25046 (71%)]\tLoss: 0.138939\n",
            "Train epoch: 270 [643840/25046 (82%)]\tLoss: 0.043698\n",
            "Train epoch: 270 [761760/25046 (92%)]\tLoss: 0.075917\n",
            "Make prediction for 5010 samples...\n",
            "0.25774318 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 271 [0/25046 (0%)]\tLoss: 0.079693\n",
            "Train epoch: 271 [80240/25046 (10%)]\tLoss: 0.050167\n",
            "Train epoch: 271 [163760/25046 (20%)]\tLoss: 0.050528\n",
            "Train epoch: 271 [243060/25046 (31%)]\tLoss: 0.076683\n",
            "Train epoch: 271 [328640/25046 (41%)]\tLoss: 0.043972\n",
            "Train epoch: 271 [418200/25046 (51%)]\tLoss: 0.104309\n",
            "Train epoch: 271 [497040/25046 (61%)]\tLoss: 0.093114\n",
            "Train epoch: 271 [577640/25046 (71%)]\tLoss: 0.048217\n",
            "Train epoch: 271 [651200/25046 (82%)]\tLoss: 0.117545\n",
            "Train epoch: 271 [747540/25046 (92%)]\tLoss: 0.048314\n",
            "Make prediction for 5010 samples...\n",
            "0.25902846 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 272 [0/25046 (0%)]\tLoss: 0.028943\n",
            "Train epoch: 272 [82540/25046 (10%)]\tLoss: 0.096761\n",
            "Train epoch: 272 [163280/25046 (20%)]\tLoss: 0.047698\n",
            "Train epoch: 272 [247080/25046 (31%)]\tLoss: 0.065738\n",
            "Train epoch: 272 [327680/25046 (41%)]\tLoss: 0.073013\n",
            "Train epoch: 272 [400000/25046 (51%)]\tLoss: 0.068417\n",
            "Train epoch: 272 [496080/25046 (61%)]\tLoss: 0.049738\n",
            "Train epoch: 272 [563500/25046 (71%)]\tLoss: 0.086500\n",
            "Train epoch: 272 [678880/25046 (82%)]\tLoss: 0.044337\n",
            "Train epoch: 272 [757800/25046 (92%)]\tLoss: 0.102572\n",
            "Make prediction for 5010 samples...\n",
            "0.25938192 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 273 [0/25046 (0%)]\tLoss: 0.065861\n",
            "Train epoch: 273 [81600/25046 (10%)]\tLoss: 0.044050\n",
            "Train epoch: 273 [161200/25046 (20%)]\tLoss: 0.080058\n",
            "Train epoch: 273 [244800/25046 (31%)]\tLoss: 0.032417\n",
            "Train epoch: 273 [326400/25046 (41%)]\tLoss: 0.056964\n",
            "Train epoch: 273 [407800/25046 (51%)]\tLoss: 0.071156\n",
            "Train epoch: 273 [492120/25046 (61%)]\tLoss: 0.061513\n",
            "Train epoch: 273 [578620/25046 (71%)]\tLoss: 0.139038\n",
            "Train epoch: 273 [663840/25046 (82%)]\tLoss: 0.040718\n",
            "Train epoch: 273 [736200/25046 (92%)]\tLoss: 0.076451\n",
            "Make prediction for 5010 samples...\n",
            "0.25353009 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 274 [0/25046 (0%)]\tLoss: 0.049467\n",
            "Train epoch: 274 [81300/25046 (10%)]\tLoss: 0.039728\n",
            "Train epoch: 274 [167440/25046 (20%)]\tLoss: 0.067308\n",
            "Train epoch: 274 [237240/25046 (31%)]\tLoss: 0.073081\n",
            "Train epoch: 274 [327280/25046 (41%)]\tLoss: 0.050512\n",
            "Train epoch: 274 [401100/25046 (51%)]\tLoss: 0.050608\n",
            "Train epoch: 274 [499320/25046 (61%)]\tLoss: 0.072320\n",
            "Train epoch: 274 [582260/25046 (71%)]\tLoss: 0.085675\n",
            "Train epoch: 274 [637120/25046 (82%)]\tLoss: 0.044657\n",
            "Train epoch: 274 [748080/25046 (92%)]\tLoss: 0.032681\n",
            "Make prediction for 5010 samples...\n",
            "0.2625114 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 275 [0/25046 (0%)]\tLoss: 0.069372\n",
            "Train epoch: 275 [82740/25046 (10%)]\tLoss: 0.050891\n",
            "Train epoch: 275 [160320/25046 (20%)]\tLoss: 0.082579\n",
            "Train epoch: 275 [245340/25046 (31%)]\tLoss: 0.042202\n",
            "Train epoch: 275 [331680/25046 (41%)]\tLoss: 0.051045\n",
            "Train epoch: 275 [416900/25046 (51%)]\tLoss: 0.077649\n",
            "Train epoch: 275 [499680/25046 (61%)]\tLoss: 0.098563\n",
            "Train epoch: 275 [588980/25046 (71%)]\tLoss: 0.106927\n",
            "Train epoch: 275 [670400/25046 (82%)]\tLoss: 0.052646\n",
            "Train epoch: 275 [723420/25046 (92%)]\tLoss: 0.119096\n",
            "Make prediction for 5010 samples...\n",
            "0.26919368 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 276 [0/25046 (0%)]\tLoss: 0.055969\n",
            "Train epoch: 276 [83580/25046 (10%)]\tLoss: 0.047205\n",
            "Train epoch: 276 [163920/25046 (20%)]\tLoss: 0.046488\n",
            "Train epoch: 276 [246060/25046 (31%)]\tLoss: 0.049366\n",
            "Train epoch: 276 [323360/25046 (41%)]\tLoss: 0.056779\n",
            "Train epoch: 276 [415200/25046 (51%)]\tLoss: 0.046231\n",
            "Train epoch: 276 [498240/25046 (61%)]\tLoss: 0.044745\n",
            "Train epoch: 276 [575120/25046 (71%)]\tLoss: 0.069219\n",
            "Train epoch: 276 [673920/25046 (82%)]\tLoss: 0.107538\n",
            "Train epoch: 276 [729900/25046 (92%)]\tLoss: 0.055370\n",
            "Make prediction for 5010 samples...\n",
            "0.26058525 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 277 [0/25046 (0%)]\tLoss: 0.043094\n",
            "Train epoch: 277 [84460/25046 (10%)]\tLoss: 0.031969\n",
            "Train epoch: 277 [159480/25046 (20%)]\tLoss: 0.048828\n",
            "Train epoch: 277 [245400/25046 (31%)]\tLoss: 0.043199\n",
            "Train epoch: 277 [333200/25046 (41%)]\tLoss: 0.107664\n",
            "Train epoch: 277 [405800/25046 (51%)]\tLoss: 0.052036\n",
            "Train epoch: 277 [479040/25046 (61%)]\tLoss: 0.034720\n",
            "Train epoch: 277 [590940/25046 (71%)]\tLoss: 0.039747\n",
            "Train epoch: 277 [650880/25046 (82%)]\tLoss: 0.081257\n",
            "Train epoch: 277 [721980/25046 (92%)]\tLoss: 0.098195\n",
            "Make prediction for 5010 samples...\n",
            "0.27717367 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 278 [0/25046 (0%)]\tLoss: 0.219955\n",
            "Train epoch: 278 [82420/25046 (10%)]\tLoss: 0.081274\n",
            "Train epoch: 278 [168480/25046 (20%)]\tLoss: 0.055413\n",
            "Train epoch: 278 [246660/25046 (31%)]\tLoss: 0.048134\n",
            "Train epoch: 278 [324640/25046 (41%)]\tLoss: 0.034965\n",
            "Train epoch: 278 [416600/25046 (51%)]\tLoss: 0.077499\n",
            "Train epoch: 278 [502560/25046 (61%)]\tLoss: 0.051601\n",
            "Train epoch: 278 [577640/25046 (71%)]\tLoss: 0.038591\n",
            "Train epoch: 278 [651840/25046 (82%)]\tLoss: 0.033331\n",
            "Train epoch: 278 [716760/25046 (92%)]\tLoss: 0.043563\n",
            "Make prediction for 5010 samples...\n",
            "0.26525587 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 279 [0/25046 (0%)]\tLoss: 0.042388\n",
            "Train epoch: 279 [81680/25046 (10%)]\tLoss: 0.091300\n",
            "Train epoch: 279 [164880/25046 (20%)]\tLoss: 0.082307\n",
            "Train epoch: 279 [250020/25046 (31%)]\tLoss: 0.073800\n",
            "Train epoch: 279 [328480/25046 (41%)]\tLoss: 0.034080\n",
            "Train epoch: 279 [402600/25046 (51%)]\tLoss: 0.082112\n",
            "Train epoch: 279 [490920/25046 (61%)]\tLoss: 0.039863\n",
            "Train epoch: 279 [559720/25046 (71%)]\tLoss: 0.086263\n",
            "Train epoch: 279 [666400/25046 (82%)]\tLoss: 0.044168\n",
            "Train epoch: 279 [721260/25046 (92%)]\tLoss: 0.075763\n",
            "Make prediction for 5010 samples...\n",
            "0.2622894 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 280 [0/25046 (0%)]\tLoss: 0.059409\n",
            "Train epoch: 280 [81020/25046 (10%)]\tLoss: 0.052445\n",
            "Train epoch: 280 [163920/25046 (20%)]\tLoss: 0.037543\n",
            "Train epoch: 280 [243960/25046 (31%)]\tLoss: 0.038279\n",
            "Train epoch: 280 [331360/25046 (41%)]\tLoss: 0.044665\n",
            "Train epoch: 280 [411700/25046 (51%)]\tLoss: 0.042380\n",
            "Train epoch: 280 [480600/25046 (61%)]\tLoss: 0.037654\n",
            "Train epoch: 280 [564760/25046 (71%)]\tLoss: 0.144678\n",
            "Train epoch: 280 [632960/25046 (82%)]\tLoss: 0.114370\n",
            "Train epoch: 280 [729360/25046 (92%)]\tLoss: 0.046524\n",
            "Make prediction for 5010 samples...\n",
            "0.25209853 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 281 [0/25046 (0%)]\tLoss: 0.088679\n",
            "Train epoch: 281 [82760/25046 (10%)]\tLoss: 0.140894\n",
            "Train epoch: 281 [160080/25046 (20%)]\tLoss: 0.064104\n",
            "Train epoch: 281 [248040/25046 (31%)]\tLoss: 0.090980\n",
            "Train epoch: 281 [334880/25046 (41%)]\tLoss: 0.045514\n",
            "Train epoch: 281 [398900/25046 (51%)]\tLoss: 0.088062\n",
            "Train epoch: 281 [483240/25046 (61%)]\tLoss: 0.065684\n",
            "Train epoch: 281 [576800/25046 (71%)]\tLoss: 0.033546\n",
            "Train epoch: 281 [650400/25046 (82%)]\tLoss: 0.066702\n",
            "Train epoch: 281 [729360/25046 (92%)]\tLoss: 0.051719\n",
            "Make prediction for 5010 samples...\n",
            "0.2634205 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 282 [0/25046 (0%)]\tLoss: 0.041885\n",
            "Train epoch: 282 [80040/25046 (10%)]\tLoss: 0.068817\n",
            "Train epoch: 282 [164720/25046 (20%)]\tLoss: 0.122469\n",
            "Train epoch: 282 [260760/25046 (31%)]\tLoss: 0.071931\n",
            "Train epoch: 282 [331920/25046 (41%)]\tLoss: 0.067212\n",
            "Train epoch: 282 [404200/25046 (51%)]\tLoss: 0.082535\n",
            "Train epoch: 282 [505200/25046 (61%)]\tLoss: 0.042128\n",
            "Train epoch: 282 [562520/25046 (71%)]\tLoss: 0.058037\n",
            "Train epoch: 282 [660160/25046 (82%)]\tLoss: 0.065936\n",
            "Train epoch: 282 [735300/25046 (92%)]\tLoss: 0.030298\n",
            "Make prediction for 5010 samples...\n",
            "0.26144597 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 283 [0/25046 (0%)]\tLoss: 0.053211\n",
            "Train epoch: 283 [83280/25046 (10%)]\tLoss: 0.059901\n",
            "Train epoch: 283 [161560/25046 (20%)]\tLoss: 0.027513\n",
            "Train epoch: 283 [243720/25046 (31%)]\tLoss: 0.057402\n",
            "Train epoch: 283 [323600/25046 (41%)]\tLoss: 0.067843\n",
            "Train epoch: 283 [405100/25046 (51%)]\tLoss: 0.042772\n",
            "Train epoch: 283 [500280/25046 (61%)]\tLoss: 0.065973\n",
            "Train epoch: 283 [574000/25046 (71%)]\tLoss: 0.051697\n",
            "Train epoch: 283 [671040/25046 (82%)]\tLoss: 0.101956\n",
            "Train epoch: 283 [731880/25046 (92%)]\tLoss: 0.042217\n",
            "Make prediction for 5010 samples...\n",
            "0.26017857 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 284 [0/25046 (0%)]\tLoss: 0.055689\n",
            "Train epoch: 284 [81200/25046 (10%)]\tLoss: 0.046354\n",
            "Train epoch: 284 [164280/25046 (20%)]\tLoss: 0.059650\n",
            "Train epoch: 284 [252180/25046 (31%)]\tLoss: 0.081101\n",
            "Train epoch: 284 [318000/25046 (41%)]\tLoss: 0.038448\n",
            "Train epoch: 284 [411400/25046 (51%)]\tLoss: 0.061719\n",
            "Train epoch: 284 [501240/25046 (61%)]\tLoss: 0.052454\n",
            "Train epoch: 284 [578620/25046 (71%)]\tLoss: 0.057513\n",
            "Train epoch: 284 [660960/25046 (82%)]\tLoss: 0.080841\n",
            "Train epoch: 284 [748080/25046 (92%)]\tLoss: 0.077117\n",
            "Make prediction for 5010 samples...\n",
            "0.26470605 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 285 [0/25046 (0%)]\tLoss: 0.090130\n",
            "Train epoch: 285 [82860/25046 (10%)]\tLoss: 0.034902\n",
            "Train epoch: 285 [164400/25046 (20%)]\tLoss: 0.107256\n",
            "Train epoch: 285 [239520/25046 (31%)]\tLoss: 0.054841\n",
            "Train epoch: 285 [330560/25046 (41%)]\tLoss: 0.054924\n",
            "Train epoch: 285 [418200/25046 (51%)]\tLoss: 0.046076\n",
            "Train epoch: 285 [491280/25046 (61%)]\tLoss: 0.062260\n",
            "Train epoch: 285 [578760/25046 (71%)]\tLoss: 0.093597\n",
            "Train epoch: 285 [662560/25046 (82%)]\tLoss: 0.051807\n",
            "Train epoch: 285 [736020/25046 (92%)]\tLoss: 0.057701\n",
            "Make prediction for 5010 samples...\n",
            "0.25732207 No improvement since epoch  266 ; best_mse,best_ci: 0.24827468 0.8691917047008523 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 286 [0/25046 (0%)]\tLoss: 0.090932\n",
            "Train epoch: 286 [82300/25046 (10%)]\tLoss: 0.034629\n",
            "Train epoch: 286 [161360/25046 (20%)]\tLoss: 0.034704\n",
            "Train epoch: 286 [247800/25046 (31%)]\tLoss: 0.059194\n",
            "Train epoch: 286 [325600/25046 (41%)]\tLoss: 0.063286\n",
            "Train epoch: 286 [407100/25046 (51%)]\tLoss: 0.059598\n",
            "Train epoch: 286 [490200/25046 (61%)]\tLoss: 0.035977\n",
            "Train epoch: 286 [576800/25046 (71%)]\tLoss: 0.055409\n",
            "Train epoch: 286 [668960/25046 (82%)]\tLoss: 0.042613\n",
            "Train epoch: 286 [741780/25046 (92%)]\tLoss: 0.041553\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 287 [0/25046 (0%)]\tLoss: 0.061158\n",
            "Train epoch: 287 [79760/25046 (10%)]\tLoss: 0.033749\n",
            "Train epoch: 287 [162320/25046 (20%)]\tLoss: 0.051724\n",
            "Train epoch: 287 [246960/25046 (31%)]\tLoss: 0.037299\n",
            "Train epoch: 287 [334720/25046 (41%)]\tLoss: 0.047251\n",
            "Train epoch: 287 [408600/25046 (51%)]\tLoss: 0.063401\n",
            "Train epoch: 287 [494880/25046 (61%)]\tLoss: 0.068593\n",
            "Train epoch: 287 [576100/25046 (71%)]\tLoss: 0.064910\n",
            "Train epoch: 287 [651840/25046 (82%)]\tLoss: 0.099198\n",
            "Train epoch: 287 [723780/25046 (92%)]\tLoss: 0.040048\n",
            "Make prediction for 5010 samples...\n",
            "0.25904018 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 288 [0/25046 (0%)]\tLoss: 0.049616\n",
            "Train epoch: 288 [83800/25046 (10%)]\tLoss: 0.047327\n",
            "Train epoch: 288 [165880/25046 (20%)]\tLoss: 0.071320\n",
            "Train epoch: 288 [246540/25046 (31%)]\tLoss: 0.036825\n",
            "Train epoch: 288 [322880/25046 (41%)]\tLoss: 0.074593\n",
            "Train epoch: 288 [397800/25046 (51%)]\tLoss: 0.066367\n",
            "Train epoch: 288 [488880/25046 (61%)]\tLoss: 0.054279\n",
            "Train epoch: 288 [565040/25046 (71%)]\tLoss: 0.048992\n",
            "Train epoch: 288 [672000/25046 (82%)]\tLoss: 0.054683\n",
            "Train epoch: 288 [754200/25046 (92%)]\tLoss: 0.061287\n",
            "Make prediction for 5010 samples...\n",
            "0.26477164 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 289 [0/25046 (0%)]\tLoss: 0.053428\n",
            "Train epoch: 289 [84660/25046 (10%)]\tLoss: 0.053402\n",
            "Train epoch: 289 [167240/25046 (20%)]\tLoss: 0.053691\n",
            "Train epoch: 289 [241200/25046 (31%)]\tLoss: 0.043499\n",
            "Train epoch: 289 [323120/25046 (41%)]\tLoss: 0.051274\n",
            "Train epoch: 289 [410900/25046 (51%)]\tLoss: 0.058503\n",
            "Train epoch: 289 [488280/25046 (61%)]\tLoss: 0.136763\n",
            "Train epoch: 289 [583380/25046 (71%)]\tLoss: 0.057316\n",
            "Train epoch: 289 [674400/25046 (82%)]\tLoss: 0.072536\n",
            "Train epoch: 289 [752400/25046 (92%)]\tLoss: 0.036121\n",
            "Make prediction for 5010 samples...\n",
            "0.2603555 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 290 [0/25046 (0%)]\tLoss: 0.054590\n",
            "Train epoch: 290 [81780/25046 (10%)]\tLoss: 0.047853\n",
            "Train epoch: 290 [162920/25046 (20%)]\tLoss: 0.028703\n",
            "Train epoch: 290 [236160/25046 (31%)]\tLoss: 0.074353\n",
            "Train epoch: 290 [329040/25046 (41%)]\tLoss: 0.027819\n",
            "Train epoch: 290 [400800/25046 (51%)]\tLoss: 0.144446\n",
            "Train epoch: 290 [501120/25046 (61%)]\tLoss: 0.046983\n",
            "Train epoch: 290 [579040/25046 (71%)]\tLoss: 0.080851\n",
            "Train epoch: 290 [661120/25046 (82%)]\tLoss: 0.093138\n",
            "Train epoch: 290 [740700/25046 (92%)]\tLoss: 0.112858\n",
            "Make prediction for 5010 samples...\n",
            "0.26874974 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 291 [0/25046 (0%)]\tLoss: 0.051907\n",
            "Train epoch: 291 [82880/25046 (10%)]\tLoss: 0.052040\n",
            "Train epoch: 291 [162200/25046 (20%)]\tLoss: 0.048768\n",
            "Train epoch: 291 [243300/25046 (31%)]\tLoss: 0.053791\n",
            "Train epoch: 291 [326960/25046 (41%)]\tLoss: 0.065569\n",
            "Train epoch: 291 [398700/25046 (51%)]\tLoss: 0.063757\n",
            "Train epoch: 291 [489720/25046 (61%)]\tLoss: 0.034121\n",
            "Train epoch: 291 [567840/25046 (71%)]\tLoss: 0.055480\n",
            "Train epoch: 291 [655360/25046 (82%)]\tLoss: 0.037548\n",
            "Train epoch: 291 [743040/25046 (92%)]\tLoss: 0.069740\n",
            "Make prediction for 5010 samples...\n",
            "0.2596685 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 292 [0/25046 (0%)]\tLoss: 0.044749\n",
            "Train epoch: 292 [81900/25046 (10%)]\tLoss: 0.048681\n",
            "Train epoch: 292 [162640/25046 (20%)]\tLoss: 0.098416\n",
            "Train epoch: 292 [251220/25046 (31%)]\tLoss: 0.062109\n",
            "Train epoch: 292 [329200/25046 (41%)]\tLoss: 0.088707\n",
            "Train epoch: 292 [406800/25046 (51%)]\tLoss: 0.040039\n",
            "Train epoch: 292 [497760/25046 (61%)]\tLoss: 0.038478\n",
            "Train epoch: 292 [570500/25046 (71%)]\tLoss: 0.227690\n",
            "Train epoch: 292 [650560/25046 (82%)]\tLoss: 0.049562\n",
            "Train epoch: 292 [751140/25046 (92%)]\tLoss: 0.079209\n",
            "Make prediction for 5010 samples...\n",
            "0.2624647 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 293 [0/25046 (0%)]\tLoss: 0.062676\n",
            "Train epoch: 293 [80040/25046 (10%)]\tLoss: 0.034471\n",
            "Train epoch: 293 [163720/25046 (20%)]\tLoss: 0.056480\n",
            "Train epoch: 293 [246060/25046 (31%)]\tLoss: 0.052527\n",
            "Train epoch: 293 [339920/25046 (41%)]\tLoss: 0.076066\n",
            "Train epoch: 293 [411300/25046 (51%)]\tLoss: 0.031475\n",
            "Train epoch: 293 [487080/25046 (61%)]\tLoss: 0.116790\n",
            "Train epoch: 293 [569380/25046 (71%)]\tLoss: 0.070184\n",
            "Train epoch: 293 [665600/25046 (82%)]\tLoss: 0.037336\n",
            "Train epoch: 293 [727020/25046 (92%)]\tLoss: 0.040324\n",
            "Make prediction for 5010 samples...\n",
            "0.2641766 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 294 [0/25046 (0%)]\tLoss: 0.045479\n",
            "Train epoch: 294 [83040/25046 (10%)]\tLoss: 0.086457\n",
            "Train epoch: 294 [161800/25046 (20%)]\tLoss: 0.070859\n",
            "Train epoch: 294 [243780/25046 (31%)]\tLoss: 0.055574\n",
            "Train epoch: 294 [337920/25046 (41%)]\tLoss: 0.035211\n",
            "Train epoch: 294 [409500/25046 (51%)]\tLoss: 0.045585\n",
            "Train epoch: 294 [494760/25046 (61%)]\tLoss: 0.047157\n",
            "Train epoch: 294 [597520/25046 (71%)]\tLoss: 0.058905\n",
            "Train epoch: 294 [673920/25046 (82%)]\tLoss: 0.092393\n",
            "Train epoch: 294 [748800/25046 (92%)]\tLoss: 0.029922\n",
            "Make prediction for 5010 samples...\n",
            "0.26543456 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 295 [0/25046 (0%)]\tLoss: 0.059569\n",
            "Train epoch: 295 [82520/25046 (10%)]\tLoss: 0.059354\n",
            "Train epoch: 295 [164280/25046 (20%)]\tLoss: 0.112670\n",
            "Train epoch: 295 [244800/25046 (31%)]\tLoss: 0.056703\n",
            "Train epoch: 295 [319920/25046 (41%)]\tLoss: 0.065219\n",
            "Train epoch: 295 [414700/25046 (51%)]\tLoss: 0.030976\n",
            "Train epoch: 295 [489720/25046 (61%)]\tLoss: 0.028007\n",
            "Train epoch: 295 [569520/25046 (71%)]\tLoss: 0.064094\n",
            "Train epoch: 295 [649760/25046 (82%)]\tLoss: 0.070009\n",
            "Train epoch: 295 [739440/25046 (92%)]\tLoss: 0.037201\n",
            "Make prediction for 5010 samples...\n",
            "0.25416544 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 296 [0/25046 (0%)]\tLoss: 0.063846\n",
            "Train epoch: 296 [82940/25046 (10%)]\tLoss: 0.044054\n",
            "Train epoch: 296 [163640/25046 (20%)]\tLoss: 0.055151\n",
            "Train epoch: 296 [249420/25046 (31%)]\tLoss: 0.060490\n",
            "Train epoch: 296 [333520/25046 (41%)]\tLoss: 0.082092\n",
            "Train epoch: 296 [420900/25046 (51%)]\tLoss: 0.033582\n",
            "Train epoch: 296 [482160/25046 (61%)]\tLoss: 0.079181\n",
            "Train epoch: 296 [569520/25046 (71%)]\tLoss: 0.059780\n",
            "Train epoch: 296 [653760/25046 (82%)]\tLoss: 0.046726\n",
            "Train epoch: 296 [740700/25046 (92%)]\tLoss: 0.057940\n",
            "Make prediction for 5010 samples...\n",
            "0.26185793 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 297 [0/25046 (0%)]\tLoss: 0.045547\n",
            "Train epoch: 297 [83460/25046 (10%)]\tLoss: 0.116493\n",
            "Train epoch: 297 [163400/25046 (20%)]\tLoss: 0.038319\n",
            "Train epoch: 297 [252540/25046 (31%)]\tLoss: 0.057685\n",
            "Train epoch: 297 [323120/25046 (41%)]\tLoss: 0.136407\n",
            "Train epoch: 297 [415700/25046 (51%)]\tLoss: 0.036511\n",
            "Train epoch: 297 [496560/25046 (61%)]\tLoss: 0.082354\n",
            "Train epoch: 297 [587300/25046 (71%)]\tLoss: 0.061869\n",
            "Train epoch: 297 [669920/25046 (82%)]\tLoss: 0.064943\n",
            "Train epoch: 297 [727920/25046 (92%)]\tLoss: 0.059945\n",
            "Make prediction for 5010 samples...\n",
            "0.26122314 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 298 [0/25046 (0%)]\tLoss: 0.053107\n",
            "Train epoch: 298 [79620/25046 (10%)]\tLoss: 0.034946\n",
            "Train epoch: 298 [162800/25046 (20%)]\tLoss: 0.042958\n",
            "Train epoch: 298 [239760/25046 (31%)]\tLoss: 0.106493\n",
            "Train epoch: 298 [330160/25046 (41%)]\tLoss: 0.040508\n",
            "Train epoch: 298 [413000/25046 (51%)]\tLoss: 0.076070\n",
            "Train epoch: 298 [494160/25046 (61%)]\tLoss: 0.059597\n",
            "Train epoch: 298 [585200/25046 (71%)]\tLoss: 0.048098\n",
            "Train epoch: 298 [636320/25046 (82%)]\tLoss: 0.073843\n",
            "Train epoch: 298 [750600/25046 (92%)]\tLoss: 0.043832\n",
            "Make prediction for 5010 samples...\n",
            "0.2639094 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 299 [0/25046 (0%)]\tLoss: 0.042884\n",
            "Train epoch: 299 [81640/25046 (10%)]\tLoss: 0.047188\n",
            "Train epoch: 299 [165200/25046 (20%)]\tLoss: 0.071915\n",
            "Train epoch: 299 [250620/25046 (31%)]\tLoss: 0.035664\n",
            "Train epoch: 299 [326960/25046 (41%)]\tLoss: 0.062746\n",
            "Train epoch: 299 [401400/25046 (51%)]\tLoss: 0.048684\n",
            "Train epoch: 299 [481080/25046 (61%)]\tLoss: 0.076342\n",
            "Train epoch: 299 [582260/25046 (71%)]\tLoss: 0.065641\n",
            "Train epoch: 299 [672960/25046 (82%)]\tLoss: 0.086999\n",
            "Train epoch: 299 [724140/25046 (92%)]\tLoss: 0.073731\n",
            "Make prediction for 5010 samples...\n",
            "0.2541224 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 300 [0/25046 (0%)]\tLoss: 0.084161\n",
            "Train epoch: 300 [82740/25046 (10%)]\tLoss: 0.073435\n",
            "Train epoch: 300 [165800/25046 (20%)]\tLoss: 0.059086\n",
            "Train epoch: 300 [249300/25046 (31%)]\tLoss: 0.071235\n",
            "Train epoch: 300 [330000/25046 (41%)]\tLoss: 0.027832\n",
            "Train epoch: 300 [418200/25046 (51%)]\tLoss: 0.036360\n",
            "Train epoch: 300 [500880/25046 (61%)]\tLoss: 0.054904\n",
            "Train epoch: 300 [572880/25046 (71%)]\tLoss: 0.059341\n",
            "Train epoch: 300 [655840/25046 (82%)]\tLoss: 0.037308\n",
            "Train epoch: 300 [753480/25046 (92%)]\tLoss: 0.041175\n",
            "Make prediction for 5010 samples...\n",
            "0.2579547 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 301 [0/25046 (0%)]\tLoss: 0.043598\n",
            "Train epoch: 301 [82380/25046 (10%)]\tLoss: 0.035897\n",
            "Train epoch: 301 [165920/25046 (20%)]\tLoss: 0.051647\n",
            "Train epoch: 301 [243720/25046 (31%)]\tLoss: 0.104329\n",
            "Train epoch: 301 [330560/25046 (41%)]\tLoss: 0.038914\n",
            "Train epoch: 301 [407700/25046 (51%)]\tLoss: 0.069456\n",
            "Train epoch: 301 [504840/25046 (61%)]\tLoss: 0.036414\n",
            "Train epoch: 301 [580720/25046 (71%)]\tLoss: 0.068750\n",
            "Train epoch: 301 [665120/25046 (82%)]\tLoss: 0.039211\n",
            "Train epoch: 301 [722160/25046 (92%)]\tLoss: 0.049835\n",
            "Make prediction for 5010 samples...\n",
            "0.26883662 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 302 [0/25046 (0%)]\tLoss: 0.056798\n",
            "Train epoch: 302 [81880/25046 (10%)]\tLoss: 0.051499\n",
            "Train epoch: 302 [165320/25046 (20%)]\tLoss: 0.048233\n",
            "Train epoch: 302 [249180/25046 (31%)]\tLoss: 0.058776\n",
            "Train epoch: 302 [331280/25046 (41%)]\tLoss: 0.051460\n",
            "Train epoch: 302 [412500/25046 (51%)]\tLoss: 0.128821\n",
            "Train epoch: 302 [503880/25046 (61%)]\tLoss: 0.057747\n",
            "Train epoch: 302 [575540/25046 (71%)]\tLoss: 0.076759\n",
            "Train epoch: 302 [653760/25046 (82%)]\tLoss: 0.057223\n",
            "Train epoch: 302 [723780/25046 (92%)]\tLoss: 0.033721\n",
            "Make prediction for 5010 samples...\n",
            "0.26178804 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 303 [0/25046 (0%)]\tLoss: 0.036765\n",
            "Train epoch: 303 [82500/25046 (10%)]\tLoss: 0.047420\n",
            "Train epoch: 303 [166280/25046 (20%)]\tLoss: 0.118069\n",
            "Train epoch: 303 [256140/25046 (31%)]\tLoss: 0.133568\n",
            "Train epoch: 303 [319040/25046 (41%)]\tLoss: 0.043049\n",
            "Train epoch: 303 [420300/25046 (51%)]\tLoss: 0.052678\n",
            "Train epoch: 303 [494520/25046 (61%)]\tLoss: 0.039442\n",
            "Train epoch: 303 [563360/25046 (71%)]\tLoss: 0.075513\n",
            "Train epoch: 303 [653760/25046 (82%)]\tLoss: 0.059379\n",
            "Train epoch: 303 [748800/25046 (92%)]\tLoss: 0.066073\n",
            "Make prediction for 5010 samples...\n",
            "0.25561053 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 304 [0/25046 (0%)]\tLoss: 0.087663\n",
            "Train epoch: 304 [81840/25046 (10%)]\tLoss: 0.038287\n",
            "Train epoch: 304 [162480/25046 (20%)]\tLoss: 0.083639\n",
            "Train epoch: 304 [239220/25046 (31%)]\tLoss: 0.053758\n",
            "Train epoch: 304 [324240/25046 (41%)]\tLoss: 0.086876\n",
            "Train epoch: 304 [400500/25046 (51%)]\tLoss: 0.041713\n",
            "Train epoch: 304 [493080/25046 (61%)]\tLoss: 0.033861\n",
            "Train epoch: 304 [570920/25046 (71%)]\tLoss: 0.080707\n",
            "Train epoch: 304 [654880/25046 (82%)]\tLoss: 0.134671\n",
            "Train epoch: 304 [737460/25046 (92%)]\tLoss: 0.051646\n",
            "Make prediction for 5010 samples...\n",
            "0.25829163 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 305 [0/25046 (0%)]\tLoss: 0.070458\n",
            "Train epoch: 305 [81860/25046 (10%)]\tLoss: 0.061562\n",
            "Train epoch: 305 [165680/25046 (20%)]\tLoss: 0.046605\n",
            "Train epoch: 305 [236460/25046 (31%)]\tLoss: 0.046800\n",
            "Train epoch: 305 [329360/25046 (41%)]\tLoss: 0.024962\n",
            "Train epoch: 305 [408700/25046 (51%)]\tLoss: 0.068573\n",
            "Train epoch: 305 [508800/25046 (61%)]\tLoss: 0.051112\n",
            "Train epoch: 305 [584920/25046 (71%)]\tLoss: 0.104487\n",
            "Train epoch: 305 [652960/25046 (82%)]\tLoss: 0.100107\n",
            "Train epoch: 305 [758880/25046 (92%)]\tLoss: 0.042938\n",
            "Make prediction for 5010 samples...\n",
            "0.26022986 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 306 [0/25046 (0%)]\tLoss: 0.040660\n",
            "Train epoch: 306 [82140/25046 (10%)]\tLoss: 0.071544\n",
            "Train epoch: 306 [166480/25046 (20%)]\tLoss: 0.121005\n",
            "Train epoch: 306 [241800/25046 (31%)]\tLoss: 0.062449\n",
            "Train epoch: 306 [334000/25046 (41%)]\tLoss: 0.051409\n",
            "Train epoch: 306 [414700/25046 (51%)]\tLoss: 0.111110\n",
            "Train epoch: 306 [488640/25046 (61%)]\tLoss: 0.076805\n",
            "Train epoch: 306 [588700/25046 (71%)]\tLoss: 0.025786\n",
            "Train epoch: 306 [657600/25046 (82%)]\tLoss: 0.036150\n",
            "Train epoch: 306 [746640/25046 (92%)]\tLoss: 0.053653\n",
            "Make prediction for 5010 samples...\n",
            "0.25990164 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 307 [0/25046 (0%)]\tLoss: 0.039723\n",
            "Train epoch: 307 [83880/25046 (10%)]\tLoss: 0.044795\n",
            "Train epoch: 307 [167320/25046 (20%)]\tLoss: 0.047129\n",
            "Train epoch: 307 [245580/25046 (31%)]\tLoss: 0.099448\n",
            "Train epoch: 307 [328000/25046 (41%)]\tLoss: 0.034946\n",
            "Train epoch: 307 [412700/25046 (51%)]\tLoss: 0.072809\n",
            "Train epoch: 307 [505680/25046 (61%)]\tLoss: 0.032038\n",
            "Train epoch: 307 [574980/25046 (71%)]\tLoss: 0.025000\n",
            "Train epoch: 307 [654720/25046 (82%)]\tLoss: 0.046852\n",
            "Train epoch: 307 [763020/25046 (92%)]\tLoss: 0.053049\n",
            "Make prediction for 5010 samples...\n",
            "0.25636747 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 308 [0/25046 (0%)]\tLoss: 0.096978\n",
            "Train epoch: 308 [81320/25046 (10%)]\tLoss: 0.044665\n",
            "Train epoch: 308 [164320/25046 (20%)]\tLoss: 0.051650\n",
            "Train epoch: 308 [240300/25046 (31%)]\tLoss: 0.047395\n",
            "Train epoch: 308 [324240/25046 (41%)]\tLoss: 0.049669\n",
            "Train epoch: 308 [407200/25046 (51%)]\tLoss: 0.125109\n",
            "Train epoch: 308 [494760/25046 (61%)]\tLoss: 0.060935\n",
            "Train epoch: 308 [570220/25046 (71%)]\tLoss: 0.060931\n",
            "Train epoch: 308 [674560/25046 (82%)]\tLoss: 0.063280\n",
            "Train epoch: 308 [723240/25046 (92%)]\tLoss: 0.049153\n",
            "Make prediction for 5010 samples...\n",
            "0.25759122 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 309 [0/25046 (0%)]\tLoss: 0.041971\n",
            "Train epoch: 309 [80680/25046 (10%)]\tLoss: 0.049911\n",
            "Train epoch: 309 [163440/25046 (20%)]\tLoss: 0.019097\n",
            "Train epoch: 309 [246000/25046 (31%)]\tLoss: 0.039872\n",
            "Train epoch: 309 [326240/25046 (41%)]\tLoss: 0.030890\n",
            "Train epoch: 309 [415100/25046 (51%)]\tLoss: 0.108027\n",
            "Train epoch: 309 [492360/25046 (61%)]\tLoss: 0.062123\n",
            "Train epoch: 309 [585060/25046 (71%)]\tLoss: 0.033259\n",
            "Train epoch: 309 [644160/25046 (82%)]\tLoss: 0.077309\n",
            "Train epoch: 309 [744840/25046 (92%)]\tLoss: 0.048119\n",
            "Make prediction for 5010 samples...\n",
            "0.25202322 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 310 [0/25046 (0%)]\tLoss: 0.029084\n",
            "Train epoch: 310 [83700/25046 (10%)]\tLoss: 0.047424\n",
            "Train epoch: 310 [159520/25046 (20%)]\tLoss: 0.037392\n",
            "Train epoch: 310 [247680/25046 (31%)]\tLoss: 0.058601\n",
            "Train epoch: 310 [335760/25046 (41%)]\tLoss: 0.044791\n",
            "Train epoch: 310 [411000/25046 (51%)]\tLoss: 0.082451\n",
            "Train epoch: 310 [503520/25046 (61%)]\tLoss: 0.050450\n",
            "Train epoch: 310 [564620/25046 (71%)]\tLoss: 0.039368\n",
            "Train epoch: 310 [649600/25046 (82%)]\tLoss: 0.085129\n",
            "Train epoch: 310 [723060/25046 (92%)]\tLoss: 0.091028\n",
            "Make prediction for 5010 samples...\n",
            "0.24984272 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 311 [0/25046 (0%)]\tLoss: 0.060145\n",
            "Train epoch: 311 [83080/25046 (10%)]\tLoss: 0.041842\n",
            "Train epoch: 311 [160400/25046 (20%)]\tLoss: 0.058203\n",
            "Train epoch: 311 [249480/25046 (31%)]\tLoss: 0.042761\n",
            "Train epoch: 311 [325360/25046 (41%)]\tLoss: 0.038153\n",
            "Train epoch: 311 [412800/25046 (51%)]\tLoss: 0.030929\n",
            "Train epoch: 311 [494640/25046 (61%)]\tLoss: 0.022803\n",
            "Train epoch: 311 [566300/25046 (71%)]\tLoss: 0.036727\n",
            "Train epoch: 311 [642720/25046 (82%)]\tLoss: 0.030415\n",
            "Train epoch: 311 [747180/25046 (92%)]\tLoss: 0.043710\n",
            "Make prediction for 5010 samples...\n",
            "0.253736 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 312 [0/25046 (0%)]\tLoss: 0.059114\n",
            "Train epoch: 312 [81980/25046 (10%)]\tLoss: 0.058089\n",
            "Train epoch: 312 [161440/25046 (20%)]\tLoss: 0.046672\n",
            "Train epoch: 312 [244560/25046 (31%)]\tLoss: 0.057706\n",
            "Train epoch: 312 [338000/25046 (41%)]\tLoss: 0.091914\n",
            "Train epoch: 312 [414000/25046 (51%)]\tLoss: 0.051802\n",
            "Train epoch: 312 [486480/25046 (61%)]\tLoss: 0.081919\n",
            "Train epoch: 312 [563640/25046 (71%)]\tLoss: 0.062305\n",
            "Train epoch: 312 [659520/25046 (82%)]\tLoss: 0.050783\n",
            "Train epoch: 312 [728640/25046 (92%)]\tLoss: 0.042545\n",
            "Make prediction for 5010 samples...\n",
            "0.25254843 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 313 [0/25046 (0%)]\tLoss: 0.019031\n",
            "Train epoch: 313 [80540/25046 (10%)]\tLoss: 0.024979\n",
            "Train epoch: 313 [166920/25046 (20%)]\tLoss: 0.078790\n",
            "Train epoch: 313 [239520/25046 (31%)]\tLoss: 0.165081\n",
            "Train epoch: 313 [329360/25046 (41%)]\tLoss: 0.085997\n",
            "Train epoch: 313 [418300/25046 (51%)]\tLoss: 0.039380\n",
            "Train epoch: 313 [497040/25046 (61%)]\tLoss: 0.047248\n",
            "Train epoch: 313 [559440/25046 (71%)]\tLoss: 0.028503\n",
            "Train epoch: 313 [649600/25046 (82%)]\tLoss: 0.109405\n",
            "Train epoch: 313 [724140/25046 (92%)]\tLoss: 0.071367\n",
            "Make prediction for 5010 samples...\n",
            "0.26403388 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 314 [0/25046 (0%)]\tLoss: 0.034009\n",
            "Train epoch: 314 [82220/25046 (10%)]\tLoss: 0.020701\n",
            "Train epoch: 314 [163640/25046 (20%)]\tLoss: 0.046484\n",
            "Train epoch: 314 [249360/25046 (31%)]\tLoss: 0.026211\n",
            "Train epoch: 314 [333440/25046 (41%)]\tLoss: 0.057908\n",
            "Train epoch: 314 [418400/25046 (51%)]\tLoss: 0.038598\n",
            "Train epoch: 314 [484440/25046 (61%)]\tLoss: 0.191845\n",
            "Train epoch: 314 [562240/25046 (71%)]\tLoss: 0.042117\n",
            "Train epoch: 314 [646080/25046 (82%)]\tLoss: 0.038723\n",
            "Train epoch: 314 [737640/25046 (92%)]\tLoss: 0.044616\n",
            "Make prediction for 5010 samples...\n",
            "0.27652386 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 315 [0/25046 (0%)]\tLoss: 0.052997\n",
            "Train epoch: 315 [82480/25046 (10%)]\tLoss: 0.041147\n",
            "Train epoch: 315 [160600/25046 (20%)]\tLoss: 0.079839\n",
            "Train epoch: 315 [245520/25046 (31%)]\tLoss: 0.057426\n",
            "Train epoch: 315 [325040/25046 (41%)]\tLoss: 0.075712\n",
            "Train epoch: 315 [414500/25046 (51%)]\tLoss: 0.064434\n",
            "Train epoch: 315 [494640/25046 (61%)]\tLoss: 0.058287\n",
            "Train epoch: 315 [568960/25046 (71%)]\tLoss: 0.066753\n",
            "Train epoch: 315 [658880/25046 (82%)]\tLoss: 0.061587\n",
            "Train epoch: 315 [746100/25046 (92%)]\tLoss: 0.025832\n",
            "Make prediction for 5010 samples...\n",
            "0.25935498 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 316 [0/25046 (0%)]\tLoss: 0.059740\n",
            "Train epoch: 316 [84620/25046 (10%)]\tLoss: 0.025341\n",
            "Train epoch: 316 [163760/25046 (20%)]\tLoss: 0.050745\n",
            "Train epoch: 316 [248340/25046 (31%)]\tLoss: 0.085843\n",
            "Train epoch: 316 [325680/25046 (41%)]\tLoss: 0.047488\n",
            "Train epoch: 316 [402600/25046 (51%)]\tLoss: 0.031847\n",
            "Train epoch: 316 [493680/25046 (61%)]\tLoss: 0.034279\n",
            "Train epoch: 316 [578760/25046 (71%)]\tLoss: 0.056115\n",
            "Train epoch: 316 [658720/25046 (82%)]\tLoss: 0.036749\n",
            "Train epoch: 316 [737820/25046 (92%)]\tLoss: 0.074431\n",
            "Make prediction for 5010 samples...\n",
            "0.27166387 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 317 [0/25046 (0%)]\tLoss: 0.095261\n",
            "Train epoch: 317 [85560/25046 (10%)]\tLoss: 0.081118\n",
            "Train epoch: 317 [171520/25046 (20%)]\tLoss: 0.057020\n",
            "Train epoch: 317 [238740/25046 (31%)]\tLoss: 0.057949\n",
            "Train epoch: 317 [329040/25046 (41%)]\tLoss: 0.102873\n",
            "Train epoch: 317 [400900/25046 (51%)]\tLoss: 0.055446\n",
            "Train epoch: 317 [489720/25046 (61%)]\tLoss: 0.070133\n",
            "Train epoch: 317 [571480/25046 (71%)]\tLoss: 0.064110\n",
            "Train epoch: 317 [659840/25046 (82%)]\tLoss: 0.032371\n",
            "Train epoch: 317 [721980/25046 (92%)]\tLoss: 0.143315\n",
            "Make prediction for 5010 samples...\n",
            "0.26061726 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 318 [0/25046 (0%)]\tLoss: 0.048380\n",
            "Train epoch: 318 [84800/25046 (10%)]\tLoss: 0.031799\n",
            "Train epoch: 318 [164720/25046 (20%)]\tLoss: 0.083437\n",
            "Train epoch: 318 [247440/25046 (31%)]\tLoss: 0.064555\n",
            "Train epoch: 318 [322880/25046 (41%)]\tLoss: 0.043087\n",
            "Train epoch: 318 [412300/25046 (51%)]\tLoss: 0.065111\n",
            "Train epoch: 318 [481320/25046 (61%)]\tLoss: 0.074316\n",
            "Train epoch: 318 [577500/25046 (71%)]\tLoss: 0.068988\n",
            "Train epoch: 318 [640800/25046 (82%)]\tLoss: 0.032875\n",
            "Train epoch: 318 [730440/25046 (92%)]\tLoss: 0.052816\n",
            "Make prediction for 5010 samples...\n",
            "0.25692394 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 319 [0/25046 (0%)]\tLoss: 0.070148\n",
            "Train epoch: 319 [85000/25046 (10%)]\tLoss: 0.042933\n",
            "Train epoch: 319 [162120/25046 (20%)]\tLoss: 0.059713\n",
            "Train epoch: 319 [248880/25046 (31%)]\tLoss: 0.044267\n",
            "Train epoch: 319 [329920/25046 (41%)]\tLoss: 0.039913\n",
            "Train epoch: 319 [401100/25046 (51%)]\tLoss: 0.081846\n",
            "Train epoch: 319 [501360/25046 (61%)]\tLoss: 0.082875\n",
            "Train epoch: 319 [566580/25046 (71%)]\tLoss: 0.072708\n",
            "Train epoch: 319 [648320/25046 (82%)]\tLoss: 0.081187\n",
            "Train epoch: 319 [738900/25046 (92%)]\tLoss: 0.056875\n",
            "Make prediction for 5010 samples...\n",
            "0.26011175 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 320 [0/25046 (0%)]\tLoss: 0.039362\n",
            "Train epoch: 320 [83400/25046 (10%)]\tLoss: 0.071435\n",
            "Train epoch: 320 [162720/25046 (20%)]\tLoss: 0.056168\n",
            "Train epoch: 320 [244740/25046 (31%)]\tLoss: 0.029739\n",
            "Train epoch: 320 [339520/25046 (41%)]\tLoss: 0.040699\n",
            "Train epoch: 320 [403500/25046 (51%)]\tLoss: 0.094479\n",
            "Train epoch: 320 [487920/25046 (61%)]\tLoss: 0.032457\n",
            "Train epoch: 320 [582120/25046 (71%)]\tLoss: 0.053180\n",
            "Train epoch: 320 [676000/25046 (82%)]\tLoss: 0.041869\n",
            "Train epoch: 320 [726840/25046 (92%)]\tLoss: 0.035438\n",
            "Make prediction for 5010 samples...\n",
            "0.2645253 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 321 [0/25046 (0%)]\tLoss: 0.044889\n",
            "Train epoch: 321 [80240/25046 (10%)]\tLoss: 0.058126\n",
            "Train epoch: 321 [161320/25046 (20%)]\tLoss: 0.057283\n",
            "Train epoch: 321 [241560/25046 (31%)]\tLoss: 0.057917\n",
            "Train epoch: 321 [337120/25046 (41%)]\tLoss: 0.065219\n",
            "Train epoch: 321 [409500/25046 (51%)]\tLoss: 0.076323\n",
            "Train epoch: 321 [478920/25046 (61%)]\tLoss: 0.094141\n",
            "Train epoch: 321 [564060/25046 (71%)]\tLoss: 0.063785\n",
            "Train epoch: 321 [648640/25046 (82%)]\tLoss: 0.023372\n",
            "Train epoch: 321 [741600/25046 (92%)]\tLoss: 0.035388\n",
            "Make prediction for 5010 samples...\n",
            "0.26705393 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 322 [0/25046 (0%)]\tLoss: 0.064866\n",
            "Train epoch: 322 [81860/25046 (10%)]\tLoss: 0.057230\n",
            "Train epoch: 322 [163720/25046 (20%)]\tLoss: 0.080938\n",
            "Train epoch: 322 [244320/25046 (31%)]\tLoss: 0.049939\n",
            "Train epoch: 322 [319840/25046 (41%)]\tLoss: 0.063667\n",
            "Train epoch: 322 [404700/25046 (51%)]\tLoss: 0.043276\n",
            "Train epoch: 322 [496080/25046 (61%)]\tLoss: 0.049162\n",
            "Train epoch: 322 [572880/25046 (71%)]\tLoss: 0.081003\n",
            "Train epoch: 322 [660160/25046 (82%)]\tLoss: 0.054603\n",
            "Train epoch: 322 [727200/25046 (92%)]\tLoss: 0.061623\n",
            "Make prediction for 5010 samples...\n",
            "0.25702405 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 323 [0/25046 (0%)]\tLoss: 0.045550\n",
            "Train epoch: 323 [81360/25046 (10%)]\tLoss: 0.069929\n",
            "Train epoch: 323 [163840/25046 (20%)]\tLoss: 0.113607\n",
            "Train epoch: 323 [243780/25046 (31%)]\tLoss: 0.066501\n",
            "Train epoch: 323 [314640/25046 (41%)]\tLoss: 0.081740\n",
            "Train epoch: 323 [413600/25046 (51%)]\tLoss: 0.059062\n",
            "Train epoch: 323 [493680/25046 (61%)]\tLoss: 0.075226\n",
            "Train epoch: 323 [574420/25046 (71%)]\tLoss: 0.106406\n",
            "Train epoch: 323 [648320/25046 (82%)]\tLoss: 0.061722\n",
            "Train epoch: 323 [713520/25046 (92%)]\tLoss: 0.105345\n",
            "Make prediction for 5010 samples...\n",
            "0.2689173 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 324 [0/25046 (0%)]\tLoss: 0.079122\n",
            "Train epoch: 324 [83140/25046 (10%)]\tLoss: 0.041211\n",
            "Train epoch: 324 [163800/25046 (20%)]\tLoss: 0.042875\n",
            "Train epoch: 324 [248460/25046 (31%)]\tLoss: 0.068740\n",
            "Train epoch: 324 [324240/25046 (41%)]\tLoss: 0.067781\n",
            "Train epoch: 324 [401400/25046 (51%)]\tLoss: 0.030123\n",
            "Train epoch: 324 [489360/25046 (61%)]\tLoss: 0.050683\n",
            "Train epoch: 324 [587440/25046 (71%)]\tLoss: 0.052350\n",
            "Train epoch: 324 [641760/25046 (82%)]\tLoss: 0.080274\n",
            "Train epoch: 324 [738000/25046 (92%)]\tLoss: 0.060637\n",
            "Make prediction for 5010 samples...\n",
            "0.25356573 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 325 [0/25046 (0%)]\tLoss: 0.044154\n",
            "Train epoch: 325 [83300/25046 (10%)]\tLoss: 0.061898\n",
            "Train epoch: 325 [159200/25046 (20%)]\tLoss: 0.038088\n",
            "Train epoch: 325 [239580/25046 (31%)]\tLoss: 0.106034\n",
            "Train epoch: 325 [333360/25046 (41%)]\tLoss: 0.026097\n",
            "Train epoch: 325 [401900/25046 (51%)]\tLoss: 0.039334\n",
            "Train epoch: 325 [488280/25046 (61%)]\tLoss: 0.089829\n",
            "Train epoch: 325 [576380/25046 (71%)]\tLoss: 0.103693\n",
            "Train epoch: 325 [649760/25046 (82%)]\tLoss: 0.090945\n",
            "Train epoch: 325 [735300/25046 (92%)]\tLoss: 0.105278\n",
            "Make prediction for 5010 samples...\n",
            "0.2552357 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 326 [0/25046 (0%)]\tLoss: 0.060231\n",
            "Train epoch: 326 [82300/25046 (10%)]\tLoss: 0.044816\n",
            "Train epoch: 326 [160600/25046 (20%)]\tLoss: 0.040576\n",
            "Train epoch: 326 [240780/25046 (31%)]\tLoss: 0.042404\n",
            "Train epoch: 326 [321280/25046 (41%)]\tLoss: 0.040108\n",
            "Train epoch: 326 [418000/25046 (51%)]\tLoss: 0.062908\n",
            "Train epoch: 326 [490560/25046 (61%)]\tLoss: 0.081981\n",
            "Train epoch: 326 [580580/25046 (71%)]\tLoss: 0.032733\n",
            "Train epoch: 326 [650560/25046 (82%)]\tLoss: 0.097913\n",
            "Train epoch: 326 [743400/25046 (92%)]\tLoss: 0.055548\n",
            "Make prediction for 5010 samples...\n",
            "0.26206112 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 327 [0/25046 (0%)]\tLoss: 0.034413\n",
            "Train epoch: 327 [80760/25046 (10%)]\tLoss: 0.054421\n",
            "Train epoch: 327 [162920/25046 (20%)]\tLoss: 0.094764\n",
            "Train epoch: 327 [246300/25046 (31%)]\tLoss: 0.055862\n",
            "Train epoch: 327 [329760/25046 (41%)]\tLoss: 0.033463\n",
            "Train epoch: 327 [405100/25046 (51%)]\tLoss: 0.051095\n",
            "Train epoch: 327 [486000/25046 (61%)]\tLoss: 0.130929\n",
            "Train epoch: 327 [590520/25046 (71%)]\tLoss: 0.057180\n",
            "Train epoch: 327 [650880/25046 (82%)]\tLoss: 0.134089\n",
            "Train epoch: 327 [743580/25046 (92%)]\tLoss: 0.055777\n",
            "Make prediction for 5010 samples...\n",
            "0.26095483 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 328 [0/25046 (0%)]\tLoss: 0.050969\n",
            "Train epoch: 328 [83660/25046 (10%)]\tLoss: 0.039684\n",
            "Train epoch: 328 [159840/25046 (20%)]\tLoss: 0.075247\n",
            "Train epoch: 328 [245460/25046 (31%)]\tLoss: 0.055939\n",
            "Train epoch: 328 [322400/25046 (41%)]\tLoss: 0.079329\n",
            "Train epoch: 328 [411400/25046 (51%)]\tLoss: 0.046711\n",
            "Train epoch: 328 [512040/25046 (61%)]\tLoss: 0.044888\n",
            "Train epoch: 328 [568820/25046 (71%)]\tLoss: 0.025264\n",
            "Train epoch: 328 [646880/25046 (82%)]\tLoss: 0.037196\n",
            "Train epoch: 328 [725580/25046 (92%)]\tLoss: 0.040383\n",
            "Make prediction for 5010 samples...\n",
            "0.25870582 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 329 [0/25046 (0%)]\tLoss: 0.038421\n",
            "Train epoch: 329 [81440/25046 (10%)]\tLoss: 0.046646\n",
            "Train epoch: 329 [172320/25046 (20%)]\tLoss: 0.066532\n",
            "Train epoch: 329 [247260/25046 (31%)]\tLoss: 0.088983\n",
            "Train epoch: 329 [331440/25046 (41%)]\tLoss: 0.031913\n",
            "Train epoch: 329 [400400/25046 (51%)]\tLoss: 0.062829\n",
            "Train epoch: 329 [503760/25046 (61%)]\tLoss: 0.087075\n",
            "Train epoch: 329 [570360/25046 (71%)]\tLoss: 0.034245\n",
            "Train epoch: 329 [658560/25046 (82%)]\tLoss: 0.025984\n",
            "Train epoch: 329 [727200/25046 (92%)]\tLoss: 0.069954\n",
            "Make prediction for 5010 samples...\n",
            "0.25134477 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 330 [0/25046 (0%)]\tLoss: 0.040749\n",
            "Train epoch: 330 [82940/25046 (10%)]\tLoss: 0.035271\n",
            "Train epoch: 330 [167800/25046 (20%)]\tLoss: 0.181675\n",
            "Train epoch: 330 [246660/25046 (31%)]\tLoss: 0.103567\n",
            "Train epoch: 330 [323760/25046 (41%)]\tLoss: 0.049070\n",
            "Train epoch: 330 [423200/25046 (51%)]\tLoss: 0.033788\n",
            "Train epoch: 330 [489120/25046 (61%)]\tLoss: 0.100428\n",
            "Train epoch: 330 [586880/25046 (71%)]\tLoss: 0.065150\n",
            "Train epoch: 330 [664800/25046 (82%)]\tLoss: 0.054133\n",
            "Train epoch: 330 [739080/25046 (92%)]\tLoss: 0.082501\n",
            "Make prediction for 5010 samples...\n",
            "0.2695396 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 331 [0/25046 (0%)]\tLoss: 0.076725\n",
            "Train epoch: 331 [81860/25046 (10%)]\tLoss: 0.043148\n",
            "Train epoch: 331 [161040/25046 (20%)]\tLoss: 0.056914\n",
            "Train epoch: 331 [247260/25046 (31%)]\tLoss: 0.100536\n",
            "Train epoch: 331 [322320/25046 (41%)]\tLoss: 0.050182\n",
            "Train epoch: 331 [414000/25046 (51%)]\tLoss: 0.032890\n",
            "Train epoch: 331 [475920/25046 (61%)]\tLoss: 0.024413\n",
            "Train epoch: 331 [575260/25046 (71%)]\tLoss: 0.036827\n",
            "Train epoch: 331 [661600/25046 (82%)]\tLoss: 0.031649\n",
            "Train epoch: 331 [756900/25046 (92%)]\tLoss: 0.148813\n",
            "Make prediction for 5010 samples...\n",
            "0.2676277 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 332 [0/25046 (0%)]\tLoss: 0.041576\n",
            "Train epoch: 332 [80280/25046 (10%)]\tLoss: 0.034084\n",
            "Train epoch: 332 [164680/25046 (20%)]\tLoss: 0.027698\n",
            "Train epoch: 332 [237060/25046 (31%)]\tLoss: 0.069638\n",
            "Train epoch: 332 [330000/25046 (41%)]\tLoss: 0.053373\n",
            "Train epoch: 332 [414100/25046 (51%)]\tLoss: 0.030989\n",
            "Train epoch: 332 [498240/25046 (61%)]\tLoss: 0.051030\n",
            "Train epoch: 332 [584640/25046 (71%)]\tLoss: 0.049227\n",
            "Train epoch: 332 [667200/25046 (82%)]\tLoss: 0.053943\n",
            "Train epoch: 332 [736380/25046 (92%)]\tLoss: 0.044712\n",
            "Make prediction for 5010 samples...\n",
            "0.25716564 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 333 [0/25046 (0%)]\tLoss: 0.059293\n",
            "Train epoch: 333 [81280/25046 (10%)]\tLoss: 0.088629\n",
            "Train epoch: 333 [160720/25046 (20%)]\tLoss: 0.086075\n",
            "Train epoch: 333 [246600/25046 (31%)]\tLoss: 0.037293\n",
            "Train epoch: 333 [322080/25046 (41%)]\tLoss: 0.080656\n",
            "Train epoch: 333 [406800/25046 (51%)]\tLoss: 0.034049\n",
            "Train epoch: 333 [489240/25046 (61%)]\tLoss: 0.054238\n",
            "Train epoch: 333 [566300/25046 (71%)]\tLoss: 0.028639\n",
            "Train epoch: 333 [649440/25046 (82%)]\tLoss: 0.069888\n",
            "Train epoch: 333 [729360/25046 (92%)]\tLoss: 0.048468\n",
            "Make prediction for 5010 samples...\n",
            "0.2571833 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 334 [0/25046 (0%)]\tLoss: 0.037065\n",
            "Train epoch: 334 [82220/25046 (10%)]\tLoss: 0.031346\n",
            "Train epoch: 334 [158080/25046 (20%)]\tLoss: 0.026039\n",
            "Train epoch: 334 [245640/25046 (31%)]\tLoss: 0.037364\n",
            "Train epoch: 334 [328400/25046 (41%)]\tLoss: 0.037074\n",
            "Train epoch: 334 [407900/25046 (51%)]\tLoss: 0.094606\n",
            "Train epoch: 334 [495120/25046 (61%)]\tLoss: 0.033740\n",
            "Train epoch: 334 [583240/25046 (71%)]\tLoss: 0.085969\n",
            "Train epoch: 334 [667680/25046 (82%)]\tLoss: 0.049716\n",
            "Train epoch: 334 [755100/25046 (92%)]\tLoss: 0.077522\n",
            "Make prediction for 5010 samples...\n",
            "0.25459877 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 335 [0/25046 (0%)]\tLoss: 0.050575\n",
            "Train epoch: 335 [81800/25046 (10%)]\tLoss: 0.045161\n",
            "Train epoch: 335 [164120/25046 (20%)]\tLoss: 0.037923\n",
            "Train epoch: 335 [245220/25046 (31%)]\tLoss: 0.064111\n",
            "Train epoch: 335 [327680/25046 (41%)]\tLoss: 0.091307\n",
            "Train epoch: 335 [408500/25046 (51%)]\tLoss: 0.079522\n",
            "Train epoch: 335 [494160/25046 (61%)]\tLoss: 0.071607\n",
            "Train epoch: 335 [583520/25046 (71%)]\tLoss: 0.038737\n",
            "Train epoch: 335 [648480/25046 (82%)]\tLoss: 0.049284\n",
            "Train epoch: 335 [737280/25046 (92%)]\tLoss: 0.146281\n",
            "Make prediction for 5010 samples...\n",
            "0.25985864 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 336 [0/25046 (0%)]\tLoss: 0.066719\n",
            "Train epoch: 336 [79980/25046 (10%)]\tLoss: 0.064549\n",
            "Train epoch: 336 [161080/25046 (20%)]\tLoss: 0.085279\n",
            "Train epoch: 336 [245820/25046 (31%)]\tLoss: 0.097229\n",
            "Train epoch: 336 [336080/25046 (41%)]\tLoss: 0.034820\n",
            "Train epoch: 336 [403600/25046 (51%)]\tLoss: 0.035605\n",
            "Train epoch: 336 [474720/25046 (61%)]\tLoss: 0.037139\n",
            "Train epoch: 336 [574420/25046 (71%)]\tLoss: 0.057538\n",
            "Train epoch: 336 [633440/25046 (82%)]\tLoss: 0.035814\n",
            "Train epoch: 336 [731160/25046 (92%)]\tLoss: 0.047407\n",
            "Make prediction for 5010 samples...\n",
            "0.2637976 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 337 [0/25046 (0%)]\tLoss: 0.066574\n",
            "Train epoch: 337 [79900/25046 (10%)]\tLoss: 0.042657\n",
            "Train epoch: 337 [163520/25046 (20%)]\tLoss: 0.031977\n",
            "Train epoch: 337 [239700/25046 (31%)]\tLoss: 0.046103\n",
            "Train epoch: 337 [331520/25046 (41%)]\tLoss: 0.042916\n",
            "Train epoch: 337 [415700/25046 (51%)]\tLoss: 0.066759\n",
            "Train epoch: 337 [486720/25046 (61%)]\tLoss: 0.100642\n",
            "Train epoch: 337 [567420/25046 (71%)]\tLoss: 0.105177\n",
            "Train epoch: 337 [666400/25046 (82%)]\tLoss: 0.088331\n",
            "Train epoch: 337 [720360/25046 (92%)]\tLoss: 0.056868\n",
            "Make prediction for 5010 samples...\n",
            "0.26447704 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 338 [0/25046 (0%)]\tLoss: 0.039608\n",
            "Train epoch: 338 [83020/25046 (10%)]\tLoss: 0.190912\n",
            "Train epoch: 338 [161920/25046 (20%)]\tLoss: 0.041429\n",
            "Train epoch: 338 [245280/25046 (31%)]\tLoss: 0.057106\n",
            "Train epoch: 338 [331040/25046 (41%)]\tLoss: 0.025204\n",
            "Train epoch: 338 [410700/25046 (51%)]\tLoss: 0.074059\n",
            "Train epoch: 338 [498120/25046 (61%)]\tLoss: 0.041167\n",
            "Train epoch: 338 [582820/25046 (71%)]\tLoss: 0.029112\n",
            "Train epoch: 338 [649600/25046 (82%)]\tLoss: 0.044156\n",
            "Train epoch: 338 [747720/25046 (92%)]\tLoss: 0.019863\n",
            "Make prediction for 5010 samples...\n",
            "0.25522003 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 339 [0/25046 (0%)]\tLoss: 0.025537\n",
            "Train epoch: 339 [80000/25046 (10%)]\tLoss: 0.034066\n",
            "Train epoch: 339 [167440/25046 (20%)]\tLoss: 0.042993\n",
            "Train epoch: 339 [249120/25046 (31%)]\tLoss: 0.036431\n",
            "Train epoch: 339 [333280/25046 (41%)]\tLoss: 0.031456\n",
            "Train epoch: 339 [405000/25046 (51%)]\tLoss: 0.032135\n",
            "Train epoch: 339 [492720/25046 (61%)]\tLoss: 0.087539\n",
            "Train epoch: 339 [563220/25046 (71%)]\tLoss: 0.046288\n",
            "Train epoch: 339 [661440/25046 (82%)]\tLoss: 0.042359\n",
            "Train epoch: 339 [731880/25046 (92%)]\tLoss: 0.053958\n",
            "Make prediction for 5010 samples...\n",
            "0.27096164 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 340 [0/25046 (0%)]\tLoss: 0.072197\n",
            "Train epoch: 340 [83780/25046 (10%)]\tLoss: 0.129415\n",
            "Train epoch: 340 [158880/25046 (20%)]\tLoss: 0.070311\n",
            "Train epoch: 340 [250680/25046 (31%)]\tLoss: 0.049308\n",
            "Train epoch: 340 [322000/25046 (41%)]\tLoss: 0.026931\n",
            "Train epoch: 340 [406600/25046 (51%)]\tLoss: 0.092085\n",
            "Train epoch: 340 [478080/25046 (61%)]\tLoss: 0.031122\n",
            "Train epoch: 340 [580440/25046 (71%)]\tLoss: 0.058493\n",
            "Train epoch: 340 [652960/25046 (82%)]\tLoss: 0.035279\n",
            "Train epoch: 340 [748260/25046 (92%)]\tLoss: 0.058235\n",
            "Make prediction for 5010 samples...\n",
            "0.25553206 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 341 [0/25046 (0%)]\tLoss: 0.052266\n",
            "Train epoch: 341 [79980/25046 (10%)]\tLoss: 0.074762\n",
            "Train epoch: 341 [167600/25046 (20%)]\tLoss: 0.024498\n",
            "Train epoch: 341 [243120/25046 (31%)]\tLoss: 0.031220\n",
            "Train epoch: 341 [319120/25046 (41%)]\tLoss: 0.056189\n",
            "Train epoch: 341 [412500/25046 (51%)]\tLoss: 0.041523\n",
            "Train epoch: 341 [507600/25046 (61%)]\tLoss: 0.115184\n",
            "Train epoch: 341 [561680/25046 (71%)]\tLoss: 0.056955\n",
            "Train epoch: 341 [644640/25046 (82%)]\tLoss: 0.055289\n",
            "Train epoch: 341 [744300/25046 (92%)]\tLoss: 0.045248\n",
            "Make prediction for 5010 samples...\n",
            "0.26054898 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 342 [0/25046 (0%)]\tLoss: 0.062895\n",
            "Train epoch: 342 [80000/25046 (10%)]\tLoss: 0.041159\n",
            "Train epoch: 342 [165360/25046 (20%)]\tLoss: 0.027023\n",
            "Train epoch: 342 [247500/25046 (31%)]\tLoss: 0.032285\n",
            "Train epoch: 342 [324720/25046 (41%)]\tLoss: 0.066970\n",
            "Train epoch: 342 [416300/25046 (51%)]\tLoss: 0.047435\n",
            "Train epoch: 342 [486000/25046 (61%)]\tLoss: 0.116479\n",
            "Train epoch: 342 [572180/25046 (71%)]\tLoss: 0.051773\n",
            "Train epoch: 342 [649120/25046 (82%)]\tLoss: 0.078448\n",
            "Train epoch: 342 [732960/25046 (92%)]\tLoss: 0.098995\n",
            "Make prediction for 5010 samples...\n",
            "0.25547642 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 343 [0/25046 (0%)]\tLoss: 0.028982\n",
            "Train epoch: 343 [81120/25046 (10%)]\tLoss: 0.091004\n",
            "Train epoch: 343 [163320/25046 (20%)]\tLoss: 0.030792\n",
            "Train epoch: 343 [236760/25046 (31%)]\tLoss: 0.073077\n",
            "Train epoch: 343 [337920/25046 (41%)]\tLoss: 0.032289\n",
            "Train epoch: 343 [412800/25046 (51%)]\tLoss: 0.097424\n",
            "Train epoch: 343 [484680/25046 (61%)]\tLoss: 0.052032\n",
            "Train epoch: 343 [577360/25046 (71%)]\tLoss: 0.043626\n",
            "Train epoch: 343 [650080/25046 (82%)]\tLoss: 0.051694\n",
            "Train epoch: 343 [738000/25046 (92%)]\tLoss: 0.064432\n",
            "Make prediction for 5010 samples...\n",
            "0.27328426 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 344 [0/25046 (0%)]\tLoss: 0.052460\n",
            "Train epoch: 344 [84340/25046 (10%)]\tLoss: 0.096192\n",
            "Train epoch: 344 [168400/25046 (20%)]\tLoss: 0.084021\n",
            "Train epoch: 344 [248400/25046 (31%)]\tLoss: 0.062310\n",
            "Train epoch: 344 [323680/25046 (41%)]\tLoss: 0.064261\n",
            "Train epoch: 344 [415000/25046 (51%)]\tLoss: 0.026294\n",
            "Train epoch: 344 [490800/25046 (61%)]\tLoss: 0.058947\n",
            "Train epoch: 344 [564200/25046 (71%)]\tLoss: 0.046768\n",
            "Train epoch: 344 [654080/25046 (82%)]\tLoss: 0.074923\n",
            "Train epoch: 344 [745920/25046 (92%)]\tLoss: 0.023088\n",
            "Make prediction for 5010 samples...\n",
            "0.25256348 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 345 [0/25046 (0%)]\tLoss: 0.044105\n",
            "Train epoch: 345 [82360/25046 (10%)]\tLoss: 0.037953\n",
            "Train epoch: 345 [167040/25046 (20%)]\tLoss: 0.040418\n",
            "Train epoch: 345 [248520/25046 (31%)]\tLoss: 0.041414\n",
            "Train epoch: 345 [336160/25046 (41%)]\tLoss: 0.046570\n",
            "Train epoch: 345 [416100/25046 (51%)]\tLoss: 0.059409\n",
            "Train epoch: 345 [488520/25046 (61%)]\tLoss: 0.039437\n",
            "Train epoch: 345 [543760/25046 (71%)]\tLoss: 0.030486\n",
            "Train epoch: 345 [658560/25046 (82%)]\tLoss: 0.044867\n",
            "Train epoch: 345 [740880/25046 (92%)]\tLoss: 0.046311\n",
            "Make prediction for 5010 samples...\n",
            "0.25556484 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 346 [0/25046 (0%)]\tLoss: 0.046704\n",
            "Train epoch: 346 [82560/25046 (10%)]\tLoss: 0.046681\n",
            "Train epoch: 346 [167800/25046 (20%)]\tLoss: 0.092176\n",
            "Train epoch: 346 [248220/25046 (31%)]\tLoss: 0.083103\n",
            "Train epoch: 346 [323920/25046 (41%)]\tLoss: 0.042223\n",
            "Train epoch: 346 [416300/25046 (51%)]\tLoss: 0.124799\n",
            "Train epoch: 346 [482400/25046 (61%)]\tLoss: 0.062058\n",
            "Train epoch: 346 [564480/25046 (71%)]\tLoss: 0.049185\n",
            "Train epoch: 346 [660320/25046 (82%)]\tLoss: 0.041350\n",
            "Train epoch: 346 [741240/25046 (92%)]\tLoss: 0.056885\n",
            "Make prediction for 5010 samples...\n",
            "0.26091173 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 347 [0/25046 (0%)]\tLoss: 0.039771\n",
            "Train epoch: 347 [82940/25046 (10%)]\tLoss: 0.093635\n",
            "Train epoch: 347 [159480/25046 (20%)]\tLoss: 0.039575\n",
            "Train epoch: 347 [245700/25046 (31%)]\tLoss: 0.048375\n",
            "Train epoch: 347 [335120/25046 (41%)]\tLoss: 0.049238\n",
            "Train epoch: 347 [416000/25046 (51%)]\tLoss: 0.079702\n",
            "Train epoch: 347 [486000/25046 (61%)]\tLoss: 0.031507\n",
            "Train epoch: 347 [577640/25046 (71%)]\tLoss: 0.082596\n",
            "Train epoch: 347 [664800/25046 (82%)]\tLoss: 0.042818\n",
            "Train epoch: 347 [727740/25046 (92%)]\tLoss: 0.044079\n",
            "Make prediction for 5010 samples...\n",
            "0.25489557 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 348 [0/25046 (0%)]\tLoss: 0.051416\n",
            "Train epoch: 348 [80960/25046 (10%)]\tLoss: 0.034825\n",
            "Train epoch: 348 [159640/25046 (20%)]\tLoss: 0.114609\n",
            "Train epoch: 348 [249600/25046 (31%)]\tLoss: 0.047353\n",
            "Train epoch: 348 [328480/25046 (41%)]\tLoss: 0.062808\n",
            "Train epoch: 348 [413600/25046 (51%)]\tLoss: 0.075560\n",
            "Train epoch: 348 [499560/25046 (61%)]\tLoss: 0.071930\n",
            "Train epoch: 348 [564200/25046 (71%)]\tLoss: 0.043845\n",
            "Train epoch: 348 [645120/25046 (82%)]\tLoss: 0.060358\n",
            "Train epoch: 348 [742500/25046 (92%)]\tLoss: 0.042704\n",
            "Make prediction for 5010 samples...\n",
            "0.25921667 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 349 [0/25046 (0%)]\tLoss: 0.045968\n",
            "Train epoch: 349 [82020/25046 (10%)]\tLoss: 0.026162\n",
            "Train epoch: 349 [162120/25046 (20%)]\tLoss: 0.053733\n",
            "Train epoch: 349 [241980/25046 (31%)]\tLoss: 0.116022\n",
            "Train epoch: 349 [332160/25046 (41%)]\tLoss: 0.061887\n",
            "Train epoch: 349 [412100/25046 (51%)]\tLoss: 0.107010\n",
            "Train epoch: 349 [486240/25046 (61%)]\tLoss: 0.054474\n",
            "Train epoch: 349 [563920/25046 (71%)]\tLoss: 0.035907\n",
            "Train epoch: 349 [662560/25046 (82%)]\tLoss: 0.050316\n",
            "Train epoch: 349 [728820/25046 (92%)]\tLoss: 0.056313\n",
            "Make prediction for 5010 samples...\n",
            "0.2641179 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 350 [0/25046 (0%)]\tLoss: 0.046592\n",
            "Train epoch: 350 [81360/25046 (10%)]\tLoss: 0.070862\n",
            "Train epoch: 350 [158520/25046 (20%)]\tLoss: 0.039383\n",
            "Train epoch: 350 [246840/25046 (31%)]\tLoss: 0.037777\n",
            "Train epoch: 350 [328960/25046 (41%)]\tLoss: 0.051766\n",
            "Train epoch: 350 [403100/25046 (51%)]\tLoss: 0.036893\n",
            "Train epoch: 350 [497400/25046 (61%)]\tLoss: 0.041831\n",
            "Train epoch: 350 [571060/25046 (71%)]\tLoss: 0.057910\n",
            "Train epoch: 350 [648160/25046 (82%)]\tLoss: 0.080413\n",
            "Train epoch: 350 [741420/25046 (92%)]\tLoss: 0.046324\n",
            "Make prediction for 5010 samples...\n",
            "0.2670373 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 351 [0/25046 (0%)]\tLoss: 0.044959\n",
            "Train epoch: 351 [83820/25046 (10%)]\tLoss: 0.071407\n",
            "Train epoch: 351 [165080/25046 (20%)]\tLoss: 0.050029\n",
            "Train epoch: 351 [250260/25046 (31%)]\tLoss: 0.058038\n",
            "Train epoch: 351 [330480/25046 (41%)]\tLoss: 0.089075\n",
            "Train epoch: 351 [408500/25046 (51%)]\tLoss: 0.049264\n",
            "Train epoch: 351 [490080/25046 (61%)]\tLoss: 0.037119\n",
            "Train epoch: 351 [576100/25046 (71%)]\tLoss: 0.075664\n",
            "Train epoch: 351 [640480/25046 (82%)]\tLoss: 0.071313\n",
            "Train epoch: 351 [730080/25046 (92%)]\tLoss: 0.133981\n",
            "Make prediction for 5010 samples...\n",
            "0.25135267 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 352 [0/25046 (0%)]\tLoss: 0.035519\n",
            "Train epoch: 352 [81000/25046 (10%)]\tLoss: 0.060638\n",
            "Train epoch: 352 [163200/25046 (20%)]\tLoss: 0.105862\n",
            "Train epoch: 352 [245400/25046 (31%)]\tLoss: 0.050136\n",
            "Train epoch: 352 [329200/25046 (41%)]\tLoss: 0.038370\n",
            "Train epoch: 352 [418600/25046 (51%)]\tLoss: 0.050409\n",
            "Train epoch: 352 [488880/25046 (61%)]\tLoss: 0.047840\n",
            "Train epoch: 352 [596820/25046 (71%)]\tLoss: 0.069294\n",
            "Train epoch: 352 [643360/25046 (82%)]\tLoss: 0.036234\n",
            "Train epoch: 352 [718020/25046 (92%)]\tLoss: 0.055900\n",
            "Make prediction for 5010 samples...\n",
            "0.26061973 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 353 [0/25046 (0%)]\tLoss: 0.036827\n",
            "Train epoch: 353 [81940/25046 (10%)]\tLoss: 0.048159\n",
            "Train epoch: 353 [164840/25046 (20%)]\tLoss: 0.053808\n",
            "Train epoch: 353 [244260/25046 (31%)]\tLoss: 0.050720\n",
            "Train epoch: 353 [336000/25046 (41%)]\tLoss: 0.044096\n",
            "Train epoch: 353 [418900/25046 (51%)]\tLoss: 0.041915\n",
            "Train epoch: 353 [495360/25046 (61%)]\tLoss: 0.077435\n",
            "Train epoch: 353 [560560/25046 (71%)]\tLoss: 0.050920\n",
            "Train epoch: 353 [666880/25046 (82%)]\tLoss: 0.048582\n",
            "Train epoch: 353 [748980/25046 (92%)]\tLoss: 0.040025\n",
            "Make prediction for 5010 samples...\n",
            "0.25529552 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 354 [0/25046 (0%)]\tLoss: 0.077334\n",
            "Train epoch: 354 [84100/25046 (10%)]\tLoss: 0.044157\n",
            "Train epoch: 354 [159000/25046 (20%)]\tLoss: 0.029655\n",
            "Train epoch: 354 [240120/25046 (31%)]\tLoss: 0.052361\n",
            "Train epoch: 354 [334080/25046 (41%)]\tLoss: 0.079948\n",
            "Train epoch: 354 [410800/25046 (51%)]\tLoss: 0.053376\n",
            "Train epoch: 354 [489000/25046 (61%)]\tLoss: 0.034221\n",
            "Train epoch: 354 [579040/25046 (71%)]\tLoss: 0.125310\n",
            "Train epoch: 354 [657600/25046 (82%)]\tLoss: 0.066707\n",
            "Train epoch: 354 [764820/25046 (92%)]\tLoss: 0.065259\n",
            "Make prediction for 5010 samples...\n",
            "0.25870323 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 355 [0/25046 (0%)]\tLoss: 0.097159\n",
            "Train epoch: 355 [83340/25046 (10%)]\tLoss: 0.051444\n",
            "Train epoch: 355 [166640/25046 (20%)]\tLoss: 0.038163\n",
            "Train epoch: 355 [241740/25046 (31%)]\tLoss: 0.053115\n",
            "Train epoch: 355 [336880/25046 (41%)]\tLoss: 0.077666\n",
            "Train epoch: 355 [407900/25046 (51%)]\tLoss: 0.115765\n",
            "Train epoch: 355 [492720/25046 (61%)]\tLoss: 0.036512\n",
            "Train epoch: 355 [572880/25046 (71%)]\tLoss: 0.049271\n",
            "Train epoch: 355 [669120/25046 (82%)]\tLoss: 0.050580\n",
            "Train epoch: 355 [746100/25046 (92%)]\tLoss: 0.080494\n",
            "Make prediction for 5010 samples...\n",
            "0.25817096 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 356 [0/25046 (0%)]\tLoss: 0.051751\n",
            "Train epoch: 356 [82040/25046 (10%)]\tLoss: 0.029549\n",
            "Train epoch: 356 [164000/25046 (20%)]\tLoss: 0.031140\n",
            "Train epoch: 356 [250200/25046 (31%)]\tLoss: 0.103031\n",
            "Train epoch: 356 [333200/25046 (41%)]\tLoss: 0.047237\n",
            "Train epoch: 356 [420000/25046 (51%)]\tLoss: 0.047179\n",
            "Train epoch: 356 [497520/25046 (61%)]\tLoss: 0.085699\n",
            "Train epoch: 356 [574140/25046 (71%)]\tLoss: 0.092058\n",
            "Train epoch: 356 [658880/25046 (82%)]\tLoss: 0.061702\n",
            "Train epoch: 356 [741060/25046 (92%)]\tLoss: 0.163212\n",
            "Make prediction for 5010 samples...\n",
            "0.2534004 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 357 [0/25046 (0%)]\tLoss: 0.069222\n",
            "Train epoch: 357 [80820/25046 (10%)]\tLoss: 0.056798\n",
            "Train epoch: 357 [162400/25046 (20%)]\tLoss: 0.056497\n",
            "Train epoch: 357 [245100/25046 (31%)]\tLoss: 0.076118\n",
            "Train epoch: 357 [319520/25046 (41%)]\tLoss: 0.058686\n",
            "Train epoch: 357 [410100/25046 (51%)]\tLoss: 0.099144\n",
            "Train epoch: 357 [491760/25046 (61%)]\tLoss: 0.017173\n",
            "Train epoch: 357 [573440/25046 (71%)]\tLoss: 0.077663\n",
            "Train epoch: 357 [651040/25046 (82%)]\tLoss: 0.044676\n",
            "Train epoch: 357 [757260/25046 (92%)]\tLoss: 0.049173\n",
            "Make prediction for 5010 samples...\n",
            "0.25503227 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 358 [0/25046 (0%)]\tLoss: 0.074483\n",
            "Train epoch: 358 [81760/25046 (10%)]\tLoss: 0.163585\n",
            "Train epoch: 358 [162560/25046 (20%)]\tLoss: 0.027669\n",
            "Train epoch: 358 [243780/25046 (31%)]\tLoss: 0.027518\n",
            "Train epoch: 358 [323440/25046 (41%)]\tLoss: 0.085182\n",
            "Train epoch: 358 [412300/25046 (51%)]\tLoss: 0.076245\n",
            "Train epoch: 358 [488640/25046 (61%)]\tLoss: 0.141559\n",
            "Train epoch: 358 [578060/25046 (71%)]\tLoss: 0.047731\n",
            "Train epoch: 358 [652320/25046 (82%)]\tLoss: 0.045902\n",
            "Train epoch: 358 [747000/25046 (92%)]\tLoss: 0.016186\n",
            "Make prediction for 5010 samples...\n",
            "0.25903904 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 359 [0/25046 (0%)]\tLoss: 0.042388\n",
            "Train epoch: 359 [82660/25046 (10%)]\tLoss: 0.072492\n",
            "Train epoch: 359 [164640/25046 (20%)]\tLoss: 0.028334\n",
            "Train epoch: 359 [242640/25046 (31%)]\tLoss: 0.043493\n",
            "Train epoch: 359 [328080/25046 (41%)]\tLoss: 0.077516\n",
            "Train epoch: 359 [394200/25046 (51%)]\tLoss: 0.029672\n",
            "Train epoch: 359 [500040/25046 (61%)]\tLoss: 0.034884\n",
            "Train epoch: 359 [574420/25046 (71%)]\tLoss: 0.031811\n",
            "Train epoch: 359 [666560/25046 (82%)]\tLoss: 0.061129\n",
            "Train epoch: 359 [749880/25046 (92%)]\tLoss: 0.022448\n",
            "Make prediction for 5010 samples...\n",
            "0.2548791 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 360 [0/25046 (0%)]\tLoss: 0.107193\n",
            "Train epoch: 360 [81480/25046 (10%)]\tLoss: 0.039709\n",
            "Train epoch: 360 [162680/25046 (20%)]\tLoss: 0.041884\n",
            "Train epoch: 360 [244920/25046 (31%)]\tLoss: 0.038200\n",
            "Train epoch: 360 [334800/25046 (41%)]\tLoss: 0.053112\n",
            "Train epoch: 360 [408500/25046 (51%)]\tLoss: 0.064592\n",
            "Train epoch: 360 [491040/25046 (61%)]\tLoss: 0.063284\n",
            "Train epoch: 360 [572180/25046 (71%)]\tLoss: 0.023454\n",
            "Train epoch: 360 [642720/25046 (82%)]\tLoss: 0.029208\n",
            "Train epoch: 360 [718200/25046 (92%)]\tLoss: 0.020943\n",
            "Make prediction for 5010 samples...\n",
            "0.2643254 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 361 [0/25046 (0%)]\tLoss: 0.082057\n",
            "Train epoch: 361 [82740/25046 (10%)]\tLoss: 0.035334\n",
            "Train epoch: 361 [164960/25046 (20%)]\tLoss: 0.077727\n",
            "Train epoch: 361 [240960/25046 (31%)]\tLoss: 0.043966\n",
            "Train epoch: 361 [325040/25046 (41%)]\tLoss: 0.054534\n",
            "Train epoch: 361 [397400/25046 (51%)]\tLoss: 0.101490\n",
            "Train epoch: 361 [482160/25046 (61%)]\tLoss: 0.033183\n",
            "Train epoch: 361 [573160/25046 (71%)]\tLoss: 0.034107\n",
            "Train epoch: 361 [639840/25046 (82%)]\tLoss: 0.070632\n",
            "Train epoch: 361 [735120/25046 (92%)]\tLoss: 0.046663\n",
            "Make prediction for 5010 samples...\n",
            "0.26388 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 362 [0/25046 (0%)]\tLoss: 0.115598\n",
            "Train epoch: 362 [83980/25046 (10%)]\tLoss: 0.041971\n",
            "Train epoch: 362 [166280/25046 (20%)]\tLoss: 0.044939\n",
            "Train epoch: 362 [254100/25046 (31%)]\tLoss: 0.042449\n",
            "Train epoch: 362 [334880/25046 (41%)]\tLoss: 0.067877\n",
            "Train epoch: 362 [407100/25046 (51%)]\tLoss: 0.037172\n",
            "Train epoch: 362 [494640/25046 (61%)]\tLoss: 0.072857\n",
            "Train epoch: 362 [569940/25046 (71%)]\tLoss: 0.054576\n",
            "Train epoch: 362 [639520/25046 (82%)]\tLoss: 0.038845\n",
            "Train epoch: 362 [737820/25046 (92%)]\tLoss: 0.016067\n",
            "Make prediction for 5010 samples...\n",
            "0.25257516 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 363 [0/25046 (0%)]\tLoss: 0.066971\n",
            "Train epoch: 363 [83440/25046 (10%)]\tLoss: 0.049157\n",
            "Train epoch: 363 [164080/25046 (20%)]\tLoss: 0.035567\n",
            "Train epoch: 363 [244740/25046 (31%)]\tLoss: 0.046608\n",
            "Train epoch: 363 [337120/25046 (41%)]\tLoss: 0.075656\n",
            "Train epoch: 363 [409600/25046 (51%)]\tLoss: 0.078214\n",
            "Train epoch: 363 [499560/25046 (61%)]\tLoss: 0.100771\n",
            "Train epoch: 363 [568820/25046 (71%)]\tLoss: 0.040849\n",
            "Train epoch: 363 [652480/25046 (82%)]\tLoss: 0.053963\n",
            "Train epoch: 363 [739980/25046 (92%)]\tLoss: 0.073121\n",
            "Make prediction for 5010 samples...\n",
            "0.25945812 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 364 [0/25046 (0%)]\tLoss: 0.051251\n",
            "Train epoch: 364 [82740/25046 (10%)]\tLoss: 0.037537\n",
            "Train epoch: 364 [164480/25046 (20%)]\tLoss: 0.058423\n",
            "Train epoch: 364 [242760/25046 (31%)]\tLoss: 0.042661\n",
            "Train epoch: 364 [328480/25046 (41%)]\tLoss: 0.028264\n",
            "Train epoch: 364 [406200/25046 (51%)]\tLoss: 0.040912\n",
            "Train epoch: 364 [501480/25046 (61%)]\tLoss: 0.097280\n",
            "Train epoch: 364 [588560/25046 (71%)]\tLoss: 0.063735\n",
            "Train epoch: 364 [652320/25046 (82%)]\tLoss: 0.052476\n",
            "Train epoch: 364 [744300/25046 (92%)]\tLoss: 0.037277\n",
            "Make prediction for 5010 samples...\n",
            "0.2574877 No improvement since epoch  286 ; best_mse,best_ci: 0.2472185 0.8809575808496695 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 365 [0/25046 (0%)]\tLoss: 0.029045\n",
            "Train epoch: 365 [83040/25046 (10%)]\tLoss: 0.033425\n",
            "Train epoch: 365 [162440/25046 (20%)]\tLoss: 0.040393\n",
            "Train epoch: 365 [242640/25046 (31%)]\tLoss: 0.038319\n",
            "Train epoch: 365 [324880/25046 (41%)]\tLoss: 0.040764\n",
            "Train epoch: 365 [400200/25046 (51%)]\tLoss: 0.039489\n",
            "Train epoch: 365 [501600/25046 (61%)]\tLoss: 0.045683\n",
            "Train epoch: 365 [577220/25046 (71%)]\tLoss: 0.053635\n",
            "Train epoch: 365 [646080/25046 (82%)]\tLoss: 0.084224\n",
            "Train epoch: 365 [752760/25046 (92%)]\tLoss: 0.083546\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 366 [0/25046 (0%)]\tLoss: 0.047438\n",
            "Train epoch: 366 [83780/25046 (10%)]\tLoss: 0.046948\n",
            "Train epoch: 366 [160880/25046 (20%)]\tLoss: 0.083119\n",
            "Train epoch: 366 [248460/25046 (31%)]\tLoss: 0.071364\n",
            "Train epoch: 366 [338560/25046 (41%)]\tLoss: 0.044348\n",
            "Train epoch: 366 [419600/25046 (51%)]\tLoss: 0.053039\n",
            "Train epoch: 366 [481080/25046 (61%)]\tLoss: 0.042418\n",
            "Train epoch: 366 [573300/25046 (71%)]\tLoss: 0.054115\n",
            "Train epoch: 366 [651680/25046 (82%)]\tLoss: 0.033603\n",
            "Train epoch: 366 [725760/25046 (92%)]\tLoss: 0.050674\n",
            "Make prediction for 5010 samples...\n",
            "0.26404253 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 367 [0/25046 (0%)]\tLoss: 0.047549\n",
            "Train epoch: 367 [79800/25046 (10%)]\tLoss: 0.046783\n",
            "Train epoch: 367 [160320/25046 (20%)]\tLoss: 0.037353\n",
            "Train epoch: 367 [246060/25046 (31%)]\tLoss: 0.077146\n",
            "Train epoch: 367 [328480/25046 (41%)]\tLoss: 0.103334\n",
            "Train epoch: 367 [409600/25046 (51%)]\tLoss: 0.060618\n",
            "Train epoch: 367 [485880/25046 (61%)]\tLoss: 0.037075\n",
            "Train epoch: 367 [574140/25046 (71%)]\tLoss: 0.048577\n",
            "Train epoch: 367 [687680/25046 (82%)]\tLoss: 0.056989\n",
            "Train epoch: 367 [711900/25046 (92%)]\tLoss: 0.025498\n",
            "Make prediction for 5010 samples...\n",
            "0.25626087 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 368 [0/25046 (0%)]\tLoss: 0.095153\n",
            "Train epoch: 368 [79080/25046 (10%)]\tLoss: 0.044929\n",
            "Train epoch: 368 [162800/25046 (20%)]\tLoss: 0.020879\n",
            "Train epoch: 368 [247080/25046 (31%)]\tLoss: 0.066700\n",
            "Train epoch: 368 [318720/25046 (41%)]\tLoss: 0.094435\n",
            "Train epoch: 368 [421300/25046 (51%)]\tLoss: 0.046492\n",
            "Train epoch: 368 [484320/25046 (61%)]\tLoss: 0.050691\n",
            "Train epoch: 368 [582120/25046 (71%)]\tLoss: 0.041631\n",
            "Train epoch: 368 [640640/25046 (82%)]\tLoss: 0.070239\n",
            "Train epoch: 368 [741060/25046 (92%)]\tLoss: 0.081032\n",
            "Make prediction for 5010 samples...\n",
            "0.25830352 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 369 [0/25046 (0%)]\tLoss: 0.038215\n",
            "Train epoch: 369 [83000/25046 (10%)]\tLoss: 0.031237\n",
            "Train epoch: 369 [163000/25046 (20%)]\tLoss: 0.103104\n",
            "Train epoch: 369 [246360/25046 (31%)]\tLoss: 0.065463\n",
            "Train epoch: 369 [326960/25046 (41%)]\tLoss: 0.060828\n",
            "Train epoch: 369 [418900/25046 (51%)]\tLoss: 0.068321\n",
            "Train epoch: 369 [503640/25046 (61%)]\tLoss: 0.084671\n",
            "Train epoch: 369 [586740/25046 (71%)]\tLoss: 0.096289\n",
            "Train epoch: 369 [684320/25046 (82%)]\tLoss: 0.024168\n",
            "Train epoch: 369 [721440/25046 (92%)]\tLoss: 0.081019\n",
            "Make prediction for 5010 samples...\n",
            "0.2575115 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 370 [0/25046 (0%)]\tLoss: 0.067942\n",
            "Train epoch: 370 [80800/25046 (10%)]\tLoss: 0.030121\n",
            "Train epoch: 370 [163520/25046 (20%)]\tLoss: 0.042849\n",
            "Train epoch: 370 [247200/25046 (31%)]\tLoss: 0.041970\n",
            "Train epoch: 370 [322000/25046 (41%)]\tLoss: 0.056315\n",
            "Train epoch: 370 [411600/25046 (51%)]\tLoss: 0.142982\n",
            "Train epoch: 370 [483960/25046 (61%)]\tLoss: 0.040139\n",
            "Train epoch: 370 [576940/25046 (71%)]\tLoss: 0.103112\n",
            "Train epoch: 370 [665280/25046 (82%)]\tLoss: 0.082009\n",
            "Train epoch: 370 [731880/25046 (92%)]\tLoss: 0.037208\n",
            "Make prediction for 5010 samples...\n",
            "0.26330796 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 371 [0/25046 (0%)]\tLoss: 0.040420\n",
            "Train epoch: 371 [81100/25046 (10%)]\tLoss: 0.036482\n",
            "Train epoch: 371 [163920/25046 (20%)]\tLoss: 0.053150\n",
            "Train epoch: 371 [244380/25046 (31%)]\tLoss: 0.029933\n",
            "Train epoch: 371 [328160/25046 (41%)]\tLoss: 0.059354\n",
            "Train epoch: 371 [397700/25046 (51%)]\tLoss: 0.063651\n",
            "Train epoch: 371 [487560/25046 (61%)]\tLoss: 0.035781\n",
            "Train epoch: 371 [560420/25046 (71%)]\tLoss: 0.054144\n",
            "Train epoch: 371 [646720/25046 (82%)]\tLoss: 0.028067\n",
            "Train epoch: 371 [738000/25046 (92%)]\tLoss: 0.123005\n",
            "Make prediction for 5010 samples...\n",
            "0.25469506 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 372 [0/25046 (0%)]\tLoss: 0.055737\n",
            "Train epoch: 372 [81880/25046 (10%)]\tLoss: 0.023976\n",
            "Train epoch: 372 [165000/25046 (20%)]\tLoss: 0.057340\n",
            "Train epoch: 372 [247980/25046 (31%)]\tLoss: 0.054767\n",
            "Train epoch: 372 [333440/25046 (41%)]\tLoss: 0.026891\n",
            "Train epoch: 372 [405600/25046 (51%)]\tLoss: 0.040102\n",
            "Train epoch: 372 [502080/25046 (61%)]\tLoss: 0.026690\n",
            "Train epoch: 372 [582400/25046 (71%)]\tLoss: 0.094075\n",
            "Train epoch: 372 [670400/25046 (82%)]\tLoss: 0.044144\n",
            "Train epoch: 372 [747360/25046 (92%)]\tLoss: 0.097253\n",
            "Make prediction for 5010 samples...\n",
            "0.26674467 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 373 [0/25046 (0%)]\tLoss: 0.043760\n",
            "Train epoch: 373 [81720/25046 (10%)]\tLoss: 0.040625\n",
            "Train epoch: 373 [162200/25046 (20%)]\tLoss: 0.076449\n",
            "Train epoch: 373 [249360/25046 (31%)]\tLoss: 0.022409\n",
            "Train epoch: 373 [319200/25046 (41%)]\tLoss: 0.047321\n",
            "Train epoch: 373 [408300/25046 (51%)]\tLoss: 0.045097\n",
            "Train epoch: 373 [487080/25046 (61%)]\tLoss: 0.058009\n",
            "Train epoch: 373 [561120/25046 (71%)]\tLoss: 0.023288\n",
            "Train epoch: 373 [666080/25046 (82%)]\tLoss: 0.082967\n",
            "Train epoch: 373 [755640/25046 (92%)]\tLoss: 0.075024\n",
            "Make prediction for 5010 samples...\n",
            "0.25238988 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 374 [0/25046 (0%)]\tLoss: 0.068095\n",
            "Train epoch: 374 [82080/25046 (10%)]\tLoss: 0.048665\n",
            "Train epoch: 374 [163280/25046 (20%)]\tLoss: 0.073538\n",
            "Train epoch: 374 [247980/25046 (31%)]\tLoss: 0.055477\n",
            "Train epoch: 374 [330160/25046 (41%)]\tLoss: 0.032670\n",
            "Train epoch: 374 [408500/25046 (51%)]\tLoss: 0.021496\n",
            "Train epoch: 374 [474240/25046 (61%)]\tLoss: 0.060119\n",
            "Train epoch: 374 [587440/25046 (71%)]\tLoss: 0.045586\n",
            "Train epoch: 374 [633280/25046 (82%)]\tLoss: 0.041884\n",
            "Train epoch: 374 [759420/25046 (92%)]\tLoss: 0.046564\n",
            "Make prediction for 5010 samples...\n",
            "0.25551534 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 375 [0/25046 (0%)]\tLoss: 0.040800\n",
            "Train epoch: 375 [81660/25046 (10%)]\tLoss: 0.060256\n",
            "Train epoch: 375 [165560/25046 (20%)]\tLoss: 0.056174\n",
            "Train epoch: 375 [246540/25046 (31%)]\tLoss: 0.060446\n",
            "Train epoch: 375 [330000/25046 (41%)]\tLoss: 0.079529\n",
            "Train epoch: 375 [400200/25046 (51%)]\tLoss: 0.046193\n",
            "Train epoch: 375 [508200/25046 (61%)]\tLoss: 0.032396\n",
            "Train epoch: 375 [567280/25046 (71%)]\tLoss: 0.063919\n",
            "Train epoch: 375 [663360/25046 (82%)]\tLoss: 0.053399\n",
            "Train epoch: 375 [739800/25046 (92%)]\tLoss: 0.068075\n",
            "Make prediction for 5010 samples...\n",
            "0.2551921 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 376 [0/25046 (0%)]\tLoss: 0.056354\n",
            "Train epoch: 376 [84980/25046 (10%)]\tLoss: 0.046523\n",
            "Train epoch: 376 [168600/25046 (20%)]\tLoss: 0.049621\n",
            "Train epoch: 376 [251520/25046 (31%)]\tLoss: 0.036165\n",
            "Train epoch: 376 [331200/25046 (41%)]\tLoss: 0.031368\n",
            "Train epoch: 376 [398700/25046 (51%)]\tLoss: 0.022356\n",
            "Train epoch: 376 [478920/25046 (61%)]\tLoss: 0.048106\n",
            "Train epoch: 376 [577080/25046 (71%)]\tLoss: 0.030882\n",
            "Train epoch: 376 [664640/25046 (82%)]\tLoss: 0.056703\n",
            "Train epoch: 376 [746280/25046 (92%)]\tLoss: 0.027207\n",
            "Make prediction for 5010 samples...\n",
            "0.26335073 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 377 [0/25046 (0%)]\tLoss: 0.032086\n",
            "Train epoch: 377 [81460/25046 (10%)]\tLoss: 0.194497\n",
            "Train epoch: 377 [166680/25046 (20%)]\tLoss: 0.025237\n",
            "Train epoch: 377 [255300/25046 (31%)]\tLoss: 0.033836\n",
            "Train epoch: 377 [337840/25046 (41%)]\tLoss: 0.110371\n",
            "Train epoch: 377 [411900/25046 (51%)]\tLoss: 0.041186\n",
            "Train epoch: 377 [488040/25046 (61%)]\tLoss: 0.061266\n",
            "Train epoch: 377 [575820/25046 (71%)]\tLoss: 0.050062\n",
            "Train epoch: 377 [662720/25046 (82%)]\tLoss: 0.060204\n",
            "Train epoch: 377 [739440/25046 (92%)]\tLoss: 0.074027\n",
            "Make prediction for 5010 samples...\n",
            "0.25879672 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 378 [0/25046 (0%)]\tLoss: 0.052919\n",
            "Train epoch: 378 [83260/25046 (10%)]\tLoss: 0.073711\n",
            "Train epoch: 378 [164280/25046 (20%)]\tLoss: 0.064252\n",
            "Train epoch: 378 [244560/25046 (31%)]\tLoss: 0.071632\n",
            "Train epoch: 378 [327040/25046 (41%)]\tLoss: 0.082745\n",
            "Train epoch: 378 [399200/25046 (51%)]\tLoss: 0.061917\n",
            "Train epoch: 378 [486960/25046 (61%)]\tLoss: 0.039568\n",
            "Train epoch: 378 [576100/25046 (71%)]\tLoss: 0.069653\n",
            "Train epoch: 378 [696000/25046 (82%)]\tLoss: 0.095973\n",
            "Train epoch: 378 [734220/25046 (92%)]\tLoss: 0.036272\n",
            "Make prediction for 5010 samples...\n",
            "0.2629388 No improvement since epoch  365 ; best_mse,best_ci: 0.2466217 0.8795210855215146 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 379 [0/25046 (0%)]\tLoss: 0.070205\n",
            "Train epoch: 379 [80000/25046 (10%)]\tLoss: 0.144276\n",
            "Train epoch: 379 [164160/25046 (20%)]\tLoss: 0.033612\n",
            "Train epoch: 379 [249720/25046 (31%)]\tLoss: 0.040309\n",
            "Train epoch: 379 [325280/25046 (41%)]\tLoss: 0.038757\n",
            "Train epoch: 379 [403700/25046 (51%)]\tLoss: 0.023743\n",
            "Train epoch: 379 [478680/25046 (61%)]\tLoss: 0.070825\n",
            "Train epoch: 379 [587580/25046 (71%)]\tLoss: 0.051574\n",
            "Train epoch: 379 [660480/25046 (82%)]\tLoss: 0.041164\n",
            "Train epoch: 379 [731700/25046 (92%)]\tLoss: 0.119142\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  379 ; best_mse,best_ci: 0.24632236 0.8806711088083758 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 380 [0/25046 (0%)]\tLoss: 0.059268\n",
            "Train epoch: 380 [79560/25046 (10%)]\tLoss: 0.032123\n",
            "Train epoch: 380 [160840/25046 (20%)]\tLoss: 0.050213\n",
            "Train epoch: 380 [246960/25046 (31%)]\tLoss: 0.076153\n",
            "Train epoch: 380 [322640/25046 (41%)]\tLoss: 0.037071\n",
            "Train epoch: 380 [402200/25046 (51%)]\tLoss: 0.050741\n",
            "Train epoch: 380 [490800/25046 (61%)]\tLoss: 0.141498\n",
            "Train epoch: 380 [574980/25046 (71%)]\tLoss: 0.035784\n",
            "Train epoch: 380 [625440/25046 (82%)]\tLoss: 0.043726\n",
            "Train epoch: 380 [747360/25046 (92%)]\tLoss: 0.038304\n",
            "Make prediction for 5010 samples...\n",
            "0.25932622 No improvement since epoch  379 ; best_mse,best_ci: 0.24632236 0.8806711088083758 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 381 [0/25046 (0%)]\tLoss: 0.041767\n",
            "Train epoch: 381 [80400/25046 (10%)]\tLoss: 0.342060\n",
            "Train epoch: 381 [161960/25046 (20%)]\tLoss: 0.061292\n",
            "Train epoch: 381 [238740/25046 (31%)]\tLoss: 0.049189\n",
            "Train epoch: 381 [333120/25046 (41%)]\tLoss: 0.027966\n",
            "Train epoch: 381 [402600/25046 (51%)]\tLoss: 0.047271\n",
            "Train epoch: 381 [488160/25046 (61%)]\tLoss: 0.189915\n",
            "Train epoch: 381 [569800/25046 (71%)]\tLoss: 0.045388\n",
            "Train epoch: 381 [654080/25046 (82%)]\tLoss: 0.079251\n",
            "Train epoch: 381 [757980/25046 (92%)]\tLoss: 0.047294\n",
            "Make prediction for 5010 samples...\n",
            "0.2549676 No improvement since epoch  379 ; best_mse,best_ci: 0.24632236 0.8806711088083758 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 382 [0/25046 (0%)]\tLoss: 0.059770\n",
            "Train epoch: 382 [80200/25046 (10%)]\tLoss: 0.060629\n",
            "Train epoch: 382 [166720/25046 (20%)]\tLoss: 0.039557\n",
            "Train epoch: 382 [248520/25046 (31%)]\tLoss: 0.081083\n",
            "Train epoch: 382 [331840/25046 (41%)]\tLoss: 0.044478\n",
            "Train epoch: 382 [408000/25046 (51%)]\tLoss: 0.036064\n",
            "Train epoch: 382 [490200/25046 (61%)]\tLoss: 0.083358\n",
            "Train epoch: 382 [572600/25046 (71%)]\tLoss: 0.047290\n",
            "Train epoch: 382 [658240/25046 (82%)]\tLoss: 0.057137\n",
            "Train epoch: 382 [760680/25046 (92%)]\tLoss: 0.069758\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 383 [0/25046 (0%)]\tLoss: 0.029575\n",
            "Train epoch: 383 [82540/25046 (10%)]\tLoss: 0.051587\n",
            "Train epoch: 383 [168960/25046 (20%)]\tLoss: 0.094359\n",
            "Train epoch: 383 [244080/25046 (31%)]\tLoss: 0.022762\n",
            "Train epoch: 383 [324720/25046 (41%)]\tLoss: 0.043807\n",
            "Train epoch: 383 [403500/25046 (51%)]\tLoss: 0.031399\n",
            "Train epoch: 383 [489000/25046 (61%)]\tLoss: 0.059103\n",
            "Train epoch: 383 [578760/25046 (71%)]\tLoss: 0.036445\n",
            "Train epoch: 383 [660960/25046 (82%)]\tLoss: 0.096801\n",
            "Train epoch: 383 [720180/25046 (92%)]\tLoss: 0.067861\n",
            "Make prediction for 5010 samples...\n",
            "0.25832015 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 384 [0/25046 (0%)]\tLoss: 0.050167\n",
            "Train epoch: 384 [80540/25046 (10%)]\tLoss: 0.114022\n",
            "Train epoch: 384 [164680/25046 (20%)]\tLoss: 0.034992\n",
            "Train epoch: 384 [242580/25046 (31%)]\tLoss: 0.038650\n",
            "Train epoch: 384 [334000/25046 (41%)]\tLoss: 0.022495\n",
            "Train epoch: 384 [418000/25046 (51%)]\tLoss: 0.040737\n",
            "Train epoch: 384 [483360/25046 (61%)]\tLoss: 0.072750\n",
            "Train epoch: 384 [575120/25046 (71%)]\tLoss: 0.036502\n",
            "Train epoch: 384 [654720/25046 (82%)]\tLoss: 0.039897\n",
            "Train epoch: 384 [750600/25046 (92%)]\tLoss: 0.078789\n",
            "Make prediction for 5010 samples...\n",
            "0.25202173 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 385 [0/25046 (0%)]\tLoss: 0.023802\n",
            "Train epoch: 385 [82460/25046 (10%)]\tLoss: 0.030617\n",
            "Train epoch: 385 [166280/25046 (20%)]\tLoss: 0.088853\n",
            "Train epoch: 385 [248340/25046 (31%)]\tLoss: 0.023729\n",
            "Train epoch: 385 [323840/25046 (41%)]\tLoss: 0.033837\n",
            "Train epoch: 385 [395700/25046 (51%)]\tLoss: 0.043454\n",
            "Train epoch: 385 [496080/25046 (61%)]\tLoss: 0.061305\n",
            "Train epoch: 385 [575960/25046 (71%)]\tLoss: 0.025386\n",
            "Train epoch: 385 [646880/25046 (82%)]\tLoss: 0.140872\n",
            "Train epoch: 385 [745920/25046 (92%)]\tLoss: 0.073107\n",
            "Make prediction for 5010 samples...\n",
            "0.24798207 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 386 [0/25046 (0%)]\tLoss: 0.034593\n",
            "Train epoch: 386 [82380/25046 (10%)]\tLoss: 0.041198\n",
            "Train epoch: 386 [163480/25046 (20%)]\tLoss: 0.053925\n",
            "Train epoch: 386 [242940/25046 (31%)]\tLoss: 0.058222\n",
            "Train epoch: 386 [324880/25046 (41%)]\tLoss: 0.040478\n",
            "Train epoch: 386 [405100/25046 (51%)]\tLoss: 0.028269\n",
            "Train epoch: 386 [489960/25046 (61%)]\tLoss: 0.025076\n",
            "Train epoch: 386 [582680/25046 (71%)]\tLoss: 0.035355\n",
            "Train epoch: 386 [641760/25046 (82%)]\tLoss: 0.093070\n",
            "Train epoch: 386 [729900/25046 (92%)]\tLoss: 0.049250\n",
            "Make prediction for 5010 samples...\n",
            "0.25369552 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 387 [0/25046 (0%)]\tLoss: 0.060888\n",
            "Train epoch: 387 [82900/25046 (10%)]\tLoss: 0.045433\n",
            "Train epoch: 387 [160400/25046 (20%)]\tLoss: 0.069784\n",
            "Train epoch: 387 [247500/25046 (31%)]\tLoss: 0.081168\n",
            "Train epoch: 387 [318320/25046 (41%)]\tLoss: 0.029539\n",
            "Train epoch: 387 [422600/25046 (51%)]\tLoss: 0.167851\n",
            "Train epoch: 387 [498000/25046 (61%)]\tLoss: 0.045417\n",
            "Train epoch: 387 [566020/25046 (71%)]\tLoss: 0.091914\n",
            "Train epoch: 387 [640000/25046 (82%)]\tLoss: 0.057883\n",
            "Train epoch: 387 [739080/25046 (92%)]\tLoss: 0.055900\n",
            "Make prediction for 5010 samples...\n",
            "0.25220942 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 388 [0/25046 (0%)]\tLoss: 0.041283\n",
            "Train epoch: 388 [84900/25046 (10%)]\tLoss: 0.101029\n",
            "Train epoch: 388 [168920/25046 (20%)]\tLoss: 0.033969\n",
            "Train epoch: 388 [243180/25046 (31%)]\tLoss: 0.050881\n",
            "Train epoch: 388 [336080/25046 (41%)]\tLoss: 0.044148\n",
            "Train epoch: 388 [414200/25046 (51%)]\tLoss: 0.042696\n",
            "Train epoch: 388 [492840/25046 (61%)]\tLoss: 0.078272\n",
            "Train epoch: 388 [585340/25046 (71%)]\tLoss: 0.035516\n",
            "Train epoch: 388 [658880/25046 (82%)]\tLoss: 0.041753\n",
            "Train epoch: 388 [728640/25046 (92%)]\tLoss: 0.035156\n",
            "Make prediction for 5010 samples...\n",
            "0.2497233 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 389 [0/25046 (0%)]\tLoss: 0.041266\n",
            "Train epoch: 389 [82440/25046 (10%)]\tLoss: 0.037431\n",
            "Train epoch: 389 [166640/25046 (20%)]\tLoss: 0.052850\n",
            "Train epoch: 389 [251460/25046 (31%)]\tLoss: 0.070830\n",
            "Train epoch: 389 [324960/25046 (41%)]\tLoss: 0.030811\n",
            "Train epoch: 389 [401100/25046 (51%)]\tLoss: 0.047582\n",
            "Train epoch: 389 [483600/25046 (61%)]\tLoss: 0.029040\n",
            "Train epoch: 389 [560980/25046 (71%)]\tLoss: 0.053712\n",
            "Train epoch: 389 [664320/25046 (82%)]\tLoss: 0.046972\n",
            "Train epoch: 389 [745020/25046 (92%)]\tLoss: 0.056162\n",
            "Make prediction for 5010 samples...\n",
            "0.25290745 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 390 [0/25046 (0%)]\tLoss: 0.086035\n",
            "Train epoch: 390 [82880/25046 (10%)]\tLoss: 0.049597\n",
            "Train epoch: 390 [159160/25046 (20%)]\tLoss: 0.039107\n",
            "Train epoch: 390 [247320/25046 (31%)]\tLoss: 0.047256\n",
            "Train epoch: 390 [321760/25046 (41%)]\tLoss: 0.072944\n",
            "Train epoch: 390 [399300/25046 (51%)]\tLoss: 0.031725\n",
            "Train epoch: 390 [508440/25046 (61%)]\tLoss: 0.053222\n",
            "Train epoch: 390 [579880/25046 (71%)]\tLoss: 0.058746\n",
            "Train epoch: 390 [658720/25046 (82%)]\tLoss: 0.063529\n",
            "Train epoch: 390 [761040/25046 (92%)]\tLoss: 0.052673\n",
            "Make prediction for 5010 samples...\n",
            "0.2512843 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 391 [0/25046 (0%)]\tLoss: 0.067541\n",
            "Train epoch: 391 [81620/25046 (10%)]\tLoss: 0.045816\n",
            "Train epoch: 391 [165680/25046 (20%)]\tLoss: 0.060296\n",
            "Train epoch: 391 [250260/25046 (31%)]\tLoss: 0.040702\n",
            "Train epoch: 391 [327680/25046 (41%)]\tLoss: 0.027001\n",
            "Train epoch: 391 [416000/25046 (51%)]\tLoss: 0.042734\n",
            "Train epoch: 391 [497040/25046 (61%)]\tLoss: 0.053891\n",
            "Train epoch: 391 [578620/25046 (71%)]\tLoss: 0.033392\n",
            "Train epoch: 391 [643520/25046 (82%)]\tLoss: 0.035349\n",
            "Train epoch: 391 [745920/25046 (92%)]\tLoss: 0.031940\n",
            "Make prediction for 5010 samples...\n",
            "0.24931721 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 392 [0/25046 (0%)]\tLoss: 0.111706\n",
            "Train epoch: 392 [80480/25046 (10%)]\tLoss: 0.060203\n",
            "Train epoch: 392 [168640/25046 (20%)]\tLoss: 0.047971\n",
            "Train epoch: 392 [245160/25046 (31%)]\tLoss: 0.031138\n",
            "Train epoch: 392 [326880/25046 (41%)]\tLoss: 0.135674\n",
            "Train epoch: 392 [401800/25046 (51%)]\tLoss: 0.056542\n",
            "Train epoch: 392 [488640/25046 (61%)]\tLoss: 0.031566\n",
            "Train epoch: 392 [563640/25046 (71%)]\tLoss: 0.037709\n",
            "Train epoch: 392 [660320/25046 (82%)]\tLoss: 0.037042\n",
            "Train epoch: 392 [742140/25046 (92%)]\tLoss: 0.054215\n",
            "Make prediction for 5010 samples...\n",
            "0.2525723 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 393 [0/25046 (0%)]\tLoss: 0.045997\n",
            "Train epoch: 393 [81160/25046 (10%)]\tLoss: 0.100006\n",
            "Train epoch: 393 [164120/25046 (20%)]\tLoss: 0.046662\n",
            "Train epoch: 393 [251220/25046 (31%)]\tLoss: 0.055967\n",
            "Train epoch: 393 [327680/25046 (41%)]\tLoss: 0.051394\n",
            "Train epoch: 393 [407300/25046 (51%)]\tLoss: 0.028170\n",
            "Train epoch: 393 [500640/25046 (61%)]\tLoss: 0.058162\n",
            "Train epoch: 393 [578060/25046 (71%)]\tLoss: 0.057834\n",
            "Train epoch: 393 [669920/25046 (82%)]\tLoss: 0.221317\n",
            "Train epoch: 393 [756540/25046 (92%)]\tLoss: 0.033781\n",
            "Make prediction for 5010 samples...\n",
            "0.25212407 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 394 [0/25046 (0%)]\tLoss: 0.036653\n",
            "Train epoch: 394 [80800/25046 (10%)]\tLoss: 0.093941\n",
            "Train epoch: 394 [161400/25046 (20%)]\tLoss: 0.030794\n",
            "Train epoch: 394 [245040/25046 (31%)]\tLoss: 0.040636\n",
            "Train epoch: 394 [333280/25046 (41%)]\tLoss: 0.095971\n",
            "Train epoch: 394 [410200/25046 (51%)]\tLoss: 0.093089\n",
            "Train epoch: 394 [504720/25046 (61%)]\tLoss: 0.052599\n",
            "Train epoch: 394 [577500/25046 (71%)]\tLoss: 0.140643\n",
            "Train epoch: 394 [685600/25046 (82%)]\tLoss: 0.105223\n",
            "Train epoch: 394 [748080/25046 (92%)]\tLoss: 0.049167\n",
            "Make prediction for 5010 samples...\n",
            "0.24896972 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 395 [0/25046 (0%)]\tLoss: 0.069828\n",
            "Train epoch: 395 [85180/25046 (10%)]\tLoss: 0.047400\n",
            "Train epoch: 395 [168360/25046 (20%)]\tLoss: 0.029809\n",
            "Train epoch: 395 [250140/25046 (31%)]\tLoss: 0.041502\n",
            "Train epoch: 395 [323440/25046 (41%)]\tLoss: 0.030736\n",
            "Train epoch: 395 [403300/25046 (51%)]\tLoss: 0.013107\n",
            "Train epoch: 395 [480120/25046 (61%)]\tLoss: 0.088623\n",
            "Train epoch: 395 [563360/25046 (71%)]\tLoss: 0.048327\n",
            "Train epoch: 395 [658720/25046 (82%)]\tLoss: 0.060107\n",
            "Train epoch: 395 [740520/25046 (92%)]\tLoss: 0.051466\n",
            "Make prediction for 5010 samples...\n",
            "0.2523217 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 396 [0/25046 (0%)]\tLoss: 0.050752\n",
            "Train epoch: 396 [81380/25046 (10%)]\tLoss: 0.034290\n",
            "Train epoch: 396 [167520/25046 (20%)]\tLoss: 0.033336\n",
            "Train epoch: 396 [244500/25046 (31%)]\tLoss: 0.021323\n",
            "Train epoch: 396 [330800/25046 (41%)]\tLoss: 0.099535\n",
            "Train epoch: 396 [414800/25046 (51%)]\tLoss: 0.075657\n",
            "Train epoch: 396 [482400/25046 (61%)]\tLoss: 0.042659\n",
            "Train epoch: 396 [565180/25046 (71%)]\tLoss: 0.049201\n",
            "Train epoch: 396 [662720/25046 (82%)]\tLoss: 0.041458\n",
            "Train epoch: 396 [723060/25046 (92%)]\tLoss: 0.135490\n",
            "Make prediction for 5010 samples...\n",
            "0.2560911 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 397 [0/25046 (0%)]\tLoss: 0.035557\n",
            "Train epoch: 397 [81200/25046 (10%)]\tLoss: 0.075331\n",
            "Train epoch: 397 [164320/25046 (20%)]\tLoss: 0.032691\n",
            "Train epoch: 397 [235800/25046 (31%)]\tLoss: 0.050275\n",
            "Train epoch: 397 [326480/25046 (41%)]\tLoss: 0.096044\n",
            "Train epoch: 397 [398200/25046 (51%)]\tLoss: 0.049509\n",
            "Train epoch: 397 [485400/25046 (61%)]\tLoss: 0.035703\n",
            "Train epoch: 397 [582540/25046 (71%)]\tLoss: 0.064791\n",
            "Train epoch: 397 [629120/25046 (82%)]\tLoss: 0.033432\n",
            "Train epoch: 397 [727200/25046 (92%)]\tLoss: 0.088976\n",
            "Make prediction for 5010 samples...\n",
            "0.25566015 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 398 [0/25046 (0%)]\tLoss: 0.048079\n",
            "Train epoch: 398 [82660/25046 (10%)]\tLoss: 0.045119\n",
            "Train epoch: 398 [160040/25046 (20%)]\tLoss: 0.074720\n",
            "Train epoch: 398 [247080/25046 (31%)]\tLoss: 0.034235\n",
            "Train epoch: 398 [326480/25046 (41%)]\tLoss: 0.056295\n",
            "Train epoch: 398 [413600/25046 (51%)]\tLoss: 0.045404\n",
            "Train epoch: 398 [486120/25046 (61%)]\tLoss: 0.075926\n",
            "Train epoch: 398 [570780/25046 (71%)]\tLoss: 0.042948\n",
            "Train epoch: 398 [650240/25046 (82%)]\tLoss: 0.179963\n",
            "Train epoch: 398 [757260/25046 (92%)]\tLoss: 0.035292\n",
            "Make prediction for 5010 samples...\n",
            "0.25901884 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 399 [0/25046 (0%)]\tLoss: 0.061805\n",
            "Train epoch: 399 [83520/25046 (10%)]\tLoss: 0.037476\n",
            "Train epoch: 399 [164200/25046 (20%)]\tLoss: 0.055731\n",
            "Train epoch: 399 [248220/25046 (31%)]\tLoss: 0.067477\n",
            "Train epoch: 399 [334560/25046 (41%)]\tLoss: 0.068849\n",
            "Train epoch: 399 [409400/25046 (51%)]\tLoss: 0.036684\n",
            "Train epoch: 399 [493320/25046 (61%)]\tLoss: 0.035189\n",
            "Train epoch: 399 [570500/25046 (71%)]\tLoss: 0.059956\n",
            "Train epoch: 399 [665440/25046 (82%)]\tLoss: 0.034238\n",
            "Train epoch: 399 [760860/25046 (92%)]\tLoss: 0.052202\n",
            "Make prediction for 5010 samples...\n",
            "0.2583646 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 400 [0/25046 (0%)]\tLoss: 0.038143\n",
            "Train epoch: 400 [83860/25046 (10%)]\tLoss: 0.104892\n",
            "Train epoch: 400 [169720/25046 (20%)]\tLoss: 0.075750\n",
            "Train epoch: 400 [241440/25046 (31%)]\tLoss: 0.021040\n",
            "Train epoch: 400 [329520/25046 (41%)]\tLoss: 0.047569\n",
            "Train epoch: 400 [405600/25046 (51%)]\tLoss: 0.095437\n",
            "Train epoch: 400 [502560/25046 (61%)]\tLoss: 0.028504\n",
            "Train epoch: 400 [562800/25046 (71%)]\tLoss: 0.083965\n",
            "Train epoch: 400 [659360/25046 (82%)]\tLoss: 0.070102\n",
            "Train epoch: 400 [721620/25046 (92%)]\tLoss: 0.055036\n",
            "Make prediction for 5010 samples...\n",
            "0.25469342 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 401 [0/25046 (0%)]\tLoss: 0.069125\n",
            "Train epoch: 401 [78200/25046 (10%)]\tLoss: 0.077359\n",
            "Train epoch: 401 [173400/25046 (20%)]\tLoss: 0.060141\n",
            "Train epoch: 401 [251820/25046 (31%)]\tLoss: 0.065041\n",
            "Train epoch: 401 [328720/25046 (41%)]\tLoss: 0.045036\n",
            "Train epoch: 401 [416300/25046 (51%)]\tLoss: 0.044831\n",
            "Train epoch: 401 [497400/25046 (61%)]\tLoss: 0.058955\n",
            "Train epoch: 401 [585480/25046 (71%)]\tLoss: 0.033443\n",
            "Train epoch: 401 [642240/25046 (82%)]\tLoss: 0.028175\n",
            "Train epoch: 401 [734220/25046 (92%)]\tLoss: 0.056921\n",
            "Make prediction for 5010 samples...\n",
            "0.25645375 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 402 [0/25046 (0%)]\tLoss: 0.041940\n",
            "Train epoch: 402 [81800/25046 (10%)]\tLoss: 0.101369\n",
            "Train epoch: 402 [164160/25046 (20%)]\tLoss: 0.041117\n",
            "Train epoch: 402 [247800/25046 (31%)]\tLoss: 0.040327\n",
            "Train epoch: 402 [332240/25046 (41%)]\tLoss: 0.062281\n",
            "Train epoch: 402 [419900/25046 (51%)]\tLoss: 0.048206\n",
            "Train epoch: 402 [497880/25046 (61%)]\tLoss: 0.038986\n",
            "Train epoch: 402 [593180/25046 (71%)]\tLoss: 0.072080\n",
            "Train epoch: 402 [649440/25046 (82%)]\tLoss: 0.036211\n",
            "Train epoch: 402 [752400/25046 (92%)]\tLoss: 0.041086\n",
            "Make prediction for 5010 samples...\n",
            "0.2575831 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 403 [0/25046 (0%)]\tLoss: 0.049891\n",
            "Train epoch: 403 [79920/25046 (10%)]\tLoss: 0.041006\n",
            "Train epoch: 403 [168640/25046 (20%)]\tLoss: 0.028776\n",
            "Train epoch: 403 [246900/25046 (31%)]\tLoss: 0.038064\n",
            "Train epoch: 403 [326880/25046 (41%)]\tLoss: 0.093209\n",
            "Train epoch: 403 [405100/25046 (51%)]\tLoss: 0.083754\n",
            "Train epoch: 403 [492000/25046 (61%)]\tLoss: 0.061990\n",
            "Train epoch: 403 [560280/25046 (71%)]\tLoss: 0.040398\n",
            "Train epoch: 403 [638080/25046 (82%)]\tLoss: 0.031193\n",
            "Train epoch: 403 [734940/25046 (92%)]\tLoss: 0.097950\n",
            "Make prediction for 5010 samples...\n",
            "0.257895 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 404 [0/25046 (0%)]\tLoss: 0.068589\n",
            "Train epoch: 404 [80980/25046 (10%)]\tLoss: 0.038901\n",
            "Train epoch: 404 [162800/25046 (20%)]\tLoss: 0.032643\n",
            "Train epoch: 404 [243000/25046 (31%)]\tLoss: 0.033153\n",
            "Train epoch: 404 [326240/25046 (41%)]\tLoss: 0.046607\n",
            "Train epoch: 404 [415500/25046 (51%)]\tLoss: 0.067380\n",
            "Train epoch: 404 [482160/25046 (61%)]\tLoss: 0.029938\n",
            "Train epoch: 404 [578620/25046 (71%)]\tLoss: 0.049981\n",
            "Train epoch: 404 [652160/25046 (82%)]\tLoss: 0.039630\n",
            "Train epoch: 404 [766080/25046 (92%)]\tLoss: 0.096219\n",
            "Make prediction for 5010 samples...\n",
            "0.25213823 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 405 [0/25046 (0%)]\tLoss: 0.025771\n",
            "Train epoch: 405 [81720/25046 (10%)]\tLoss: 0.043312\n",
            "Train epoch: 405 [159280/25046 (20%)]\tLoss: 0.025901\n",
            "Train epoch: 405 [250440/25046 (31%)]\tLoss: 0.072300\n",
            "Train epoch: 405 [329120/25046 (41%)]\tLoss: 0.058740\n",
            "Train epoch: 405 [396600/25046 (51%)]\tLoss: 0.021782\n",
            "Train epoch: 405 [492720/25046 (61%)]\tLoss: 0.028296\n",
            "Train epoch: 405 [571200/25046 (71%)]\tLoss: 0.039454\n",
            "Train epoch: 405 [644800/25046 (82%)]\tLoss: 0.043814\n",
            "Train epoch: 405 [734400/25046 (92%)]\tLoss: 0.085944\n",
            "Make prediction for 5010 samples...\n",
            "0.25284728 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 406 [0/25046 (0%)]\tLoss: 0.052702\n",
            "Train epoch: 406 [81980/25046 (10%)]\tLoss: 0.047565\n",
            "Train epoch: 406 [162560/25046 (20%)]\tLoss: 0.047731\n",
            "Train epoch: 406 [240480/25046 (31%)]\tLoss: 0.054067\n",
            "Train epoch: 406 [319360/25046 (41%)]\tLoss: 0.030032\n",
            "Train epoch: 406 [415100/25046 (51%)]\tLoss: 0.043400\n",
            "Train epoch: 406 [495120/25046 (61%)]\tLoss: 0.073780\n",
            "Train epoch: 406 [570780/25046 (71%)]\tLoss: 0.062823\n",
            "Train epoch: 406 [647040/25046 (82%)]\tLoss: 0.058853\n",
            "Train epoch: 406 [735300/25046 (92%)]\tLoss: 0.019984\n",
            "Make prediction for 5010 samples...\n",
            "0.25307652 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 407 [0/25046 (0%)]\tLoss: 0.044251\n",
            "Train epoch: 407 [82540/25046 (10%)]\tLoss: 0.055489\n",
            "Train epoch: 407 [159640/25046 (20%)]\tLoss: 0.042282\n",
            "Train epoch: 407 [251160/25046 (31%)]\tLoss: 0.045210\n",
            "Train epoch: 407 [332240/25046 (41%)]\tLoss: 0.038668\n",
            "Train epoch: 407 [414500/25046 (51%)]\tLoss: 0.056586\n",
            "Train epoch: 407 [483960/25046 (61%)]\tLoss: 0.042030\n",
            "Train epoch: 407 [584920/25046 (71%)]\tLoss: 0.048900\n",
            "Train epoch: 407 [675360/25046 (82%)]\tLoss: 0.044761\n",
            "Train epoch: 407 [729000/25046 (92%)]\tLoss: 0.054525\n",
            "Make prediction for 5010 samples...\n",
            "0.2563462 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 408 [0/25046 (0%)]\tLoss: 0.043767\n",
            "Train epoch: 408 [80800/25046 (10%)]\tLoss: 0.057759\n",
            "Train epoch: 408 [164800/25046 (20%)]\tLoss: 0.062805\n",
            "Train epoch: 408 [244680/25046 (31%)]\tLoss: 0.048420\n",
            "Train epoch: 408 [340560/25046 (41%)]\tLoss: 0.080274\n",
            "Train epoch: 408 [413600/25046 (51%)]\tLoss: 0.066561\n",
            "Train epoch: 408 [489600/25046 (61%)]\tLoss: 0.043779\n",
            "Train epoch: 408 [602280/25046 (71%)]\tLoss: 0.040211\n",
            "Train epoch: 408 [653440/25046 (82%)]\tLoss: 0.036009\n",
            "Train epoch: 408 [751500/25046 (92%)]\tLoss: 0.066908\n",
            "Make prediction for 5010 samples...\n",
            "0.26219696 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 409 [0/25046 (0%)]\tLoss: 0.045969\n",
            "Train epoch: 409 [82440/25046 (10%)]\tLoss: 0.034576\n",
            "Train epoch: 409 [162880/25046 (20%)]\tLoss: 0.039252\n",
            "Train epoch: 409 [250860/25046 (31%)]\tLoss: 0.066499\n",
            "Train epoch: 409 [336240/25046 (41%)]\tLoss: 0.050213\n",
            "Train epoch: 409 [409000/25046 (51%)]\tLoss: 0.043987\n",
            "Train epoch: 409 [478560/25046 (61%)]\tLoss: 0.072648\n",
            "Train epoch: 409 [585760/25046 (71%)]\tLoss: 0.099955\n",
            "Train epoch: 409 [673440/25046 (82%)]\tLoss: 0.023802\n",
            "Train epoch: 409 [724320/25046 (92%)]\tLoss: 0.030437\n",
            "Make prediction for 5010 samples...\n",
            "0.25150138 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 410 [0/25046 (0%)]\tLoss: 0.047795\n",
            "Train epoch: 410 [83280/25046 (10%)]\tLoss: 0.065285\n",
            "Train epoch: 410 [162000/25046 (20%)]\tLoss: 0.052732\n",
            "Train epoch: 410 [244860/25046 (31%)]\tLoss: 0.029700\n",
            "Train epoch: 410 [330320/25046 (41%)]\tLoss: 0.086462\n",
            "Train epoch: 410 [412800/25046 (51%)]\tLoss: 0.046216\n",
            "Train epoch: 410 [479760/25046 (61%)]\tLoss: 0.029160\n",
            "Train epoch: 410 [574420/25046 (71%)]\tLoss: 0.153059\n",
            "Train epoch: 410 [656480/25046 (82%)]\tLoss: 0.061447\n",
            "Train epoch: 410 [722340/25046 (92%)]\tLoss: 0.072152\n",
            "Make prediction for 5010 samples...\n",
            "0.25683242 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 411 [0/25046 (0%)]\tLoss: 0.026667\n",
            "Train epoch: 411 [79700/25046 (10%)]\tLoss: 0.079647\n",
            "Train epoch: 411 [161000/25046 (20%)]\tLoss: 0.025504\n",
            "Train epoch: 411 [241800/25046 (31%)]\tLoss: 0.020282\n",
            "Train epoch: 411 [317440/25046 (41%)]\tLoss: 0.077138\n",
            "Train epoch: 411 [413100/25046 (51%)]\tLoss: 0.039166\n",
            "Train epoch: 411 [494760/25046 (61%)]\tLoss: 0.083025\n",
            "Train epoch: 411 [560000/25046 (71%)]\tLoss: 0.038394\n",
            "Train epoch: 411 [646240/25046 (82%)]\tLoss: 0.053028\n",
            "Train epoch: 411 [735840/25046 (92%)]\tLoss: 0.032893\n",
            "Make prediction for 5010 samples...\n",
            "0.24808244 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 412 [0/25046 (0%)]\tLoss: 0.062927\n",
            "Train epoch: 412 [79060/25046 (10%)]\tLoss: 0.056884\n",
            "Train epoch: 412 [159800/25046 (20%)]\tLoss: 0.077469\n",
            "Train epoch: 412 [243480/25046 (31%)]\tLoss: 0.061594\n",
            "Train epoch: 412 [337360/25046 (41%)]\tLoss: 0.049874\n",
            "Train epoch: 412 [413400/25046 (51%)]\tLoss: 0.096145\n",
            "Train epoch: 412 [491880/25046 (61%)]\tLoss: 0.067445\n",
            "Train epoch: 412 [572740/25046 (71%)]\tLoss: 0.029931\n",
            "Train epoch: 412 [665920/25046 (82%)]\tLoss: 0.079337\n",
            "Train epoch: 412 [753660/25046 (92%)]\tLoss: 0.034375\n",
            "Make prediction for 5010 samples...\n",
            "0.25363883 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 413 [0/25046 (0%)]\tLoss: 0.069109\n",
            "Train epoch: 413 [82340/25046 (10%)]\tLoss: 0.036999\n",
            "Train epoch: 413 [161560/25046 (20%)]\tLoss: 0.037234\n",
            "Train epoch: 413 [243360/25046 (31%)]\tLoss: 0.084234\n",
            "Train epoch: 413 [331760/25046 (41%)]\tLoss: 0.064939\n",
            "Train epoch: 413 [412500/25046 (51%)]\tLoss: 0.029969\n",
            "Train epoch: 413 [478920/25046 (61%)]\tLoss: 0.061236\n",
            "Train epoch: 413 [560280/25046 (71%)]\tLoss: 0.048431\n",
            "Train epoch: 413 [672800/25046 (82%)]\tLoss: 0.024637\n",
            "Train epoch: 413 [739440/25046 (92%)]\tLoss: 0.088982\n",
            "Make prediction for 5010 samples...\n",
            "0.25364807 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 414 [0/25046 (0%)]\tLoss: 0.046301\n",
            "Train epoch: 414 [82020/25046 (10%)]\tLoss: 0.095440\n",
            "Train epoch: 414 [164320/25046 (20%)]\tLoss: 0.042115\n",
            "Train epoch: 414 [249660/25046 (31%)]\tLoss: 0.034672\n",
            "Train epoch: 414 [331120/25046 (41%)]\tLoss: 0.118664\n",
            "Train epoch: 414 [414400/25046 (51%)]\tLoss: 0.037802\n",
            "Train epoch: 414 [490440/25046 (61%)]\tLoss: 0.042545\n",
            "Train epoch: 414 [577920/25046 (71%)]\tLoss: 0.030050\n",
            "Train epoch: 414 [640800/25046 (82%)]\tLoss: 0.122099\n",
            "Train epoch: 414 [746280/25046 (92%)]\tLoss: 0.050366\n",
            "Make prediction for 5010 samples...\n",
            "0.25321877 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 415 [0/25046 (0%)]\tLoss: 0.049793\n",
            "Train epoch: 415 [81740/25046 (10%)]\tLoss: 0.080536\n",
            "Train epoch: 415 [164440/25046 (20%)]\tLoss: 0.027117\n",
            "Train epoch: 415 [252180/25046 (31%)]\tLoss: 0.046220\n",
            "Train epoch: 415 [327120/25046 (41%)]\tLoss: 0.057530\n",
            "Train epoch: 415 [406900/25046 (51%)]\tLoss: 0.052356\n",
            "Train epoch: 415 [499440/25046 (61%)]\tLoss: 0.062096\n",
            "Train epoch: 415 [569380/25046 (71%)]\tLoss: 0.036882\n",
            "Train epoch: 415 [668640/25046 (82%)]\tLoss: 0.068747\n",
            "Train epoch: 415 [744660/25046 (92%)]\tLoss: 0.085681\n",
            "Make prediction for 5010 samples...\n",
            "0.2546443 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 416 [0/25046 (0%)]\tLoss: 0.035624\n",
            "Train epoch: 416 [80640/25046 (10%)]\tLoss: 0.081817\n",
            "Train epoch: 416 [166040/25046 (20%)]\tLoss: 0.034266\n",
            "Train epoch: 416 [247560/25046 (31%)]\tLoss: 0.111116\n",
            "Train epoch: 416 [327600/25046 (41%)]\tLoss: 0.072147\n",
            "Train epoch: 416 [417400/25046 (51%)]\tLoss: 0.022915\n",
            "Train epoch: 416 [507240/25046 (61%)]\tLoss: 0.031593\n",
            "Train epoch: 416 [571200/25046 (71%)]\tLoss: 0.061161\n",
            "Train epoch: 416 [642560/25046 (82%)]\tLoss: 0.048337\n",
            "Train epoch: 416 [747720/25046 (92%)]\tLoss: 0.024283\n",
            "Make prediction for 5010 samples...\n",
            "0.24709322 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 417 [0/25046 (0%)]\tLoss: 0.039824\n",
            "Train epoch: 417 [83160/25046 (10%)]\tLoss: 0.042207\n",
            "Train epoch: 417 [163560/25046 (20%)]\tLoss: 0.058210\n",
            "Train epoch: 417 [251520/25046 (31%)]\tLoss: 0.081882\n",
            "Train epoch: 417 [322960/25046 (41%)]\tLoss: 0.042859\n",
            "Train epoch: 417 [412000/25046 (51%)]\tLoss: 0.035625\n",
            "Train epoch: 417 [492120/25046 (61%)]\tLoss: 0.034572\n",
            "Train epoch: 417 [574700/25046 (71%)]\tLoss: 0.048665\n",
            "Train epoch: 417 [648640/25046 (82%)]\tLoss: 0.027005\n",
            "Train epoch: 417 [742140/25046 (92%)]\tLoss: 0.038834\n",
            "Make prediction for 5010 samples...\n",
            "0.25286487 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 418 [0/25046 (0%)]\tLoss: 0.042609\n",
            "Train epoch: 418 [81380/25046 (10%)]\tLoss: 0.058274\n",
            "Train epoch: 418 [165160/25046 (20%)]\tLoss: 0.018590\n",
            "Train epoch: 418 [252360/25046 (31%)]\tLoss: 0.087658\n",
            "Train epoch: 418 [331680/25046 (41%)]\tLoss: 0.055626\n",
            "Train epoch: 418 [400800/25046 (51%)]\tLoss: 0.040947\n",
            "Train epoch: 418 [491640/25046 (61%)]\tLoss: 0.053642\n",
            "Train epoch: 418 [592060/25046 (71%)]\tLoss: 0.056399\n",
            "Train epoch: 418 [657120/25046 (82%)]\tLoss: 0.046604\n",
            "Train epoch: 418 [734940/25046 (92%)]\tLoss: 0.042645\n",
            "Make prediction for 5010 samples...\n",
            "0.25592923 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 419 [0/25046 (0%)]\tLoss: 0.057555\n",
            "Train epoch: 419 [79220/25046 (10%)]\tLoss: 0.046859\n",
            "Train epoch: 419 [173000/25046 (20%)]\tLoss: 0.048212\n",
            "Train epoch: 419 [245580/25046 (31%)]\tLoss: 0.017391\n",
            "Train epoch: 419 [333520/25046 (41%)]\tLoss: 0.042179\n",
            "Train epoch: 419 [404500/25046 (51%)]\tLoss: 0.080880\n",
            "Train epoch: 419 [486960/25046 (61%)]\tLoss: 0.024416\n",
            "Train epoch: 419 [558880/25046 (71%)]\tLoss: 0.020947\n",
            "Train epoch: 419 [640960/25046 (82%)]\tLoss: 0.032008\n",
            "Train epoch: 419 [753480/25046 (92%)]\tLoss: 0.093490\n",
            "Make prediction for 5010 samples...\n",
            "0.2650946 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 420 [0/25046 (0%)]\tLoss: 0.033832\n",
            "Train epoch: 420 [79980/25046 (10%)]\tLoss: 0.033378\n",
            "Train epoch: 420 [166120/25046 (20%)]\tLoss: 0.038074\n",
            "Train epoch: 420 [245940/25046 (31%)]\tLoss: 0.065237\n",
            "Train epoch: 420 [321360/25046 (41%)]\tLoss: 0.081845\n",
            "Train epoch: 420 [423900/25046 (51%)]\tLoss: 0.028841\n",
            "Train epoch: 420 [471000/25046 (61%)]\tLoss: 0.088725\n",
            "Train epoch: 420 [571060/25046 (71%)]\tLoss: 0.064123\n",
            "Train epoch: 420 [662080/25046 (82%)]\tLoss: 0.109508\n",
            "Train epoch: 420 [737280/25046 (92%)]\tLoss: 0.066536\n",
            "Make prediction for 5010 samples...\n",
            "0.25169003 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 421 [0/25046 (0%)]\tLoss: 0.041070\n",
            "Train epoch: 421 [82080/25046 (10%)]\tLoss: 0.039631\n",
            "Train epoch: 421 [164920/25046 (20%)]\tLoss: 0.035623\n",
            "Train epoch: 421 [250980/25046 (31%)]\tLoss: 0.040345\n",
            "Train epoch: 421 [329680/25046 (41%)]\tLoss: 0.026710\n",
            "Train epoch: 421 [410300/25046 (51%)]\tLoss: 0.067278\n",
            "Train epoch: 421 [512520/25046 (61%)]\tLoss: 0.038240\n",
            "Train epoch: 421 [571200/25046 (71%)]\tLoss: 0.029488\n",
            "Train epoch: 421 [650880/25046 (82%)]\tLoss: 0.031382\n",
            "Train epoch: 421 [736560/25046 (92%)]\tLoss: 0.058932\n",
            "Make prediction for 5010 samples...\n",
            "0.25664324 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 422 [0/25046 (0%)]\tLoss: 0.076762\n",
            "Train epoch: 422 [80740/25046 (10%)]\tLoss: 0.048446\n",
            "Train epoch: 422 [166960/25046 (20%)]\tLoss: 0.078810\n",
            "Train epoch: 422 [248520/25046 (31%)]\tLoss: 0.054811\n",
            "Train epoch: 422 [315600/25046 (41%)]\tLoss: 0.016139\n",
            "Train epoch: 422 [415600/25046 (51%)]\tLoss: 0.096989\n",
            "Train epoch: 422 [490560/25046 (61%)]\tLoss: 0.052064\n",
            "Train epoch: 422 [564620/25046 (71%)]\tLoss: 0.039255\n",
            "Train epoch: 422 [644800/25046 (82%)]\tLoss: 0.031397\n",
            "Train epoch: 422 [751320/25046 (92%)]\tLoss: 0.020290\n",
            "Make prediction for 5010 samples...\n",
            "0.25634468 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 423 [0/25046 (0%)]\tLoss: 0.069300\n",
            "Train epoch: 423 [82400/25046 (10%)]\tLoss: 0.032460\n",
            "Train epoch: 423 [169600/25046 (20%)]\tLoss: 0.052902\n",
            "Train epoch: 423 [246480/25046 (31%)]\tLoss: 0.041720\n",
            "Train epoch: 423 [331680/25046 (41%)]\tLoss: 0.022237\n",
            "Train epoch: 423 [412600/25046 (51%)]\tLoss: 0.043821\n",
            "Train epoch: 423 [500160/25046 (61%)]\tLoss: 0.023658\n",
            "Train epoch: 423 [577640/25046 (71%)]\tLoss: 0.115288\n",
            "Train epoch: 423 [643680/25046 (82%)]\tLoss: 0.034868\n",
            "Train epoch: 423 [741420/25046 (92%)]\tLoss: 0.015676\n",
            "Make prediction for 5010 samples...\n",
            "0.27414712 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 424 [0/25046 (0%)]\tLoss: 0.039669\n",
            "Train epoch: 424 [79500/25046 (10%)]\tLoss: 0.024743\n",
            "Train epoch: 424 [166520/25046 (20%)]\tLoss: 0.078842\n",
            "Train epoch: 424 [244860/25046 (31%)]\tLoss: 0.049913\n",
            "Train epoch: 424 [340640/25046 (41%)]\tLoss: 0.070241\n",
            "Train epoch: 424 [408200/25046 (51%)]\tLoss: 0.032127\n",
            "Train epoch: 424 [484320/25046 (61%)]\tLoss: 0.034850\n",
            "Train epoch: 424 [583100/25046 (71%)]\tLoss: 0.029223\n",
            "Train epoch: 424 [657280/25046 (82%)]\tLoss: 0.105095\n",
            "Train epoch: 424 [753120/25046 (92%)]\tLoss: 0.042771\n",
            "Make prediction for 5010 samples...\n",
            "0.2580755 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 425 [0/25046 (0%)]\tLoss: 0.064872\n",
            "Train epoch: 425 [83120/25046 (10%)]\tLoss: 0.038788\n",
            "Train epoch: 425 [165400/25046 (20%)]\tLoss: 0.029142\n",
            "Train epoch: 425 [245700/25046 (31%)]\tLoss: 0.054445\n",
            "Train epoch: 425 [322560/25046 (41%)]\tLoss: 0.093860\n",
            "Train epoch: 425 [415700/25046 (51%)]\tLoss: 0.174358\n",
            "Train epoch: 425 [493440/25046 (61%)]\tLoss: 0.065430\n",
            "Train epoch: 425 [572740/25046 (71%)]\tLoss: 0.067730\n",
            "Train epoch: 425 [649920/25046 (82%)]\tLoss: 0.043464\n",
            "Train epoch: 425 [748080/25046 (92%)]\tLoss: 0.044087\n",
            "Make prediction for 5010 samples...\n",
            "0.25299838 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 426 [0/25046 (0%)]\tLoss: 0.035100\n",
            "Train epoch: 426 [83080/25046 (10%)]\tLoss: 0.100421\n",
            "Train epoch: 426 [161360/25046 (20%)]\tLoss: 0.023327\n",
            "Train epoch: 426 [254760/25046 (31%)]\tLoss: 0.045172\n",
            "Train epoch: 426 [323680/25046 (41%)]\tLoss: 0.019370\n",
            "Train epoch: 426 [405000/25046 (51%)]\tLoss: 0.041093\n",
            "Train epoch: 426 [493680/25046 (61%)]\tLoss: 0.047218\n",
            "Train epoch: 426 [577500/25046 (71%)]\tLoss: 0.057208\n",
            "Train epoch: 426 [665120/25046 (82%)]\tLoss: 0.027524\n",
            "Train epoch: 426 [752040/25046 (92%)]\tLoss: 0.045957\n",
            "Make prediction for 5010 samples...\n",
            "0.2582763 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 427 [0/25046 (0%)]\tLoss: 0.031866\n",
            "Train epoch: 427 [83360/25046 (10%)]\tLoss: 0.073426\n",
            "Train epoch: 427 [162320/25046 (20%)]\tLoss: 0.040060\n",
            "Train epoch: 427 [251100/25046 (31%)]\tLoss: 0.061693\n",
            "Train epoch: 427 [336000/25046 (41%)]\tLoss: 0.051635\n",
            "Train epoch: 427 [414500/25046 (51%)]\tLoss: 0.032223\n",
            "Train epoch: 427 [483600/25046 (61%)]\tLoss: 0.095578\n",
            "Train epoch: 427 [558320/25046 (71%)]\tLoss: 0.030608\n",
            "Train epoch: 427 [658080/25046 (82%)]\tLoss: 0.068383\n",
            "Train epoch: 427 [745020/25046 (92%)]\tLoss: 0.074852\n",
            "Make prediction for 5010 samples...\n",
            "0.2518784 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 428 [0/25046 (0%)]\tLoss: 0.056459\n",
            "Train epoch: 428 [81060/25046 (10%)]\tLoss: 0.034530\n",
            "Train epoch: 428 [163880/25046 (20%)]\tLoss: 0.023769\n",
            "Train epoch: 428 [245160/25046 (31%)]\tLoss: 0.052626\n",
            "Train epoch: 428 [336000/25046 (41%)]\tLoss: 0.077517\n",
            "Train epoch: 428 [423200/25046 (51%)]\tLoss: 0.057005\n",
            "Train epoch: 428 [495360/25046 (61%)]\tLoss: 0.066683\n",
            "Train epoch: 428 [582820/25046 (71%)]\tLoss: 0.045446\n",
            "Train epoch: 428 [631200/25046 (82%)]\tLoss: 0.049810\n",
            "Train epoch: 428 [740340/25046 (92%)]\tLoss: 0.044614\n",
            "Make prediction for 5010 samples...\n",
            "0.25092208 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 429 [0/25046 (0%)]\tLoss: 0.024570\n",
            "Train epoch: 429 [79940/25046 (10%)]\tLoss: 0.059842\n",
            "Train epoch: 429 [166880/25046 (20%)]\tLoss: 0.101193\n",
            "Train epoch: 429 [240840/25046 (31%)]\tLoss: 0.047629\n",
            "Train epoch: 429 [321120/25046 (41%)]\tLoss: 0.035185\n",
            "Train epoch: 429 [407600/25046 (51%)]\tLoss: 0.047353\n",
            "Train epoch: 429 [497160/25046 (61%)]\tLoss: 0.053564\n",
            "Train epoch: 429 [572740/25046 (71%)]\tLoss: 0.037072\n",
            "Train epoch: 429 [656480/25046 (82%)]\tLoss: 0.054367\n",
            "Train epoch: 429 [732420/25046 (92%)]\tLoss: 0.035317\n",
            "Make prediction for 5010 samples...\n",
            "0.24742977 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 430 [0/25046 (0%)]\tLoss: 0.057172\n",
            "Train epoch: 430 [83120/25046 (10%)]\tLoss: 0.056619\n",
            "Train epoch: 430 [165160/25046 (20%)]\tLoss: 0.068500\n",
            "Train epoch: 430 [239640/25046 (31%)]\tLoss: 0.067240\n",
            "Train epoch: 430 [329680/25046 (41%)]\tLoss: 0.027271\n",
            "Train epoch: 430 [410100/25046 (51%)]\tLoss: 0.046417\n",
            "Train epoch: 430 [473520/25046 (61%)]\tLoss: 0.013834\n",
            "Train epoch: 430 [568400/25046 (71%)]\tLoss: 0.033102\n",
            "Train epoch: 430 [649440/25046 (82%)]\tLoss: 0.034625\n",
            "Train epoch: 430 [721080/25046 (92%)]\tLoss: 0.022671\n",
            "Make prediction for 5010 samples...\n",
            "0.25388905 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 431 [0/25046 (0%)]\tLoss: 0.078956\n",
            "Train epoch: 431 [80260/25046 (10%)]\tLoss: 0.039680\n",
            "Train epoch: 431 [168040/25046 (20%)]\tLoss: 0.057242\n",
            "Train epoch: 431 [241980/25046 (31%)]\tLoss: 0.053180\n",
            "Train epoch: 431 [325760/25046 (41%)]\tLoss: 0.033434\n",
            "Train epoch: 431 [412300/25046 (51%)]\tLoss: 0.032256\n",
            "Train epoch: 431 [483120/25046 (61%)]\tLoss: 0.036578\n",
            "Train epoch: 431 [563080/25046 (71%)]\tLoss: 0.035478\n",
            "Train epoch: 431 [639520/25046 (82%)]\tLoss: 0.060597\n",
            "Train epoch: 431 [732780/25046 (92%)]\tLoss: 0.024627\n",
            "Make prediction for 5010 samples...\n",
            "0.25609127 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 432 [0/25046 (0%)]\tLoss: 0.059383\n",
            "Train epoch: 432 [83280/25046 (10%)]\tLoss: 0.038493\n",
            "Train epoch: 432 [163880/25046 (20%)]\tLoss: 0.030910\n",
            "Train epoch: 432 [250620/25046 (31%)]\tLoss: 0.103554\n",
            "Train epoch: 432 [332400/25046 (41%)]\tLoss: 0.170622\n",
            "Train epoch: 432 [405200/25046 (51%)]\tLoss: 0.019582\n",
            "Train epoch: 432 [487560/25046 (61%)]\tLoss: 0.051347\n",
            "Train epoch: 432 [567700/25046 (71%)]\tLoss: 0.033961\n",
            "Train epoch: 432 [668320/25046 (82%)]\tLoss: 0.061935\n",
            "Train epoch: 432 [731160/25046 (92%)]\tLoss: 0.061933\n",
            "Make prediction for 5010 samples...\n",
            "0.26165602 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 433 [0/25046 (0%)]\tLoss: 0.061457\n",
            "Train epoch: 433 [80080/25046 (10%)]\tLoss: 0.040732\n",
            "Train epoch: 433 [160040/25046 (20%)]\tLoss: 0.050455\n",
            "Train epoch: 433 [249180/25046 (31%)]\tLoss: 0.056056\n",
            "Train epoch: 433 [337440/25046 (41%)]\tLoss: 0.061638\n",
            "Train epoch: 433 [405400/25046 (51%)]\tLoss: 0.053953\n",
            "Train epoch: 433 [488880/25046 (61%)]\tLoss: 0.023083\n",
            "Train epoch: 433 [569800/25046 (71%)]\tLoss: 0.052034\n",
            "Train epoch: 433 [640800/25046 (82%)]\tLoss: 0.037282\n",
            "Train epoch: 433 [782460/25046 (92%)]\tLoss: 0.043827\n",
            "Make prediction for 5010 samples...\n",
            "0.25351605 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 434 [0/25046 (0%)]\tLoss: 0.022155\n",
            "Train epoch: 434 [82420/25046 (10%)]\tLoss: 0.023756\n",
            "Train epoch: 434 [162760/25046 (20%)]\tLoss: 0.044369\n",
            "Train epoch: 434 [246900/25046 (31%)]\tLoss: 0.144527\n",
            "Train epoch: 434 [333440/25046 (41%)]\tLoss: 0.049683\n",
            "Train epoch: 434 [407500/25046 (51%)]\tLoss: 0.036648\n",
            "Train epoch: 434 [490920/25046 (61%)]\tLoss: 0.033031\n",
            "Train epoch: 434 [592760/25046 (71%)]\tLoss: 0.034056\n",
            "Train epoch: 434 [654240/25046 (82%)]\tLoss: 0.073692\n",
            "Train epoch: 434 [750420/25046 (92%)]\tLoss: 0.028327\n",
            "Make prediction for 5010 samples...\n",
            "0.2592407 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 435 [0/25046 (0%)]\tLoss: 0.045934\n",
            "Train epoch: 435 [84120/25046 (10%)]\tLoss: 0.070889\n",
            "Train epoch: 435 [163600/25046 (20%)]\tLoss: 0.018560\n",
            "Train epoch: 435 [247500/25046 (31%)]\tLoss: 0.024220\n",
            "Train epoch: 435 [335520/25046 (41%)]\tLoss: 0.053889\n",
            "Train epoch: 435 [420700/25046 (51%)]\tLoss: 0.042828\n",
            "Train epoch: 435 [483960/25046 (61%)]\tLoss: 0.030559\n",
            "Train epoch: 435 [590940/25046 (71%)]\tLoss: 0.036516\n",
            "Train epoch: 435 [662240/25046 (82%)]\tLoss: 0.063681\n",
            "Train epoch: 435 [742860/25046 (92%)]\tLoss: 0.046731\n",
            "Make prediction for 5010 samples...\n",
            "0.253753 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 436 [0/25046 (0%)]\tLoss: 0.042711\n",
            "Train epoch: 436 [84880/25046 (10%)]\tLoss: 0.067146\n",
            "Train epoch: 436 [161360/25046 (20%)]\tLoss: 0.036050\n",
            "Train epoch: 436 [254460/25046 (31%)]\tLoss: 0.057653\n",
            "Train epoch: 436 [323120/25046 (41%)]\tLoss: 0.041531\n",
            "Train epoch: 436 [422700/25046 (51%)]\tLoss: 0.030263\n",
            "Train epoch: 436 [483960/25046 (61%)]\tLoss: 0.076202\n",
            "Train epoch: 436 [575680/25046 (71%)]\tLoss: 0.107215\n",
            "Train epoch: 436 [649760/25046 (82%)]\tLoss: 0.042242\n",
            "Train epoch: 436 [754380/25046 (92%)]\tLoss: 0.105738\n",
            "Make prediction for 5010 samples...\n",
            "0.2524608 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 437 [0/25046 (0%)]\tLoss: 0.042389\n",
            "Train epoch: 437 [84540/25046 (10%)]\tLoss: 0.035321\n",
            "Train epoch: 437 [166040/25046 (20%)]\tLoss: 0.089793\n",
            "Train epoch: 437 [247920/25046 (31%)]\tLoss: 0.049880\n",
            "Train epoch: 437 [334800/25046 (41%)]\tLoss: 0.044898\n",
            "Train epoch: 437 [405700/25046 (51%)]\tLoss: 0.032291\n",
            "Train epoch: 437 [497040/25046 (61%)]\tLoss: 0.040168\n",
            "Train epoch: 437 [579460/25046 (71%)]\tLoss: 0.041996\n",
            "Train epoch: 437 [665600/25046 (82%)]\tLoss: 0.070568\n",
            "Train epoch: 437 [739260/25046 (92%)]\tLoss: 0.087927\n",
            "Make prediction for 5010 samples...\n",
            "0.255762 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 438 [0/25046 (0%)]\tLoss: 0.055618\n",
            "Train epoch: 438 [80720/25046 (10%)]\tLoss: 0.018813\n",
            "Train epoch: 438 [165400/25046 (20%)]\tLoss: 0.031287\n",
            "Train epoch: 438 [245760/25046 (31%)]\tLoss: 0.082462\n",
            "Train epoch: 438 [327520/25046 (41%)]\tLoss: 0.023124\n",
            "Train epoch: 438 [415000/25046 (51%)]\tLoss: 0.030589\n",
            "Train epoch: 438 [495360/25046 (61%)]\tLoss: 0.031429\n",
            "Train epoch: 438 [581000/25046 (71%)]\tLoss: 0.044906\n",
            "Train epoch: 438 [649760/25046 (82%)]\tLoss: 0.076678\n",
            "Train epoch: 438 [757440/25046 (92%)]\tLoss: 0.041892\n",
            "Make prediction for 5010 samples...\n",
            "0.25783888 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 439 [0/25046 (0%)]\tLoss: 0.044420\n",
            "Train epoch: 439 [82500/25046 (10%)]\tLoss: 0.092226\n",
            "Train epoch: 439 [159520/25046 (20%)]\tLoss: 0.061205\n",
            "Train epoch: 439 [240600/25046 (31%)]\tLoss: 0.048868\n",
            "Train epoch: 439 [323680/25046 (41%)]\tLoss: 0.144033\n",
            "Train epoch: 439 [415300/25046 (51%)]\tLoss: 0.038992\n",
            "Train epoch: 439 [494640/25046 (61%)]\tLoss: 0.053700\n",
            "Train epoch: 439 [567700/25046 (71%)]\tLoss: 0.052844\n",
            "Train epoch: 439 [665440/25046 (82%)]\tLoss: 0.028824\n",
            "Train epoch: 439 [751680/25046 (92%)]\tLoss: 0.046611\n",
            "Make prediction for 5010 samples...\n",
            "0.2520778 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 440 [0/25046 (0%)]\tLoss: 0.042462\n",
            "Train epoch: 440 [83660/25046 (10%)]\tLoss: 0.043199\n",
            "Train epoch: 440 [164880/25046 (20%)]\tLoss: 0.049471\n",
            "Train epoch: 440 [252240/25046 (31%)]\tLoss: 0.032548\n",
            "Train epoch: 440 [321360/25046 (41%)]\tLoss: 0.045259\n",
            "Train epoch: 440 [411800/25046 (51%)]\tLoss: 0.045122\n",
            "Train epoch: 440 [492360/25046 (61%)]\tLoss: 0.058302\n",
            "Train epoch: 440 [583380/25046 (71%)]\tLoss: 0.041833\n",
            "Train epoch: 440 [651680/25046 (82%)]\tLoss: 0.031165\n",
            "Train epoch: 440 [738360/25046 (92%)]\tLoss: 0.044791\n",
            "Make prediction for 5010 samples...\n",
            "0.26291302 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 441 [0/25046 (0%)]\tLoss: 0.024276\n",
            "Train epoch: 441 [81700/25046 (10%)]\tLoss: 0.065054\n",
            "Train epoch: 441 [163680/25046 (20%)]\tLoss: 0.045978\n",
            "Train epoch: 441 [244620/25046 (31%)]\tLoss: 0.051835\n",
            "Train epoch: 441 [330480/25046 (41%)]\tLoss: 0.079875\n",
            "Train epoch: 441 [409700/25046 (51%)]\tLoss: 0.073097\n",
            "Train epoch: 441 [486840/25046 (61%)]\tLoss: 0.031015\n",
            "Train epoch: 441 [571760/25046 (71%)]\tLoss: 0.092070\n",
            "Train epoch: 441 [651680/25046 (82%)]\tLoss: 0.040283\n",
            "Train epoch: 441 [761040/25046 (92%)]\tLoss: 0.047893\n",
            "Make prediction for 5010 samples...\n",
            "0.26012567 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 442 [0/25046 (0%)]\tLoss: 0.044059\n",
            "Train epoch: 442 [81300/25046 (10%)]\tLoss: 0.039531\n",
            "Train epoch: 442 [169440/25046 (20%)]\tLoss: 0.065992\n",
            "Train epoch: 442 [244980/25046 (31%)]\tLoss: 0.034941\n",
            "Train epoch: 442 [330640/25046 (41%)]\tLoss: 0.028339\n",
            "Train epoch: 442 [421400/25046 (51%)]\tLoss: 0.064818\n",
            "Train epoch: 442 [478920/25046 (61%)]\tLoss: 0.085892\n",
            "Train epoch: 442 [576380/25046 (71%)]\tLoss: 0.029735\n",
            "Train epoch: 442 [677440/25046 (82%)]\tLoss: 0.080378\n",
            "Train epoch: 442 [770580/25046 (92%)]\tLoss: 0.096175\n",
            "Make prediction for 5010 samples...\n",
            "0.26454532 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 443 [0/25046 (0%)]\tLoss: 0.079325\n",
            "Train epoch: 443 [81020/25046 (10%)]\tLoss: 0.042031\n",
            "Train epoch: 443 [162200/25046 (20%)]\tLoss: 0.097570\n",
            "Train epoch: 443 [249840/25046 (31%)]\tLoss: 0.050424\n",
            "Train epoch: 443 [332000/25046 (41%)]\tLoss: 0.079734\n",
            "Train epoch: 443 [406600/25046 (51%)]\tLoss: 0.040512\n",
            "Train epoch: 443 [486960/25046 (61%)]\tLoss: 0.052873\n",
            "Train epoch: 443 [571060/25046 (71%)]\tLoss: 0.063176\n",
            "Train epoch: 443 [657760/25046 (82%)]\tLoss: 0.033396\n",
            "Train epoch: 443 [738180/25046 (92%)]\tLoss: 0.027595\n",
            "Make prediction for 5010 samples...\n",
            "0.25555524 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 444 [0/25046 (0%)]\tLoss: 0.062393\n",
            "Train epoch: 444 [82280/25046 (10%)]\tLoss: 0.101108\n",
            "Train epoch: 444 [164080/25046 (20%)]\tLoss: 0.026569\n",
            "Train epoch: 444 [245460/25046 (31%)]\tLoss: 0.049100\n",
            "Train epoch: 444 [338320/25046 (41%)]\tLoss: 0.065421\n",
            "Train epoch: 444 [407700/25046 (51%)]\tLoss: 0.040891\n",
            "Train epoch: 444 [489360/25046 (61%)]\tLoss: 0.074972\n",
            "Train epoch: 444 [589120/25046 (71%)]\tLoss: 0.116455\n",
            "Train epoch: 444 [653440/25046 (82%)]\tLoss: 0.031165\n",
            "Train epoch: 444 [745380/25046 (92%)]\tLoss: 0.040167\n",
            "Make prediction for 5010 samples...\n",
            "0.25802407 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 445 [0/25046 (0%)]\tLoss: 0.044371\n",
            "Train epoch: 445 [82120/25046 (10%)]\tLoss: 0.034086\n",
            "Train epoch: 445 [164040/25046 (20%)]\tLoss: 0.031493\n",
            "Train epoch: 445 [255180/25046 (31%)]\tLoss: 0.083609\n",
            "Train epoch: 445 [333520/25046 (41%)]\tLoss: 0.054014\n",
            "Train epoch: 445 [421200/25046 (51%)]\tLoss: 0.050531\n",
            "Train epoch: 445 [501600/25046 (61%)]\tLoss: 0.039030\n",
            "Train epoch: 445 [569100/25046 (71%)]\tLoss: 0.066342\n",
            "Train epoch: 445 [668480/25046 (82%)]\tLoss: 0.059160\n",
            "Train epoch: 445 [736560/25046 (92%)]\tLoss: 0.073384\n",
            "Make prediction for 5010 samples...\n",
            "0.26050314 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 446 [0/25046 (0%)]\tLoss: 0.030265\n",
            "Train epoch: 446 [82540/25046 (10%)]\tLoss: 0.047746\n",
            "Train epoch: 446 [162160/25046 (20%)]\tLoss: 0.024140\n",
            "Train epoch: 446 [251280/25046 (31%)]\tLoss: 0.029359\n",
            "Train epoch: 446 [340560/25046 (41%)]\tLoss: 0.079947\n",
            "Train epoch: 446 [415000/25046 (51%)]\tLoss: 0.050671\n",
            "Train epoch: 446 [486480/25046 (61%)]\tLoss: 0.036498\n",
            "Train epoch: 446 [586740/25046 (71%)]\tLoss: 0.050780\n",
            "Train epoch: 446 [668800/25046 (82%)]\tLoss: 0.055638\n",
            "Train epoch: 446 [741780/25046 (92%)]\tLoss: 0.057130\n",
            "Make prediction for 5010 samples...\n",
            "0.2520463 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 447 [0/25046 (0%)]\tLoss: 0.028806\n",
            "Train epoch: 447 [80960/25046 (10%)]\tLoss: 0.091030\n",
            "Train epoch: 447 [164920/25046 (20%)]\tLoss: 0.031136\n",
            "Train epoch: 447 [252000/25046 (31%)]\tLoss: 0.145689\n",
            "Train epoch: 447 [335920/25046 (41%)]\tLoss: 0.046563\n",
            "Train epoch: 447 [414400/25046 (51%)]\tLoss: 0.026333\n",
            "Train epoch: 447 [487800/25046 (61%)]\tLoss: 0.023912\n",
            "Train epoch: 447 [594160/25046 (71%)]\tLoss: 0.061521\n",
            "Train epoch: 447 [675200/25046 (82%)]\tLoss: 0.071682\n",
            "Train epoch: 447 [760860/25046 (92%)]\tLoss: 0.058000\n",
            "Make prediction for 5010 samples...\n",
            "0.25875765 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 448 [0/25046 (0%)]\tLoss: 0.034878\n",
            "Train epoch: 448 [83120/25046 (10%)]\tLoss: 0.110717\n",
            "Train epoch: 448 [162440/25046 (20%)]\tLoss: 0.058204\n",
            "Train epoch: 448 [251400/25046 (31%)]\tLoss: 0.025007\n",
            "Train epoch: 448 [326640/25046 (41%)]\tLoss: 0.052350\n",
            "Train epoch: 448 [415800/25046 (51%)]\tLoss: 0.042262\n",
            "Train epoch: 448 [480480/25046 (61%)]\tLoss: 0.085463\n",
            "Train epoch: 448 [574420/25046 (71%)]\tLoss: 0.035426\n",
            "Train epoch: 448 [649920/25046 (82%)]\tLoss: 0.149920\n",
            "Train epoch: 448 [719100/25046 (92%)]\tLoss: 0.113830\n",
            "Make prediction for 5010 samples...\n",
            "0.25236538 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 449 [0/25046 (0%)]\tLoss: 0.046073\n",
            "Train epoch: 449 [80140/25046 (10%)]\tLoss: 0.054779\n",
            "Train epoch: 449 [163000/25046 (20%)]\tLoss: 0.034730\n",
            "Train epoch: 449 [241620/25046 (31%)]\tLoss: 0.046707\n",
            "Train epoch: 449 [327360/25046 (41%)]\tLoss: 0.046254\n",
            "Train epoch: 449 [401900/25046 (51%)]\tLoss: 0.028913\n",
            "Train epoch: 449 [490200/25046 (61%)]\tLoss: 0.061073\n",
            "Train epoch: 449 [581560/25046 (71%)]\tLoss: 0.088006\n",
            "Train epoch: 449 [657920/25046 (82%)]\tLoss: 0.062469\n",
            "Train epoch: 449 [745200/25046 (92%)]\tLoss: 0.046468\n",
            "Make prediction for 5010 samples...\n",
            "0.25071317 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 450 [0/25046 (0%)]\tLoss: 0.036574\n",
            "Train epoch: 450 [81200/25046 (10%)]\tLoss: 0.049527\n",
            "Train epoch: 450 [163720/25046 (20%)]\tLoss: 0.038164\n",
            "Train epoch: 450 [246060/25046 (31%)]\tLoss: 0.030460\n",
            "Train epoch: 450 [336400/25046 (41%)]\tLoss: 0.042796\n",
            "Train epoch: 450 [419100/25046 (51%)]\tLoss: 0.090204\n",
            "Train epoch: 450 [497160/25046 (61%)]\tLoss: 0.056616\n",
            "Train epoch: 450 [579460/25046 (71%)]\tLoss: 0.024194\n",
            "Train epoch: 450 [649600/25046 (82%)]\tLoss: 0.075162\n",
            "Train epoch: 450 [746100/25046 (92%)]\tLoss: 0.038148\n",
            "Make prediction for 5010 samples...\n",
            "0.26136076 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 451 [0/25046 (0%)]\tLoss: 0.047156\n",
            "Train epoch: 451 [82900/25046 (10%)]\tLoss: 0.082530\n",
            "Train epoch: 451 [168360/25046 (20%)]\tLoss: 0.097658\n",
            "Train epoch: 451 [244440/25046 (31%)]\tLoss: 0.069842\n",
            "Train epoch: 451 [332640/25046 (41%)]\tLoss: 0.051173\n",
            "Train epoch: 451 [412700/25046 (51%)]\tLoss: 0.027024\n",
            "Train epoch: 451 [501840/25046 (61%)]\tLoss: 0.042781\n",
            "Train epoch: 451 [577080/25046 (71%)]\tLoss: 0.160151\n",
            "Train epoch: 451 [653120/25046 (82%)]\tLoss: 0.028965\n",
            "Train epoch: 451 [703620/25046 (92%)]\tLoss: 0.051717\n",
            "Make prediction for 5010 samples...\n",
            "0.25616404 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 452 [0/25046 (0%)]\tLoss: 0.045884\n",
            "Train epoch: 452 [82160/25046 (10%)]\tLoss: 0.032276\n",
            "Train epoch: 452 [163560/25046 (20%)]\tLoss: 0.037673\n",
            "Train epoch: 452 [246060/25046 (31%)]\tLoss: 0.025726\n",
            "Train epoch: 452 [323760/25046 (41%)]\tLoss: 0.042495\n",
            "Train epoch: 452 [401700/25046 (51%)]\tLoss: 0.046476\n",
            "Train epoch: 452 [494400/25046 (61%)]\tLoss: 0.034104\n",
            "Train epoch: 452 [579320/25046 (71%)]\tLoss: 0.027649\n",
            "Train epoch: 452 [656800/25046 (82%)]\tLoss: 0.048092\n",
            "Train epoch: 452 [743220/25046 (92%)]\tLoss: 0.058249\n",
            "Make prediction for 5010 samples...\n",
            "0.25660077 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 453 [0/25046 (0%)]\tLoss: 0.078491\n",
            "Train epoch: 453 [81040/25046 (10%)]\tLoss: 0.100182\n",
            "Train epoch: 453 [162320/25046 (20%)]\tLoss: 0.044763\n",
            "Train epoch: 453 [248700/25046 (31%)]\tLoss: 0.044572\n",
            "Train epoch: 453 [325360/25046 (41%)]\tLoss: 0.034573\n",
            "Train epoch: 453 [407200/25046 (51%)]\tLoss: 0.062797\n",
            "Train epoch: 453 [488760/25046 (61%)]\tLoss: 0.074322\n",
            "Train epoch: 453 [567000/25046 (71%)]\tLoss: 0.036498\n",
            "Train epoch: 453 [674240/25046 (82%)]\tLoss: 0.060411\n",
            "Train epoch: 453 [757440/25046 (92%)]\tLoss: 0.048483\n",
            "Make prediction for 5010 samples...\n",
            "0.24952991 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 454 [0/25046 (0%)]\tLoss: 0.076328\n",
            "Train epoch: 454 [84180/25046 (10%)]\tLoss: 0.124788\n",
            "Train epoch: 454 [165680/25046 (20%)]\tLoss: 0.035071\n",
            "Train epoch: 454 [243540/25046 (31%)]\tLoss: 0.067380\n",
            "Train epoch: 454 [328000/25046 (41%)]\tLoss: 0.087562\n",
            "Train epoch: 454 [413600/25046 (51%)]\tLoss: 0.032853\n",
            "Train epoch: 454 [492600/25046 (61%)]\tLoss: 0.066349\n",
            "Train epoch: 454 [557200/25046 (71%)]\tLoss: 0.104814\n",
            "Train epoch: 454 [655680/25046 (82%)]\tLoss: 0.036732\n",
            "Train epoch: 454 [735120/25046 (92%)]\tLoss: 0.048200\n",
            "Make prediction for 5010 samples...\n",
            "0.25703067 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 455 [0/25046 (0%)]\tLoss: 0.054535\n",
            "Train epoch: 455 [82580/25046 (10%)]\tLoss: 0.041935\n",
            "Train epoch: 455 [163520/25046 (20%)]\tLoss: 0.086015\n",
            "Train epoch: 455 [240840/25046 (31%)]\tLoss: 0.042175\n",
            "Train epoch: 455 [333040/25046 (41%)]\tLoss: 0.064805\n",
            "Train epoch: 455 [398000/25046 (51%)]\tLoss: 0.078326\n",
            "Train epoch: 455 [493680/25046 (61%)]\tLoss: 0.034540\n",
            "Train epoch: 455 [567980/25046 (71%)]\tLoss: 0.047822\n",
            "Train epoch: 455 [662400/25046 (82%)]\tLoss: 0.102792\n",
            "Train epoch: 455 [727920/25046 (92%)]\tLoss: 0.021041\n",
            "Make prediction for 5010 samples...\n",
            "0.24701752 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 456 [0/25046 (0%)]\tLoss: 0.057253\n",
            "Train epoch: 456 [80780/25046 (10%)]\tLoss: 0.026516\n",
            "Train epoch: 456 [161200/25046 (20%)]\tLoss: 0.074022\n",
            "Train epoch: 456 [249780/25046 (31%)]\tLoss: 0.023034\n",
            "Train epoch: 456 [331680/25046 (41%)]\tLoss: 0.036832\n",
            "Train epoch: 456 [408100/25046 (51%)]\tLoss: 0.062341\n",
            "Train epoch: 456 [489360/25046 (61%)]\tLoss: 0.067829\n",
            "Train epoch: 456 [577920/25046 (71%)]\tLoss: 0.054624\n",
            "Train epoch: 456 [650400/25046 (82%)]\tLoss: 0.090689\n",
            "Train epoch: 456 [736380/25046 (92%)]\tLoss: 0.051576\n",
            "Make prediction for 5010 samples...\n",
            "0.26211745 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 457 [0/25046 (0%)]\tLoss: 0.038140\n",
            "Train epoch: 457 [84280/25046 (10%)]\tLoss: 0.064187\n",
            "Train epoch: 457 [163600/25046 (20%)]\tLoss: 0.023421\n",
            "Train epoch: 457 [249120/25046 (31%)]\tLoss: 0.033581\n",
            "Train epoch: 457 [324480/25046 (41%)]\tLoss: 0.034886\n",
            "Train epoch: 457 [397400/25046 (51%)]\tLoss: 0.087715\n",
            "Train epoch: 457 [488640/25046 (61%)]\tLoss: 0.036055\n",
            "Train epoch: 457 [574840/25046 (71%)]\tLoss: 0.037799\n",
            "Train epoch: 457 [645600/25046 (82%)]\tLoss: 0.026315\n",
            "Train epoch: 457 [751500/25046 (92%)]\tLoss: 0.108005\n",
            "Make prediction for 5010 samples...\n",
            "0.2566891 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 458 [0/25046 (0%)]\tLoss: 0.085885\n",
            "Train epoch: 458 [84360/25046 (10%)]\tLoss: 0.035856\n",
            "Train epoch: 458 [165160/25046 (20%)]\tLoss: 0.040348\n",
            "Train epoch: 458 [246960/25046 (31%)]\tLoss: 0.061980\n",
            "Train epoch: 458 [317200/25046 (41%)]\tLoss: 0.024113\n",
            "Train epoch: 458 [407500/25046 (51%)]\tLoss: 0.053230\n",
            "Train epoch: 458 [500640/25046 (61%)]\tLoss: 0.036029\n",
            "Train epoch: 458 [576100/25046 (71%)]\tLoss: 0.025178\n",
            "Train epoch: 458 [646880/25046 (82%)]\tLoss: 0.065729\n",
            "Train epoch: 458 [740160/25046 (92%)]\tLoss: 0.057020\n",
            "Make prediction for 5010 samples...\n",
            "0.26639387 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 459 [0/25046 (0%)]\tLoss: 0.019052\n",
            "Train epoch: 459 [82680/25046 (10%)]\tLoss: 0.045836\n",
            "Train epoch: 459 [164680/25046 (20%)]\tLoss: 0.059757\n",
            "Train epoch: 459 [249660/25046 (31%)]\tLoss: 0.117913\n",
            "Train epoch: 459 [323840/25046 (41%)]\tLoss: 0.025651\n",
            "Train epoch: 459 [420500/25046 (51%)]\tLoss: 0.023154\n",
            "Train epoch: 459 [493440/25046 (61%)]\tLoss: 0.022753\n",
            "Train epoch: 459 [578200/25046 (71%)]\tLoss: 0.019026\n",
            "Train epoch: 459 [651840/25046 (82%)]\tLoss: 0.048181\n",
            "Train epoch: 459 [764460/25046 (92%)]\tLoss: 0.025573\n",
            "Make prediction for 5010 samples...\n",
            "0.2595365 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 460 [0/25046 (0%)]\tLoss: 0.032322\n",
            "Train epoch: 460 [82960/25046 (10%)]\tLoss: 0.069049\n",
            "Train epoch: 460 [162120/25046 (20%)]\tLoss: 0.087876\n",
            "Train epoch: 460 [247980/25046 (31%)]\tLoss: 0.017611\n",
            "Train epoch: 460 [326240/25046 (41%)]\tLoss: 0.046131\n",
            "Train epoch: 460 [405000/25046 (51%)]\tLoss: 0.049632\n",
            "Train epoch: 460 [494520/25046 (61%)]\tLoss: 0.026524\n",
            "Train epoch: 460 [573160/25046 (71%)]\tLoss: 0.048604\n",
            "Train epoch: 460 [658880/25046 (82%)]\tLoss: 0.057557\n",
            "Train epoch: 460 [745380/25046 (92%)]\tLoss: 0.027400\n",
            "Make prediction for 5010 samples...\n",
            "0.25232875 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 461 [0/25046 (0%)]\tLoss: 0.042741\n",
            "Train epoch: 461 [81220/25046 (10%)]\tLoss: 0.050620\n",
            "Train epoch: 461 [166400/25046 (20%)]\tLoss: 0.035312\n",
            "Train epoch: 461 [239580/25046 (31%)]\tLoss: 0.059083\n",
            "Train epoch: 461 [326560/25046 (41%)]\tLoss: 0.023469\n",
            "Train epoch: 461 [396900/25046 (51%)]\tLoss: 0.042529\n",
            "Train epoch: 461 [488520/25046 (61%)]\tLoss: 0.049042\n",
            "Train epoch: 461 [568120/25046 (71%)]\tLoss: 0.026046\n",
            "Train epoch: 461 [656160/25046 (82%)]\tLoss: 0.028643\n",
            "Train epoch: 461 [722880/25046 (92%)]\tLoss: 0.047893\n",
            "Make prediction for 5010 samples...\n",
            "0.26250532 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 462 [0/25046 (0%)]\tLoss: 0.060876\n",
            "Train epoch: 462 [84320/25046 (10%)]\tLoss: 0.048278\n",
            "Train epoch: 462 [163760/25046 (20%)]\tLoss: 0.047842\n",
            "Train epoch: 462 [245460/25046 (31%)]\tLoss: 0.074481\n",
            "Train epoch: 462 [330320/25046 (41%)]\tLoss: 0.046069\n",
            "Train epoch: 462 [406000/25046 (51%)]\tLoss: 0.036261\n",
            "Train epoch: 462 [498240/25046 (61%)]\tLoss: 0.067709\n",
            "Train epoch: 462 [578620/25046 (71%)]\tLoss: 0.026928\n",
            "Train epoch: 462 [665280/25046 (82%)]\tLoss: 0.028886\n",
            "Train epoch: 462 [762660/25046 (92%)]\tLoss: 0.035647\n",
            "Make prediction for 5010 samples...\n",
            "0.25172588 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 463 [0/25046 (0%)]\tLoss: 0.029159\n",
            "Train epoch: 463 [79960/25046 (10%)]\tLoss: 0.026675\n",
            "Train epoch: 463 [164280/25046 (20%)]\tLoss: 0.048672\n",
            "Train epoch: 463 [246600/25046 (31%)]\tLoss: 0.026754\n",
            "Train epoch: 463 [326640/25046 (41%)]\tLoss: 0.035220\n",
            "Train epoch: 463 [399300/25046 (51%)]\tLoss: 0.017578\n",
            "Train epoch: 463 [487920/25046 (61%)]\tLoss: 0.048512\n",
            "Train epoch: 463 [581840/25046 (71%)]\tLoss: 0.060187\n",
            "Train epoch: 463 [654240/25046 (82%)]\tLoss: 0.068703\n",
            "Train epoch: 463 [738900/25046 (92%)]\tLoss: 0.036999\n",
            "Make prediction for 5010 samples...\n",
            "0.2544551 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 464 [0/25046 (0%)]\tLoss: 0.043621\n",
            "Train epoch: 464 [81620/25046 (10%)]\tLoss: 0.028530\n",
            "Train epoch: 464 [166080/25046 (20%)]\tLoss: 0.063579\n",
            "Train epoch: 464 [241500/25046 (31%)]\tLoss: 0.049331\n",
            "Train epoch: 464 [333600/25046 (41%)]\tLoss: 0.043881\n",
            "Train epoch: 464 [400300/25046 (51%)]\tLoss: 0.026498\n",
            "Train epoch: 464 [499920/25046 (61%)]\tLoss: 0.122291\n",
            "Train epoch: 464 [580020/25046 (71%)]\tLoss: 0.050921\n",
            "Train epoch: 464 [651360/25046 (82%)]\tLoss: 0.046259\n",
            "Train epoch: 464 [743400/25046 (92%)]\tLoss: 0.067022\n",
            "Make prediction for 5010 samples...\n",
            "0.2544316 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 465 [0/25046 (0%)]\tLoss: 0.064509\n",
            "Train epoch: 465 [84080/25046 (10%)]\tLoss: 0.023962\n",
            "Train epoch: 465 [163840/25046 (20%)]\tLoss: 0.045039\n",
            "Train epoch: 465 [243180/25046 (31%)]\tLoss: 0.024111\n",
            "Train epoch: 465 [339120/25046 (41%)]\tLoss: 0.027192\n",
            "Train epoch: 465 [414200/25046 (51%)]\tLoss: 0.104168\n",
            "Train epoch: 465 [483360/25046 (61%)]\tLoss: 0.028710\n",
            "Train epoch: 465 [562940/25046 (71%)]\tLoss: 0.015096\n",
            "Train epoch: 465 [681600/25046 (82%)]\tLoss: 0.024800\n",
            "Train epoch: 465 [744120/25046 (92%)]\tLoss: 0.045045\n",
            "Make prediction for 5010 samples...\n",
            "0.26223007 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 466 [0/25046 (0%)]\tLoss: 0.034789\n",
            "Train epoch: 466 [83080/25046 (10%)]\tLoss: 0.028200\n",
            "Train epoch: 466 [165680/25046 (20%)]\tLoss: 0.052271\n",
            "Train epoch: 466 [249420/25046 (31%)]\tLoss: 0.031534\n",
            "Train epoch: 466 [320880/25046 (41%)]\tLoss: 0.116440\n",
            "Train epoch: 466 [410700/25046 (51%)]\tLoss: 0.051962\n",
            "Train epoch: 466 [487560/25046 (61%)]\tLoss: 0.072250\n",
            "Train epoch: 466 [543900/25046 (71%)]\tLoss: 0.028942\n",
            "Train epoch: 466 [654400/25046 (82%)]\tLoss: 0.040658\n",
            "Train epoch: 466 [733680/25046 (92%)]\tLoss: 0.072729\n",
            "Make prediction for 5010 samples...\n",
            "0.25994077 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 467 [0/25046 (0%)]\tLoss: 0.049302\n",
            "Train epoch: 467 [81120/25046 (10%)]\tLoss: 0.025706\n",
            "Train epoch: 467 [161880/25046 (20%)]\tLoss: 0.068999\n",
            "Train epoch: 467 [237960/25046 (31%)]\tLoss: 0.024388\n",
            "Train epoch: 467 [326880/25046 (41%)]\tLoss: 0.061763\n",
            "Train epoch: 467 [408800/25046 (51%)]\tLoss: 0.024636\n",
            "Train epoch: 467 [487320/25046 (61%)]\tLoss: 0.049288\n",
            "Train epoch: 467 [569660/25046 (71%)]\tLoss: 0.051772\n",
            "Train epoch: 467 [675520/25046 (82%)]\tLoss: 0.164939\n",
            "Train epoch: 467 [749160/25046 (92%)]\tLoss: 0.068616\n",
            "Make prediction for 5010 samples...\n",
            "0.25556415 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 468 [0/25046 (0%)]\tLoss: 0.051828\n",
            "Train epoch: 468 [83740/25046 (10%)]\tLoss: 0.073885\n",
            "Train epoch: 468 [162880/25046 (20%)]\tLoss: 0.032482\n",
            "Train epoch: 468 [248880/25046 (31%)]\tLoss: 0.061505\n",
            "Train epoch: 468 [315600/25046 (41%)]\tLoss: 0.072561\n",
            "Train epoch: 468 [418700/25046 (51%)]\tLoss: 0.059759\n",
            "Train epoch: 468 [485760/25046 (61%)]\tLoss: 0.034266\n",
            "Train epoch: 468 [571620/25046 (71%)]\tLoss: 0.056097\n",
            "Train epoch: 468 [659040/25046 (82%)]\tLoss: 0.081501\n",
            "Train epoch: 468 [739620/25046 (92%)]\tLoss: 0.029069\n",
            "Make prediction for 5010 samples...\n",
            "0.25304753 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 469 [0/25046 (0%)]\tLoss: 0.036090\n",
            "Train epoch: 469 [82700/25046 (10%)]\tLoss: 0.046382\n",
            "Train epoch: 469 [161320/25046 (20%)]\tLoss: 0.046966\n",
            "Train epoch: 469 [244320/25046 (31%)]\tLoss: 0.041711\n",
            "Train epoch: 469 [338160/25046 (41%)]\tLoss: 0.038436\n",
            "Train epoch: 469 [407900/25046 (51%)]\tLoss: 0.054664\n",
            "Train epoch: 469 [502680/25046 (61%)]\tLoss: 0.018966\n",
            "Train epoch: 469 [587300/25046 (71%)]\tLoss: 0.033000\n",
            "Train epoch: 469 [664640/25046 (82%)]\tLoss: 0.073457\n",
            "Train epoch: 469 [747900/25046 (92%)]\tLoss: 0.052230\n",
            "Make prediction for 5010 samples...\n",
            "0.24883363 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 470 [0/25046 (0%)]\tLoss: 0.026150\n",
            "Train epoch: 470 [82700/25046 (10%)]\tLoss: 0.102743\n",
            "Train epoch: 470 [165480/25046 (20%)]\tLoss: 0.138025\n",
            "Train epoch: 470 [245640/25046 (31%)]\tLoss: 0.041595\n",
            "Train epoch: 470 [337600/25046 (41%)]\tLoss: 0.041245\n",
            "Train epoch: 470 [415600/25046 (51%)]\tLoss: 0.032495\n",
            "Train epoch: 470 [489600/25046 (61%)]\tLoss: 0.053839\n",
            "Train epoch: 470 [567700/25046 (71%)]\tLoss: 0.038715\n",
            "Train epoch: 470 [658560/25046 (82%)]\tLoss: 0.090552\n",
            "Train epoch: 470 [754200/25046 (92%)]\tLoss: 0.066415\n",
            "Make prediction for 5010 samples...\n",
            "0.24757648 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 471 [0/25046 (0%)]\tLoss: 0.045202\n",
            "Train epoch: 471 [81620/25046 (10%)]\tLoss: 0.025071\n",
            "Train epoch: 471 [166240/25046 (20%)]\tLoss: 0.027824\n",
            "Train epoch: 471 [250140/25046 (31%)]\tLoss: 0.043674\n",
            "Train epoch: 471 [322480/25046 (41%)]\tLoss: 0.049326\n",
            "Train epoch: 471 [403900/25046 (51%)]\tLoss: 0.028037\n",
            "Train epoch: 471 [488040/25046 (61%)]\tLoss: 0.035171\n",
            "Train epoch: 471 [567560/25046 (71%)]\tLoss: 0.022045\n",
            "Train epoch: 471 [654080/25046 (82%)]\tLoss: 0.038861\n",
            "Train epoch: 471 [755640/25046 (92%)]\tLoss: 0.044848\n",
            "Make prediction for 5010 samples...\n",
            "0.25235626 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 472 [0/25046 (0%)]\tLoss: 0.044863\n",
            "Train epoch: 472 [80320/25046 (10%)]\tLoss: 0.085527\n",
            "Train epoch: 472 [165840/25046 (20%)]\tLoss: 0.024051\n",
            "Train epoch: 472 [244140/25046 (31%)]\tLoss: 0.069254\n",
            "Train epoch: 472 [328320/25046 (41%)]\tLoss: 0.077095\n",
            "Train epoch: 472 [403700/25046 (51%)]\tLoss: 0.019618\n",
            "Train epoch: 472 [507360/25046 (61%)]\tLoss: 0.030512\n",
            "Train epoch: 472 [593320/25046 (71%)]\tLoss: 0.050212\n",
            "Train epoch: 472 [636640/25046 (82%)]\tLoss: 0.025489\n",
            "Train epoch: 472 [718020/25046 (92%)]\tLoss: 0.068224\n",
            "Make prediction for 5010 samples...\n",
            "0.25504154 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 473 [0/25046 (0%)]\tLoss: 0.058543\n",
            "Train epoch: 473 [81920/25046 (10%)]\tLoss: 0.031263\n",
            "Train epoch: 473 [164000/25046 (20%)]\tLoss: 0.037766\n",
            "Train epoch: 473 [243420/25046 (31%)]\tLoss: 0.036403\n",
            "Train epoch: 473 [326800/25046 (41%)]\tLoss: 0.049963\n",
            "Train epoch: 473 [407100/25046 (51%)]\tLoss: 0.053270\n",
            "Train epoch: 473 [498600/25046 (61%)]\tLoss: 0.038768\n",
            "Train epoch: 473 [583240/25046 (71%)]\tLoss: 0.044101\n",
            "Train epoch: 473 [654880/25046 (82%)]\tLoss: 0.043162\n",
            "Train epoch: 473 [730080/25046 (92%)]\tLoss: 0.030299\n",
            "Make prediction for 5010 samples...\n",
            "0.24664909 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 474 [0/25046 (0%)]\tLoss: 0.043503\n",
            "Train epoch: 474 [83380/25046 (10%)]\tLoss: 0.031388\n",
            "Train epoch: 474 [162600/25046 (20%)]\tLoss: 0.089232\n",
            "Train epoch: 474 [249060/25046 (31%)]\tLoss: 0.039115\n",
            "Train epoch: 474 [315600/25046 (41%)]\tLoss: 0.097225\n",
            "Train epoch: 474 [419900/25046 (51%)]\tLoss: 0.072146\n",
            "Train epoch: 474 [493440/25046 (61%)]\tLoss: 0.091258\n",
            "Train epoch: 474 [576380/25046 (71%)]\tLoss: 0.077110\n",
            "Train epoch: 474 [654720/25046 (82%)]\tLoss: 0.026177\n",
            "Train epoch: 474 [732960/25046 (92%)]\tLoss: 0.035642\n",
            "Make prediction for 5010 samples...\n",
            "0.25634637 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 475 [0/25046 (0%)]\tLoss: 0.061443\n",
            "Train epoch: 475 [82200/25046 (10%)]\tLoss: 0.149843\n",
            "Train epoch: 475 [163320/25046 (20%)]\tLoss: 0.030954\n",
            "Train epoch: 475 [245460/25046 (31%)]\tLoss: 0.078466\n",
            "Train epoch: 475 [336480/25046 (41%)]\tLoss: 0.029801\n",
            "Train epoch: 475 [413900/25046 (51%)]\tLoss: 0.018538\n",
            "Train epoch: 475 [502560/25046 (61%)]\tLoss: 0.042002\n",
            "Train epoch: 475 [579460/25046 (71%)]\tLoss: 0.033511\n",
            "Train epoch: 475 [652000/25046 (82%)]\tLoss: 0.062838\n",
            "Train epoch: 475 [731160/25046 (92%)]\tLoss: 0.053264\n",
            "Make prediction for 5010 samples...\n",
            "0.25489837 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 476 [0/25046 (0%)]\tLoss: 0.018662\n",
            "Train epoch: 476 [85160/25046 (10%)]\tLoss: 0.038890\n",
            "Train epoch: 476 [159960/25046 (20%)]\tLoss: 0.055265\n",
            "Train epoch: 476 [252420/25046 (31%)]\tLoss: 0.033123\n",
            "Train epoch: 476 [328080/25046 (41%)]\tLoss: 0.025278\n",
            "Train epoch: 476 [423500/25046 (51%)]\tLoss: 0.032293\n",
            "Train epoch: 476 [486480/25046 (61%)]\tLoss: 0.021957\n",
            "Train epoch: 476 [578900/25046 (71%)]\tLoss: 0.042655\n",
            "Train epoch: 476 [656960/25046 (82%)]\tLoss: 0.065032\n",
            "Train epoch: 476 [749880/25046 (92%)]\tLoss: 0.030432\n",
            "Make prediction for 5010 samples...\n",
            "0.24812938 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 477 [0/25046 (0%)]\tLoss: 0.040660\n",
            "Train epoch: 477 [82620/25046 (10%)]\tLoss: 0.030793\n",
            "Train epoch: 477 [163240/25046 (20%)]\tLoss: 0.052385\n",
            "Train epoch: 477 [247500/25046 (31%)]\tLoss: 0.046068\n",
            "Train epoch: 477 [332160/25046 (41%)]\tLoss: 0.020307\n",
            "Train epoch: 477 [404500/25046 (51%)]\tLoss: 0.068160\n",
            "Train epoch: 477 [501360/25046 (61%)]\tLoss: 0.086901\n",
            "Train epoch: 477 [591080/25046 (71%)]\tLoss: 0.045475\n",
            "Train epoch: 477 [644960/25046 (82%)]\tLoss: 0.047341\n",
            "Train epoch: 477 [735120/25046 (92%)]\tLoss: 0.035618\n",
            "Make prediction for 5010 samples...\n",
            "0.24798274 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 478 [0/25046 (0%)]\tLoss: 0.043421\n",
            "Train epoch: 478 [84340/25046 (10%)]\tLoss: 0.042924\n",
            "Train epoch: 478 [162880/25046 (20%)]\tLoss: 0.026064\n",
            "Train epoch: 478 [241980/25046 (31%)]\tLoss: 0.035988\n",
            "Train epoch: 478 [335360/25046 (41%)]\tLoss: 0.031368\n",
            "Train epoch: 478 [416000/25046 (51%)]\tLoss: 0.045235\n",
            "Train epoch: 478 [492720/25046 (61%)]\tLoss: 0.049955\n",
            "Train epoch: 478 [560000/25046 (71%)]\tLoss: 0.063342\n",
            "Train epoch: 478 [633440/25046 (82%)]\tLoss: 0.070770\n",
            "Train epoch: 478 [730440/25046 (92%)]\tLoss: 0.034918\n",
            "Make prediction for 5010 samples...\n",
            "0.24772267 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 479 [0/25046 (0%)]\tLoss: 0.030382\n",
            "Train epoch: 479 [82460/25046 (10%)]\tLoss: 0.024338\n",
            "Train epoch: 479 [171280/25046 (20%)]\tLoss: 0.041147\n",
            "Train epoch: 479 [253860/25046 (31%)]\tLoss: 0.074938\n",
            "Train epoch: 479 [330160/25046 (41%)]\tLoss: 0.048646\n",
            "Train epoch: 479 [406700/25046 (51%)]\tLoss: 0.044329\n",
            "Train epoch: 479 [498600/25046 (61%)]\tLoss: 0.050806\n",
            "Train epoch: 479 [581980/25046 (71%)]\tLoss: 0.041405\n",
            "Train epoch: 479 [639200/25046 (82%)]\tLoss: 0.050036\n",
            "Train epoch: 479 [745200/25046 (92%)]\tLoss: 0.034211\n",
            "Make prediction for 5010 samples...\n",
            "0.25582838 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 480 [0/25046 (0%)]\tLoss: 0.058925\n",
            "Train epoch: 480 [79840/25046 (10%)]\tLoss: 0.083754\n",
            "Train epoch: 480 [163280/25046 (20%)]\tLoss: 0.061184\n",
            "Train epoch: 480 [250380/25046 (31%)]\tLoss: 0.035988\n",
            "Train epoch: 480 [336560/25046 (41%)]\tLoss: 0.051753\n",
            "Train epoch: 480 [404500/25046 (51%)]\tLoss: 0.082892\n",
            "Train epoch: 480 [489720/25046 (61%)]\tLoss: 0.091008\n",
            "Train epoch: 480 [585900/25046 (71%)]\tLoss: 0.053841\n",
            "Train epoch: 480 [646400/25046 (82%)]\tLoss: 0.055805\n",
            "Train epoch: 480 [739620/25046 (92%)]\tLoss: 0.100830\n",
            "Make prediction for 5010 samples...\n",
            "0.25120634 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 481 [0/25046 (0%)]\tLoss: 0.044452\n",
            "Train epoch: 481 [81100/25046 (10%)]\tLoss: 0.050016\n",
            "Train epoch: 481 [165960/25046 (20%)]\tLoss: 0.064992\n",
            "Train epoch: 481 [243000/25046 (31%)]\tLoss: 0.046545\n",
            "Train epoch: 481 [331120/25046 (41%)]\tLoss: 0.020089\n",
            "Train epoch: 481 [412900/25046 (51%)]\tLoss: 0.051836\n",
            "Train epoch: 481 [503040/25046 (61%)]\tLoss: 0.034203\n",
            "Train epoch: 481 [574000/25046 (71%)]\tLoss: 0.029823\n",
            "Train epoch: 481 [644960/25046 (82%)]\tLoss: 0.118240\n",
            "Train epoch: 481 [735660/25046 (92%)]\tLoss: 0.056065\n",
            "Make prediction for 5010 samples...\n",
            "0.25550708 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 482 [0/25046 (0%)]\tLoss: 0.028523\n",
            "Train epoch: 482 [82900/25046 (10%)]\tLoss: 0.031991\n",
            "Train epoch: 482 [163840/25046 (20%)]\tLoss: 0.062909\n",
            "Train epoch: 482 [252960/25046 (31%)]\tLoss: 0.075559\n",
            "Train epoch: 482 [332400/25046 (41%)]\tLoss: 0.054132\n",
            "Train epoch: 482 [419700/25046 (51%)]\tLoss: 0.029357\n",
            "Train epoch: 482 [480720/25046 (61%)]\tLoss: 0.033937\n",
            "Train epoch: 482 [561540/25046 (71%)]\tLoss: 0.049038\n",
            "Train epoch: 482 [651200/25046 (82%)]\tLoss: 0.043405\n",
            "Train epoch: 482 [738720/25046 (92%)]\tLoss: 0.069287\n",
            "Make prediction for 5010 samples...\n",
            "0.250917 No improvement since epoch  382 ; best_mse,best_ci: 0.24459933 0.8875289783967459 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 483 [0/25046 (0%)]\tLoss: 0.039016\n",
            "Train epoch: 483 [82120/25046 (10%)]\tLoss: 0.023000\n",
            "Train epoch: 483 [163960/25046 (20%)]\tLoss: 0.049525\n",
            "Train epoch: 483 [247740/25046 (31%)]\tLoss: 0.025085\n",
            "Train epoch: 483 [332080/25046 (41%)]\tLoss: 0.076978\n",
            "Train epoch: 483 [398800/25046 (51%)]\tLoss: 0.040274\n",
            "Train epoch: 483 [494280/25046 (61%)]\tLoss: 0.076465\n",
            "Train epoch: 483 [574000/25046 (71%)]\tLoss: 0.047900\n",
            "Train epoch: 483 [669600/25046 (82%)]\tLoss: 0.052338\n",
            "Train epoch: 483 [751860/25046 (92%)]\tLoss: 0.097321\n",
            "Make prediction for 5010 samples...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphDTA-new/training.py\", line 93, in <module>\n",
            "    torch.save(model.state_dict(), model_file_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 440, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 315, in _open_zipfile_writer\n",
            "    return container(name_or_buffer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 288, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileWriter(str(name)))\n",
            "RuntimeError: File model_GAT_GAT_davis.model cannot be opened.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbTx4r7DqzrX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "outputId": "2e83405a-0b8c-46f7-f596-bdb14f2229bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GATNet(\n",
            "  (gcn1): GATConv(78, 78, heads=10)\n",
            "  (gcn2): GATConv(780, 128, heads=1)\n",
            "  (fc_g1): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (embedding_xt): Embedding(26, 128)\n",
            "  (conv_xt1): Conv1d(1000, 32, kernel_size=(8,), stride=(1,))\n",
            "  (fc_xt1): Linear(in_features=3872, out_features=128, bias=True)\n",
            "  (fc1): Linear(in_features=128, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (gelu): GELU(approximate='none')\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            ")\n",
            "GAT_GAT(\n",
            "  (conv1): GATConv(78, 78, heads=10)\n",
            "  (conv2): GATConv(780, 780, heads=1)\n",
            "  (conv3): GATConv(780, 780, heads=1)\n",
            "  (fc_g1): Linear(in_features=1560, out_features=1500, bias=True)\n",
            "  (fc_g2): Linear(in_features=1500, out_features=128, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (embedding_xt): Embedding(26, 128)\n",
            "  (conv_xt_1): Conv1d(1000, 32, kernel_size=(8,), stride=(1,))\n",
            "  (fc1_xt): Linear(in_features=3872, out_features=128, bias=True)\n",
            "  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (out): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8185da26a983>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGATNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat_gcn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGAT_GATNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mginconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGINConvNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GAT_GATNet' from 'models.gat_gcn' (/content/drive/MyDrive/GraphDTA-new/models/gat_gcn.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "from random import shuffle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from models.gat import GATNet\n",
        "from models.gat_gcn import GAT_GATNet\n",
        "from models.gcn import GCNNet\n",
        "from models.ginconv import GINConvNet\n",
        "from utils import *\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dEmAFv7_0jxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create data.**py**"
      ],
      "metadata": {
        "id": "sRHRI1bUz94t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bJN2dLKR8CGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Nf4J2xrJ61o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}