{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WE1KU42srSR",
        "outputId": "4496acaa-9bb0-4a3d-908b-9966e360ad21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GraphDTA'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 2), reused 4 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 69.03 MiB | 31.95 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/thinng/GraphDTA.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision numpy pandas scikit-learn tqdm matplotlib seaborn\n"
      ],
      "metadata": {
        "id": "S6Sw_Bgds4b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2acaa384-5125-4a8f-c632-3d024d97ec20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_68bfz3is4eh",
        "outputId": "c6838127-a16e-408a-dcc1-7e9b01afd09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.1-cp310-cp310-manylinux1_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GraphDTA/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXS7Yr1qs4hK",
        "outputId": "42de27dd-637a-4f28-865b-7a531c9497f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GraphDTA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFT5F71GuyvR",
        "outputId": "6913d60f-410f-4c19-a3d4-db731baa6246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=c16bae1bdd946a72b449983060673a11a8f0eddeae931d7e68d1df0ceae22842\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9MV__J1vBKv",
        "outputId": "36b1881e-9cab-4d82-babf-a7e9fcad4b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python create_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsrehNeDvBHX",
        "outputId": "d95d5988-b9a1-4131-9735-a4f6a0b9d4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Converting SMILES to graph: 14712/19709\n",
            "Converting SMILES to graph: 14713/19709\n",
            "Converting SMILES to graph: 14714/19709\n",
            "Converting SMILES to graph: 14715/19709\n",
            "Converting SMILES to graph: 14716/19709\n",
            "Converting SMILES to graph: 14717/19709\n",
            "Converting SMILES to graph: 14718/19709\n",
            "Converting SMILES to graph: 14719/19709\n",
            "Converting SMILES to graph: 14720/19709\n",
            "Converting SMILES to graph: 14721/19709\n",
            "Converting SMILES to graph: 14722/19709\n",
            "Converting SMILES to graph: 14723/19709\n",
            "Converting SMILES to graph: 14724/19709\n",
            "Converting SMILES to graph: 14725/19709\n",
            "Converting SMILES to graph: 14726/19709\n",
            "Converting SMILES to graph: 14727/19709\n",
            "Converting SMILES to graph: 14728/19709\n",
            "Converting SMILES to graph: 14729/19709\n",
            "Converting SMILES to graph: 14730/19709\n",
            "Converting SMILES to graph: 14731/19709\n",
            "Converting SMILES to graph: 14732/19709\n",
            "Converting SMILES to graph: 14733/19709\n",
            "Converting SMILES to graph: 14734/19709\n",
            "Converting SMILES to graph: 14735/19709\n",
            "Converting SMILES to graph: 14736/19709\n",
            "Converting SMILES to graph: 14737/19709\n",
            "Converting SMILES to graph: 14738/19709\n",
            "Converting SMILES to graph: 14739/19709\n",
            "Converting SMILES to graph: 14740/19709\n",
            "Converting SMILES to graph: 14741/19709\n",
            "Converting SMILES to graph: 14742/19709\n",
            "Converting SMILES to graph: 14743/19709\n",
            "Converting SMILES to graph: 14744/19709\n",
            "Converting SMILES to graph: 14745/19709\n",
            "Converting SMILES to graph: 14746/19709\n",
            "Converting SMILES to graph: 14747/19709\n",
            "Converting SMILES to graph: 14748/19709\n",
            "Converting SMILES to graph: 14749/19709\n",
            "Converting SMILES to graph: 14750/19709\n",
            "Converting SMILES to graph: 14751/19709\n",
            "Converting SMILES to graph: 14752/19709\n",
            "Converting SMILES to graph: 14753/19709\n",
            "Converting SMILES to graph: 14754/19709\n",
            "Converting SMILES to graph: 14755/19709\n",
            "Converting SMILES to graph: 14756/19709\n",
            "Converting SMILES to graph: 14757/19709\n",
            "Converting SMILES to graph: 14758/19709\n",
            "Converting SMILES to graph: 14759/19709\n",
            "Converting SMILES to graph: 14760/19709\n",
            "Converting SMILES to graph: 14761/19709\n",
            "Converting SMILES to graph: 14762/19709\n",
            "Converting SMILES to graph: 14763/19709\n",
            "Converting SMILES to graph: 14764/19709\n",
            "Converting SMILES to graph: 14765/19709\n",
            "Converting SMILES to graph: 14766/19709\n",
            "Converting SMILES to graph: 14767/19709\n",
            "Converting SMILES to graph: 14768/19709\n",
            "Converting SMILES to graph: 14769/19709\n",
            "Converting SMILES to graph: 14770/19709\n",
            "Converting SMILES to graph: 14771/19709\n",
            "Converting SMILES to graph: 14772/19709\n",
            "Converting SMILES to graph: 14773/19709\n",
            "Converting SMILES to graph: 14774/19709\n",
            "Converting SMILES to graph: 14775/19709\n",
            "Converting SMILES to graph: 14776/19709\n",
            "Converting SMILES to graph: 14777/19709\n",
            "Converting SMILES to graph: 14778/19709\n",
            "Converting SMILES to graph: 14779/19709\n",
            "Converting SMILES to graph: 14780/19709\n",
            "Converting SMILES to graph: 14781/19709\n",
            "Converting SMILES to graph: 14782/19709\n",
            "Converting SMILES to graph: 14783/19709\n",
            "Converting SMILES to graph: 14784/19709\n",
            "Converting SMILES to graph: 14785/19709\n",
            "Converting SMILES to graph: 14786/19709\n",
            "Converting SMILES to graph: 14787/19709\n",
            "Converting SMILES to graph: 14788/19709\n",
            "Converting SMILES to graph: 14789/19709\n",
            "Converting SMILES to graph: 14790/19709\n",
            "Converting SMILES to graph: 14791/19709\n",
            "Converting SMILES to graph: 14792/19709\n",
            "Converting SMILES to graph: 14793/19709\n",
            "Converting SMILES to graph: 14794/19709\n",
            "Converting SMILES to graph: 14795/19709\n",
            "Converting SMILES to graph: 14796/19709\n",
            "Converting SMILES to graph: 14797/19709\n",
            "Converting SMILES to graph: 14798/19709\n",
            "Converting SMILES to graph: 14799/19709\n",
            "Converting SMILES to graph: 14800/19709\n",
            "Converting SMILES to graph: 14801/19709\n",
            "Converting SMILES to graph: 14802/19709\n",
            "Converting SMILES to graph: 14803/19709\n",
            "Converting SMILES to graph: 14804/19709\n",
            "Converting SMILES to graph: 14805/19709\n",
            "Converting SMILES to graph: 14806/19709\n",
            "Converting SMILES to graph: 14807/19709\n",
            "Converting SMILES to graph: 14808/19709\n",
            "Converting SMILES to graph: 14809/19709\n",
            "Converting SMILES to graph: 14810/19709\n",
            "Converting SMILES to graph: 14811/19709\n",
            "Converting SMILES to graph: 14812/19709\n",
            "Converting SMILES to graph: 14813/19709\n",
            "Converting SMILES to graph: 14814/19709\n",
            "Converting SMILES to graph: 14815/19709\n",
            "Converting SMILES to graph: 14816/19709\n",
            "Converting SMILES to graph: 14817/19709\n",
            "Converting SMILES to graph: 14818/19709\n",
            "Converting SMILES to graph: 14819/19709\n",
            "Converting SMILES to graph: 14820/19709\n",
            "Converting SMILES to graph: 14821/19709\n",
            "Converting SMILES to graph: 14822/19709\n",
            "Converting SMILES to graph: 14823/19709\n",
            "Converting SMILES to graph: 14824/19709\n",
            "Converting SMILES to graph: 14825/19709\n",
            "Converting SMILES to graph: 14826/19709\n",
            "Converting SMILES to graph: 14827/19709\n",
            "Converting SMILES to graph: 14828/19709\n",
            "Converting SMILES to graph: 14829/19709\n",
            "Converting SMILES to graph: 14830/19709\n",
            "Converting SMILES to graph: 14831/19709\n",
            "Converting SMILES to graph: 14832/19709\n",
            "Converting SMILES to graph: 14833/19709\n",
            "Converting SMILES to graph: 14834/19709\n",
            "Converting SMILES to graph: 14835/19709\n",
            "Converting SMILES to graph: 14836/19709\n",
            "Converting SMILES to graph: 14837/19709\n",
            "Converting SMILES to graph: 14838/19709\n",
            "Converting SMILES to graph: 14839/19709\n",
            "Converting SMILES to graph: 14840/19709\n",
            "Converting SMILES to graph: 14841/19709\n",
            "Converting SMILES to graph: 14842/19709\n",
            "Converting SMILES to graph: 14843/19709\n",
            "Converting SMILES to graph: 14844/19709\n",
            "Converting SMILES to graph: 14845/19709\n",
            "Converting SMILES to graph: 14846/19709\n",
            "Converting SMILES to graph: 14847/19709\n",
            "Converting SMILES to graph: 14848/19709\n",
            "Converting SMILES to graph: 14849/19709\n",
            "Converting SMILES to graph: 14850/19709\n",
            "Converting SMILES to graph: 14851/19709\n",
            "Converting SMILES to graph: 14852/19709\n",
            "Converting SMILES to graph: 14853/19709\n",
            "Converting SMILES to graph: 14854/19709\n",
            "Converting SMILES to graph: 14855/19709\n",
            "Converting SMILES to graph: 14856/19709\n",
            "Converting SMILES to graph: 14857/19709\n",
            "Converting SMILES to graph: 14858/19709\n",
            "Converting SMILES to graph: 14859/19709\n",
            "Converting SMILES to graph: 14860/19709\n",
            "Converting SMILES to graph: 14861/19709\n",
            "Converting SMILES to graph: 14862/19709\n",
            "Converting SMILES to graph: 14863/19709\n",
            "Converting SMILES to graph: 14864/19709\n",
            "Converting SMILES to graph: 14865/19709\n",
            "Converting SMILES to graph: 14866/19709\n",
            "Converting SMILES to graph: 14867/19709\n",
            "Converting SMILES to graph: 14868/19709\n",
            "Converting SMILES to graph: 14869/19709\n",
            "Converting SMILES to graph: 14870/19709\n",
            "Converting SMILES to graph: 14871/19709\n",
            "Converting SMILES to graph: 14872/19709\n",
            "Converting SMILES to graph: 14873/19709\n",
            "Converting SMILES to graph: 14874/19709\n",
            "Converting SMILES to graph: 14875/19709\n",
            "Converting SMILES to graph: 14876/19709\n",
            "Converting SMILES to graph: 14877/19709\n",
            "Converting SMILES to graph: 14878/19709\n",
            "Converting SMILES to graph: 14879/19709\n",
            "Converting SMILES to graph: 14880/19709\n",
            "Converting SMILES to graph: 14881/19709\n",
            "Converting SMILES to graph: 14882/19709\n",
            "Converting SMILES to graph: 14883/19709\n",
            "Converting SMILES to graph: 14884/19709\n",
            "Converting SMILES to graph: 14885/19709\n",
            "Converting SMILES to graph: 14886/19709\n",
            "Converting SMILES to graph: 14887/19709\n",
            "Converting SMILES to graph: 14888/19709\n",
            "Converting SMILES to graph: 14889/19709\n",
            "Converting SMILES to graph: 14890/19709\n",
            "Converting SMILES to graph: 14891/19709\n",
            "Converting SMILES to graph: 14892/19709\n",
            "Converting SMILES to graph: 14893/19709\n",
            "Converting SMILES to graph: 14894/19709\n",
            "Converting SMILES to graph: 14895/19709\n",
            "Converting SMILES to graph: 14896/19709\n",
            "Converting SMILES to graph: 14897/19709\n",
            "Converting SMILES to graph: 14898/19709\n",
            "Converting SMILES to graph: 14899/19709\n",
            "Converting SMILES to graph: 14900/19709\n",
            "Converting SMILES to graph: 14901/19709\n",
            "Converting SMILES to graph: 14902/19709\n",
            "Converting SMILES to graph: 14903/19709\n",
            "Converting SMILES to graph: 14904/19709\n",
            "Converting SMILES to graph: 14905/19709\n",
            "Converting SMILES to graph: 14906/19709\n",
            "Converting SMILES to graph: 14907/19709\n",
            "Converting SMILES to graph: 14908/19709\n",
            "Converting SMILES to graph: 14909/19709\n",
            "Converting SMILES to graph: 14910/19709\n",
            "Converting SMILES to graph: 14911/19709\n",
            "Converting SMILES to graph: 14912/19709\n",
            "Converting SMILES to graph: 14913/19709\n",
            "Converting SMILES to graph: 14914/19709\n",
            "Converting SMILES to graph: 14915/19709\n",
            "Converting SMILES to graph: 14916/19709\n",
            "Converting SMILES to graph: 14917/19709\n",
            "Converting SMILES to graph: 14918/19709\n",
            "Converting SMILES to graph: 14919/19709\n",
            "Converting SMILES to graph: 14920/19709\n",
            "Converting SMILES to graph: 14921/19709\n",
            "Converting SMILES to graph: 14922/19709\n",
            "Converting SMILES to graph: 14923/19709\n",
            "Converting SMILES to graph: 14924/19709\n",
            "Converting SMILES to graph: 14925/19709\n",
            "Converting SMILES to graph: 14926/19709\n",
            "Converting SMILES to graph: 14927/19709\n",
            "Converting SMILES to graph: 14928/19709\n",
            "Converting SMILES to graph: 14929/19709\n",
            "Converting SMILES to graph: 14930/19709\n",
            "Converting SMILES to graph: 14931/19709\n",
            "Converting SMILES to graph: 14932/19709\n",
            "Converting SMILES to graph: 14933/19709\n",
            "Converting SMILES to graph: 14934/19709\n",
            "Converting SMILES to graph: 14935/19709\n",
            "Converting SMILES to graph: 14936/19709\n",
            "Converting SMILES to graph: 14937/19709\n",
            "Converting SMILES to graph: 14938/19709\n",
            "Converting SMILES to graph: 14939/19709\n",
            "Converting SMILES to graph: 14940/19709\n",
            "Converting SMILES to graph: 14941/19709\n",
            "Converting SMILES to graph: 14942/19709\n",
            "Converting SMILES to graph: 14943/19709\n",
            "Converting SMILES to graph: 14944/19709\n",
            "Converting SMILES to graph: 14945/19709\n",
            "Converting SMILES to graph: 14946/19709\n",
            "Converting SMILES to graph: 14947/19709\n",
            "Converting SMILES to graph: 14948/19709\n",
            "Converting SMILES to graph: 14949/19709\n",
            "Converting SMILES to graph: 14950/19709\n",
            "Converting SMILES to graph: 14951/19709\n",
            "Converting SMILES to graph: 14952/19709\n",
            "Converting SMILES to graph: 14953/19709\n",
            "Converting SMILES to graph: 14954/19709\n",
            "Converting SMILES to graph: 14955/19709\n",
            "Converting SMILES to graph: 14956/19709\n",
            "Converting SMILES to graph: 14957/19709\n",
            "Converting SMILES to graph: 14958/19709\n",
            "Converting SMILES to graph: 14959/19709\n",
            "Converting SMILES to graph: 14960/19709\n",
            "Converting SMILES to graph: 14961/19709\n",
            "Converting SMILES to graph: 14962/19709\n",
            "Converting SMILES to graph: 14963/19709\n",
            "Converting SMILES to graph: 14964/19709\n",
            "Converting SMILES to graph: 14965/19709\n",
            "Converting SMILES to graph: 14966/19709\n",
            "Converting SMILES to graph: 14967/19709\n",
            "Converting SMILES to graph: 14968/19709\n",
            "Converting SMILES to graph: 14969/19709\n",
            "Converting SMILES to graph: 14970/19709\n",
            "Converting SMILES to graph: 14971/19709\n",
            "Converting SMILES to graph: 14972/19709\n",
            "Converting SMILES to graph: 14973/19709\n",
            "Converting SMILES to graph: 14974/19709\n",
            "Converting SMILES to graph: 14975/19709\n",
            "Converting SMILES to graph: 14976/19709\n",
            "Converting SMILES to graph: 14977/19709\n",
            "Converting SMILES to graph: 14978/19709\n",
            "Converting SMILES to graph: 14979/19709\n",
            "Converting SMILES to graph: 14980/19709\n",
            "Converting SMILES to graph: 14981/19709\n",
            "Converting SMILES to graph: 14982/19709\n",
            "Converting SMILES to graph: 14983/19709\n",
            "Converting SMILES to graph: 14984/19709\n",
            "Converting SMILES to graph: 14985/19709\n",
            "Converting SMILES to graph: 14986/19709\n",
            "Converting SMILES to graph: 14987/19709\n",
            "Converting SMILES to graph: 14988/19709\n",
            "Converting SMILES to graph: 14989/19709\n",
            "Converting SMILES to graph: 14990/19709\n",
            "Converting SMILES to graph: 14991/19709\n",
            "Converting SMILES to graph: 14992/19709\n",
            "Converting SMILES to graph: 14993/19709\n",
            "Converting SMILES to graph: 14994/19709\n",
            "Converting SMILES to graph: 14995/19709\n",
            "Converting SMILES to graph: 14996/19709\n",
            "Converting SMILES to graph: 14997/19709\n",
            "Converting SMILES to graph: 14998/19709\n",
            "Converting SMILES to graph: 14999/19709\n",
            "Converting SMILES to graph: 15000/19709\n",
            "Converting SMILES to graph: 15001/19709\n",
            "Converting SMILES to graph: 15002/19709\n",
            "Converting SMILES to graph: 15003/19709\n",
            "Converting SMILES to graph: 15004/19709\n",
            "Converting SMILES to graph: 15005/19709\n",
            "Converting SMILES to graph: 15006/19709\n",
            "Converting SMILES to graph: 15007/19709\n",
            "Converting SMILES to graph: 15008/19709\n",
            "Converting SMILES to graph: 15009/19709\n",
            "Converting SMILES to graph: 15010/19709\n",
            "Converting SMILES to graph: 15011/19709\n",
            "Converting SMILES to graph: 15012/19709\n",
            "Converting SMILES to graph: 15013/19709\n",
            "Converting SMILES to graph: 15014/19709\n",
            "Converting SMILES to graph: 15015/19709\n",
            "Converting SMILES to graph: 15016/19709\n",
            "Converting SMILES to graph: 15017/19709\n",
            "Converting SMILES to graph: 15018/19709\n",
            "Converting SMILES to graph: 15019/19709\n",
            "Converting SMILES to graph: 15020/19709\n",
            "Converting SMILES to graph: 15021/19709\n",
            "Converting SMILES to graph: 15022/19709\n",
            "Converting SMILES to graph: 15023/19709\n",
            "Converting SMILES to graph: 15024/19709\n",
            "Converting SMILES to graph: 15025/19709\n",
            "Converting SMILES to graph: 15026/19709\n",
            "Converting SMILES to graph: 15027/19709\n",
            "Converting SMILES to graph: 15028/19709\n",
            "Converting SMILES to graph: 15029/19709\n",
            "Converting SMILES to graph: 15030/19709\n",
            "Converting SMILES to graph: 15031/19709\n",
            "Converting SMILES to graph: 15032/19709\n",
            "Converting SMILES to graph: 15033/19709\n",
            "Converting SMILES to graph: 15034/19709\n",
            "Converting SMILES to graph: 15035/19709\n",
            "Converting SMILES to graph: 15036/19709\n",
            "Converting SMILES to graph: 15037/19709\n",
            "Converting SMILES to graph: 15038/19709\n",
            "Converting SMILES to graph: 15039/19709\n",
            "Converting SMILES to graph: 15040/19709\n",
            "Converting SMILES to graph: 15041/19709\n",
            "Converting SMILES to graph: 15042/19709\n",
            "Converting SMILES to graph: 15043/19709\n",
            "Converting SMILES to graph: 15044/19709\n",
            "Converting SMILES to graph: 15045/19709\n",
            "Converting SMILES to graph: 15046/19709\n",
            "Converting SMILES to graph: 15047/19709\n",
            "Converting SMILES to graph: 15048/19709\n",
            "Converting SMILES to graph: 15049/19709\n",
            "Converting SMILES to graph: 15050/19709\n",
            "Converting SMILES to graph: 15051/19709\n",
            "Converting SMILES to graph: 15052/19709\n",
            "Converting SMILES to graph: 15053/19709\n",
            "Converting SMILES to graph: 15054/19709\n",
            "Converting SMILES to graph: 15055/19709\n",
            "Converting SMILES to graph: 15056/19709\n",
            "Converting SMILES to graph: 15057/19709\n",
            "Converting SMILES to graph: 15058/19709\n",
            "Converting SMILES to graph: 15059/19709\n",
            "Converting SMILES to graph: 15060/19709\n",
            "Converting SMILES to graph: 15061/19709\n",
            "Converting SMILES to graph: 15062/19709\n",
            "Converting SMILES to graph: 15063/19709\n",
            "Converting SMILES to graph: 15064/19709\n",
            "Converting SMILES to graph: 15065/19709\n",
            "Converting SMILES to graph: 15066/19709\n",
            "Converting SMILES to graph: 15067/19709\n",
            "Converting SMILES to graph: 15068/19709\n",
            "Converting SMILES to graph: 15069/19709\n",
            "Converting SMILES to graph: 15070/19709\n",
            "Converting SMILES to graph: 15071/19709\n",
            "Converting SMILES to graph: 15072/19709\n",
            "Converting SMILES to graph: 15073/19709\n",
            "Converting SMILES to graph: 15074/19709\n",
            "Converting SMILES to graph: 15075/19709\n",
            "Converting SMILES to graph: 15076/19709\n",
            "Converting SMILES to graph: 15077/19709\n",
            "Converting SMILES to graph: 15078/19709\n",
            "Converting SMILES to graph: 15079/19709\n",
            "Converting SMILES to graph: 15080/19709\n",
            "Converting SMILES to graph: 15081/19709\n",
            "Converting SMILES to graph: 15082/19709\n",
            "Converting SMILES to graph: 15083/19709\n",
            "Converting SMILES to graph: 15084/19709\n",
            "Converting SMILES to graph: 15085/19709\n",
            "Converting SMILES to graph: 15086/19709\n",
            "Converting SMILES to graph: 15087/19709\n",
            "Converting SMILES to graph: 15088/19709\n",
            "Converting SMILES to graph: 15089/19709\n",
            "Converting SMILES to graph: 15090/19709\n",
            "Converting SMILES to graph: 15091/19709\n",
            "Converting SMILES to graph: 15092/19709\n",
            "Converting SMILES to graph: 15093/19709\n",
            "Converting SMILES to graph: 15094/19709\n",
            "Converting SMILES to graph: 15095/19709\n",
            "Converting SMILES to graph: 15096/19709\n",
            "Converting SMILES to graph: 15097/19709\n",
            "Converting SMILES to graph: 15098/19709\n",
            "Converting SMILES to graph: 15099/19709\n",
            "Converting SMILES to graph: 15100/19709\n",
            "Converting SMILES to graph: 15101/19709\n",
            "Converting SMILES to graph: 15102/19709\n",
            "Converting SMILES to graph: 15103/19709\n",
            "Converting SMILES to graph: 15104/19709\n",
            "Converting SMILES to graph: 15105/19709\n",
            "Converting SMILES to graph: 15106/19709\n",
            "Converting SMILES to graph: 15107/19709\n",
            "Converting SMILES to graph: 15108/19709\n",
            "Converting SMILES to graph: 15109/19709\n",
            "Converting SMILES to graph: 15110/19709\n",
            "Converting SMILES to graph: 15111/19709\n",
            "Converting SMILES to graph: 15112/19709\n",
            "Converting SMILES to graph: 15113/19709\n",
            "Converting SMILES to graph: 15114/19709\n",
            "Converting SMILES to graph: 15115/19709\n",
            "Converting SMILES to graph: 15116/19709\n",
            "Converting SMILES to graph: 15117/19709\n",
            "Converting SMILES to graph: 15118/19709\n",
            "Converting SMILES to graph: 15119/19709\n",
            "Converting SMILES to graph: 15120/19709\n",
            "Converting SMILES to graph: 15121/19709\n",
            "Converting SMILES to graph: 15122/19709\n",
            "Converting SMILES to graph: 15123/19709\n",
            "Converting SMILES to graph: 15124/19709\n",
            "Converting SMILES to graph: 15125/19709\n",
            "Converting SMILES to graph: 15126/19709\n",
            "Converting SMILES to graph: 15127/19709\n",
            "Converting SMILES to graph: 15128/19709\n",
            "Converting SMILES to graph: 15129/19709\n",
            "Converting SMILES to graph: 15130/19709\n",
            "Converting SMILES to graph: 15131/19709\n",
            "Converting SMILES to graph: 15132/19709\n",
            "Converting SMILES to graph: 15133/19709\n",
            "Converting SMILES to graph: 15134/19709\n",
            "Converting SMILES to graph: 15135/19709\n",
            "Converting SMILES to graph: 15136/19709\n",
            "Converting SMILES to graph: 15137/19709\n",
            "Converting SMILES to graph: 15138/19709\n",
            "Converting SMILES to graph: 15139/19709\n",
            "Converting SMILES to graph: 15140/19709\n",
            "Converting SMILES to graph: 15141/19709\n",
            "Converting SMILES to graph: 15142/19709\n",
            "Converting SMILES to graph: 15143/19709\n",
            "Converting SMILES to graph: 15144/19709\n",
            "Converting SMILES to graph: 15145/19709\n",
            "Converting SMILES to graph: 15146/19709\n",
            "Converting SMILES to graph: 15147/19709\n",
            "Converting SMILES to graph: 15148/19709\n",
            "Converting SMILES to graph: 15149/19709\n",
            "Converting SMILES to graph: 15150/19709\n",
            "Converting SMILES to graph: 15151/19709\n",
            "Converting SMILES to graph: 15152/19709\n",
            "Converting SMILES to graph: 15153/19709\n",
            "Converting SMILES to graph: 15154/19709\n",
            "Converting SMILES to graph: 15155/19709\n",
            "Converting SMILES to graph: 15156/19709\n",
            "Converting SMILES to graph: 15157/19709\n",
            "Converting SMILES to graph: 15158/19709\n",
            "Converting SMILES to graph: 15159/19709\n",
            "Converting SMILES to graph: 15160/19709\n",
            "Converting SMILES to graph: 15161/19709\n",
            "Converting SMILES to graph: 15162/19709\n",
            "Converting SMILES to graph: 15163/19709\n",
            "Converting SMILES to graph: 15164/19709\n",
            "Converting SMILES to graph: 15165/19709\n",
            "Converting SMILES to graph: 15166/19709\n",
            "Converting SMILES to graph: 15167/19709\n",
            "Converting SMILES to graph: 15168/19709\n",
            "Converting SMILES to graph: 15169/19709\n",
            "Converting SMILES to graph: 15170/19709\n",
            "Converting SMILES to graph: 15171/19709\n",
            "Converting SMILES to graph: 15172/19709\n",
            "Converting SMILES to graph: 15173/19709\n",
            "Converting SMILES to graph: 15174/19709\n",
            "Converting SMILES to graph: 15175/19709\n",
            "Converting SMILES to graph: 15176/19709\n",
            "Converting SMILES to graph: 15177/19709\n",
            "Converting SMILES to graph: 15178/19709\n",
            "Converting SMILES to graph: 15179/19709\n",
            "Converting SMILES to graph: 15180/19709\n",
            "Converting SMILES to graph: 15181/19709\n",
            "Converting SMILES to graph: 15182/19709\n",
            "Converting SMILES to graph: 15183/19709\n",
            "Converting SMILES to graph: 15184/19709\n",
            "Converting SMILES to graph: 15185/19709\n",
            "Converting SMILES to graph: 15186/19709\n",
            "Converting SMILES to graph: 15187/19709\n",
            "Converting SMILES to graph: 15188/19709\n",
            "Converting SMILES to graph: 15189/19709\n",
            "Converting SMILES to graph: 15190/19709\n",
            "Converting SMILES to graph: 15191/19709\n",
            "Converting SMILES to graph: 15192/19709\n",
            "Converting SMILES to graph: 15193/19709\n",
            "Converting SMILES to graph: 15194/19709\n",
            "Converting SMILES to graph: 15195/19709\n",
            "Converting SMILES to graph: 15196/19709\n",
            "Converting SMILES to graph: 15197/19709\n",
            "Converting SMILES to graph: 15198/19709\n",
            "Converting SMILES to graph: 15199/19709\n",
            "Converting SMILES to graph: 15200/19709\n",
            "Converting SMILES to graph: 15201/19709\n",
            "Converting SMILES to graph: 15202/19709\n",
            "Converting SMILES to graph: 15203/19709\n",
            "Converting SMILES to graph: 15204/19709\n",
            "Converting SMILES to graph: 15205/19709\n",
            "Converting SMILES to graph: 15206/19709\n",
            "Converting SMILES to graph: 15207/19709\n",
            "Converting SMILES to graph: 15208/19709\n",
            "Converting SMILES to graph: 15209/19709\n",
            "Converting SMILES to graph: 15210/19709\n",
            "Converting SMILES to graph: 15211/19709\n",
            "Converting SMILES to graph: 15212/19709\n",
            "Converting SMILES to graph: 15213/19709\n",
            "Converting SMILES to graph: 15214/19709\n",
            "Converting SMILES to graph: 15215/19709\n",
            "Converting SMILES to graph: 15216/19709\n",
            "Converting SMILES to graph: 15217/19709\n",
            "Converting SMILES to graph: 15218/19709\n",
            "Converting SMILES to graph: 15219/19709\n",
            "Converting SMILES to graph: 15220/19709\n",
            "Converting SMILES to graph: 15221/19709\n",
            "Converting SMILES to graph: 15222/19709\n",
            "Converting SMILES to graph: 15223/19709\n",
            "Converting SMILES to graph: 15224/19709\n",
            "Converting SMILES to graph: 15225/19709\n",
            "Converting SMILES to graph: 15226/19709\n",
            "Converting SMILES to graph: 15227/19709\n",
            "Converting SMILES to graph: 15228/19709\n",
            "Converting SMILES to graph: 15229/19709\n",
            "Converting SMILES to graph: 15230/19709\n",
            "Converting SMILES to graph: 15231/19709\n",
            "Converting SMILES to graph: 15232/19709\n",
            "Converting SMILES to graph: 15233/19709\n",
            "Converting SMILES to graph: 15234/19709\n",
            "Converting SMILES to graph: 15235/19709\n",
            "Converting SMILES to graph: 15236/19709\n",
            "Converting SMILES to graph: 15237/19709\n",
            "Converting SMILES to graph: 15238/19709\n",
            "Converting SMILES to graph: 15239/19709\n",
            "Converting SMILES to graph: 15240/19709\n",
            "Converting SMILES to graph: 15241/19709\n",
            "Converting SMILES to graph: 15242/19709\n",
            "Converting SMILES to graph: 15243/19709\n",
            "Converting SMILES to graph: 15244/19709\n",
            "Converting SMILES to graph: 15245/19709\n",
            "Converting SMILES to graph: 15246/19709\n",
            "Converting SMILES to graph: 15247/19709\n",
            "Converting SMILES to graph: 15248/19709\n",
            "Converting SMILES to graph: 15249/19709\n",
            "Converting SMILES to graph: 15250/19709\n",
            "Converting SMILES to graph: 15251/19709\n",
            "Converting SMILES to graph: 15252/19709\n",
            "Converting SMILES to graph: 15253/19709\n",
            "Converting SMILES to graph: 15254/19709\n",
            "Converting SMILES to graph: 15255/19709\n",
            "Converting SMILES to graph: 15256/19709\n",
            "Converting SMILES to graph: 15257/19709\n",
            "Converting SMILES to graph: 15258/19709\n",
            "Converting SMILES to graph: 15259/19709\n",
            "Converting SMILES to graph: 15260/19709\n",
            "Converting SMILES to graph: 15261/19709\n",
            "Converting SMILES to graph: 15262/19709\n",
            "Converting SMILES to graph: 15263/19709\n",
            "Converting SMILES to graph: 15264/19709\n",
            "Converting SMILES to graph: 15265/19709\n",
            "Converting SMILES to graph: 15266/19709\n",
            "Converting SMILES to graph: 15267/19709\n",
            "Converting SMILES to graph: 15268/19709\n",
            "Converting SMILES to graph: 15269/19709\n",
            "Converting SMILES to graph: 15270/19709\n",
            "Converting SMILES to graph: 15271/19709\n",
            "Converting SMILES to graph: 15272/19709\n",
            "Converting SMILES to graph: 15273/19709\n",
            "Converting SMILES to graph: 15274/19709\n",
            "Converting SMILES to graph: 15275/19709\n",
            "Converting SMILES to graph: 15276/19709\n",
            "Converting SMILES to graph: 15277/19709\n",
            "Converting SMILES to graph: 15278/19709\n",
            "Converting SMILES to graph: 15279/19709\n",
            "Converting SMILES to graph: 15280/19709\n",
            "Converting SMILES to graph: 15281/19709\n",
            "Converting SMILES to graph: 15282/19709\n",
            "Converting SMILES to graph: 15283/19709\n",
            "Converting SMILES to graph: 15284/19709\n",
            "Converting SMILES to graph: 15285/19709\n",
            "Converting SMILES to graph: 15286/19709\n",
            "Converting SMILES to graph: 15287/19709\n",
            "Converting SMILES to graph: 15288/19709\n",
            "Converting SMILES to graph: 15289/19709\n",
            "Converting SMILES to graph: 15290/19709\n",
            "Converting SMILES to graph: 15291/19709\n",
            "Converting SMILES to graph: 15292/19709\n",
            "Converting SMILES to graph: 15293/19709\n",
            "Converting SMILES to graph: 15294/19709\n",
            "Converting SMILES to graph: 15295/19709\n",
            "Converting SMILES to graph: 15296/19709\n",
            "Converting SMILES to graph: 15297/19709\n",
            "Converting SMILES to graph: 15298/19709\n",
            "Converting SMILES to graph: 15299/19709\n",
            "Converting SMILES to graph: 15300/19709\n",
            "Converting SMILES to graph: 15301/19709\n",
            "Converting SMILES to graph: 15302/19709\n",
            "Converting SMILES to graph: 15303/19709\n",
            "Converting SMILES to graph: 15304/19709\n",
            "Converting SMILES to graph: 15305/19709\n",
            "Converting SMILES to graph: 15306/19709\n",
            "Converting SMILES to graph: 15307/19709\n",
            "Converting SMILES to graph: 15308/19709\n",
            "Converting SMILES to graph: 15309/19709\n",
            "Converting SMILES to graph: 15310/19709\n",
            "Converting SMILES to graph: 15311/19709\n",
            "Converting SMILES to graph: 15312/19709\n",
            "Converting SMILES to graph: 15313/19709\n",
            "Converting SMILES to graph: 15314/19709\n",
            "Converting SMILES to graph: 15315/19709\n",
            "Converting SMILES to graph: 15316/19709\n",
            "Converting SMILES to graph: 15317/19709\n",
            "Converting SMILES to graph: 15318/19709\n",
            "Converting SMILES to graph: 15319/19709\n",
            "Converting SMILES to graph: 15320/19709\n",
            "Converting SMILES to graph: 15321/19709\n",
            "Converting SMILES to graph: 15322/19709\n",
            "Converting SMILES to graph: 15323/19709\n",
            "Converting SMILES to graph: 15324/19709\n",
            "Converting SMILES to graph: 15325/19709\n",
            "Converting SMILES to graph: 15326/19709\n",
            "Converting SMILES to graph: 15327/19709\n",
            "Converting SMILES to graph: 15328/19709\n",
            "Converting SMILES to graph: 15329/19709\n",
            "Converting SMILES to graph: 15330/19709\n",
            "Converting SMILES to graph: 15331/19709\n",
            "Converting SMILES to graph: 15332/19709\n",
            "Converting SMILES to graph: 15333/19709\n",
            "Converting SMILES to graph: 15334/19709\n",
            "Converting SMILES to graph: 15335/19709\n",
            "Converting SMILES to graph: 15336/19709\n",
            "Converting SMILES to graph: 15337/19709\n",
            "Converting SMILES to graph: 15338/19709\n",
            "Converting SMILES to graph: 15339/19709\n",
            "Converting SMILES to graph: 15340/19709\n",
            "Converting SMILES to graph: 15341/19709\n",
            "Converting SMILES to graph: 15342/19709\n",
            "Converting SMILES to graph: 15343/19709\n",
            "Converting SMILES to graph: 15344/19709\n",
            "Converting SMILES to graph: 15345/19709\n",
            "Converting SMILES to graph: 15346/19709\n",
            "Converting SMILES to graph: 15347/19709\n",
            "Converting SMILES to graph: 15348/19709\n",
            "Converting SMILES to graph: 15349/19709\n",
            "Converting SMILES to graph: 15350/19709\n",
            "Converting SMILES to graph: 15351/19709\n",
            "Converting SMILES to graph: 15352/19709\n",
            "Converting SMILES to graph: 15353/19709\n",
            "Converting SMILES to graph: 15354/19709\n",
            "Converting SMILES to graph: 15355/19709\n",
            "Converting SMILES to graph: 15356/19709\n",
            "Converting SMILES to graph: 15357/19709\n",
            "Converting SMILES to graph: 15358/19709\n",
            "Converting SMILES to graph: 15359/19709\n",
            "Converting SMILES to graph: 15360/19709\n",
            "Converting SMILES to graph: 15361/19709\n",
            "Converting SMILES to graph: 15362/19709\n",
            "Converting SMILES to graph: 15363/19709\n",
            "Converting SMILES to graph: 15364/19709\n",
            "Converting SMILES to graph: 15365/19709\n",
            "Converting SMILES to graph: 15366/19709\n",
            "Converting SMILES to graph: 15367/19709\n",
            "Converting SMILES to graph: 15368/19709\n",
            "Converting SMILES to graph: 15369/19709\n",
            "Converting SMILES to graph: 15370/19709\n",
            "Converting SMILES to graph: 15371/19709\n",
            "Converting SMILES to graph: 15372/19709\n",
            "Converting SMILES to graph: 15373/19709\n",
            "Converting SMILES to graph: 15374/19709\n",
            "Converting SMILES to graph: 15375/19709\n",
            "Converting SMILES to graph: 15376/19709\n",
            "Converting SMILES to graph: 15377/19709\n",
            "Converting SMILES to graph: 15378/19709\n",
            "Converting SMILES to graph: 15379/19709\n",
            "Converting SMILES to graph: 15380/19709\n",
            "Converting SMILES to graph: 15381/19709\n",
            "Converting SMILES to graph: 15382/19709\n",
            "Converting SMILES to graph: 15383/19709\n",
            "Converting SMILES to graph: 15384/19709\n",
            "Converting SMILES to graph: 15385/19709\n",
            "Converting SMILES to graph: 15386/19709\n",
            "Converting SMILES to graph: 15387/19709\n",
            "Converting SMILES to graph: 15388/19709\n",
            "Converting SMILES to graph: 15389/19709\n",
            "Converting SMILES to graph: 15390/19709\n",
            "Converting SMILES to graph: 15391/19709\n",
            "Converting SMILES to graph: 15392/19709\n",
            "Converting SMILES to graph: 15393/19709\n",
            "Converting SMILES to graph: 15394/19709\n",
            "Converting SMILES to graph: 15395/19709\n",
            "Converting SMILES to graph: 15396/19709\n",
            "Converting SMILES to graph: 15397/19709\n",
            "Converting SMILES to graph: 15398/19709\n",
            "Converting SMILES to graph: 15399/19709\n",
            "Converting SMILES to graph: 15400/19709\n",
            "Converting SMILES to graph: 15401/19709\n",
            "Converting SMILES to graph: 15402/19709\n",
            "Converting SMILES to graph: 15403/19709\n",
            "Converting SMILES to graph: 15404/19709\n",
            "Converting SMILES to graph: 15405/19709\n",
            "Converting SMILES to graph: 15406/19709\n",
            "Converting SMILES to graph: 15407/19709\n",
            "Converting SMILES to graph: 15408/19709\n",
            "Converting SMILES to graph: 15409/19709\n",
            "Converting SMILES to graph: 15410/19709\n",
            "Converting SMILES to graph: 15411/19709\n",
            "Converting SMILES to graph: 15412/19709\n",
            "Converting SMILES to graph: 15413/19709\n",
            "Converting SMILES to graph: 15414/19709\n",
            "Converting SMILES to graph: 15415/19709\n",
            "Converting SMILES to graph: 15416/19709\n",
            "Converting SMILES to graph: 15417/19709\n",
            "Converting SMILES to graph: 15418/19709\n",
            "Converting SMILES to graph: 15419/19709\n",
            "Converting SMILES to graph: 15420/19709\n",
            "Converting SMILES to graph: 15421/19709\n",
            "Converting SMILES to graph: 15422/19709\n",
            "Converting SMILES to graph: 15423/19709\n",
            "Converting SMILES to graph: 15424/19709\n",
            "Converting SMILES to graph: 15425/19709\n",
            "Converting SMILES to graph: 15426/19709\n",
            "Converting SMILES to graph: 15427/19709\n",
            "Converting SMILES to graph: 15428/19709\n",
            "Converting SMILES to graph: 15429/19709\n",
            "Converting SMILES to graph: 15430/19709\n",
            "Converting SMILES to graph: 15431/19709\n",
            "Converting SMILES to graph: 15432/19709\n",
            "Converting SMILES to graph: 15433/19709\n",
            "Converting SMILES to graph: 15434/19709\n",
            "Converting SMILES to graph: 15435/19709\n",
            "Converting SMILES to graph: 15436/19709\n",
            "Converting SMILES to graph: 15437/19709\n",
            "Converting SMILES to graph: 15438/19709\n",
            "Converting SMILES to graph: 15439/19709\n",
            "Converting SMILES to graph: 15440/19709\n",
            "Converting SMILES to graph: 15441/19709\n",
            "Converting SMILES to graph: 15442/19709\n",
            "Converting SMILES to graph: 15443/19709\n",
            "Converting SMILES to graph: 15444/19709\n",
            "Converting SMILES to graph: 15445/19709\n",
            "Converting SMILES to graph: 15446/19709\n",
            "Converting SMILES to graph: 15447/19709\n",
            "Converting SMILES to graph: 15448/19709\n",
            "Converting SMILES to graph: 15449/19709\n",
            "Converting SMILES to graph: 15450/19709\n",
            "Converting SMILES to graph: 15451/19709\n",
            "Converting SMILES to graph: 15452/19709\n",
            "Converting SMILES to graph: 15453/19709\n",
            "Converting SMILES to graph: 15454/19709\n",
            "Converting SMILES to graph: 15455/19709\n",
            "Converting SMILES to graph: 15456/19709\n",
            "Converting SMILES to graph: 15457/19709\n",
            "Converting SMILES to graph: 15458/19709\n",
            "Converting SMILES to graph: 15459/19709\n",
            "Converting SMILES to graph: 15460/19709\n",
            "Converting SMILES to graph: 15461/19709\n",
            "Converting SMILES to graph: 15462/19709\n",
            "Converting SMILES to graph: 15463/19709\n",
            "Converting SMILES to graph: 15464/19709\n",
            "Converting SMILES to graph: 15465/19709\n",
            "Converting SMILES to graph: 15466/19709\n",
            "Converting SMILES to graph: 15467/19709\n",
            "Converting SMILES to graph: 15468/19709\n",
            "Converting SMILES to graph: 15469/19709\n",
            "Converting SMILES to graph: 15470/19709\n",
            "Converting SMILES to graph: 15471/19709\n",
            "Converting SMILES to graph: 15472/19709\n",
            "Converting SMILES to graph: 15473/19709\n",
            "Converting SMILES to graph: 15474/19709\n",
            "Converting SMILES to graph: 15475/19709\n",
            "Converting SMILES to graph: 15476/19709\n",
            "Converting SMILES to graph: 15477/19709\n",
            "Converting SMILES to graph: 15478/19709\n",
            "Converting SMILES to graph: 15479/19709\n",
            "Converting SMILES to graph: 15480/19709\n",
            "Converting SMILES to graph: 15481/19709\n",
            "Converting SMILES to graph: 15482/19709\n",
            "Converting SMILES to graph: 15483/19709\n",
            "Converting SMILES to graph: 15484/19709\n",
            "Converting SMILES to graph: 15485/19709\n",
            "Converting SMILES to graph: 15486/19709\n",
            "Converting SMILES to graph: 15487/19709\n",
            "Converting SMILES to graph: 15488/19709\n",
            "Converting SMILES to graph: 15489/19709\n",
            "Converting SMILES to graph: 15490/19709\n",
            "Converting SMILES to graph: 15491/19709\n",
            "Converting SMILES to graph: 15492/19709\n",
            "Converting SMILES to graph: 15493/19709\n",
            "Converting SMILES to graph: 15494/19709\n",
            "Converting SMILES to graph: 15495/19709\n",
            "Converting SMILES to graph: 15496/19709\n",
            "Converting SMILES to graph: 15497/19709\n",
            "Converting SMILES to graph: 15498/19709\n",
            "Converting SMILES to graph: 15499/19709\n",
            "Converting SMILES to graph: 15500/19709\n",
            "Converting SMILES to graph: 15501/19709\n",
            "Converting SMILES to graph: 15502/19709\n",
            "Converting SMILES to graph: 15503/19709\n",
            "Converting SMILES to graph: 15504/19709\n",
            "Converting SMILES to graph: 15505/19709\n",
            "Converting SMILES to graph: 15506/19709\n",
            "Converting SMILES to graph: 15507/19709\n",
            "Converting SMILES to graph: 15508/19709\n",
            "Converting SMILES to graph: 15509/19709\n",
            "Converting SMILES to graph: 15510/19709\n",
            "Converting SMILES to graph: 15511/19709\n",
            "Converting SMILES to graph: 15512/19709\n",
            "Converting SMILES to graph: 15513/19709\n",
            "Converting SMILES to graph: 15514/19709\n",
            "Converting SMILES to graph: 15515/19709\n",
            "Converting SMILES to graph: 15516/19709\n",
            "Converting SMILES to graph: 15517/19709\n",
            "Converting SMILES to graph: 15518/19709\n",
            "Converting SMILES to graph: 15519/19709\n",
            "Converting SMILES to graph: 15520/19709\n",
            "Converting SMILES to graph: 15521/19709\n",
            "Converting SMILES to graph: 15522/19709\n",
            "Converting SMILES to graph: 15523/19709\n",
            "Converting SMILES to graph: 15524/19709\n",
            "Converting SMILES to graph: 15525/19709\n",
            "Converting SMILES to graph: 15526/19709\n",
            "Converting SMILES to graph: 15527/19709\n",
            "Converting SMILES to graph: 15528/19709\n",
            "Converting SMILES to graph: 15529/19709\n",
            "Converting SMILES to graph: 15530/19709\n",
            "Converting SMILES to graph: 15531/19709\n",
            "Converting SMILES to graph: 15532/19709\n",
            "Converting SMILES to graph: 15533/19709\n",
            "Converting SMILES to graph: 15534/19709\n",
            "Converting SMILES to graph: 15535/19709\n",
            "Converting SMILES to graph: 15536/19709\n",
            "Converting SMILES to graph: 15537/19709\n",
            "Converting SMILES to graph: 15538/19709\n",
            "Converting SMILES to graph: 15539/19709\n",
            "Converting SMILES to graph: 15540/19709\n",
            "Converting SMILES to graph: 15541/19709\n",
            "Converting SMILES to graph: 15542/19709\n",
            "Converting SMILES to graph: 15543/19709\n",
            "Converting SMILES to graph: 15544/19709\n",
            "Converting SMILES to graph: 15545/19709\n",
            "Converting SMILES to graph: 15546/19709\n",
            "Converting SMILES to graph: 15547/19709\n",
            "Converting SMILES to graph: 15548/19709\n",
            "Converting SMILES to graph: 15549/19709\n",
            "Converting SMILES to graph: 15550/19709\n",
            "Converting SMILES to graph: 15551/19709\n",
            "Converting SMILES to graph: 15552/19709\n",
            "Converting SMILES to graph: 15553/19709\n",
            "Converting SMILES to graph: 15554/19709\n",
            "Converting SMILES to graph: 15555/19709\n",
            "Converting SMILES to graph: 15556/19709\n",
            "Converting SMILES to graph: 15557/19709\n",
            "Converting SMILES to graph: 15558/19709\n",
            "Converting SMILES to graph: 15559/19709\n",
            "Converting SMILES to graph: 15560/19709\n",
            "Converting SMILES to graph: 15561/19709\n",
            "Converting SMILES to graph: 15562/19709\n",
            "Converting SMILES to graph: 15563/19709\n",
            "Converting SMILES to graph: 15564/19709\n",
            "Converting SMILES to graph: 15565/19709\n",
            "Converting SMILES to graph: 15566/19709\n",
            "Converting SMILES to graph: 15567/19709\n",
            "Converting SMILES to graph: 15568/19709\n",
            "Converting SMILES to graph: 15569/19709\n",
            "Converting SMILES to graph: 15570/19709\n",
            "Converting SMILES to graph: 15571/19709\n",
            "Converting SMILES to graph: 15572/19709\n",
            "Converting SMILES to graph: 15573/19709\n",
            "Converting SMILES to graph: 15574/19709\n",
            "Converting SMILES to graph: 15575/19709\n",
            "Converting SMILES to graph: 15576/19709\n",
            "Converting SMILES to graph: 15577/19709\n",
            "Converting SMILES to graph: 15578/19709\n",
            "Converting SMILES to graph: 15579/19709\n",
            "Converting SMILES to graph: 15580/19709\n",
            "Converting SMILES to graph: 15581/19709\n",
            "Converting SMILES to graph: 15582/19709\n",
            "Converting SMILES to graph: 15583/19709\n",
            "Converting SMILES to graph: 15584/19709\n",
            "Converting SMILES to graph: 15585/19709\n",
            "Converting SMILES to graph: 15586/19709\n",
            "Converting SMILES to graph: 15587/19709\n",
            "Converting SMILES to graph: 15588/19709\n",
            "Converting SMILES to graph: 15589/19709\n",
            "Converting SMILES to graph: 15590/19709\n",
            "Converting SMILES to graph: 15591/19709\n",
            "Converting SMILES to graph: 15592/19709\n",
            "Converting SMILES to graph: 15593/19709\n",
            "Converting SMILES to graph: 15594/19709\n",
            "Converting SMILES to graph: 15595/19709\n",
            "Converting SMILES to graph: 15596/19709\n",
            "Converting SMILES to graph: 15597/19709\n",
            "Converting SMILES to graph: 15598/19709\n",
            "Converting SMILES to graph: 15599/19709\n",
            "Converting SMILES to graph: 15600/19709\n",
            "Converting SMILES to graph: 15601/19709\n",
            "Converting SMILES to graph: 15602/19709\n",
            "Converting SMILES to graph: 15603/19709\n",
            "Converting SMILES to graph: 15604/19709\n",
            "Converting SMILES to graph: 15605/19709\n",
            "Converting SMILES to graph: 15606/19709\n",
            "Converting SMILES to graph: 15607/19709\n",
            "Converting SMILES to graph: 15608/19709\n",
            "Converting SMILES to graph: 15609/19709\n",
            "Converting SMILES to graph: 15610/19709\n",
            "Converting SMILES to graph: 15611/19709\n",
            "Converting SMILES to graph: 15612/19709\n",
            "Converting SMILES to graph: 15613/19709\n",
            "Converting SMILES to graph: 15614/19709\n",
            "Converting SMILES to graph: 15615/19709\n",
            "Converting SMILES to graph: 15616/19709\n",
            "Converting SMILES to graph: 15617/19709\n",
            "Converting SMILES to graph: 15618/19709\n",
            "Converting SMILES to graph: 15619/19709\n",
            "Converting SMILES to graph: 15620/19709\n",
            "Converting SMILES to graph: 15621/19709\n",
            "Converting SMILES to graph: 15622/19709\n",
            "Converting SMILES to graph: 15623/19709\n",
            "Converting SMILES to graph: 15624/19709\n",
            "Converting SMILES to graph: 15625/19709\n",
            "Converting SMILES to graph: 15626/19709\n",
            "Converting SMILES to graph: 15627/19709\n",
            "Converting SMILES to graph: 15628/19709\n",
            "Converting SMILES to graph: 15629/19709\n",
            "Converting SMILES to graph: 15630/19709\n",
            "Converting SMILES to graph: 15631/19709\n",
            "Converting SMILES to graph: 15632/19709\n",
            "Converting SMILES to graph: 15633/19709\n",
            "Converting SMILES to graph: 15634/19709\n",
            "Converting SMILES to graph: 15635/19709\n",
            "Converting SMILES to graph: 15636/19709\n",
            "Converting SMILES to graph: 15637/19709\n",
            "Converting SMILES to graph: 15638/19709\n",
            "Converting SMILES to graph: 15639/19709\n",
            "Converting SMILES to graph: 15640/19709\n",
            "Converting SMILES to graph: 15641/19709\n",
            "Converting SMILES to graph: 15642/19709\n",
            "Converting SMILES to graph: 15643/19709\n",
            "Converting SMILES to graph: 15644/19709\n",
            "Converting SMILES to graph: 15645/19709\n",
            "Converting SMILES to graph: 15646/19709\n",
            "Converting SMILES to graph: 15647/19709\n",
            "Converting SMILES to graph: 15648/19709\n",
            "Converting SMILES to graph: 15649/19709\n",
            "Converting SMILES to graph: 15650/19709\n",
            "Converting SMILES to graph: 15651/19709\n",
            "Converting SMILES to graph: 15652/19709\n",
            "Converting SMILES to graph: 15653/19709\n",
            "Converting SMILES to graph: 15654/19709\n",
            "Converting SMILES to graph: 15655/19709\n",
            "Converting SMILES to graph: 15656/19709\n",
            "Converting SMILES to graph: 15657/19709\n",
            "Converting SMILES to graph: 15658/19709\n",
            "Converting SMILES to graph: 15659/19709\n",
            "Converting SMILES to graph: 15660/19709\n",
            "Converting SMILES to graph: 15661/19709\n",
            "Converting SMILES to graph: 15662/19709\n",
            "Converting SMILES to graph: 15663/19709\n",
            "Converting SMILES to graph: 15664/19709\n",
            "Converting SMILES to graph: 15665/19709\n",
            "Converting SMILES to graph: 15666/19709\n",
            "Converting SMILES to graph: 15667/19709\n",
            "Converting SMILES to graph: 15668/19709\n",
            "Converting SMILES to graph: 15669/19709\n",
            "Converting SMILES to graph: 15670/19709\n",
            "Converting SMILES to graph: 15671/19709\n",
            "Converting SMILES to graph: 15672/19709\n",
            "Converting SMILES to graph: 15673/19709\n",
            "Converting SMILES to graph: 15674/19709\n",
            "Converting SMILES to graph: 15675/19709\n",
            "Converting SMILES to graph: 15676/19709\n",
            "Converting SMILES to graph: 15677/19709\n",
            "Converting SMILES to graph: 15678/19709\n",
            "Converting SMILES to graph: 15679/19709\n",
            "Converting SMILES to graph: 15680/19709\n",
            "Converting SMILES to graph: 15681/19709\n",
            "Converting SMILES to graph: 15682/19709\n",
            "Converting SMILES to graph: 15683/19709\n",
            "Converting SMILES to graph: 15684/19709\n",
            "Converting SMILES to graph: 15685/19709\n",
            "Converting SMILES to graph: 15686/19709\n",
            "Converting SMILES to graph: 15687/19709\n",
            "Converting SMILES to graph: 15688/19709\n",
            "Converting SMILES to graph: 15689/19709\n",
            "Converting SMILES to graph: 15690/19709\n",
            "Converting SMILES to graph: 15691/19709\n",
            "Converting SMILES to graph: 15692/19709\n",
            "Converting SMILES to graph: 15693/19709\n",
            "Converting SMILES to graph: 15694/19709\n",
            "Converting SMILES to graph: 15695/19709\n",
            "Converting SMILES to graph: 15696/19709\n",
            "Converting SMILES to graph: 15697/19709\n",
            "Converting SMILES to graph: 15698/19709\n",
            "Converting SMILES to graph: 15699/19709\n",
            "Converting SMILES to graph: 15700/19709\n",
            "Converting SMILES to graph: 15701/19709\n",
            "Converting SMILES to graph: 15702/19709\n",
            "Converting SMILES to graph: 15703/19709\n",
            "Converting SMILES to graph: 15704/19709\n",
            "Converting SMILES to graph: 15705/19709\n",
            "Converting SMILES to graph: 15706/19709\n",
            "Converting SMILES to graph: 15707/19709\n",
            "Converting SMILES to graph: 15708/19709\n",
            "Converting SMILES to graph: 15709/19709\n",
            "Converting SMILES to graph: 15710/19709\n",
            "Converting SMILES to graph: 15711/19709\n",
            "Converting SMILES to graph: 15712/19709\n",
            "Converting SMILES to graph: 15713/19709\n",
            "Converting SMILES to graph: 15714/19709\n",
            "Converting SMILES to graph: 15715/19709\n",
            "Converting SMILES to graph: 15716/19709\n",
            "Converting SMILES to graph: 15717/19709\n",
            "Converting SMILES to graph: 15718/19709\n",
            "Converting SMILES to graph: 15719/19709\n",
            "Converting SMILES to graph: 15720/19709\n",
            "Converting SMILES to graph: 15721/19709\n",
            "Converting SMILES to graph: 15722/19709\n",
            "Converting SMILES to graph: 15723/19709\n",
            "Converting SMILES to graph: 15724/19709\n",
            "Converting SMILES to graph: 15725/19709\n",
            "Converting SMILES to graph: 15726/19709\n",
            "Converting SMILES to graph: 15727/19709\n",
            "Converting SMILES to graph: 15728/19709\n",
            "Converting SMILES to graph: 15729/19709\n",
            "Converting SMILES to graph: 15730/19709\n",
            "Converting SMILES to graph: 15731/19709\n",
            "Converting SMILES to graph: 15732/19709\n",
            "Converting SMILES to graph: 15733/19709\n",
            "Converting SMILES to graph: 15734/19709\n",
            "Converting SMILES to graph: 15735/19709\n",
            "Converting SMILES to graph: 15736/19709\n",
            "Converting SMILES to graph: 15737/19709\n",
            "Converting SMILES to graph: 15738/19709\n",
            "Converting SMILES to graph: 15739/19709\n",
            "Converting SMILES to graph: 15740/19709\n",
            "Converting SMILES to graph: 15741/19709\n",
            "Converting SMILES to graph: 15742/19709\n",
            "Converting SMILES to graph: 15743/19709\n",
            "Converting SMILES to graph: 15744/19709\n",
            "Converting SMILES to graph: 15745/19709\n",
            "Converting SMILES to graph: 15746/19709\n",
            "Converting SMILES to graph: 15747/19709\n",
            "Converting SMILES to graph: 15748/19709\n",
            "Converting SMILES to graph: 15749/19709\n",
            "Converting SMILES to graph: 15750/19709\n",
            "Converting SMILES to graph: 15751/19709\n",
            "Converting SMILES to graph: 15752/19709\n",
            "Converting SMILES to graph: 15753/19709\n",
            "Converting SMILES to graph: 15754/19709\n",
            "Converting SMILES to graph: 15755/19709\n",
            "Converting SMILES to graph: 15756/19709\n",
            "Converting SMILES to graph: 15757/19709\n",
            "Converting SMILES to graph: 15758/19709\n",
            "Converting SMILES to graph: 15759/19709\n",
            "Converting SMILES to graph: 15760/19709\n",
            "Converting SMILES to graph: 15761/19709\n",
            "Converting SMILES to graph: 15762/19709\n",
            "Converting SMILES to graph: 15763/19709\n",
            "Converting SMILES to graph: 15764/19709\n",
            "Converting SMILES to graph: 15765/19709\n",
            "Converting SMILES to graph: 15766/19709\n",
            "Converting SMILES to graph: 15767/19709\n",
            "Converting SMILES to graph: 15768/19709\n",
            "Converting SMILES to graph: 15769/19709\n",
            "Converting SMILES to graph: 15770/19709\n",
            "Converting SMILES to graph: 15771/19709\n",
            "Converting SMILES to graph: 15772/19709\n",
            "Converting SMILES to graph: 15773/19709\n",
            "Converting SMILES to graph: 15774/19709\n",
            "Converting SMILES to graph: 15775/19709\n",
            "Converting SMILES to graph: 15776/19709\n",
            "Converting SMILES to graph: 15777/19709\n",
            "Converting SMILES to graph: 15778/19709\n",
            "Converting SMILES to graph: 15779/19709\n",
            "Converting SMILES to graph: 15780/19709\n",
            "Converting SMILES to graph: 15781/19709\n",
            "Converting SMILES to graph: 15782/19709\n",
            "Converting SMILES to graph: 15783/19709\n",
            "Converting SMILES to graph: 15784/19709\n",
            "Converting SMILES to graph: 15785/19709\n",
            "Converting SMILES to graph: 15786/19709\n",
            "Converting SMILES to graph: 15787/19709\n",
            "Converting SMILES to graph: 15788/19709\n",
            "Converting SMILES to graph: 15789/19709\n",
            "Converting SMILES to graph: 15790/19709\n",
            "Converting SMILES to graph: 15791/19709\n",
            "Converting SMILES to graph: 15792/19709\n",
            "Converting SMILES to graph: 15793/19709\n",
            "Converting SMILES to graph: 15794/19709\n",
            "Converting SMILES to graph: 15795/19709\n",
            "Converting SMILES to graph: 15796/19709\n",
            "Converting SMILES to graph: 15797/19709\n",
            "Converting SMILES to graph: 15798/19709\n",
            "Converting SMILES to graph: 15799/19709\n",
            "Converting SMILES to graph: 15800/19709\n",
            "Converting SMILES to graph: 15801/19709\n",
            "Converting SMILES to graph: 15802/19709\n",
            "Converting SMILES to graph: 15803/19709\n",
            "Converting SMILES to graph: 15804/19709\n",
            "Converting SMILES to graph: 15805/19709\n",
            "Converting SMILES to graph: 15806/19709\n",
            "Converting SMILES to graph: 15807/19709\n",
            "Converting SMILES to graph: 15808/19709\n",
            "Converting SMILES to graph: 15809/19709\n",
            "Converting SMILES to graph: 15810/19709\n",
            "Converting SMILES to graph: 15811/19709\n",
            "Converting SMILES to graph: 15812/19709\n",
            "Converting SMILES to graph: 15813/19709\n",
            "Converting SMILES to graph: 15814/19709\n",
            "Converting SMILES to graph: 15815/19709\n",
            "Converting SMILES to graph: 15816/19709\n",
            "Converting SMILES to graph: 15817/19709\n",
            "Converting SMILES to graph: 15818/19709\n",
            "Converting SMILES to graph: 15819/19709\n",
            "Converting SMILES to graph: 15820/19709\n",
            "Converting SMILES to graph: 15821/19709\n",
            "Converting SMILES to graph: 15822/19709\n",
            "Converting SMILES to graph: 15823/19709\n",
            "Converting SMILES to graph: 15824/19709\n",
            "Converting SMILES to graph: 15825/19709\n",
            "Converting SMILES to graph: 15826/19709\n",
            "Converting SMILES to graph: 15827/19709\n",
            "Converting SMILES to graph: 15828/19709\n",
            "Converting SMILES to graph: 15829/19709\n",
            "Converting SMILES to graph: 15830/19709\n",
            "Converting SMILES to graph: 15831/19709\n",
            "Converting SMILES to graph: 15832/19709\n",
            "Converting SMILES to graph: 15833/19709\n",
            "Converting SMILES to graph: 15834/19709\n",
            "Converting SMILES to graph: 15835/19709\n",
            "Converting SMILES to graph: 15836/19709\n",
            "Converting SMILES to graph: 15837/19709\n",
            "Converting SMILES to graph: 15838/19709\n",
            "Converting SMILES to graph: 15839/19709\n",
            "Converting SMILES to graph: 15840/19709\n",
            "Converting SMILES to graph: 15841/19709\n",
            "Converting SMILES to graph: 15842/19709\n",
            "Converting SMILES to graph: 15843/19709\n",
            "Converting SMILES to graph: 15844/19709\n",
            "Converting SMILES to graph: 15845/19709\n",
            "Converting SMILES to graph: 15846/19709\n",
            "Converting SMILES to graph: 15847/19709\n",
            "Converting SMILES to graph: 15848/19709\n",
            "Converting SMILES to graph: 15849/19709\n",
            "Converting SMILES to graph: 15850/19709\n",
            "Converting SMILES to graph: 15851/19709\n",
            "Converting SMILES to graph: 15852/19709\n",
            "Converting SMILES to graph: 15853/19709\n",
            "Converting SMILES to graph: 15854/19709\n",
            "Converting SMILES to graph: 15855/19709\n",
            "Converting SMILES to graph: 15856/19709\n",
            "Converting SMILES to graph: 15857/19709\n",
            "Converting SMILES to graph: 15858/19709\n",
            "Converting SMILES to graph: 15859/19709\n",
            "Converting SMILES to graph: 15860/19709\n",
            "Converting SMILES to graph: 15861/19709\n",
            "Converting SMILES to graph: 15862/19709\n",
            "Converting SMILES to graph: 15863/19709\n",
            "Converting SMILES to graph: 15864/19709\n",
            "Converting SMILES to graph: 15865/19709\n",
            "Converting SMILES to graph: 15866/19709\n",
            "Converting SMILES to graph: 15867/19709\n",
            "Converting SMILES to graph: 15868/19709\n",
            "Converting SMILES to graph: 15869/19709\n",
            "Converting SMILES to graph: 15870/19709\n",
            "Converting SMILES to graph: 15871/19709\n",
            "Converting SMILES to graph: 15872/19709\n",
            "Converting SMILES to graph: 15873/19709\n",
            "Converting SMILES to graph: 15874/19709\n",
            "Converting SMILES to graph: 15875/19709\n",
            "Converting SMILES to graph: 15876/19709\n",
            "Converting SMILES to graph: 15877/19709\n",
            "Converting SMILES to graph: 15878/19709\n",
            "Converting SMILES to graph: 15879/19709\n",
            "Converting SMILES to graph: 15880/19709\n",
            "Converting SMILES to graph: 15881/19709\n",
            "Converting SMILES to graph: 15882/19709\n",
            "Converting SMILES to graph: 15883/19709\n",
            "Converting SMILES to graph: 15884/19709\n",
            "Converting SMILES to graph: 15885/19709\n",
            "Converting SMILES to graph: 15886/19709\n",
            "Converting SMILES to graph: 15887/19709\n",
            "Converting SMILES to graph: 15888/19709\n",
            "Converting SMILES to graph: 15889/19709\n",
            "Converting SMILES to graph: 15890/19709\n",
            "Converting SMILES to graph: 15891/19709\n",
            "Converting SMILES to graph: 15892/19709\n",
            "Converting SMILES to graph: 15893/19709\n",
            "Converting SMILES to graph: 15894/19709\n",
            "Converting SMILES to graph: 15895/19709\n",
            "Converting SMILES to graph: 15896/19709\n",
            "Converting SMILES to graph: 15897/19709\n",
            "Converting SMILES to graph: 15898/19709\n",
            "Converting SMILES to graph: 15899/19709\n",
            "Converting SMILES to graph: 15900/19709\n",
            "Converting SMILES to graph: 15901/19709\n",
            "Converting SMILES to graph: 15902/19709\n",
            "Converting SMILES to graph: 15903/19709\n",
            "Converting SMILES to graph: 15904/19709\n",
            "Converting SMILES to graph: 15905/19709\n",
            "Converting SMILES to graph: 15906/19709\n",
            "Converting SMILES to graph: 15907/19709\n",
            "Converting SMILES to graph: 15908/19709\n",
            "Converting SMILES to graph: 15909/19709\n",
            "Converting SMILES to graph: 15910/19709\n",
            "Converting SMILES to graph: 15911/19709\n",
            "Converting SMILES to graph: 15912/19709\n",
            "Converting SMILES to graph: 15913/19709\n",
            "Converting SMILES to graph: 15914/19709\n",
            "Converting SMILES to graph: 15915/19709\n",
            "Converting SMILES to graph: 15916/19709\n",
            "Converting SMILES to graph: 15917/19709\n",
            "Converting SMILES to graph: 15918/19709\n",
            "Converting SMILES to graph: 15919/19709\n",
            "Converting SMILES to graph: 15920/19709\n",
            "Converting SMILES to graph: 15921/19709\n",
            "Converting SMILES to graph: 15922/19709\n",
            "Converting SMILES to graph: 15923/19709\n",
            "Converting SMILES to graph: 15924/19709\n",
            "Converting SMILES to graph: 15925/19709\n",
            "Converting SMILES to graph: 15926/19709\n",
            "Converting SMILES to graph: 15927/19709\n",
            "Converting SMILES to graph: 15928/19709\n",
            "Converting SMILES to graph: 15929/19709\n",
            "Converting SMILES to graph: 15930/19709\n",
            "Converting SMILES to graph: 15931/19709\n",
            "Converting SMILES to graph: 15932/19709\n",
            "Converting SMILES to graph: 15933/19709\n",
            "Converting SMILES to graph: 15934/19709\n",
            "Converting SMILES to graph: 15935/19709\n",
            "Converting SMILES to graph: 15936/19709\n",
            "Converting SMILES to graph: 15937/19709\n",
            "Converting SMILES to graph: 15938/19709\n",
            "Converting SMILES to graph: 15939/19709\n",
            "Converting SMILES to graph: 15940/19709\n",
            "Converting SMILES to graph: 15941/19709\n",
            "Converting SMILES to graph: 15942/19709\n",
            "Converting SMILES to graph: 15943/19709\n",
            "Converting SMILES to graph: 15944/19709\n",
            "Converting SMILES to graph: 15945/19709\n",
            "Converting SMILES to graph: 15946/19709\n",
            "Converting SMILES to graph: 15947/19709\n",
            "Converting SMILES to graph: 15948/19709\n",
            "Converting SMILES to graph: 15949/19709\n",
            "Converting SMILES to graph: 15950/19709\n",
            "Converting SMILES to graph: 15951/19709\n",
            "Converting SMILES to graph: 15952/19709\n",
            "Converting SMILES to graph: 15953/19709\n",
            "Converting SMILES to graph: 15954/19709\n",
            "Converting SMILES to graph: 15955/19709\n",
            "Converting SMILES to graph: 15956/19709\n",
            "Converting SMILES to graph: 15957/19709\n",
            "Converting SMILES to graph: 15958/19709\n",
            "Converting SMILES to graph: 15959/19709\n",
            "Converting SMILES to graph: 15960/19709\n",
            "Converting SMILES to graph: 15961/19709\n",
            "Converting SMILES to graph: 15962/19709\n",
            "Converting SMILES to graph: 15963/19709\n",
            "Converting SMILES to graph: 15964/19709\n",
            "Converting SMILES to graph: 15965/19709\n",
            "Converting SMILES to graph: 15966/19709\n",
            "Converting SMILES to graph: 15967/19709\n",
            "Converting SMILES to graph: 15968/19709\n",
            "Converting SMILES to graph: 15969/19709\n",
            "Converting SMILES to graph: 15970/19709\n",
            "Converting SMILES to graph: 15971/19709\n",
            "Converting SMILES to graph: 15972/19709\n",
            "Converting SMILES to graph: 15973/19709\n",
            "Converting SMILES to graph: 15974/19709\n",
            "Converting SMILES to graph: 15975/19709\n",
            "Converting SMILES to graph: 15976/19709\n",
            "Converting SMILES to graph: 15977/19709\n",
            "Converting SMILES to graph: 15978/19709\n",
            "Converting SMILES to graph: 15979/19709\n",
            "Converting SMILES to graph: 15980/19709\n",
            "Converting SMILES to graph: 15981/19709\n",
            "Converting SMILES to graph: 15982/19709\n",
            "Converting SMILES to graph: 15983/19709\n",
            "Converting SMILES to graph: 15984/19709\n",
            "Converting SMILES to graph: 15985/19709\n",
            "Converting SMILES to graph: 15986/19709\n",
            "Converting SMILES to graph: 15987/19709\n",
            "Converting SMILES to graph: 15988/19709\n",
            "Converting SMILES to graph: 15989/19709\n",
            "Converting SMILES to graph: 15990/19709\n",
            "Converting SMILES to graph: 15991/19709\n",
            "Converting SMILES to graph: 15992/19709\n",
            "Converting SMILES to graph: 15993/19709\n",
            "Converting SMILES to graph: 15994/19709\n",
            "Converting SMILES to graph: 15995/19709\n",
            "Converting SMILES to graph: 15996/19709\n",
            "Converting SMILES to graph: 15997/19709\n",
            "Converting SMILES to graph: 15998/19709\n",
            "Converting SMILES to graph: 15999/19709\n",
            "Converting SMILES to graph: 16000/19709\n",
            "Converting SMILES to graph: 16001/19709\n",
            "Converting SMILES to graph: 16002/19709\n",
            "Converting SMILES to graph: 16003/19709\n",
            "Converting SMILES to graph: 16004/19709\n",
            "Converting SMILES to graph: 16005/19709\n",
            "Converting SMILES to graph: 16006/19709\n",
            "Converting SMILES to graph: 16007/19709\n",
            "Converting SMILES to graph: 16008/19709\n",
            "Converting SMILES to graph: 16009/19709\n",
            "Converting SMILES to graph: 16010/19709\n",
            "Converting SMILES to graph: 16011/19709\n",
            "Converting SMILES to graph: 16012/19709\n",
            "Converting SMILES to graph: 16013/19709\n",
            "Converting SMILES to graph: 16014/19709\n",
            "Converting SMILES to graph: 16015/19709\n",
            "Converting SMILES to graph: 16016/19709\n",
            "Converting SMILES to graph: 16017/19709\n",
            "Converting SMILES to graph: 16018/19709\n",
            "Converting SMILES to graph: 16019/19709\n",
            "Converting SMILES to graph: 16020/19709\n",
            "Converting SMILES to graph: 16021/19709\n",
            "Converting SMILES to graph: 16022/19709\n",
            "Converting SMILES to graph: 16023/19709\n",
            "Converting SMILES to graph: 16024/19709\n",
            "Converting SMILES to graph: 16025/19709\n",
            "Converting SMILES to graph: 16026/19709\n",
            "Converting SMILES to graph: 16027/19709\n",
            "Converting SMILES to graph: 16028/19709\n",
            "Converting SMILES to graph: 16029/19709\n",
            "Converting SMILES to graph: 16030/19709\n",
            "Converting SMILES to graph: 16031/19709\n",
            "Converting SMILES to graph: 16032/19709\n",
            "Converting SMILES to graph: 16033/19709\n",
            "Converting SMILES to graph: 16034/19709\n",
            "Converting SMILES to graph: 16035/19709\n",
            "Converting SMILES to graph: 16036/19709\n",
            "Converting SMILES to graph: 16037/19709\n",
            "Converting SMILES to graph: 16038/19709\n",
            "Converting SMILES to graph: 16039/19709\n",
            "Converting SMILES to graph: 16040/19709\n",
            "Converting SMILES to graph: 16041/19709\n",
            "Converting SMILES to graph: 16042/19709\n",
            "Converting SMILES to graph: 16043/19709\n",
            "Converting SMILES to graph: 16044/19709\n",
            "Converting SMILES to graph: 16045/19709\n",
            "Converting SMILES to graph: 16046/19709\n",
            "Converting SMILES to graph: 16047/19709\n",
            "Converting SMILES to graph: 16048/19709\n",
            "Converting SMILES to graph: 16049/19709\n",
            "Converting SMILES to graph: 16050/19709\n",
            "Converting SMILES to graph: 16051/19709\n",
            "Converting SMILES to graph: 16052/19709\n",
            "Converting SMILES to graph: 16053/19709\n",
            "Converting SMILES to graph: 16054/19709\n",
            "Converting SMILES to graph: 16055/19709\n",
            "Converting SMILES to graph: 16056/19709\n",
            "Converting SMILES to graph: 16057/19709\n",
            "Converting SMILES to graph: 16058/19709\n",
            "Converting SMILES to graph: 16059/19709\n",
            "Converting SMILES to graph: 16060/19709\n",
            "Converting SMILES to graph: 16061/19709\n",
            "Converting SMILES to graph: 16062/19709\n",
            "Converting SMILES to graph: 16063/19709\n",
            "Converting SMILES to graph: 16064/19709\n",
            "Converting SMILES to graph: 16065/19709\n",
            "Converting SMILES to graph: 16066/19709\n",
            "Converting SMILES to graph: 16067/19709\n",
            "Converting SMILES to graph: 16068/19709\n",
            "Converting SMILES to graph: 16069/19709\n",
            "Converting SMILES to graph: 16070/19709\n",
            "Converting SMILES to graph: 16071/19709\n",
            "Converting SMILES to graph: 16072/19709\n",
            "Converting SMILES to graph: 16073/19709\n",
            "Converting SMILES to graph: 16074/19709\n",
            "Converting SMILES to graph: 16075/19709\n",
            "Converting SMILES to graph: 16076/19709\n",
            "Converting SMILES to graph: 16077/19709\n",
            "Converting SMILES to graph: 16078/19709\n",
            "Converting SMILES to graph: 16079/19709\n",
            "Converting SMILES to graph: 16080/19709\n",
            "Converting SMILES to graph: 16081/19709\n",
            "Converting SMILES to graph: 16082/19709\n",
            "Converting SMILES to graph: 16083/19709\n",
            "Converting SMILES to graph: 16084/19709\n",
            "Converting SMILES to graph: 16085/19709\n",
            "Converting SMILES to graph: 16086/19709\n",
            "Converting SMILES to graph: 16087/19709\n",
            "Converting SMILES to graph: 16088/19709\n",
            "Converting SMILES to graph: 16089/19709\n",
            "Converting SMILES to graph: 16090/19709\n",
            "Converting SMILES to graph: 16091/19709\n",
            "Converting SMILES to graph: 16092/19709\n",
            "Converting SMILES to graph: 16093/19709\n",
            "Converting SMILES to graph: 16094/19709\n",
            "Converting SMILES to graph: 16095/19709\n",
            "Converting SMILES to graph: 16096/19709\n",
            "Converting SMILES to graph: 16097/19709\n",
            "Converting SMILES to graph: 16098/19709\n",
            "Converting SMILES to graph: 16099/19709\n",
            "Converting SMILES to graph: 16100/19709\n",
            "Converting SMILES to graph: 16101/19709\n",
            "Converting SMILES to graph: 16102/19709\n",
            "Converting SMILES to graph: 16103/19709\n",
            "Converting SMILES to graph: 16104/19709\n",
            "Converting SMILES to graph: 16105/19709\n",
            "Converting SMILES to graph: 16106/19709\n",
            "Converting SMILES to graph: 16107/19709\n",
            "Converting SMILES to graph: 16108/19709\n",
            "Converting SMILES to graph: 16109/19709\n",
            "Converting SMILES to graph: 16110/19709\n",
            "Converting SMILES to graph: 16111/19709\n",
            "Converting SMILES to graph: 16112/19709\n",
            "Converting SMILES to graph: 16113/19709\n",
            "Converting SMILES to graph: 16114/19709\n",
            "Converting SMILES to graph: 16115/19709\n",
            "Converting SMILES to graph: 16116/19709\n",
            "Converting SMILES to graph: 16117/19709\n",
            "Converting SMILES to graph: 16118/19709\n",
            "Converting SMILES to graph: 16119/19709\n",
            "Converting SMILES to graph: 16120/19709\n",
            "Converting SMILES to graph: 16121/19709\n",
            "Converting SMILES to graph: 16122/19709\n",
            "Converting SMILES to graph: 16123/19709\n",
            "Converting SMILES to graph: 16124/19709\n",
            "Converting SMILES to graph: 16125/19709\n",
            "Converting SMILES to graph: 16126/19709\n",
            "Converting SMILES to graph: 16127/19709\n",
            "Converting SMILES to graph: 16128/19709\n",
            "Converting SMILES to graph: 16129/19709\n",
            "Converting SMILES to graph: 16130/19709\n",
            "Converting SMILES to graph: 16131/19709\n",
            "Converting SMILES to graph: 16132/19709\n",
            "Converting SMILES to graph: 16133/19709\n",
            "Converting SMILES to graph: 16134/19709\n",
            "Converting SMILES to graph: 16135/19709\n",
            "Converting SMILES to graph: 16136/19709\n",
            "Converting SMILES to graph: 16137/19709\n",
            "Converting SMILES to graph: 16138/19709\n",
            "Converting SMILES to graph: 16139/19709\n",
            "Converting SMILES to graph: 16140/19709\n",
            "Converting SMILES to graph: 16141/19709\n",
            "Converting SMILES to graph: 16142/19709\n",
            "Converting SMILES to graph: 16143/19709\n",
            "Converting SMILES to graph: 16144/19709\n",
            "Converting SMILES to graph: 16145/19709\n",
            "Converting SMILES to graph: 16146/19709\n",
            "Converting SMILES to graph: 16147/19709\n",
            "Converting SMILES to graph: 16148/19709\n",
            "Converting SMILES to graph: 16149/19709\n",
            "Converting SMILES to graph: 16150/19709\n",
            "Converting SMILES to graph: 16151/19709\n",
            "Converting SMILES to graph: 16152/19709\n",
            "Converting SMILES to graph: 16153/19709\n",
            "Converting SMILES to graph: 16154/19709\n",
            "Converting SMILES to graph: 16155/19709\n",
            "Converting SMILES to graph: 16156/19709\n",
            "Converting SMILES to graph: 16157/19709\n",
            "Converting SMILES to graph: 16158/19709\n",
            "Converting SMILES to graph: 16159/19709\n",
            "Converting SMILES to graph: 16160/19709\n",
            "Converting SMILES to graph: 16161/19709\n",
            "Converting SMILES to graph: 16162/19709\n",
            "Converting SMILES to graph: 16163/19709\n",
            "Converting SMILES to graph: 16164/19709\n",
            "Converting SMILES to graph: 16165/19709\n",
            "Converting SMILES to graph: 16166/19709\n",
            "Converting SMILES to graph: 16167/19709\n",
            "Converting SMILES to graph: 16168/19709\n",
            "Converting SMILES to graph: 16169/19709\n",
            "Converting SMILES to graph: 16170/19709\n",
            "Converting SMILES to graph: 16171/19709\n",
            "Converting SMILES to graph: 16172/19709\n",
            "Converting SMILES to graph: 16173/19709\n",
            "Converting SMILES to graph: 16174/19709\n",
            "Converting SMILES to graph: 16175/19709\n",
            "Converting SMILES to graph: 16176/19709\n",
            "Converting SMILES to graph: 16177/19709\n",
            "Converting SMILES to graph: 16178/19709\n",
            "Converting SMILES to graph: 16179/19709\n",
            "Converting SMILES to graph: 16180/19709\n",
            "Converting SMILES to graph: 16181/19709\n",
            "Converting SMILES to graph: 16182/19709\n",
            "Converting SMILES to graph: 16183/19709\n",
            "Converting SMILES to graph: 16184/19709\n",
            "Converting SMILES to graph: 16185/19709\n",
            "Converting SMILES to graph: 16186/19709\n",
            "Converting SMILES to graph: 16187/19709\n",
            "Converting SMILES to graph: 16188/19709\n",
            "Converting SMILES to graph: 16189/19709\n",
            "Converting SMILES to graph: 16190/19709\n",
            "Converting SMILES to graph: 16191/19709\n",
            "Converting SMILES to graph: 16192/19709\n",
            "Converting SMILES to graph: 16193/19709\n",
            "Converting SMILES to graph: 16194/19709\n",
            "Converting SMILES to graph: 16195/19709\n",
            "Converting SMILES to graph: 16196/19709\n",
            "Converting SMILES to graph: 16197/19709\n",
            "Converting SMILES to graph: 16198/19709\n",
            "Converting SMILES to graph: 16199/19709\n",
            "Converting SMILES to graph: 16200/19709\n",
            "Converting SMILES to graph: 16201/19709\n",
            "Converting SMILES to graph: 16202/19709\n",
            "Converting SMILES to graph: 16203/19709\n",
            "Converting SMILES to graph: 16204/19709\n",
            "Converting SMILES to graph: 16205/19709\n",
            "Converting SMILES to graph: 16206/19709\n",
            "Converting SMILES to graph: 16207/19709\n",
            "Converting SMILES to graph: 16208/19709\n",
            "Converting SMILES to graph: 16209/19709\n",
            "Converting SMILES to graph: 16210/19709\n",
            "Converting SMILES to graph: 16211/19709\n",
            "Converting SMILES to graph: 16212/19709\n",
            "Converting SMILES to graph: 16213/19709\n",
            "Converting SMILES to graph: 16214/19709\n",
            "Converting SMILES to graph: 16215/19709\n",
            "Converting SMILES to graph: 16216/19709\n",
            "Converting SMILES to graph: 16217/19709\n",
            "Converting SMILES to graph: 16218/19709\n",
            "Converting SMILES to graph: 16219/19709\n",
            "Converting SMILES to graph: 16220/19709\n",
            "Converting SMILES to graph: 16221/19709\n",
            "Converting SMILES to graph: 16222/19709\n",
            "Converting SMILES to graph: 16223/19709\n",
            "Converting SMILES to graph: 16224/19709\n",
            "Converting SMILES to graph: 16225/19709\n",
            "Converting SMILES to graph: 16226/19709\n",
            "Converting SMILES to graph: 16227/19709\n",
            "Converting SMILES to graph: 16228/19709\n",
            "Converting SMILES to graph: 16229/19709\n",
            "Converting SMILES to graph: 16230/19709\n",
            "Converting SMILES to graph: 16231/19709\n",
            "Converting SMILES to graph: 16232/19709\n",
            "Converting SMILES to graph: 16233/19709\n",
            "Converting SMILES to graph: 16234/19709\n",
            "Converting SMILES to graph: 16235/19709\n",
            "Converting SMILES to graph: 16236/19709\n",
            "Converting SMILES to graph: 16237/19709\n",
            "Converting SMILES to graph: 16238/19709\n",
            "Converting SMILES to graph: 16239/19709\n",
            "Converting SMILES to graph: 16240/19709\n",
            "Converting SMILES to graph: 16241/19709\n",
            "Converting SMILES to graph: 16242/19709\n",
            "Converting SMILES to graph: 16243/19709\n",
            "Converting SMILES to graph: 16244/19709\n",
            "Converting SMILES to graph: 16245/19709\n",
            "Converting SMILES to graph: 16246/19709\n",
            "Converting SMILES to graph: 16247/19709\n",
            "Converting SMILES to graph: 16248/19709\n",
            "Converting SMILES to graph: 16249/19709\n",
            "Converting SMILES to graph: 16250/19709\n",
            "Converting SMILES to graph: 16251/19709\n",
            "Converting SMILES to graph: 16252/19709\n",
            "Converting SMILES to graph: 16253/19709\n",
            "Converting SMILES to graph: 16254/19709\n",
            "Converting SMILES to graph: 16255/19709\n",
            "Converting SMILES to graph: 16256/19709\n",
            "Converting SMILES to graph: 16257/19709\n",
            "Converting SMILES to graph: 16258/19709\n",
            "Converting SMILES to graph: 16259/19709\n",
            "Converting SMILES to graph: 16260/19709\n",
            "Converting SMILES to graph: 16261/19709\n",
            "Converting SMILES to graph: 16262/19709\n",
            "Converting SMILES to graph: 16263/19709\n",
            "Converting SMILES to graph: 16264/19709\n",
            "Converting SMILES to graph: 16265/19709\n",
            "Converting SMILES to graph: 16266/19709\n",
            "Converting SMILES to graph: 16267/19709\n",
            "Converting SMILES to graph: 16268/19709\n",
            "Converting SMILES to graph: 16269/19709\n",
            "Converting SMILES to graph: 16270/19709\n",
            "Converting SMILES to graph: 16271/19709\n",
            "Converting SMILES to graph: 16272/19709\n",
            "Converting SMILES to graph: 16273/19709\n",
            "Converting SMILES to graph: 16274/19709\n",
            "Converting SMILES to graph: 16275/19709\n",
            "Converting SMILES to graph: 16276/19709\n",
            "Converting SMILES to graph: 16277/19709\n",
            "Converting SMILES to graph: 16278/19709\n",
            "Converting SMILES to graph: 16279/19709\n",
            "Converting SMILES to graph: 16280/19709\n",
            "Converting SMILES to graph: 16281/19709\n",
            "Converting SMILES to graph: 16282/19709\n",
            "Converting SMILES to graph: 16283/19709\n",
            "Converting SMILES to graph: 16284/19709\n",
            "Converting SMILES to graph: 16285/19709\n",
            "Converting SMILES to graph: 16286/19709\n",
            "Converting SMILES to graph: 16287/19709\n",
            "Converting SMILES to graph: 16288/19709\n",
            "Converting SMILES to graph: 16289/19709\n",
            "Converting SMILES to graph: 16290/19709\n",
            "Converting SMILES to graph: 16291/19709\n",
            "Converting SMILES to graph: 16292/19709\n",
            "Converting SMILES to graph: 16293/19709\n",
            "Converting SMILES to graph: 16294/19709\n",
            "Converting SMILES to graph: 16295/19709\n",
            "Converting SMILES to graph: 16296/19709\n",
            "Converting SMILES to graph: 16297/19709\n",
            "Converting SMILES to graph: 16298/19709\n",
            "Converting SMILES to graph: 16299/19709\n",
            "Converting SMILES to graph: 16300/19709\n",
            "Converting SMILES to graph: 16301/19709\n",
            "Converting SMILES to graph: 16302/19709\n",
            "Converting SMILES to graph: 16303/19709\n",
            "Converting SMILES to graph: 16304/19709\n",
            "Converting SMILES to graph: 16305/19709\n",
            "Converting SMILES to graph: 16306/19709\n",
            "Converting SMILES to graph: 16307/19709\n",
            "Converting SMILES to graph: 16308/19709\n",
            "Converting SMILES to graph: 16309/19709\n",
            "Converting SMILES to graph: 16310/19709\n",
            "Converting SMILES to graph: 16311/19709\n",
            "Converting SMILES to graph: 16312/19709\n",
            "Converting SMILES to graph: 16313/19709\n",
            "Converting SMILES to graph: 16314/19709\n",
            "Converting SMILES to graph: 16315/19709\n",
            "Converting SMILES to graph: 16316/19709\n",
            "Converting SMILES to graph: 16317/19709\n",
            "Converting SMILES to graph: 16318/19709\n",
            "Converting SMILES to graph: 16319/19709\n",
            "Converting SMILES to graph: 16320/19709\n",
            "Converting SMILES to graph: 16321/19709\n",
            "Converting SMILES to graph: 16322/19709\n",
            "Converting SMILES to graph: 16323/19709\n",
            "Converting SMILES to graph: 16324/19709\n",
            "Converting SMILES to graph: 16325/19709\n",
            "Converting SMILES to graph: 16326/19709\n",
            "Converting SMILES to graph: 16327/19709\n",
            "Converting SMILES to graph: 16328/19709\n",
            "Converting SMILES to graph: 16329/19709\n",
            "Converting SMILES to graph: 16330/19709\n",
            "Converting SMILES to graph: 16331/19709\n",
            "Converting SMILES to graph: 16332/19709\n",
            "Converting SMILES to graph: 16333/19709\n",
            "Converting SMILES to graph: 16334/19709\n",
            "Converting SMILES to graph: 16335/19709\n",
            "Converting SMILES to graph: 16336/19709\n",
            "Converting SMILES to graph: 16337/19709\n",
            "Converting SMILES to graph: 16338/19709\n",
            "Converting SMILES to graph: 16339/19709\n",
            "Converting SMILES to graph: 16340/19709\n",
            "Converting SMILES to graph: 16341/19709\n",
            "Converting SMILES to graph: 16342/19709\n",
            "Converting SMILES to graph: 16343/19709\n",
            "Converting SMILES to graph: 16344/19709\n",
            "Converting SMILES to graph: 16345/19709\n",
            "Converting SMILES to graph: 16346/19709\n",
            "Converting SMILES to graph: 16347/19709\n",
            "Converting SMILES to graph: 16348/19709\n",
            "Converting SMILES to graph: 16349/19709\n",
            "Converting SMILES to graph: 16350/19709\n",
            "Converting SMILES to graph: 16351/19709\n",
            "Converting SMILES to graph: 16352/19709\n",
            "Converting SMILES to graph: 16353/19709\n",
            "Converting SMILES to graph: 16354/19709\n",
            "Converting SMILES to graph: 16355/19709\n",
            "Converting SMILES to graph: 16356/19709\n",
            "Converting SMILES to graph: 16357/19709\n",
            "Converting SMILES to graph: 16358/19709\n",
            "Converting SMILES to graph: 16359/19709\n",
            "Converting SMILES to graph: 16360/19709\n",
            "Converting SMILES to graph: 16361/19709\n",
            "Converting SMILES to graph: 16362/19709\n",
            "Converting SMILES to graph: 16363/19709\n",
            "Converting SMILES to graph: 16364/19709\n",
            "Converting SMILES to graph: 16365/19709\n",
            "Converting SMILES to graph: 16366/19709\n",
            "Converting SMILES to graph: 16367/19709\n",
            "Converting SMILES to graph: 16368/19709\n",
            "Converting SMILES to graph: 16369/19709\n",
            "Converting SMILES to graph: 16370/19709\n",
            "Converting SMILES to graph: 16371/19709\n",
            "Converting SMILES to graph: 16372/19709\n",
            "Converting SMILES to graph: 16373/19709\n",
            "Converting SMILES to graph: 16374/19709\n",
            "Converting SMILES to graph: 16375/19709\n",
            "Converting SMILES to graph: 16376/19709\n",
            "Converting SMILES to graph: 16377/19709\n",
            "Converting SMILES to graph: 16378/19709\n",
            "Converting SMILES to graph: 16379/19709\n",
            "Converting SMILES to graph: 16380/19709\n",
            "Converting SMILES to graph: 16381/19709\n",
            "Converting SMILES to graph: 16382/19709\n",
            "Converting SMILES to graph: 16383/19709\n",
            "Converting SMILES to graph: 16384/19709\n",
            "Converting SMILES to graph: 16385/19709\n",
            "Converting SMILES to graph: 16386/19709\n",
            "Converting SMILES to graph: 16387/19709\n",
            "Converting SMILES to graph: 16388/19709\n",
            "Converting SMILES to graph: 16389/19709\n",
            "Converting SMILES to graph: 16390/19709\n",
            "Converting SMILES to graph: 16391/19709\n",
            "Converting SMILES to graph: 16392/19709\n",
            "Converting SMILES to graph: 16393/19709\n",
            "Converting SMILES to graph: 16394/19709\n",
            "Converting SMILES to graph: 16395/19709\n",
            "Converting SMILES to graph: 16396/19709\n",
            "Converting SMILES to graph: 16397/19709\n",
            "Converting SMILES to graph: 16398/19709\n",
            "Converting SMILES to graph: 16399/19709\n",
            "Converting SMILES to graph: 16400/19709\n",
            "Converting SMILES to graph: 16401/19709\n",
            "Converting SMILES to graph: 16402/19709\n",
            "Converting SMILES to graph: 16403/19709\n",
            "Converting SMILES to graph: 16404/19709\n",
            "Converting SMILES to graph: 16405/19709\n",
            "Converting SMILES to graph: 16406/19709\n",
            "Converting SMILES to graph: 16407/19709\n",
            "Converting SMILES to graph: 16408/19709\n",
            "Converting SMILES to graph: 16409/19709\n",
            "Converting SMILES to graph: 16410/19709\n",
            "Converting SMILES to graph: 16411/19709\n",
            "Converting SMILES to graph: 16412/19709\n",
            "Converting SMILES to graph: 16413/19709\n",
            "Converting SMILES to graph: 16414/19709\n",
            "Converting SMILES to graph: 16415/19709\n",
            "Converting SMILES to graph: 16416/19709\n",
            "Converting SMILES to graph: 16417/19709\n",
            "Converting SMILES to graph: 16418/19709\n",
            "Converting SMILES to graph: 16419/19709\n",
            "Converting SMILES to graph: 16420/19709\n",
            "Converting SMILES to graph: 16421/19709\n",
            "Converting SMILES to graph: 16422/19709\n",
            "Converting SMILES to graph: 16423/19709\n",
            "Converting SMILES to graph: 16424/19709\n",
            "Converting SMILES to graph: 16425/19709\n",
            "Converting SMILES to graph: 16426/19709\n",
            "Converting SMILES to graph: 16427/19709\n",
            "Converting SMILES to graph: 16428/19709\n",
            "Converting SMILES to graph: 16429/19709\n",
            "Converting SMILES to graph: 16430/19709\n",
            "Converting SMILES to graph: 16431/19709\n",
            "Converting SMILES to graph: 16432/19709\n",
            "Converting SMILES to graph: 16433/19709\n",
            "Converting SMILES to graph: 16434/19709\n",
            "Converting SMILES to graph: 16435/19709\n",
            "Converting SMILES to graph: 16436/19709\n",
            "Converting SMILES to graph: 16437/19709\n",
            "Converting SMILES to graph: 16438/19709\n",
            "Converting SMILES to graph: 16439/19709\n",
            "Converting SMILES to graph: 16440/19709\n",
            "Converting SMILES to graph: 16441/19709\n",
            "Converting SMILES to graph: 16442/19709\n",
            "Converting SMILES to graph: 16443/19709\n",
            "Converting SMILES to graph: 16444/19709\n",
            "Converting SMILES to graph: 16445/19709\n",
            "Converting SMILES to graph: 16446/19709\n",
            "Converting SMILES to graph: 16447/19709\n",
            "Converting SMILES to graph: 16448/19709\n",
            "Converting SMILES to graph: 16449/19709\n",
            "Converting SMILES to graph: 16450/19709\n",
            "Converting SMILES to graph: 16451/19709\n",
            "Converting SMILES to graph: 16452/19709\n",
            "Converting SMILES to graph: 16453/19709\n",
            "Converting SMILES to graph: 16454/19709\n",
            "Converting SMILES to graph: 16455/19709\n",
            "Converting SMILES to graph: 16456/19709\n",
            "Converting SMILES to graph: 16457/19709\n",
            "Converting SMILES to graph: 16458/19709\n",
            "Converting SMILES to graph: 16459/19709\n",
            "Converting SMILES to graph: 16460/19709\n",
            "Converting SMILES to graph: 16461/19709\n",
            "Converting SMILES to graph: 16462/19709\n",
            "Converting SMILES to graph: 16463/19709\n",
            "Converting SMILES to graph: 16464/19709\n",
            "Converting SMILES to graph: 16465/19709\n",
            "Converting SMILES to graph: 16466/19709\n",
            "Converting SMILES to graph: 16467/19709\n",
            "Converting SMILES to graph: 16468/19709\n",
            "Converting SMILES to graph: 16469/19709\n",
            "Converting SMILES to graph: 16470/19709\n",
            "Converting SMILES to graph: 16471/19709\n",
            "Converting SMILES to graph: 16472/19709\n",
            "Converting SMILES to graph: 16473/19709\n",
            "Converting SMILES to graph: 16474/19709\n",
            "Converting SMILES to graph: 16475/19709\n",
            "Converting SMILES to graph: 16476/19709\n",
            "Converting SMILES to graph: 16477/19709\n",
            "Converting SMILES to graph: 16478/19709\n",
            "Converting SMILES to graph: 16479/19709\n",
            "Converting SMILES to graph: 16480/19709\n",
            "Converting SMILES to graph: 16481/19709\n",
            "Converting SMILES to graph: 16482/19709\n",
            "Converting SMILES to graph: 16483/19709\n",
            "Converting SMILES to graph: 16484/19709\n",
            "Converting SMILES to graph: 16485/19709\n",
            "Converting SMILES to graph: 16486/19709\n",
            "Converting SMILES to graph: 16487/19709\n",
            "Converting SMILES to graph: 16488/19709\n",
            "Converting SMILES to graph: 16489/19709\n",
            "Converting SMILES to graph: 16490/19709\n",
            "Converting SMILES to graph: 16491/19709\n",
            "Converting SMILES to graph: 16492/19709\n",
            "Converting SMILES to graph: 16493/19709\n",
            "Converting SMILES to graph: 16494/19709\n",
            "Converting SMILES to graph: 16495/19709\n",
            "Converting SMILES to graph: 16496/19709\n",
            "Converting SMILES to graph: 16497/19709\n",
            "Converting SMILES to graph: 16498/19709\n",
            "Converting SMILES to graph: 16499/19709\n",
            "Converting SMILES to graph: 16500/19709\n",
            "Converting SMILES to graph: 16501/19709\n",
            "Converting SMILES to graph: 16502/19709\n",
            "Converting SMILES to graph: 16503/19709\n",
            "Converting SMILES to graph: 16504/19709\n",
            "Converting SMILES to graph: 16505/19709\n",
            "Converting SMILES to graph: 16506/19709\n",
            "Converting SMILES to graph: 16507/19709\n",
            "Converting SMILES to graph: 16508/19709\n",
            "Converting SMILES to graph: 16509/19709\n",
            "Converting SMILES to graph: 16510/19709\n",
            "Converting SMILES to graph: 16511/19709\n",
            "Converting SMILES to graph: 16512/19709\n",
            "Converting SMILES to graph: 16513/19709\n",
            "Converting SMILES to graph: 16514/19709\n",
            "Converting SMILES to graph: 16515/19709\n",
            "Converting SMILES to graph: 16516/19709\n",
            "Converting SMILES to graph: 16517/19709\n",
            "Converting SMILES to graph: 16518/19709\n",
            "Converting SMILES to graph: 16519/19709\n",
            "Converting SMILES to graph: 16520/19709\n",
            "Converting SMILES to graph: 16521/19709\n",
            "Converting SMILES to graph: 16522/19709\n",
            "Converting SMILES to graph: 16523/19709\n",
            "Converting SMILES to graph: 16524/19709\n",
            "Converting SMILES to graph: 16525/19709\n",
            "Converting SMILES to graph: 16526/19709\n",
            "Converting SMILES to graph: 16527/19709\n",
            "Converting SMILES to graph: 16528/19709\n",
            "Converting SMILES to graph: 16529/19709\n",
            "Converting SMILES to graph: 16530/19709\n",
            "Converting SMILES to graph: 16531/19709\n",
            "Converting SMILES to graph: 16532/19709\n",
            "Converting SMILES to graph: 16533/19709\n",
            "Converting SMILES to graph: 16534/19709\n",
            "Converting SMILES to graph: 16535/19709\n",
            "Converting SMILES to graph: 16536/19709\n",
            "Converting SMILES to graph: 16537/19709\n",
            "Converting SMILES to graph: 16538/19709\n",
            "Converting SMILES to graph: 16539/19709\n",
            "Converting SMILES to graph: 16540/19709\n",
            "Converting SMILES to graph: 16541/19709\n",
            "Converting SMILES to graph: 16542/19709\n",
            "Converting SMILES to graph: 16543/19709\n",
            "Converting SMILES to graph: 16544/19709\n",
            "Converting SMILES to graph: 16545/19709\n",
            "Converting SMILES to graph: 16546/19709\n",
            "Converting SMILES to graph: 16547/19709\n",
            "Converting SMILES to graph: 16548/19709\n",
            "Converting SMILES to graph: 16549/19709\n",
            "Converting SMILES to graph: 16550/19709\n",
            "Converting SMILES to graph: 16551/19709\n",
            "Converting SMILES to graph: 16552/19709\n",
            "Converting SMILES to graph: 16553/19709\n",
            "Converting SMILES to graph: 16554/19709\n",
            "Converting SMILES to graph: 16555/19709\n",
            "Converting SMILES to graph: 16556/19709\n",
            "Converting SMILES to graph: 16557/19709\n",
            "Converting SMILES to graph: 16558/19709\n",
            "Converting SMILES to graph: 16559/19709\n",
            "Converting SMILES to graph: 16560/19709\n",
            "Converting SMILES to graph: 16561/19709\n",
            "Converting SMILES to graph: 16562/19709\n",
            "Converting SMILES to graph: 16563/19709\n",
            "Converting SMILES to graph: 16564/19709\n",
            "Converting SMILES to graph: 16565/19709\n",
            "Converting SMILES to graph: 16566/19709\n",
            "Converting SMILES to graph: 16567/19709\n",
            "Converting SMILES to graph: 16568/19709\n",
            "Converting SMILES to graph: 16569/19709\n",
            "Converting SMILES to graph: 16570/19709\n",
            "Converting SMILES to graph: 16571/19709\n",
            "Converting SMILES to graph: 16572/19709\n",
            "Converting SMILES to graph: 16573/19709\n",
            "Converting SMILES to graph: 16574/19709\n",
            "Converting SMILES to graph: 16575/19709\n",
            "Converting SMILES to graph: 16576/19709\n",
            "Converting SMILES to graph: 16577/19709\n",
            "Converting SMILES to graph: 16578/19709\n",
            "Converting SMILES to graph: 16579/19709\n",
            "Converting SMILES to graph: 16580/19709\n",
            "Converting SMILES to graph: 16581/19709\n",
            "Converting SMILES to graph: 16582/19709\n",
            "Converting SMILES to graph: 16583/19709\n",
            "Converting SMILES to graph: 16584/19709\n",
            "Converting SMILES to graph: 16585/19709\n",
            "Converting SMILES to graph: 16586/19709\n",
            "Converting SMILES to graph: 16587/19709\n",
            "Converting SMILES to graph: 16588/19709\n",
            "Converting SMILES to graph: 16589/19709\n",
            "Converting SMILES to graph: 16590/19709\n",
            "Converting SMILES to graph: 16591/19709\n",
            "Converting SMILES to graph: 16592/19709\n",
            "Converting SMILES to graph: 16593/19709\n",
            "Converting SMILES to graph: 16594/19709\n",
            "Converting SMILES to graph: 16595/19709\n",
            "Converting SMILES to graph: 16596/19709\n",
            "Converting SMILES to graph: 16597/19709\n",
            "Converting SMILES to graph: 16598/19709\n",
            "Converting SMILES to graph: 16599/19709\n",
            "Converting SMILES to graph: 16600/19709\n",
            "Converting SMILES to graph: 16601/19709\n",
            "Converting SMILES to graph: 16602/19709\n",
            "Converting SMILES to graph: 16603/19709\n",
            "Converting SMILES to graph: 16604/19709\n",
            "Converting SMILES to graph: 16605/19709\n",
            "Converting SMILES to graph: 16606/19709\n",
            "Converting SMILES to graph: 16607/19709\n",
            "Converting SMILES to graph: 16608/19709\n",
            "Converting SMILES to graph: 16609/19709\n",
            "Converting SMILES to graph: 16610/19709\n",
            "Converting SMILES to graph: 16611/19709\n",
            "Converting SMILES to graph: 16612/19709\n",
            "Converting SMILES to graph: 16613/19709\n",
            "Converting SMILES to graph: 16614/19709\n",
            "Converting SMILES to graph: 16615/19709\n",
            "Converting SMILES to graph: 16616/19709\n",
            "Converting SMILES to graph: 16617/19709\n",
            "Converting SMILES to graph: 16618/19709\n",
            "Converting SMILES to graph: 16619/19709\n",
            "Converting SMILES to graph: 16620/19709\n",
            "Converting SMILES to graph: 16621/19709\n",
            "Converting SMILES to graph: 16622/19709\n",
            "Converting SMILES to graph: 16623/19709\n",
            "Converting SMILES to graph: 16624/19709\n",
            "Converting SMILES to graph: 16625/19709\n",
            "Converting SMILES to graph: 16626/19709\n",
            "Converting SMILES to graph: 16627/19709\n",
            "Converting SMILES to graph: 16628/19709\n",
            "Converting SMILES to graph: 16629/19709\n",
            "Converting SMILES to graph: 16630/19709\n",
            "Converting SMILES to graph: 16631/19709\n",
            "Converting SMILES to graph: 16632/19709\n",
            "Converting SMILES to graph: 16633/19709\n",
            "Converting SMILES to graph: 16634/19709\n",
            "Converting SMILES to graph: 16635/19709\n",
            "Converting SMILES to graph: 16636/19709\n",
            "Converting SMILES to graph: 16637/19709\n",
            "Converting SMILES to graph: 16638/19709\n",
            "Converting SMILES to graph: 16639/19709\n",
            "Converting SMILES to graph: 16640/19709\n",
            "Converting SMILES to graph: 16641/19709\n",
            "Converting SMILES to graph: 16642/19709\n",
            "Converting SMILES to graph: 16643/19709\n",
            "Converting SMILES to graph: 16644/19709\n",
            "Converting SMILES to graph: 16645/19709\n",
            "Converting SMILES to graph: 16646/19709\n",
            "Converting SMILES to graph: 16647/19709\n",
            "Converting SMILES to graph: 16648/19709\n",
            "Converting SMILES to graph: 16649/19709\n",
            "Converting SMILES to graph: 16650/19709\n",
            "Converting SMILES to graph: 16651/19709\n",
            "Converting SMILES to graph: 16652/19709\n",
            "Converting SMILES to graph: 16653/19709\n",
            "Converting SMILES to graph: 16654/19709\n",
            "Converting SMILES to graph: 16655/19709\n",
            "Converting SMILES to graph: 16656/19709\n",
            "Converting SMILES to graph: 16657/19709\n",
            "Converting SMILES to graph: 16658/19709\n",
            "Converting SMILES to graph: 16659/19709\n",
            "Converting SMILES to graph: 16660/19709\n",
            "Converting SMILES to graph: 16661/19709\n",
            "Converting SMILES to graph: 16662/19709\n",
            "Converting SMILES to graph: 16663/19709\n",
            "Converting SMILES to graph: 16664/19709\n",
            "Converting SMILES to graph: 16665/19709\n",
            "Converting SMILES to graph: 16666/19709\n",
            "Converting SMILES to graph: 16667/19709\n",
            "Converting SMILES to graph: 16668/19709\n",
            "Converting SMILES to graph: 16669/19709\n",
            "Converting SMILES to graph: 16670/19709\n",
            "Converting SMILES to graph: 16671/19709\n",
            "Converting SMILES to graph: 16672/19709\n",
            "Converting SMILES to graph: 16673/19709\n",
            "Converting SMILES to graph: 16674/19709\n",
            "Converting SMILES to graph: 16675/19709\n",
            "Converting SMILES to graph: 16676/19709\n",
            "Converting SMILES to graph: 16677/19709\n",
            "Converting SMILES to graph: 16678/19709\n",
            "Converting SMILES to graph: 16679/19709\n",
            "Converting SMILES to graph: 16680/19709\n",
            "Converting SMILES to graph: 16681/19709\n",
            "Converting SMILES to graph: 16682/19709\n",
            "Converting SMILES to graph: 16683/19709\n",
            "Converting SMILES to graph: 16684/19709\n",
            "Converting SMILES to graph: 16685/19709\n",
            "Converting SMILES to graph: 16686/19709\n",
            "Converting SMILES to graph: 16687/19709\n",
            "Converting SMILES to graph: 16688/19709\n",
            "Converting SMILES to graph: 16689/19709\n",
            "Converting SMILES to graph: 16690/19709\n",
            "Converting SMILES to graph: 16691/19709\n",
            "Converting SMILES to graph: 16692/19709\n",
            "Converting SMILES to graph: 16693/19709\n",
            "Converting SMILES to graph: 16694/19709\n",
            "Converting SMILES to graph: 16695/19709\n",
            "Converting SMILES to graph: 16696/19709\n",
            "Converting SMILES to graph: 16697/19709\n",
            "Converting SMILES to graph: 16698/19709\n",
            "Converting SMILES to graph: 16699/19709\n",
            "Converting SMILES to graph: 16700/19709\n",
            "Converting SMILES to graph: 16701/19709\n",
            "Converting SMILES to graph: 16702/19709\n",
            "Converting SMILES to graph: 16703/19709\n",
            "Converting SMILES to graph: 16704/19709\n",
            "Converting SMILES to graph: 16705/19709\n",
            "Converting SMILES to graph: 16706/19709\n",
            "Converting SMILES to graph: 16707/19709\n",
            "Converting SMILES to graph: 16708/19709\n",
            "Converting SMILES to graph: 16709/19709\n",
            "Converting SMILES to graph: 16710/19709\n",
            "Converting SMILES to graph: 16711/19709\n",
            "Converting SMILES to graph: 16712/19709\n",
            "Converting SMILES to graph: 16713/19709\n",
            "Converting SMILES to graph: 16714/19709\n",
            "Converting SMILES to graph: 16715/19709\n",
            "Converting SMILES to graph: 16716/19709\n",
            "Converting SMILES to graph: 16717/19709\n",
            "Converting SMILES to graph: 16718/19709\n",
            "Converting SMILES to graph: 16719/19709\n",
            "Converting SMILES to graph: 16720/19709\n",
            "Converting SMILES to graph: 16721/19709\n",
            "Converting SMILES to graph: 16722/19709\n",
            "Converting SMILES to graph: 16723/19709\n",
            "Converting SMILES to graph: 16724/19709\n",
            "Converting SMILES to graph: 16725/19709\n",
            "Converting SMILES to graph: 16726/19709\n",
            "Converting SMILES to graph: 16727/19709\n",
            "Converting SMILES to graph: 16728/19709\n",
            "Converting SMILES to graph: 16729/19709\n",
            "Converting SMILES to graph: 16730/19709\n",
            "Converting SMILES to graph: 16731/19709\n",
            "Converting SMILES to graph: 16732/19709\n",
            "Converting SMILES to graph: 16733/19709\n",
            "Converting SMILES to graph: 16734/19709\n",
            "Converting SMILES to graph: 16735/19709\n",
            "Converting SMILES to graph: 16736/19709\n",
            "Converting SMILES to graph: 16737/19709\n",
            "Converting SMILES to graph: 16738/19709\n",
            "Converting SMILES to graph: 16739/19709\n",
            "Converting SMILES to graph: 16740/19709\n",
            "Converting SMILES to graph: 16741/19709\n",
            "Converting SMILES to graph: 16742/19709\n",
            "Converting SMILES to graph: 16743/19709\n",
            "Converting SMILES to graph: 16744/19709\n",
            "Converting SMILES to graph: 16745/19709\n",
            "Converting SMILES to graph: 16746/19709\n",
            "Converting SMILES to graph: 16747/19709\n",
            "Converting SMILES to graph: 16748/19709\n",
            "Converting SMILES to graph: 16749/19709\n",
            "Converting SMILES to graph: 16750/19709\n",
            "Converting SMILES to graph: 16751/19709\n",
            "Converting SMILES to graph: 16752/19709\n",
            "Converting SMILES to graph: 16753/19709\n",
            "Converting SMILES to graph: 16754/19709\n",
            "Converting SMILES to graph: 16755/19709\n",
            "Converting SMILES to graph: 16756/19709\n",
            "Converting SMILES to graph: 16757/19709\n",
            "Converting SMILES to graph: 16758/19709\n",
            "Converting SMILES to graph: 16759/19709\n",
            "Converting SMILES to graph: 16760/19709\n",
            "Converting SMILES to graph: 16761/19709\n",
            "Converting SMILES to graph: 16762/19709\n",
            "Converting SMILES to graph: 16763/19709\n",
            "Converting SMILES to graph: 16764/19709\n",
            "Converting SMILES to graph: 16765/19709\n",
            "Converting SMILES to graph: 16766/19709\n",
            "Converting SMILES to graph: 16767/19709\n",
            "Converting SMILES to graph: 16768/19709\n",
            "Converting SMILES to graph: 16769/19709\n",
            "Converting SMILES to graph: 16770/19709\n",
            "Converting SMILES to graph: 16771/19709\n",
            "Converting SMILES to graph: 16772/19709\n",
            "Converting SMILES to graph: 16773/19709\n",
            "Converting SMILES to graph: 16774/19709\n",
            "Converting SMILES to graph: 16775/19709\n",
            "Converting SMILES to graph: 16776/19709\n",
            "Converting SMILES to graph: 16777/19709\n",
            "Converting SMILES to graph: 16778/19709\n",
            "Converting SMILES to graph: 16779/19709\n",
            "Converting SMILES to graph: 16780/19709\n",
            "Converting SMILES to graph: 16781/19709\n",
            "Converting SMILES to graph: 16782/19709\n",
            "Converting SMILES to graph: 16783/19709\n",
            "Converting SMILES to graph: 16784/19709\n",
            "Converting SMILES to graph: 16785/19709\n",
            "Converting SMILES to graph: 16786/19709\n",
            "Converting SMILES to graph: 16787/19709\n",
            "Converting SMILES to graph: 16788/19709\n",
            "Converting SMILES to graph: 16789/19709\n",
            "Converting SMILES to graph: 16790/19709\n",
            "Converting SMILES to graph: 16791/19709\n",
            "Converting SMILES to graph: 16792/19709\n",
            "Converting SMILES to graph: 16793/19709\n",
            "Converting SMILES to graph: 16794/19709\n",
            "Converting SMILES to graph: 16795/19709\n",
            "Converting SMILES to graph: 16796/19709\n",
            "Converting SMILES to graph: 16797/19709\n",
            "Converting SMILES to graph: 16798/19709\n",
            "Converting SMILES to graph: 16799/19709\n",
            "Converting SMILES to graph: 16800/19709\n",
            "Converting SMILES to graph: 16801/19709\n",
            "Converting SMILES to graph: 16802/19709\n",
            "Converting SMILES to graph: 16803/19709\n",
            "Converting SMILES to graph: 16804/19709\n",
            "Converting SMILES to graph: 16805/19709\n",
            "Converting SMILES to graph: 16806/19709\n",
            "Converting SMILES to graph: 16807/19709\n",
            "Converting SMILES to graph: 16808/19709\n",
            "Converting SMILES to graph: 16809/19709\n",
            "Converting SMILES to graph: 16810/19709\n",
            "Converting SMILES to graph: 16811/19709\n",
            "Converting SMILES to graph: 16812/19709\n",
            "Converting SMILES to graph: 16813/19709\n",
            "Converting SMILES to graph: 16814/19709\n",
            "Converting SMILES to graph: 16815/19709\n",
            "Converting SMILES to graph: 16816/19709\n",
            "Converting SMILES to graph: 16817/19709\n",
            "Converting SMILES to graph: 16818/19709\n",
            "Converting SMILES to graph: 16819/19709\n",
            "Converting SMILES to graph: 16820/19709\n",
            "Converting SMILES to graph: 16821/19709\n",
            "Converting SMILES to graph: 16822/19709\n",
            "Converting SMILES to graph: 16823/19709\n",
            "Converting SMILES to graph: 16824/19709\n",
            "Converting SMILES to graph: 16825/19709\n",
            "Converting SMILES to graph: 16826/19709\n",
            "Converting SMILES to graph: 16827/19709\n",
            "Converting SMILES to graph: 16828/19709\n",
            "Converting SMILES to graph: 16829/19709\n",
            "Converting SMILES to graph: 16830/19709\n",
            "Converting SMILES to graph: 16831/19709\n",
            "Converting SMILES to graph: 16832/19709\n",
            "Converting SMILES to graph: 16833/19709\n",
            "Converting SMILES to graph: 16834/19709\n",
            "Converting SMILES to graph: 16835/19709\n",
            "Converting SMILES to graph: 16836/19709\n",
            "Converting SMILES to graph: 16837/19709\n",
            "Converting SMILES to graph: 16838/19709\n",
            "Converting SMILES to graph: 16839/19709\n",
            "Converting SMILES to graph: 16840/19709\n",
            "Converting SMILES to graph: 16841/19709\n",
            "Converting SMILES to graph: 16842/19709\n",
            "Converting SMILES to graph: 16843/19709\n",
            "Converting SMILES to graph: 16844/19709\n",
            "Converting SMILES to graph: 16845/19709\n",
            "Converting SMILES to graph: 16846/19709\n",
            "Converting SMILES to graph: 16847/19709\n",
            "Converting SMILES to graph: 16848/19709\n",
            "Converting SMILES to graph: 16849/19709\n",
            "Converting SMILES to graph: 16850/19709\n",
            "Converting SMILES to graph: 16851/19709\n",
            "Converting SMILES to graph: 16852/19709\n",
            "Converting SMILES to graph: 16853/19709\n",
            "Converting SMILES to graph: 16854/19709\n",
            "Converting SMILES to graph: 16855/19709\n",
            "Converting SMILES to graph: 16856/19709\n",
            "Converting SMILES to graph: 16857/19709\n",
            "Converting SMILES to graph: 16858/19709\n",
            "Converting SMILES to graph: 16859/19709\n",
            "Converting SMILES to graph: 16860/19709\n",
            "Converting SMILES to graph: 16861/19709\n",
            "Converting SMILES to graph: 16862/19709\n",
            "Converting SMILES to graph: 16863/19709\n",
            "Converting SMILES to graph: 16864/19709\n",
            "Converting SMILES to graph: 16865/19709\n",
            "Converting SMILES to graph: 16866/19709\n",
            "Converting SMILES to graph: 16867/19709\n",
            "Converting SMILES to graph: 16868/19709\n",
            "Converting SMILES to graph: 16869/19709\n",
            "Converting SMILES to graph: 16870/19709\n",
            "Converting SMILES to graph: 16871/19709\n",
            "Converting SMILES to graph: 16872/19709\n",
            "Converting SMILES to graph: 16873/19709\n",
            "Converting SMILES to graph: 16874/19709\n",
            "Converting SMILES to graph: 16875/19709\n",
            "Converting SMILES to graph: 16876/19709\n",
            "Converting SMILES to graph: 16877/19709\n",
            "Converting SMILES to graph: 16878/19709\n",
            "Converting SMILES to graph: 16879/19709\n",
            "Converting SMILES to graph: 16880/19709\n",
            "Converting SMILES to graph: 16881/19709\n",
            "Converting SMILES to graph: 16882/19709\n",
            "Converting SMILES to graph: 16883/19709\n",
            "Converting SMILES to graph: 16884/19709\n",
            "Converting SMILES to graph: 16885/19709\n",
            "Converting SMILES to graph: 16886/19709\n",
            "Converting SMILES to graph: 16887/19709\n",
            "Converting SMILES to graph: 16888/19709\n",
            "Converting SMILES to graph: 16889/19709\n",
            "Converting SMILES to graph: 16890/19709\n",
            "Converting SMILES to graph: 16891/19709\n",
            "Converting SMILES to graph: 16892/19709\n",
            "Converting SMILES to graph: 16893/19709\n",
            "Converting SMILES to graph: 16894/19709\n",
            "Converting SMILES to graph: 16895/19709\n",
            "Converting SMILES to graph: 16896/19709\n",
            "Converting SMILES to graph: 16897/19709\n",
            "Converting SMILES to graph: 16898/19709\n",
            "Converting SMILES to graph: 16899/19709\n",
            "Converting SMILES to graph: 16900/19709\n",
            "Converting SMILES to graph: 16901/19709\n",
            "Converting SMILES to graph: 16902/19709\n",
            "Converting SMILES to graph: 16903/19709\n",
            "Converting SMILES to graph: 16904/19709\n",
            "Converting SMILES to graph: 16905/19709\n",
            "Converting SMILES to graph: 16906/19709\n",
            "Converting SMILES to graph: 16907/19709\n",
            "Converting SMILES to graph: 16908/19709\n",
            "Converting SMILES to graph: 16909/19709\n",
            "Converting SMILES to graph: 16910/19709\n",
            "Converting SMILES to graph: 16911/19709\n",
            "Converting SMILES to graph: 16912/19709\n",
            "Converting SMILES to graph: 16913/19709\n",
            "Converting SMILES to graph: 16914/19709\n",
            "Converting SMILES to graph: 16915/19709\n",
            "Converting SMILES to graph: 16916/19709\n",
            "Converting SMILES to graph: 16917/19709\n",
            "Converting SMILES to graph: 16918/19709\n",
            "Converting SMILES to graph: 16919/19709\n",
            "Converting SMILES to graph: 16920/19709\n",
            "Converting SMILES to graph: 16921/19709\n",
            "Converting SMILES to graph: 16922/19709\n",
            "Converting SMILES to graph: 16923/19709\n",
            "Converting SMILES to graph: 16924/19709\n",
            "Converting SMILES to graph: 16925/19709\n",
            "Converting SMILES to graph: 16926/19709\n",
            "Converting SMILES to graph: 16927/19709\n",
            "Converting SMILES to graph: 16928/19709\n",
            "Converting SMILES to graph: 16929/19709\n",
            "Converting SMILES to graph: 16930/19709\n",
            "Converting SMILES to graph: 16931/19709\n",
            "Converting SMILES to graph: 16932/19709\n",
            "Converting SMILES to graph: 16933/19709\n",
            "Converting SMILES to graph: 16934/19709\n",
            "Converting SMILES to graph: 16935/19709\n",
            "Converting SMILES to graph: 16936/19709\n",
            "Converting SMILES to graph: 16937/19709\n",
            "Converting SMILES to graph: 16938/19709\n",
            "Converting SMILES to graph: 16939/19709\n",
            "Converting SMILES to graph: 16940/19709\n",
            "Converting SMILES to graph: 16941/19709\n",
            "Converting SMILES to graph: 16942/19709\n",
            "Converting SMILES to graph: 16943/19709\n",
            "Converting SMILES to graph: 16944/19709\n",
            "Converting SMILES to graph: 16945/19709\n",
            "Converting SMILES to graph: 16946/19709\n",
            "Converting SMILES to graph: 16947/19709\n",
            "Converting SMILES to graph: 16948/19709\n",
            "Converting SMILES to graph: 16949/19709\n",
            "Converting SMILES to graph: 16950/19709\n",
            "Converting SMILES to graph: 16951/19709\n",
            "Converting SMILES to graph: 16952/19709\n",
            "Converting SMILES to graph: 16953/19709\n",
            "Converting SMILES to graph: 16954/19709\n",
            "Converting SMILES to graph: 16955/19709\n",
            "Converting SMILES to graph: 16956/19709\n",
            "Converting SMILES to graph: 16957/19709\n",
            "Converting SMILES to graph: 16958/19709\n",
            "Converting SMILES to graph: 16959/19709\n",
            "Converting SMILES to graph: 16960/19709\n",
            "Converting SMILES to graph: 16961/19709\n",
            "Converting SMILES to graph: 16962/19709\n",
            "Converting SMILES to graph: 16963/19709\n",
            "Converting SMILES to graph: 16964/19709\n",
            "Converting SMILES to graph: 16965/19709\n",
            "Converting SMILES to graph: 16966/19709\n",
            "Converting SMILES to graph: 16967/19709\n",
            "Converting SMILES to graph: 16968/19709\n",
            "Converting SMILES to graph: 16969/19709\n",
            "Converting SMILES to graph: 16970/19709\n",
            "Converting SMILES to graph: 16971/19709\n",
            "Converting SMILES to graph: 16972/19709\n",
            "Converting SMILES to graph: 16973/19709\n",
            "Converting SMILES to graph: 16974/19709\n",
            "Converting SMILES to graph: 16975/19709\n",
            "Converting SMILES to graph: 16976/19709\n",
            "Converting SMILES to graph: 16977/19709\n",
            "Converting SMILES to graph: 16978/19709\n",
            "Converting SMILES to graph: 16979/19709\n",
            "Converting SMILES to graph: 16980/19709\n",
            "Converting SMILES to graph: 16981/19709\n",
            "Converting SMILES to graph: 16982/19709\n",
            "Converting SMILES to graph: 16983/19709\n",
            "Converting SMILES to graph: 16984/19709\n",
            "Converting SMILES to graph: 16985/19709\n",
            "Converting SMILES to graph: 16986/19709\n",
            "Converting SMILES to graph: 16987/19709\n",
            "Converting SMILES to graph: 16988/19709\n",
            "Converting SMILES to graph: 16989/19709\n",
            "Converting SMILES to graph: 16990/19709\n",
            "Converting SMILES to graph: 16991/19709\n",
            "Converting SMILES to graph: 16992/19709\n",
            "Converting SMILES to graph: 16993/19709\n",
            "Converting SMILES to graph: 16994/19709\n",
            "Converting SMILES to graph: 16995/19709\n",
            "Converting SMILES to graph: 16996/19709\n",
            "Converting SMILES to graph: 16997/19709\n",
            "Converting SMILES to graph: 16998/19709\n",
            "Converting SMILES to graph: 16999/19709\n",
            "Converting SMILES to graph: 17000/19709\n",
            "Converting SMILES to graph: 17001/19709\n",
            "Converting SMILES to graph: 17002/19709\n",
            "Converting SMILES to graph: 17003/19709\n",
            "Converting SMILES to graph: 17004/19709\n",
            "Converting SMILES to graph: 17005/19709\n",
            "Converting SMILES to graph: 17006/19709\n",
            "Converting SMILES to graph: 17007/19709\n",
            "Converting SMILES to graph: 17008/19709\n",
            "Converting SMILES to graph: 17009/19709\n",
            "Converting SMILES to graph: 17010/19709\n",
            "Converting SMILES to graph: 17011/19709\n",
            "Converting SMILES to graph: 17012/19709\n",
            "Converting SMILES to graph: 17013/19709\n",
            "Converting SMILES to graph: 17014/19709\n",
            "Converting SMILES to graph: 17015/19709\n",
            "Converting SMILES to graph: 17016/19709\n",
            "Converting SMILES to graph: 17017/19709\n",
            "Converting SMILES to graph: 17018/19709\n",
            "Converting SMILES to graph: 17019/19709\n",
            "Converting SMILES to graph: 17020/19709\n",
            "Converting SMILES to graph: 17021/19709\n",
            "Converting SMILES to graph: 17022/19709\n",
            "Converting SMILES to graph: 17023/19709\n",
            "Converting SMILES to graph: 17024/19709\n",
            "Converting SMILES to graph: 17025/19709\n",
            "Converting SMILES to graph: 17026/19709\n",
            "Converting SMILES to graph: 17027/19709\n",
            "Converting SMILES to graph: 17028/19709\n",
            "Converting SMILES to graph: 17029/19709\n",
            "Converting SMILES to graph: 17030/19709\n",
            "Converting SMILES to graph: 17031/19709\n",
            "Converting SMILES to graph: 17032/19709\n",
            "Converting SMILES to graph: 17033/19709\n",
            "Converting SMILES to graph: 17034/19709\n",
            "Converting SMILES to graph: 17035/19709\n",
            "Converting SMILES to graph: 17036/19709\n",
            "Converting SMILES to graph: 17037/19709\n",
            "Converting SMILES to graph: 17038/19709\n",
            "Converting SMILES to graph: 17039/19709\n",
            "Converting SMILES to graph: 17040/19709\n",
            "Converting SMILES to graph: 17041/19709\n",
            "Converting SMILES to graph: 17042/19709\n",
            "Converting SMILES to graph: 17043/19709\n",
            "Converting SMILES to graph: 17044/19709\n",
            "Converting SMILES to graph: 17045/19709\n",
            "Converting SMILES to graph: 17046/19709\n",
            "Converting SMILES to graph: 17047/19709\n",
            "Converting SMILES to graph: 17048/19709\n",
            "Converting SMILES to graph: 17049/19709\n",
            "Converting SMILES to graph: 17050/19709\n",
            "Converting SMILES to graph: 17051/19709\n",
            "Converting SMILES to graph: 17052/19709\n",
            "Converting SMILES to graph: 17053/19709\n",
            "Converting SMILES to graph: 17054/19709\n",
            "Converting SMILES to graph: 17055/19709\n",
            "Converting SMILES to graph: 17056/19709\n",
            "Converting SMILES to graph: 17057/19709\n",
            "Converting SMILES to graph: 17058/19709\n",
            "Converting SMILES to graph: 17059/19709\n",
            "Converting SMILES to graph: 17060/19709\n",
            "Converting SMILES to graph: 17061/19709\n",
            "Converting SMILES to graph: 17062/19709\n",
            "Converting SMILES to graph: 17063/19709\n",
            "Converting SMILES to graph: 17064/19709\n",
            "Converting SMILES to graph: 17065/19709\n",
            "Converting SMILES to graph: 17066/19709\n",
            "Converting SMILES to graph: 17067/19709\n",
            "Converting SMILES to graph: 17068/19709\n",
            "Converting SMILES to graph: 17069/19709\n",
            "Converting SMILES to graph: 17070/19709\n",
            "Converting SMILES to graph: 17071/19709\n",
            "Converting SMILES to graph: 17072/19709\n",
            "Converting SMILES to graph: 17073/19709\n",
            "Converting SMILES to graph: 17074/19709\n",
            "Converting SMILES to graph: 17075/19709\n",
            "Converting SMILES to graph: 17076/19709\n",
            "Converting SMILES to graph: 17077/19709\n",
            "Converting SMILES to graph: 17078/19709\n",
            "Converting SMILES to graph: 17079/19709\n",
            "Converting SMILES to graph: 17080/19709\n",
            "Converting SMILES to graph: 17081/19709\n",
            "Converting SMILES to graph: 17082/19709\n",
            "Converting SMILES to graph: 17083/19709\n",
            "Converting SMILES to graph: 17084/19709\n",
            "Converting SMILES to graph: 17085/19709\n",
            "Converting SMILES to graph: 17086/19709\n",
            "Converting SMILES to graph: 17087/19709\n",
            "Converting SMILES to graph: 17088/19709\n",
            "Converting SMILES to graph: 17089/19709\n",
            "Converting SMILES to graph: 17090/19709\n",
            "Converting SMILES to graph: 17091/19709\n",
            "Converting SMILES to graph: 17092/19709\n",
            "Converting SMILES to graph: 17093/19709\n",
            "Converting SMILES to graph: 17094/19709\n",
            "Converting SMILES to graph: 17095/19709\n",
            "Converting SMILES to graph: 17096/19709\n",
            "Converting SMILES to graph: 17097/19709\n",
            "Converting SMILES to graph: 17098/19709\n",
            "Converting SMILES to graph: 17099/19709\n",
            "Converting SMILES to graph: 17100/19709\n",
            "Converting SMILES to graph: 17101/19709\n",
            "Converting SMILES to graph: 17102/19709\n",
            "Converting SMILES to graph: 17103/19709\n",
            "Converting SMILES to graph: 17104/19709\n",
            "Converting SMILES to graph: 17105/19709\n",
            "Converting SMILES to graph: 17106/19709\n",
            "Converting SMILES to graph: 17107/19709\n",
            "Converting SMILES to graph: 17108/19709\n",
            "Converting SMILES to graph: 17109/19709\n",
            "Converting SMILES to graph: 17110/19709\n",
            "Converting SMILES to graph: 17111/19709\n",
            "Converting SMILES to graph: 17112/19709\n",
            "Converting SMILES to graph: 17113/19709\n",
            "Converting SMILES to graph: 17114/19709\n",
            "Converting SMILES to graph: 17115/19709\n",
            "Converting SMILES to graph: 17116/19709\n",
            "Converting SMILES to graph: 17117/19709\n",
            "Converting SMILES to graph: 17118/19709\n",
            "Converting SMILES to graph: 17119/19709\n",
            "Converting SMILES to graph: 17120/19709\n",
            "Converting SMILES to graph: 17121/19709\n",
            "Converting SMILES to graph: 17122/19709\n",
            "Converting SMILES to graph: 17123/19709\n",
            "Converting SMILES to graph: 17124/19709\n",
            "Converting SMILES to graph: 17125/19709\n",
            "Converting SMILES to graph: 17126/19709\n",
            "Converting SMILES to graph: 17127/19709\n",
            "Converting SMILES to graph: 17128/19709\n",
            "Converting SMILES to graph: 17129/19709\n",
            "Converting SMILES to graph: 17130/19709\n",
            "Converting SMILES to graph: 17131/19709\n",
            "Converting SMILES to graph: 17132/19709\n",
            "Converting SMILES to graph: 17133/19709\n",
            "Converting SMILES to graph: 17134/19709\n",
            "Converting SMILES to graph: 17135/19709\n",
            "Converting SMILES to graph: 17136/19709\n",
            "Converting SMILES to graph: 17137/19709\n",
            "Converting SMILES to graph: 17138/19709\n",
            "Converting SMILES to graph: 17139/19709\n",
            "Converting SMILES to graph: 17140/19709\n",
            "Converting SMILES to graph: 17141/19709\n",
            "Converting SMILES to graph: 17142/19709\n",
            "Converting SMILES to graph: 17143/19709\n",
            "Converting SMILES to graph: 17144/19709\n",
            "Converting SMILES to graph: 17145/19709\n",
            "Converting SMILES to graph: 17146/19709\n",
            "Converting SMILES to graph: 17147/19709\n",
            "Converting SMILES to graph: 17148/19709\n",
            "Converting SMILES to graph: 17149/19709\n",
            "Converting SMILES to graph: 17150/19709\n",
            "Converting SMILES to graph: 17151/19709\n",
            "Converting SMILES to graph: 17152/19709\n",
            "Converting SMILES to graph: 17153/19709\n",
            "Converting SMILES to graph: 17154/19709\n",
            "Converting SMILES to graph: 17155/19709\n",
            "Converting SMILES to graph: 17156/19709\n",
            "Converting SMILES to graph: 17157/19709\n",
            "Converting SMILES to graph: 17158/19709\n",
            "Converting SMILES to graph: 17159/19709\n",
            "Converting SMILES to graph: 17160/19709\n",
            "Converting SMILES to graph: 17161/19709\n",
            "Converting SMILES to graph: 17162/19709\n",
            "Converting SMILES to graph: 17163/19709\n",
            "Converting SMILES to graph: 17164/19709\n",
            "Converting SMILES to graph: 17165/19709\n",
            "Converting SMILES to graph: 17166/19709\n",
            "Converting SMILES to graph: 17167/19709\n",
            "Converting SMILES to graph: 17168/19709\n",
            "Converting SMILES to graph: 17169/19709\n",
            "Converting SMILES to graph: 17170/19709\n",
            "Converting SMILES to graph: 17171/19709\n",
            "Converting SMILES to graph: 17172/19709\n",
            "Converting SMILES to graph: 17173/19709\n",
            "Converting SMILES to graph: 17174/19709\n",
            "Converting SMILES to graph: 17175/19709\n",
            "Converting SMILES to graph: 17176/19709\n",
            "Converting SMILES to graph: 17177/19709\n",
            "Converting SMILES to graph: 17178/19709\n",
            "Converting SMILES to graph: 17179/19709\n",
            "Converting SMILES to graph: 17180/19709\n",
            "Converting SMILES to graph: 17181/19709\n",
            "Converting SMILES to graph: 17182/19709\n",
            "Converting SMILES to graph: 17183/19709\n",
            "Converting SMILES to graph: 17184/19709\n",
            "Converting SMILES to graph: 17185/19709\n",
            "Converting SMILES to graph: 17186/19709\n",
            "Converting SMILES to graph: 17187/19709\n",
            "Converting SMILES to graph: 17188/19709\n",
            "Converting SMILES to graph: 17189/19709\n",
            "Converting SMILES to graph: 17190/19709\n",
            "Converting SMILES to graph: 17191/19709\n",
            "Converting SMILES to graph: 17192/19709\n",
            "Converting SMILES to graph: 17193/19709\n",
            "Converting SMILES to graph: 17194/19709\n",
            "Converting SMILES to graph: 17195/19709\n",
            "Converting SMILES to graph: 17196/19709\n",
            "Converting SMILES to graph: 17197/19709\n",
            "Converting SMILES to graph: 17198/19709\n",
            "Converting SMILES to graph: 17199/19709\n",
            "Converting SMILES to graph: 17200/19709\n",
            "Converting SMILES to graph: 17201/19709\n",
            "Converting SMILES to graph: 17202/19709\n",
            "Converting SMILES to graph: 17203/19709\n",
            "Converting SMILES to graph: 17204/19709\n",
            "Converting SMILES to graph: 17205/19709\n",
            "Converting SMILES to graph: 17206/19709\n",
            "Converting SMILES to graph: 17207/19709\n",
            "Converting SMILES to graph: 17208/19709\n",
            "Converting SMILES to graph: 17209/19709\n",
            "Converting SMILES to graph: 17210/19709\n",
            "Converting SMILES to graph: 17211/19709\n",
            "Converting SMILES to graph: 17212/19709\n",
            "Converting SMILES to graph: 17213/19709\n",
            "Converting SMILES to graph: 17214/19709\n",
            "Converting SMILES to graph: 17215/19709\n",
            "Converting SMILES to graph: 17216/19709\n",
            "Converting SMILES to graph: 17217/19709\n",
            "Converting SMILES to graph: 17218/19709\n",
            "Converting SMILES to graph: 17219/19709\n",
            "Converting SMILES to graph: 17220/19709\n",
            "Converting SMILES to graph: 17221/19709\n",
            "Converting SMILES to graph: 17222/19709\n",
            "Converting SMILES to graph: 17223/19709\n",
            "Converting SMILES to graph: 17224/19709\n",
            "Converting SMILES to graph: 17225/19709\n",
            "Converting SMILES to graph: 17226/19709\n",
            "Converting SMILES to graph: 17227/19709\n",
            "Converting SMILES to graph: 17228/19709\n",
            "Converting SMILES to graph: 17229/19709\n",
            "Converting SMILES to graph: 17230/19709\n",
            "Converting SMILES to graph: 17231/19709\n",
            "Converting SMILES to graph: 17232/19709\n",
            "Converting SMILES to graph: 17233/19709\n",
            "Converting SMILES to graph: 17234/19709\n",
            "Converting SMILES to graph: 17235/19709\n",
            "Converting SMILES to graph: 17236/19709\n",
            "Converting SMILES to graph: 17237/19709\n",
            "Converting SMILES to graph: 17238/19709\n",
            "Converting SMILES to graph: 17239/19709\n",
            "Converting SMILES to graph: 17240/19709\n",
            "Converting SMILES to graph: 17241/19709\n",
            "Converting SMILES to graph: 17242/19709\n",
            "Converting SMILES to graph: 17243/19709\n",
            "Converting SMILES to graph: 17244/19709\n",
            "Converting SMILES to graph: 17245/19709\n",
            "Converting SMILES to graph: 17246/19709\n",
            "Converting SMILES to graph: 17247/19709\n",
            "Converting SMILES to graph: 17248/19709\n",
            "Converting SMILES to graph: 17249/19709\n",
            "Converting SMILES to graph: 17250/19709\n",
            "Converting SMILES to graph: 17251/19709\n",
            "Converting SMILES to graph: 17252/19709\n",
            "Converting SMILES to graph: 17253/19709\n",
            "Converting SMILES to graph: 17254/19709\n",
            "Converting SMILES to graph: 17255/19709\n",
            "Converting SMILES to graph: 17256/19709\n",
            "Converting SMILES to graph: 17257/19709\n",
            "Converting SMILES to graph: 17258/19709\n",
            "Converting SMILES to graph: 17259/19709\n",
            "Converting SMILES to graph: 17260/19709\n",
            "Converting SMILES to graph: 17261/19709\n",
            "Converting SMILES to graph: 17262/19709\n",
            "Converting SMILES to graph: 17263/19709\n",
            "Converting SMILES to graph: 17264/19709\n",
            "Converting SMILES to graph: 17265/19709\n",
            "Converting SMILES to graph: 17266/19709\n",
            "Converting SMILES to graph: 17267/19709\n",
            "Converting SMILES to graph: 17268/19709\n",
            "Converting SMILES to graph: 17269/19709\n",
            "Converting SMILES to graph: 17270/19709\n",
            "Converting SMILES to graph: 17271/19709\n",
            "Converting SMILES to graph: 17272/19709\n",
            "Converting SMILES to graph: 17273/19709\n",
            "Converting SMILES to graph: 17274/19709\n",
            "Converting SMILES to graph: 17275/19709\n",
            "Converting SMILES to graph: 17276/19709\n",
            "Converting SMILES to graph: 17277/19709\n",
            "Converting SMILES to graph: 17278/19709\n",
            "Converting SMILES to graph: 17279/19709\n",
            "Converting SMILES to graph: 17280/19709\n",
            "Converting SMILES to graph: 17281/19709\n",
            "Converting SMILES to graph: 17282/19709\n",
            "Converting SMILES to graph: 17283/19709\n",
            "Converting SMILES to graph: 17284/19709\n",
            "Converting SMILES to graph: 17285/19709\n",
            "Converting SMILES to graph: 17286/19709\n",
            "Converting SMILES to graph: 17287/19709\n",
            "Converting SMILES to graph: 17288/19709\n",
            "Converting SMILES to graph: 17289/19709\n",
            "Converting SMILES to graph: 17290/19709\n",
            "Converting SMILES to graph: 17291/19709\n",
            "Converting SMILES to graph: 17292/19709\n",
            "Converting SMILES to graph: 17293/19709\n",
            "Converting SMILES to graph: 17294/19709\n",
            "Converting SMILES to graph: 17295/19709\n",
            "Converting SMILES to graph: 17296/19709\n",
            "Converting SMILES to graph: 17297/19709\n",
            "Converting SMILES to graph: 17298/19709\n",
            "Converting SMILES to graph: 17299/19709\n",
            "Converting SMILES to graph: 17300/19709\n",
            "Converting SMILES to graph: 17301/19709\n",
            "Converting SMILES to graph: 17302/19709\n",
            "Converting SMILES to graph: 17303/19709\n",
            "Converting SMILES to graph: 17304/19709\n",
            "Converting SMILES to graph: 17305/19709\n",
            "Converting SMILES to graph: 17306/19709\n",
            "Converting SMILES to graph: 17307/19709\n",
            "Converting SMILES to graph: 17308/19709\n",
            "Converting SMILES to graph: 17309/19709\n",
            "Converting SMILES to graph: 17310/19709\n",
            "Converting SMILES to graph: 17311/19709\n",
            "Converting SMILES to graph: 17312/19709\n",
            "Converting SMILES to graph: 17313/19709\n",
            "Converting SMILES to graph: 17314/19709\n",
            "Converting SMILES to graph: 17315/19709\n",
            "Converting SMILES to graph: 17316/19709\n",
            "Converting SMILES to graph: 17317/19709\n",
            "Converting SMILES to graph: 17318/19709\n",
            "Converting SMILES to graph: 17319/19709\n",
            "Converting SMILES to graph: 17320/19709\n",
            "Converting SMILES to graph: 17321/19709\n",
            "Converting SMILES to graph: 17322/19709\n",
            "Converting SMILES to graph: 17323/19709\n",
            "Converting SMILES to graph: 17324/19709\n",
            "Converting SMILES to graph: 17325/19709\n",
            "Converting SMILES to graph: 17326/19709\n",
            "Converting SMILES to graph: 17327/19709\n",
            "Converting SMILES to graph: 17328/19709\n",
            "Converting SMILES to graph: 17329/19709\n",
            "Converting SMILES to graph: 17330/19709\n",
            "Converting SMILES to graph: 17331/19709\n",
            "Converting SMILES to graph: 17332/19709\n",
            "Converting SMILES to graph: 17333/19709\n",
            "Converting SMILES to graph: 17334/19709\n",
            "Converting SMILES to graph: 17335/19709\n",
            "Converting SMILES to graph: 17336/19709\n",
            "Converting SMILES to graph: 17337/19709\n",
            "Converting SMILES to graph: 17338/19709\n",
            "Converting SMILES to graph: 17339/19709\n",
            "Converting SMILES to graph: 17340/19709\n",
            "Converting SMILES to graph: 17341/19709\n",
            "Converting SMILES to graph: 17342/19709\n",
            "Converting SMILES to graph: 17343/19709\n",
            "Converting SMILES to graph: 17344/19709\n",
            "Converting SMILES to graph: 17345/19709\n",
            "Converting SMILES to graph: 17346/19709\n",
            "Converting SMILES to graph: 17347/19709\n",
            "Converting SMILES to graph: 17348/19709\n",
            "Converting SMILES to graph: 17349/19709\n",
            "Converting SMILES to graph: 17350/19709\n",
            "Converting SMILES to graph: 17351/19709\n",
            "Converting SMILES to graph: 17352/19709\n",
            "Converting SMILES to graph: 17353/19709\n",
            "Converting SMILES to graph: 17354/19709\n",
            "Converting SMILES to graph: 17355/19709\n",
            "Converting SMILES to graph: 17356/19709\n",
            "Converting SMILES to graph: 17357/19709\n",
            "Converting SMILES to graph: 17358/19709\n",
            "Converting SMILES to graph: 17359/19709\n",
            "Converting SMILES to graph: 17360/19709\n",
            "Converting SMILES to graph: 17361/19709\n",
            "Converting SMILES to graph: 17362/19709\n",
            "Converting SMILES to graph: 17363/19709\n",
            "Converting SMILES to graph: 17364/19709\n",
            "Converting SMILES to graph: 17365/19709\n",
            "Converting SMILES to graph: 17366/19709\n",
            "Converting SMILES to graph: 17367/19709\n",
            "Converting SMILES to graph: 17368/19709\n",
            "Converting SMILES to graph: 17369/19709\n",
            "Converting SMILES to graph: 17370/19709\n",
            "Converting SMILES to graph: 17371/19709\n",
            "Converting SMILES to graph: 17372/19709\n",
            "Converting SMILES to graph: 17373/19709\n",
            "Converting SMILES to graph: 17374/19709\n",
            "Converting SMILES to graph: 17375/19709\n",
            "Converting SMILES to graph: 17376/19709\n",
            "Converting SMILES to graph: 17377/19709\n",
            "Converting SMILES to graph: 17378/19709\n",
            "Converting SMILES to graph: 17379/19709\n",
            "Converting SMILES to graph: 17380/19709\n",
            "Converting SMILES to graph: 17381/19709\n",
            "Converting SMILES to graph: 17382/19709\n",
            "Converting SMILES to graph: 17383/19709\n",
            "Converting SMILES to graph: 17384/19709\n",
            "Converting SMILES to graph: 17385/19709\n",
            "Converting SMILES to graph: 17386/19709\n",
            "Converting SMILES to graph: 17387/19709\n",
            "Converting SMILES to graph: 17388/19709\n",
            "Converting SMILES to graph: 17389/19709\n",
            "Converting SMILES to graph: 17390/19709\n",
            "Converting SMILES to graph: 17391/19709\n",
            "Converting SMILES to graph: 17392/19709\n",
            "Converting SMILES to graph: 17393/19709\n",
            "Converting SMILES to graph: 17394/19709\n",
            "Converting SMILES to graph: 17395/19709\n",
            "Converting SMILES to graph: 17396/19709\n",
            "Converting SMILES to graph: 17397/19709\n",
            "Converting SMILES to graph: 17398/19709\n",
            "Converting SMILES to graph: 17399/19709\n",
            "Converting SMILES to graph: 17400/19709\n",
            "Converting SMILES to graph: 17401/19709\n",
            "Converting SMILES to graph: 17402/19709\n",
            "Converting SMILES to graph: 17403/19709\n",
            "Converting SMILES to graph: 17404/19709\n",
            "Converting SMILES to graph: 17405/19709\n",
            "Converting SMILES to graph: 17406/19709\n",
            "Converting SMILES to graph: 17407/19709\n",
            "Converting SMILES to graph: 17408/19709\n",
            "Converting SMILES to graph: 17409/19709\n",
            "Converting SMILES to graph: 17410/19709\n",
            "Converting SMILES to graph: 17411/19709\n",
            "Converting SMILES to graph: 17412/19709\n",
            "Converting SMILES to graph: 17413/19709\n",
            "Converting SMILES to graph: 17414/19709\n",
            "Converting SMILES to graph: 17415/19709\n",
            "Converting SMILES to graph: 17416/19709\n",
            "Converting SMILES to graph: 17417/19709\n",
            "Converting SMILES to graph: 17418/19709\n",
            "Converting SMILES to graph: 17419/19709\n",
            "Converting SMILES to graph: 17420/19709\n",
            "Converting SMILES to graph: 17421/19709\n",
            "Converting SMILES to graph: 17422/19709\n",
            "Converting SMILES to graph: 17423/19709\n",
            "Converting SMILES to graph: 17424/19709\n",
            "Converting SMILES to graph: 17425/19709\n",
            "Converting SMILES to graph: 17426/19709\n",
            "Converting SMILES to graph: 17427/19709\n",
            "Converting SMILES to graph: 17428/19709\n",
            "Converting SMILES to graph: 17429/19709\n",
            "Converting SMILES to graph: 17430/19709\n",
            "Converting SMILES to graph: 17431/19709\n",
            "Converting SMILES to graph: 17432/19709\n",
            "Converting SMILES to graph: 17433/19709\n",
            "Converting SMILES to graph: 17434/19709\n",
            "Converting SMILES to graph: 17435/19709\n",
            "Converting SMILES to graph: 17436/19709\n",
            "Converting SMILES to graph: 17437/19709\n",
            "Converting SMILES to graph: 17438/19709\n",
            "Converting SMILES to graph: 17439/19709\n",
            "Converting SMILES to graph: 17440/19709\n",
            "Converting SMILES to graph: 17441/19709\n",
            "Converting SMILES to graph: 17442/19709\n",
            "Converting SMILES to graph: 17443/19709\n",
            "Converting SMILES to graph: 17444/19709\n",
            "Converting SMILES to graph: 17445/19709\n",
            "Converting SMILES to graph: 17446/19709\n",
            "Converting SMILES to graph: 17447/19709\n",
            "Converting SMILES to graph: 17448/19709\n",
            "Converting SMILES to graph: 17449/19709\n",
            "Converting SMILES to graph: 17450/19709\n",
            "Converting SMILES to graph: 17451/19709\n",
            "Converting SMILES to graph: 17452/19709\n",
            "Converting SMILES to graph: 17453/19709\n",
            "Converting SMILES to graph: 17454/19709\n",
            "Converting SMILES to graph: 17455/19709\n",
            "Converting SMILES to graph: 17456/19709\n",
            "Converting SMILES to graph: 17457/19709\n",
            "Converting SMILES to graph: 17458/19709\n",
            "Converting SMILES to graph: 17459/19709\n",
            "Converting SMILES to graph: 17460/19709\n",
            "Converting SMILES to graph: 17461/19709\n",
            "Converting SMILES to graph: 17462/19709\n",
            "Converting SMILES to graph: 17463/19709\n",
            "Converting SMILES to graph: 17464/19709\n",
            "Converting SMILES to graph: 17465/19709\n",
            "Converting SMILES to graph: 17466/19709\n",
            "Converting SMILES to graph: 17467/19709\n",
            "Converting SMILES to graph: 17468/19709\n",
            "Converting SMILES to graph: 17469/19709\n",
            "Converting SMILES to graph: 17470/19709\n",
            "Converting SMILES to graph: 17471/19709\n",
            "Converting SMILES to graph: 17472/19709\n",
            "Converting SMILES to graph: 17473/19709\n",
            "Converting SMILES to graph: 17474/19709\n",
            "Converting SMILES to graph: 17475/19709\n",
            "Converting SMILES to graph: 17476/19709\n",
            "Converting SMILES to graph: 17477/19709\n",
            "Converting SMILES to graph: 17478/19709\n",
            "Converting SMILES to graph: 17479/19709\n",
            "Converting SMILES to graph: 17480/19709\n",
            "Converting SMILES to graph: 17481/19709\n",
            "Converting SMILES to graph: 17482/19709\n",
            "Converting SMILES to graph: 17483/19709\n",
            "Converting SMILES to graph: 17484/19709\n",
            "Converting SMILES to graph: 17485/19709\n",
            "Converting SMILES to graph: 17486/19709\n",
            "Converting SMILES to graph: 17487/19709\n",
            "Converting SMILES to graph: 17488/19709\n",
            "Converting SMILES to graph: 17489/19709\n",
            "Converting SMILES to graph: 17490/19709\n",
            "Converting SMILES to graph: 17491/19709\n",
            "Converting SMILES to graph: 17492/19709\n",
            "Converting SMILES to graph: 17493/19709\n",
            "Converting SMILES to graph: 17494/19709\n",
            "Converting SMILES to graph: 17495/19709\n",
            "Converting SMILES to graph: 17496/19709\n",
            "Converting SMILES to graph: 17497/19709\n",
            "Converting SMILES to graph: 17498/19709\n",
            "Converting SMILES to graph: 17499/19709\n",
            "Converting SMILES to graph: 17500/19709\n",
            "Converting SMILES to graph: 17501/19709\n",
            "Converting SMILES to graph: 17502/19709\n",
            "Converting SMILES to graph: 17503/19709\n",
            "Converting SMILES to graph: 17504/19709\n",
            "Converting SMILES to graph: 17505/19709\n",
            "Converting SMILES to graph: 17506/19709\n",
            "Converting SMILES to graph: 17507/19709\n",
            "Converting SMILES to graph: 17508/19709\n",
            "Converting SMILES to graph: 17509/19709\n",
            "Converting SMILES to graph: 17510/19709\n",
            "Converting SMILES to graph: 17511/19709\n",
            "Converting SMILES to graph: 17512/19709\n",
            "Converting SMILES to graph: 17513/19709\n",
            "Converting SMILES to graph: 17514/19709\n",
            "Converting SMILES to graph: 17515/19709\n",
            "Converting SMILES to graph: 17516/19709\n",
            "Converting SMILES to graph: 17517/19709\n",
            "Converting SMILES to graph: 17518/19709\n",
            "Converting SMILES to graph: 17519/19709\n",
            "Converting SMILES to graph: 17520/19709\n",
            "Converting SMILES to graph: 17521/19709\n",
            "Converting SMILES to graph: 17522/19709\n",
            "Converting SMILES to graph: 17523/19709\n",
            "Converting SMILES to graph: 17524/19709\n",
            "Converting SMILES to graph: 17525/19709\n",
            "Converting SMILES to graph: 17526/19709\n",
            "Converting SMILES to graph: 17527/19709\n",
            "Converting SMILES to graph: 17528/19709\n",
            "Converting SMILES to graph: 17529/19709\n",
            "Converting SMILES to graph: 17530/19709\n",
            "Converting SMILES to graph: 17531/19709\n",
            "Converting SMILES to graph: 17532/19709\n",
            "Converting SMILES to graph: 17533/19709\n",
            "Converting SMILES to graph: 17534/19709\n",
            "Converting SMILES to graph: 17535/19709\n",
            "Converting SMILES to graph: 17536/19709\n",
            "Converting SMILES to graph: 17537/19709\n",
            "Converting SMILES to graph: 17538/19709\n",
            "Converting SMILES to graph: 17539/19709\n",
            "Converting SMILES to graph: 17540/19709\n",
            "Converting SMILES to graph: 17541/19709\n",
            "Converting SMILES to graph: 17542/19709\n",
            "Converting SMILES to graph: 17543/19709\n",
            "Converting SMILES to graph: 17544/19709\n",
            "Converting SMILES to graph: 17545/19709\n",
            "Converting SMILES to graph: 17546/19709\n",
            "Converting SMILES to graph: 17547/19709\n",
            "Converting SMILES to graph: 17548/19709\n",
            "Converting SMILES to graph: 17549/19709\n",
            "Converting SMILES to graph: 17550/19709\n",
            "Converting SMILES to graph: 17551/19709\n",
            "Converting SMILES to graph: 17552/19709\n",
            "Converting SMILES to graph: 17553/19709\n",
            "Converting SMILES to graph: 17554/19709\n",
            "Converting SMILES to graph: 17555/19709\n",
            "Converting SMILES to graph: 17556/19709\n",
            "Converting SMILES to graph: 17557/19709\n",
            "Converting SMILES to graph: 17558/19709\n",
            "Converting SMILES to graph: 17559/19709\n",
            "Converting SMILES to graph: 17560/19709\n",
            "Converting SMILES to graph: 17561/19709\n",
            "Converting SMILES to graph: 17562/19709\n",
            "Converting SMILES to graph: 17563/19709\n",
            "Converting SMILES to graph: 17564/19709\n",
            "Converting SMILES to graph: 17565/19709\n",
            "Converting SMILES to graph: 17566/19709\n",
            "Converting SMILES to graph: 17567/19709\n",
            "Converting SMILES to graph: 17568/19709\n",
            "Converting SMILES to graph: 17569/19709\n",
            "Converting SMILES to graph: 17570/19709\n",
            "Converting SMILES to graph: 17571/19709\n",
            "Converting SMILES to graph: 17572/19709\n",
            "Converting SMILES to graph: 17573/19709\n",
            "Converting SMILES to graph: 17574/19709\n",
            "Converting SMILES to graph: 17575/19709\n",
            "Converting SMILES to graph: 17576/19709\n",
            "Converting SMILES to graph: 17577/19709\n",
            "Converting SMILES to graph: 17578/19709\n",
            "Converting SMILES to graph: 17579/19709\n",
            "Converting SMILES to graph: 17580/19709\n",
            "Converting SMILES to graph: 17581/19709\n",
            "Converting SMILES to graph: 17582/19709\n",
            "Converting SMILES to graph: 17583/19709\n",
            "Converting SMILES to graph: 17584/19709\n",
            "Converting SMILES to graph: 17585/19709\n",
            "Converting SMILES to graph: 17586/19709\n",
            "Converting SMILES to graph: 17587/19709\n",
            "Converting SMILES to graph: 17588/19709\n",
            "Converting SMILES to graph: 17589/19709\n",
            "Converting SMILES to graph: 17590/19709\n",
            "Converting SMILES to graph: 17591/19709\n",
            "Converting SMILES to graph: 17592/19709\n",
            "Converting SMILES to graph: 17593/19709\n",
            "Converting SMILES to graph: 17594/19709\n",
            "Converting SMILES to graph: 17595/19709\n",
            "Converting SMILES to graph: 17596/19709\n",
            "Converting SMILES to graph: 17597/19709\n",
            "Converting SMILES to graph: 17598/19709\n",
            "Converting SMILES to graph: 17599/19709\n",
            "Converting SMILES to graph: 17600/19709\n",
            "Converting SMILES to graph: 17601/19709\n",
            "Converting SMILES to graph: 17602/19709\n",
            "Converting SMILES to graph: 17603/19709\n",
            "Converting SMILES to graph: 17604/19709\n",
            "Converting SMILES to graph: 17605/19709\n",
            "Converting SMILES to graph: 17606/19709\n",
            "Converting SMILES to graph: 17607/19709\n",
            "Converting SMILES to graph: 17608/19709\n",
            "Converting SMILES to graph: 17609/19709\n",
            "Converting SMILES to graph: 17610/19709\n",
            "Converting SMILES to graph: 17611/19709\n",
            "Converting SMILES to graph: 17612/19709\n",
            "Converting SMILES to graph: 17613/19709\n",
            "Converting SMILES to graph: 17614/19709\n",
            "Converting SMILES to graph: 17615/19709\n",
            "Converting SMILES to graph: 17616/19709\n",
            "Converting SMILES to graph: 17617/19709\n",
            "Converting SMILES to graph: 17618/19709\n",
            "Converting SMILES to graph: 17619/19709\n",
            "Converting SMILES to graph: 17620/19709\n",
            "Converting SMILES to graph: 17621/19709\n",
            "Converting SMILES to graph: 17622/19709\n",
            "Converting SMILES to graph: 17623/19709\n",
            "Converting SMILES to graph: 17624/19709\n",
            "Converting SMILES to graph: 17625/19709\n",
            "Converting SMILES to graph: 17626/19709\n",
            "Converting SMILES to graph: 17627/19709\n",
            "Converting SMILES to graph: 17628/19709\n",
            "Converting SMILES to graph: 17629/19709\n",
            "Converting SMILES to graph: 17630/19709\n",
            "Converting SMILES to graph: 17631/19709\n",
            "Converting SMILES to graph: 17632/19709\n",
            "Converting SMILES to graph: 17633/19709\n",
            "Converting SMILES to graph: 17634/19709\n",
            "Converting SMILES to graph: 17635/19709\n",
            "Converting SMILES to graph: 17636/19709\n",
            "Converting SMILES to graph: 17637/19709\n",
            "Converting SMILES to graph: 17638/19709\n",
            "Converting SMILES to graph: 17639/19709\n",
            "Converting SMILES to graph: 17640/19709\n",
            "Converting SMILES to graph: 17641/19709\n",
            "Converting SMILES to graph: 17642/19709\n",
            "Converting SMILES to graph: 17643/19709\n",
            "Converting SMILES to graph: 17644/19709\n",
            "Converting SMILES to graph: 17645/19709\n",
            "Converting SMILES to graph: 17646/19709\n",
            "Converting SMILES to graph: 17647/19709\n",
            "Converting SMILES to graph: 17648/19709\n",
            "Converting SMILES to graph: 17649/19709\n",
            "Converting SMILES to graph: 17650/19709\n",
            "Converting SMILES to graph: 17651/19709\n",
            "Converting SMILES to graph: 17652/19709\n",
            "Converting SMILES to graph: 17653/19709\n",
            "Converting SMILES to graph: 17654/19709\n",
            "Converting SMILES to graph: 17655/19709\n",
            "Converting SMILES to graph: 17656/19709\n",
            "Converting SMILES to graph: 17657/19709\n",
            "Converting SMILES to graph: 17658/19709\n",
            "Converting SMILES to graph: 17659/19709\n",
            "Converting SMILES to graph: 17660/19709\n",
            "Converting SMILES to graph: 17661/19709\n",
            "Converting SMILES to graph: 17662/19709\n",
            "Converting SMILES to graph: 17663/19709\n",
            "Converting SMILES to graph: 17664/19709\n",
            "Converting SMILES to graph: 17665/19709\n",
            "Converting SMILES to graph: 17666/19709\n",
            "Converting SMILES to graph: 17667/19709\n",
            "Converting SMILES to graph: 17668/19709\n",
            "Converting SMILES to graph: 17669/19709\n",
            "Converting SMILES to graph: 17670/19709\n",
            "Converting SMILES to graph: 17671/19709\n",
            "Converting SMILES to graph: 17672/19709\n",
            "Converting SMILES to graph: 17673/19709\n",
            "Converting SMILES to graph: 17674/19709\n",
            "Converting SMILES to graph: 17675/19709\n",
            "Converting SMILES to graph: 17676/19709\n",
            "Converting SMILES to graph: 17677/19709\n",
            "Converting SMILES to graph: 17678/19709\n",
            "Converting SMILES to graph: 17679/19709\n",
            "Converting SMILES to graph: 17680/19709\n",
            "Converting SMILES to graph: 17681/19709\n",
            "Converting SMILES to graph: 17682/19709\n",
            "Converting SMILES to graph: 17683/19709\n",
            "Converting SMILES to graph: 17684/19709\n",
            "Converting SMILES to graph: 17685/19709\n",
            "Converting SMILES to graph: 17686/19709\n",
            "Converting SMILES to graph: 17687/19709\n",
            "Converting SMILES to graph: 17688/19709\n",
            "Converting SMILES to graph: 17689/19709\n",
            "Converting SMILES to graph: 17690/19709\n",
            "Converting SMILES to graph: 17691/19709\n",
            "Converting SMILES to graph: 17692/19709\n",
            "Converting SMILES to graph: 17693/19709\n",
            "Converting SMILES to graph: 17694/19709\n",
            "Converting SMILES to graph: 17695/19709\n",
            "Converting SMILES to graph: 17696/19709\n",
            "Converting SMILES to graph: 17697/19709\n",
            "Converting SMILES to graph: 17698/19709\n",
            "Converting SMILES to graph: 17699/19709\n",
            "Converting SMILES to graph: 17700/19709\n",
            "Converting SMILES to graph: 17701/19709\n",
            "Converting SMILES to graph: 17702/19709\n",
            "Converting SMILES to graph: 17703/19709\n",
            "Converting SMILES to graph: 17704/19709\n",
            "Converting SMILES to graph: 17705/19709\n",
            "Converting SMILES to graph: 17706/19709\n",
            "Converting SMILES to graph: 17707/19709\n",
            "Converting SMILES to graph: 17708/19709\n",
            "Converting SMILES to graph: 17709/19709\n",
            "Converting SMILES to graph: 17710/19709\n",
            "Converting SMILES to graph: 17711/19709\n",
            "Converting SMILES to graph: 17712/19709\n",
            "Converting SMILES to graph: 17713/19709\n",
            "Converting SMILES to graph: 17714/19709\n",
            "Converting SMILES to graph: 17715/19709\n",
            "Converting SMILES to graph: 17716/19709\n",
            "Converting SMILES to graph: 17717/19709\n",
            "Converting SMILES to graph: 17718/19709\n",
            "Converting SMILES to graph: 17719/19709\n",
            "Converting SMILES to graph: 17720/19709\n",
            "Converting SMILES to graph: 17721/19709\n",
            "Converting SMILES to graph: 17722/19709\n",
            "Converting SMILES to graph: 17723/19709\n",
            "Converting SMILES to graph: 17724/19709\n",
            "Converting SMILES to graph: 17725/19709\n",
            "Converting SMILES to graph: 17726/19709\n",
            "Converting SMILES to graph: 17727/19709\n",
            "Converting SMILES to graph: 17728/19709\n",
            "Converting SMILES to graph: 17729/19709\n",
            "Converting SMILES to graph: 17730/19709\n",
            "Converting SMILES to graph: 17731/19709\n",
            "Converting SMILES to graph: 17732/19709\n",
            "Converting SMILES to graph: 17733/19709\n",
            "Converting SMILES to graph: 17734/19709\n",
            "Converting SMILES to graph: 17735/19709\n",
            "Converting SMILES to graph: 17736/19709\n",
            "Converting SMILES to graph: 17737/19709\n",
            "Converting SMILES to graph: 17738/19709\n",
            "Converting SMILES to graph: 17739/19709\n",
            "Converting SMILES to graph: 17740/19709\n",
            "Converting SMILES to graph: 17741/19709\n",
            "Converting SMILES to graph: 17742/19709\n",
            "Converting SMILES to graph: 17743/19709\n",
            "Converting SMILES to graph: 17744/19709\n",
            "Converting SMILES to graph: 17745/19709\n",
            "Converting SMILES to graph: 17746/19709\n",
            "Converting SMILES to graph: 17747/19709\n",
            "Converting SMILES to graph: 17748/19709\n",
            "Converting SMILES to graph: 17749/19709\n",
            "Converting SMILES to graph: 17750/19709\n",
            "Converting SMILES to graph: 17751/19709\n",
            "Converting SMILES to graph: 17752/19709\n",
            "Converting SMILES to graph: 17753/19709\n",
            "Converting SMILES to graph: 17754/19709\n",
            "Converting SMILES to graph: 17755/19709\n",
            "Converting SMILES to graph: 17756/19709\n",
            "Converting SMILES to graph: 17757/19709\n",
            "Converting SMILES to graph: 17758/19709\n",
            "Converting SMILES to graph: 17759/19709\n",
            "Converting SMILES to graph: 17760/19709\n",
            "Converting SMILES to graph: 17761/19709\n",
            "Converting SMILES to graph: 17762/19709\n",
            "Converting SMILES to graph: 17763/19709\n",
            "Converting SMILES to graph: 17764/19709\n",
            "Converting SMILES to graph: 17765/19709\n",
            "Converting SMILES to graph: 17766/19709\n",
            "Converting SMILES to graph: 17767/19709\n",
            "Converting SMILES to graph: 17768/19709\n",
            "Converting SMILES to graph: 17769/19709\n",
            "Converting SMILES to graph: 17770/19709\n",
            "Converting SMILES to graph: 17771/19709\n",
            "Converting SMILES to graph: 17772/19709\n",
            "Converting SMILES to graph: 17773/19709\n",
            "Converting SMILES to graph: 17774/19709\n",
            "Converting SMILES to graph: 17775/19709\n",
            "Converting SMILES to graph: 17776/19709\n",
            "Converting SMILES to graph: 17777/19709\n",
            "Converting SMILES to graph: 17778/19709\n",
            "Converting SMILES to graph: 17779/19709\n",
            "Converting SMILES to graph: 17780/19709\n",
            "Converting SMILES to graph: 17781/19709\n",
            "Converting SMILES to graph: 17782/19709\n",
            "Converting SMILES to graph: 17783/19709\n",
            "Converting SMILES to graph: 17784/19709\n",
            "Converting SMILES to graph: 17785/19709\n",
            "Converting SMILES to graph: 17786/19709\n",
            "Converting SMILES to graph: 17787/19709\n",
            "Converting SMILES to graph: 17788/19709\n",
            "Converting SMILES to graph: 17789/19709\n",
            "Converting SMILES to graph: 17790/19709\n",
            "Converting SMILES to graph: 17791/19709\n",
            "Converting SMILES to graph: 17792/19709\n",
            "Converting SMILES to graph: 17793/19709\n",
            "Converting SMILES to graph: 17794/19709\n",
            "Converting SMILES to graph: 17795/19709\n",
            "Converting SMILES to graph: 17796/19709\n",
            "Converting SMILES to graph: 17797/19709\n",
            "Converting SMILES to graph: 17798/19709\n",
            "Converting SMILES to graph: 17799/19709\n",
            "Converting SMILES to graph: 17800/19709\n",
            "Converting SMILES to graph: 17801/19709\n",
            "Converting SMILES to graph: 17802/19709\n",
            "Converting SMILES to graph: 17803/19709\n",
            "Converting SMILES to graph: 17804/19709\n",
            "Converting SMILES to graph: 17805/19709\n",
            "Converting SMILES to graph: 17806/19709\n",
            "Converting SMILES to graph: 17807/19709\n",
            "Converting SMILES to graph: 17808/19709\n",
            "Converting SMILES to graph: 17809/19709\n",
            "Converting SMILES to graph: 17810/19709\n",
            "Converting SMILES to graph: 17811/19709\n",
            "Converting SMILES to graph: 17812/19709\n",
            "Converting SMILES to graph: 17813/19709\n",
            "Converting SMILES to graph: 17814/19709\n",
            "Converting SMILES to graph: 17815/19709\n",
            "Converting SMILES to graph: 17816/19709\n",
            "Converting SMILES to graph: 17817/19709\n",
            "Converting SMILES to graph: 17818/19709\n",
            "Converting SMILES to graph: 17819/19709\n",
            "Converting SMILES to graph: 17820/19709\n",
            "Converting SMILES to graph: 17821/19709\n",
            "Converting SMILES to graph: 17822/19709\n",
            "Converting SMILES to graph: 17823/19709\n",
            "Converting SMILES to graph: 17824/19709\n",
            "Converting SMILES to graph: 17825/19709\n",
            "Converting SMILES to graph: 17826/19709\n",
            "Converting SMILES to graph: 17827/19709\n",
            "Converting SMILES to graph: 17828/19709\n",
            "Converting SMILES to graph: 17829/19709\n",
            "Converting SMILES to graph: 17830/19709\n",
            "Converting SMILES to graph: 17831/19709\n",
            "Converting SMILES to graph: 17832/19709\n",
            "Converting SMILES to graph: 17833/19709\n",
            "Converting SMILES to graph: 17834/19709\n",
            "Converting SMILES to graph: 17835/19709\n",
            "Converting SMILES to graph: 17836/19709\n",
            "Converting SMILES to graph: 17837/19709\n",
            "Converting SMILES to graph: 17838/19709\n",
            "Converting SMILES to graph: 17839/19709\n",
            "Converting SMILES to graph: 17840/19709\n",
            "Converting SMILES to graph: 17841/19709\n",
            "Converting SMILES to graph: 17842/19709\n",
            "Converting SMILES to graph: 17843/19709\n",
            "Converting SMILES to graph: 17844/19709\n",
            "Converting SMILES to graph: 17845/19709\n",
            "Converting SMILES to graph: 17846/19709\n",
            "Converting SMILES to graph: 17847/19709\n",
            "Converting SMILES to graph: 17848/19709\n",
            "Converting SMILES to graph: 17849/19709\n",
            "Converting SMILES to graph: 17850/19709\n",
            "Converting SMILES to graph: 17851/19709\n",
            "Converting SMILES to graph: 17852/19709\n",
            "Converting SMILES to graph: 17853/19709\n",
            "Converting SMILES to graph: 17854/19709\n",
            "Converting SMILES to graph: 17855/19709\n",
            "Converting SMILES to graph: 17856/19709\n",
            "Converting SMILES to graph: 17857/19709\n",
            "Converting SMILES to graph: 17858/19709\n",
            "Converting SMILES to graph: 17859/19709\n",
            "Converting SMILES to graph: 17860/19709\n",
            "Converting SMILES to graph: 17861/19709\n",
            "Converting SMILES to graph: 17862/19709\n",
            "Converting SMILES to graph: 17863/19709\n",
            "Converting SMILES to graph: 17864/19709\n",
            "Converting SMILES to graph: 17865/19709\n",
            "Converting SMILES to graph: 17866/19709\n",
            "Converting SMILES to graph: 17867/19709\n",
            "Converting SMILES to graph: 17868/19709\n",
            "Converting SMILES to graph: 17869/19709\n",
            "Converting SMILES to graph: 17870/19709\n",
            "Converting SMILES to graph: 17871/19709\n",
            "Converting SMILES to graph: 17872/19709\n",
            "Converting SMILES to graph: 17873/19709\n",
            "Converting SMILES to graph: 17874/19709\n",
            "Converting SMILES to graph: 17875/19709\n",
            "Converting SMILES to graph: 17876/19709\n",
            "Converting SMILES to graph: 17877/19709\n",
            "Converting SMILES to graph: 17878/19709\n",
            "Converting SMILES to graph: 17879/19709\n",
            "Converting SMILES to graph: 17880/19709\n",
            "Converting SMILES to graph: 17881/19709\n",
            "Converting SMILES to graph: 17882/19709\n",
            "Converting SMILES to graph: 17883/19709\n",
            "Converting SMILES to graph: 17884/19709\n",
            "Converting SMILES to graph: 17885/19709\n",
            "Converting SMILES to graph: 17886/19709\n",
            "Converting SMILES to graph: 17887/19709\n",
            "Converting SMILES to graph: 17888/19709\n",
            "Converting SMILES to graph: 17889/19709\n",
            "Converting SMILES to graph: 17890/19709\n",
            "Converting SMILES to graph: 17891/19709\n",
            "Converting SMILES to graph: 17892/19709\n",
            "Converting SMILES to graph: 17893/19709\n",
            "Converting SMILES to graph: 17894/19709\n",
            "Converting SMILES to graph: 17895/19709\n",
            "Converting SMILES to graph: 17896/19709\n",
            "Converting SMILES to graph: 17897/19709\n",
            "Converting SMILES to graph: 17898/19709\n",
            "Converting SMILES to graph: 17899/19709\n",
            "Converting SMILES to graph: 17900/19709\n",
            "Converting SMILES to graph: 17901/19709\n",
            "Converting SMILES to graph: 17902/19709\n",
            "Converting SMILES to graph: 17903/19709\n",
            "Converting SMILES to graph: 17904/19709\n",
            "Converting SMILES to graph: 17905/19709\n",
            "Converting SMILES to graph: 17906/19709\n",
            "Converting SMILES to graph: 17907/19709\n",
            "Converting SMILES to graph: 17908/19709\n",
            "Converting SMILES to graph: 17909/19709\n",
            "Converting SMILES to graph: 17910/19709\n",
            "Converting SMILES to graph: 17911/19709\n",
            "Converting SMILES to graph: 17912/19709\n",
            "Converting SMILES to graph: 17913/19709\n",
            "Converting SMILES to graph: 17914/19709\n",
            "Converting SMILES to graph: 17915/19709\n",
            "Converting SMILES to graph: 17916/19709\n",
            "Converting SMILES to graph: 17917/19709\n",
            "Converting SMILES to graph: 17918/19709\n",
            "Converting SMILES to graph: 17919/19709\n",
            "Converting SMILES to graph: 17920/19709\n",
            "Converting SMILES to graph: 17921/19709\n",
            "Converting SMILES to graph: 17922/19709\n",
            "Converting SMILES to graph: 17923/19709\n",
            "Converting SMILES to graph: 17924/19709\n",
            "Converting SMILES to graph: 17925/19709\n",
            "Converting SMILES to graph: 17926/19709\n",
            "Converting SMILES to graph: 17927/19709\n",
            "Converting SMILES to graph: 17928/19709\n",
            "Converting SMILES to graph: 17929/19709\n",
            "Converting SMILES to graph: 17930/19709\n",
            "Converting SMILES to graph: 17931/19709\n",
            "Converting SMILES to graph: 17932/19709\n",
            "Converting SMILES to graph: 17933/19709\n",
            "Converting SMILES to graph: 17934/19709\n",
            "Converting SMILES to graph: 17935/19709\n",
            "Converting SMILES to graph: 17936/19709\n",
            "Converting SMILES to graph: 17937/19709\n",
            "Converting SMILES to graph: 17938/19709\n",
            "Converting SMILES to graph: 17939/19709\n",
            "Converting SMILES to graph: 17940/19709\n",
            "Converting SMILES to graph: 17941/19709\n",
            "Converting SMILES to graph: 17942/19709\n",
            "Converting SMILES to graph: 17943/19709\n",
            "Converting SMILES to graph: 17944/19709\n",
            "Converting SMILES to graph: 17945/19709\n",
            "Converting SMILES to graph: 17946/19709\n",
            "Converting SMILES to graph: 17947/19709\n",
            "Converting SMILES to graph: 17948/19709\n",
            "Converting SMILES to graph: 17949/19709\n",
            "Converting SMILES to graph: 17950/19709\n",
            "Converting SMILES to graph: 17951/19709\n",
            "Converting SMILES to graph: 17952/19709\n",
            "Converting SMILES to graph: 17953/19709\n",
            "Converting SMILES to graph: 17954/19709\n",
            "Converting SMILES to graph: 17955/19709\n",
            "Converting SMILES to graph: 17956/19709\n",
            "Converting SMILES to graph: 17957/19709\n",
            "Converting SMILES to graph: 17958/19709\n",
            "Converting SMILES to graph: 17959/19709\n",
            "Converting SMILES to graph: 17960/19709\n",
            "Converting SMILES to graph: 17961/19709\n",
            "Converting SMILES to graph: 17962/19709\n",
            "Converting SMILES to graph: 17963/19709\n",
            "Converting SMILES to graph: 17964/19709\n",
            "Converting SMILES to graph: 17965/19709\n",
            "Converting SMILES to graph: 17966/19709\n",
            "Converting SMILES to graph: 17967/19709\n",
            "Converting SMILES to graph: 17968/19709\n",
            "Converting SMILES to graph: 17969/19709\n",
            "Converting SMILES to graph: 17970/19709\n",
            "Converting SMILES to graph: 17971/19709\n",
            "Converting SMILES to graph: 17972/19709\n",
            "Converting SMILES to graph: 17973/19709\n",
            "Converting SMILES to graph: 17974/19709\n",
            "Converting SMILES to graph: 17975/19709\n",
            "Converting SMILES to graph: 17976/19709\n",
            "Converting SMILES to graph: 17977/19709\n",
            "Converting SMILES to graph: 17978/19709\n",
            "Converting SMILES to graph: 17979/19709\n",
            "Converting SMILES to graph: 17980/19709\n",
            "Converting SMILES to graph: 17981/19709\n",
            "Converting SMILES to graph: 17982/19709\n",
            "Converting SMILES to graph: 17983/19709\n",
            "Converting SMILES to graph: 17984/19709\n",
            "Converting SMILES to graph: 17985/19709\n",
            "Converting SMILES to graph: 17986/19709\n",
            "Converting SMILES to graph: 17987/19709\n",
            "Converting SMILES to graph: 17988/19709\n",
            "Converting SMILES to graph: 17989/19709\n",
            "Converting SMILES to graph: 17990/19709\n",
            "Converting SMILES to graph: 17991/19709\n",
            "Converting SMILES to graph: 17992/19709\n",
            "Converting SMILES to graph: 17993/19709\n",
            "Converting SMILES to graph: 17994/19709\n",
            "Converting SMILES to graph: 17995/19709\n",
            "Converting SMILES to graph: 17996/19709\n",
            "Converting SMILES to graph: 17997/19709\n",
            "Converting SMILES to graph: 17998/19709\n",
            "Converting SMILES to graph: 17999/19709\n",
            "Converting SMILES to graph: 18000/19709\n",
            "Converting SMILES to graph: 18001/19709\n",
            "Converting SMILES to graph: 18002/19709\n",
            "Converting SMILES to graph: 18003/19709\n",
            "Converting SMILES to graph: 18004/19709\n",
            "Converting SMILES to graph: 18005/19709\n",
            "Converting SMILES to graph: 18006/19709\n",
            "Converting SMILES to graph: 18007/19709\n",
            "Converting SMILES to graph: 18008/19709\n",
            "Converting SMILES to graph: 18009/19709\n",
            "Converting SMILES to graph: 18010/19709\n",
            "Converting SMILES to graph: 18011/19709\n",
            "Converting SMILES to graph: 18012/19709\n",
            "Converting SMILES to graph: 18013/19709\n",
            "Converting SMILES to graph: 18014/19709\n",
            "Converting SMILES to graph: 18015/19709\n",
            "Converting SMILES to graph: 18016/19709\n",
            "Converting SMILES to graph: 18017/19709\n",
            "Converting SMILES to graph: 18018/19709\n",
            "Converting SMILES to graph: 18019/19709\n",
            "Converting SMILES to graph: 18020/19709\n",
            "Converting SMILES to graph: 18021/19709\n",
            "Converting SMILES to graph: 18022/19709\n",
            "Converting SMILES to graph: 18023/19709\n",
            "Converting SMILES to graph: 18024/19709\n",
            "Converting SMILES to graph: 18025/19709\n",
            "Converting SMILES to graph: 18026/19709\n",
            "Converting SMILES to graph: 18027/19709\n",
            "Converting SMILES to graph: 18028/19709\n",
            "Converting SMILES to graph: 18029/19709\n",
            "Converting SMILES to graph: 18030/19709\n",
            "Converting SMILES to graph: 18031/19709\n",
            "Converting SMILES to graph: 18032/19709\n",
            "Converting SMILES to graph: 18033/19709\n",
            "Converting SMILES to graph: 18034/19709\n",
            "Converting SMILES to graph: 18035/19709\n",
            "Converting SMILES to graph: 18036/19709\n",
            "Converting SMILES to graph: 18037/19709\n",
            "Converting SMILES to graph: 18038/19709\n",
            "Converting SMILES to graph: 18039/19709\n",
            "Converting SMILES to graph: 18040/19709\n",
            "Converting SMILES to graph: 18041/19709\n",
            "Converting SMILES to graph: 18042/19709\n",
            "Converting SMILES to graph: 18043/19709\n",
            "Converting SMILES to graph: 18044/19709\n",
            "Converting SMILES to graph: 18045/19709\n",
            "Converting SMILES to graph: 18046/19709\n",
            "Converting SMILES to graph: 18047/19709\n",
            "Converting SMILES to graph: 18048/19709\n",
            "Converting SMILES to graph: 18049/19709\n",
            "Converting SMILES to graph: 18050/19709\n",
            "Converting SMILES to graph: 18051/19709\n",
            "Converting SMILES to graph: 18052/19709\n",
            "Converting SMILES to graph: 18053/19709\n",
            "Converting SMILES to graph: 18054/19709\n",
            "Converting SMILES to graph: 18055/19709\n",
            "Converting SMILES to graph: 18056/19709\n",
            "Converting SMILES to graph: 18057/19709\n",
            "Converting SMILES to graph: 18058/19709\n",
            "Converting SMILES to graph: 18059/19709\n",
            "Converting SMILES to graph: 18060/19709\n",
            "Converting SMILES to graph: 18061/19709\n",
            "Converting SMILES to graph: 18062/19709\n",
            "Converting SMILES to graph: 18063/19709\n",
            "Converting SMILES to graph: 18064/19709\n",
            "Converting SMILES to graph: 18065/19709\n",
            "Converting SMILES to graph: 18066/19709\n",
            "Converting SMILES to graph: 18067/19709\n",
            "Converting SMILES to graph: 18068/19709\n",
            "Converting SMILES to graph: 18069/19709\n",
            "Converting SMILES to graph: 18070/19709\n",
            "Converting SMILES to graph: 18071/19709\n",
            "Converting SMILES to graph: 18072/19709\n",
            "Converting SMILES to graph: 18073/19709\n",
            "Converting SMILES to graph: 18074/19709\n",
            "Converting SMILES to graph: 18075/19709\n",
            "Converting SMILES to graph: 18076/19709\n",
            "Converting SMILES to graph: 18077/19709\n",
            "Converting SMILES to graph: 18078/19709\n",
            "Converting SMILES to graph: 18079/19709\n",
            "Converting SMILES to graph: 18080/19709\n",
            "Converting SMILES to graph: 18081/19709\n",
            "Converting SMILES to graph: 18082/19709\n",
            "Converting SMILES to graph: 18083/19709\n",
            "Converting SMILES to graph: 18084/19709\n",
            "Converting SMILES to graph: 18085/19709\n",
            "Converting SMILES to graph: 18086/19709\n",
            "Converting SMILES to graph: 18087/19709\n",
            "Converting SMILES to graph: 18088/19709\n",
            "Converting SMILES to graph: 18089/19709\n",
            "Converting SMILES to graph: 18090/19709\n",
            "Converting SMILES to graph: 18091/19709\n",
            "Converting SMILES to graph: 18092/19709\n",
            "Converting SMILES to graph: 18093/19709\n",
            "Converting SMILES to graph: 18094/19709\n",
            "Converting SMILES to graph: 18095/19709\n",
            "Converting SMILES to graph: 18096/19709\n",
            "Converting SMILES to graph: 18097/19709\n",
            "Converting SMILES to graph: 18098/19709\n",
            "Converting SMILES to graph: 18099/19709\n",
            "Converting SMILES to graph: 18100/19709\n",
            "Converting SMILES to graph: 18101/19709\n",
            "Converting SMILES to graph: 18102/19709\n",
            "Converting SMILES to graph: 18103/19709\n",
            "Converting SMILES to graph: 18104/19709\n",
            "Converting SMILES to graph: 18105/19709\n",
            "Converting SMILES to graph: 18106/19709\n",
            "Converting SMILES to graph: 18107/19709\n",
            "Converting SMILES to graph: 18108/19709\n",
            "Converting SMILES to graph: 18109/19709\n",
            "Converting SMILES to graph: 18110/19709\n",
            "Converting SMILES to graph: 18111/19709\n",
            "Converting SMILES to graph: 18112/19709\n",
            "Converting SMILES to graph: 18113/19709\n",
            "Converting SMILES to graph: 18114/19709\n",
            "Converting SMILES to graph: 18115/19709\n",
            "Converting SMILES to graph: 18116/19709\n",
            "Converting SMILES to graph: 18117/19709\n",
            "Converting SMILES to graph: 18118/19709\n",
            "Converting SMILES to graph: 18119/19709\n",
            "Converting SMILES to graph: 18120/19709\n",
            "Converting SMILES to graph: 18121/19709\n",
            "Converting SMILES to graph: 18122/19709\n",
            "Converting SMILES to graph: 18123/19709\n",
            "Converting SMILES to graph: 18124/19709\n",
            "Converting SMILES to graph: 18125/19709\n",
            "Converting SMILES to graph: 18126/19709\n",
            "Converting SMILES to graph: 18127/19709\n",
            "Converting SMILES to graph: 18128/19709\n",
            "Converting SMILES to graph: 18129/19709\n",
            "Converting SMILES to graph: 18130/19709\n",
            "Converting SMILES to graph: 18131/19709\n",
            "Converting SMILES to graph: 18132/19709\n",
            "Converting SMILES to graph: 18133/19709\n",
            "Converting SMILES to graph: 18134/19709\n",
            "Converting SMILES to graph: 18135/19709\n",
            "Converting SMILES to graph: 18136/19709\n",
            "Converting SMILES to graph: 18137/19709\n",
            "Converting SMILES to graph: 18138/19709\n",
            "Converting SMILES to graph: 18139/19709\n",
            "Converting SMILES to graph: 18140/19709\n",
            "Converting SMILES to graph: 18141/19709\n",
            "Converting SMILES to graph: 18142/19709\n",
            "Converting SMILES to graph: 18143/19709\n",
            "Converting SMILES to graph: 18144/19709\n",
            "Converting SMILES to graph: 18145/19709\n",
            "Converting SMILES to graph: 18146/19709\n",
            "Converting SMILES to graph: 18147/19709\n",
            "Converting SMILES to graph: 18148/19709\n",
            "Converting SMILES to graph: 18149/19709\n",
            "Converting SMILES to graph: 18150/19709\n",
            "Converting SMILES to graph: 18151/19709\n",
            "Converting SMILES to graph: 18152/19709\n",
            "Converting SMILES to graph: 18153/19709\n",
            "Converting SMILES to graph: 18154/19709\n",
            "Converting SMILES to graph: 18155/19709\n",
            "Converting SMILES to graph: 18156/19709\n",
            "Converting SMILES to graph: 18157/19709\n",
            "Converting SMILES to graph: 18158/19709\n",
            "Converting SMILES to graph: 18159/19709\n",
            "Converting SMILES to graph: 18160/19709\n",
            "Converting SMILES to graph: 18161/19709\n",
            "Converting SMILES to graph: 18162/19709\n",
            "Converting SMILES to graph: 18163/19709\n",
            "Converting SMILES to graph: 18164/19709\n",
            "Converting SMILES to graph: 18165/19709\n",
            "Converting SMILES to graph: 18166/19709\n",
            "Converting SMILES to graph: 18167/19709\n",
            "Converting SMILES to graph: 18168/19709\n",
            "Converting SMILES to graph: 18169/19709\n",
            "Converting SMILES to graph: 18170/19709\n",
            "Converting SMILES to graph: 18171/19709\n",
            "Converting SMILES to graph: 18172/19709\n",
            "Converting SMILES to graph: 18173/19709\n",
            "Converting SMILES to graph: 18174/19709\n",
            "Converting SMILES to graph: 18175/19709\n",
            "Converting SMILES to graph: 18176/19709\n",
            "Converting SMILES to graph: 18177/19709\n",
            "Converting SMILES to graph: 18178/19709\n",
            "Converting SMILES to graph: 18179/19709\n",
            "Converting SMILES to graph: 18180/19709\n",
            "Converting SMILES to graph: 18181/19709\n",
            "Converting SMILES to graph: 18182/19709\n",
            "Converting SMILES to graph: 18183/19709\n",
            "Converting SMILES to graph: 18184/19709\n",
            "Converting SMILES to graph: 18185/19709\n",
            "Converting SMILES to graph: 18186/19709\n",
            "Converting SMILES to graph: 18187/19709\n",
            "Converting SMILES to graph: 18188/19709\n",
            "Converting SMILES to graph: 18189/19709\n",
            "Converting SMILES to graph: 18190/19709\n",
            "Converting SMILES to graph: 18191/19709\n",
            "Converting SMILES to graph: 18192/19709\n",
            "Converting SMILES to graph: 18193/19709\n",
            "Converting SMILES to graph: 18194/19709\n",
            "Converting SMILES to graph: 18195/19709\n",
            "Converting SMILES to graph: 18196/19709\n",
            "Converting SMILES to graph: 18197/19709\n",
            "Converting SMILES to graph: 18198/19709\n",
            "Converting SMILES to graph: 18199/19709\n",
            "Converting SMILES to graph: 18200/19709\n",
            "Converting SMILES to graph: 18201/19709\n",
            "Converting SMILES to graph: 18202/19709\n",
            "Converting SMILES to graph: 18203/19709\n",
            "Converting SMILES to graph: 18204/19709\n",
            "Converting SMILES to graph: 18205/19709\n",
            "Converting SMILES to graph: 18206/19709\n",
            "Converting SMILES to graph: 18207/19709\n",
            "Converting SMILES to graph: 18208/19709\n",
            "Converting SMILES to graph: 18209/19709\n",
            "Converting SMILES to graph: 18210/19709\n",
            "Converting SMILES to graph: 18211/19709\n",
            "Converting SMILES to graph: 18212/19709\n",
            "Converting SMILES to graph: 18213/19709\n",
            "Converting SMILES to graph: 18214/19709\n",
            "Converting SMILES to graph: 18215/19709\n",
            "Converting SMILES to graph: 18216/19709\n",
            "Converting SMILES to graph: 18217/19709\n",
            "Converting SMILES to graph: 18218/19709\n",
            "Converting SMILES to graph: 18219/19709\n",
            "Converting SMILES to graph: 18220/19709\n",
            "Converting SMILES to graph: 18221/19709\n",
            "Converting SMILES to graph: 18222/19709\n",
            "Converting SMILES to graph: 18223/19709\n",
            "Converting SMILES to graph: 18224/19709\n",
            "Converting SMILES to graph: 18225/19709\n",
            "Converting SMILES to graph: 18226/19709\n",
            "Converting SMILES to graph: 18227/19709\n",
            "Converting SMILES to graph: 18228/19709\n",
            "Converting SMILES to graph: 18229/19709\n",
            "Converting SMILES to graph: 18230/19709\n",
            "Converting SMILES to graph: 18231/19709\n",
            "Converting SMILES to graph: 18232/19709\n",
            "Converting SMILES to graph: 18233/19709\n",
            "Converting SMILES to graph: 18234/19709\n",
            "Converting SMILES to graph: 18235/19709\n",
            "Converting SMILES to graph: 18236/19709\n",
            "Converting SMILES to graph: 18237/19709\n",
            "Converting SMILES to graph: 18238/19709\n",
            "Converting SMILES to graph: 18239/19709\n",
            "Converting SMILES to graph: 18240/19709\n",
            "Converting SMILES to graph: 18241/19709\n",
            "Converting SMILES to graph: 18242/19709\n",
            "Converting SMILES to graph: 18243/19709\n",
            "Converting SMILES to graph: 18244/19709\n",
            "Converting SMILES to graph: 18245/19709\n",
            "Converting SMILES to graph: 18246/19709\n",
            "Converting SMILES to graph: 18247/19709\n",
            "Converting SMILES to graph: 18248/19709\n",
            "Converting SMILES to graph: 18249/19709\n",
            "Converting SMILES to graph: 18250/19709\n",
            "Converting SMILES to graph: 18251/19709\n",
            "Converting SMILES to graph: 18252/19709\n",
            "Converting SMILES to graph: 18253/19709\n",
            "Converting SMILES to graph: 18254/19709\n",
            "Converting SMILES to graph: 18255/19709\n",
            "Converting SMILES to graph: 18256/19709\n",
            "Converting SMILES to graph: 18257/19709\n",
            "Converting SMILES to graph: 18258/19709\n",
            "Converting SMILES to graph: 18259/19709\n",
            "Converting SMILES to graph: 18260/19709\n",
            "Converting SMILES to graph: 18261/19709\n",
            "Converting SMILES to graph: 18262/19709\n",
            "Converting SMILES to graph: 18263/19709\n",
            "Converting SMILES to graph: 18264/19709\n",
            "Converting SMILES to graph: 18265/19709\n",
            "Converting SMILES to graph: 18266/19709\n",
            "Converting SMILES to graph: 18267/19709\n",
            "Converting SMILES to graph: 18268/19709\n",
            "Converting SMILES to graph: 18269/19709\n",
            "Converting SMILES to graph: 18270/19709\n",
            "Converting SMILES to graph: 18271/19709\n",
            "Converting SMILES to graph: 18272/19709\n",
            "Converting SMILES to graph: 18273/19709\n",
            "Converting SMILES to graph: 18274/19709\n",
            "Converting SMILES to graph: 18275/19709\n",
            "Converting SMILES to graph: 18276/19709\n",
            "Converting SMILES to graph: 18277/19709\n",
            "Converting SMILES to graph: 18278/19709\n",
            "Converting SMILES to graph: 18279/19709\n",
            "Converting SMILES to graph: 18280/19709\n",
            "Converting SMILES to graph: 18281/19709\n",
            "Converting SMILES to graph: 18282/19709\n",
            "Converting SMILES to graph: 18283/19709\n",
            "Converting SMILES to graph: 18284/19709\n",
            "Converting SMILES to graph: 18285/19709\n",
            "Converting SMILES to graph: 18286/19709\n",
            "Converting SMILES to graph: 18287/19709\n",
            "Converting SMILES to graph: 18288/19709\n",
            "Converting SMILES to graph: 18289/19709\n",
            "Converting SMILES to graph: 18290/19709\n",
            "Converting SMILES to graph: 18291/19709\n",
            "Converting SMILES to graph: 18292/19709\n",
            "Converting SMILES to graph: 18293/19709\n",
            "Converting SMILES to graph: 18294/19709\n",
            "Converting SMILES to graph: 18295/19709\n",
            "Converting SMILES to graph: 18296/19709\n",
            "Converting SMILES to graph: 18297/19709\n",
            "Converting SMILES to graph: 18298/19709\n",
            "Converting SMILES to graph: 18299/19709\n",
            "Converting SMILES to graph: 18300/19709\n",
            "Converting SMILES to graph: 18301/19709\n",
            "Converting SMILES to graph: 18302/19709\n",
            "Converting SMILES to graph: 18303/19709\n",
            "Converting SMILES to graph: 18304/19709\n",
            "Converting SMILES to graph: 18305/19709\n",
            "Converting SMILES to graph: 18306/19709\n",
            "Converting SMILES to graph: 18307/19709\n",
            "Converting SMILES to graph: 18308/19709\n",
            "Converting SMILES to graph: 18309/19709\n",
            "Converting SMILES to graph: 18310/19709\n",
            "Converting SMILES to graph: 18311/19709\n",
            "Converting SMILES to graph: 18312/19709\n",
            "Converting SMILES to graph: 18313/19709\n",
            "Converting SMILES to graph: 18314/19709\n",
            "Converting SMILES to graph: 18315/19709\n",
            "Converting SMILES to graph: 18316/19709\n",
            "Converting SMILES to graph: 18317/19709\n",
            "Converting SMILES to graph: 18318/19709\n",
            "Converting SMILES to graph: 18319/19709\n",
            "Converting SMILES to graph: 18320/19709\n",
            "Converting SMILES to graph: 18321/19709\n",
            "Converting SMILES to graph: 18322/19709\n",
            "Converting SMILES to graph: 18323/19709\n",
            "Converting SMILES to graph: 18324/19709\n",
            "Converting SMILES to graph: 18325/19709\n",
            "Converting SMILES to graph: 18326/19709\n",
            "Converting SMILES to graph: 18327/19709\n",
            "Converting SMILES to graph: 18328/19709\n",
            "Converting SMILES to graph: 18329/19709\n",
            "Converting SMILES to graph: 18330/19709\n",
            "Converting SMILES to graph: 18331/19709\n",
            "Converting SMILES to graph: 18332/19709\n",
            "Converting SMILES to graph: 18333/19709\n",
            "Converting SMILES to graph: 18334/19709\n",
            "Converting SMILES to graph: 18335/19709\n",
            "Converting SMILES to graph: 18336/19709\n",
            "Converting SMILES to graph: 18337/19709\n",
            "Converting SMILES to graph: 18338/19709\n",
            "Converting SMILES to graph: 18339/19709\n",
            "Converting SMILES to graph: 18340/19709\n",
            "Converting SMILES to graph: 18341/19709\n",
            "Converting SMILES to graph: 18342/19709\n",
            "Converting SMILES to graph: 18343/19709\n",
            "Converting SMILES to graph: 18344/19709\n",
            "Converting SMILES to graph: 18345/19709\n",
            "Converting SMILES to graph: 18346/19709\n",
            "Converting SMILES to graph: 18347/19709\n",
            "Converting SMILES to graph: 18348/19709\n",
            "Converting SMILES to graph: 18349/19709\n",
            "Converting SMILES to graph: 18350/19709\n",
            "Converting SMILES to graph: 18351/19709\n",
            "Converting SMILES to graph: 18352/19709\n",
            "Converting SMILES to graph: 18353/19709\n",
            "Converting SMILES to graph: 18354/19709\n",
            "Converting SMILES to graph: 18355/19709\n",
            "Converting SMILES to graph: 18356/19709\n",
            "Converting SMILES to graph: 18357/19709\n",
            "Converting SMILES to graph: 18358/19709\n",
            "Converting SMILES to graph: 18359/19709\n",
            "Converting SMILES to graph: 18360/19709\n",
            "Converting SMILES to graph: 18361/19709\n",
            "Converting SMILES to graph: 18362/19709\n",
            "Converting SMILES to graph: 18363/19709\n",
            "Converting SMILES to graph: 18364/19709\n",
            "Converting SMILES to graph: 18365/19709\n",
            "Converting SMILES to graph: 18366/19709\n",
            "Converting SMILES to graph: 18367/19709\n",
            "Converting SMILES to graph: 18368/19709\n",
            "Converting SMILES to graph: 18369/19709\n",
            "Converting SMILES to graph: 18370/19709\n",
            "Converting SMILES to graph: 18371/19709\n",
            "Converting SMILES to graph: 18372/19709\n",
            "Converting SMILES to graph: 18373/19709\n",
            "Converting SMILES to graph: 18374/19709\n",
            "Converting SMILES to graph: 18375/19709\n",
            "Converting SMILES to graph: 18376/19709\n",
            "Converting SMILES to graph: 18377/19709\n",
            "Converting SMILES to graph: 18378/19709\n",
            "Converting SMILES to graph: 18379/19709\n",
            "Converting SMILES to graph: 18380/19709\n",
            "Converting SMILES to graph: 18381/19709\n",
            "Converting SMILES to graph: 18382/19709\n",
            "Converting SMILES to graph: 18383/19709\n",
            "Converting SMILES to graph: 18384/19709\n",
            "Converting SMILES to graph: 18385/19709\n",
            "Converting SMILES to graph: 18386/19709\n",
            "Converting SMILES to graph: 18387/19709\n",
            "Converting SMILES to graph: 18388/19709\n",
            "Converting SMILES to graph: 18389/19709\n",
            "Converting SMILES to graph: 18390/19709\n",
            "Converting SMILES to graph: 18391/19709\n",
            "Converting SMILES to graph: 18392/19709\n",
            "Converting SMILES to graph: 18393/19709\n",
            "Converting SMILES to graph: 18394/19709\n",
            "Converting SMILES to graph: 18395/19709\n",
            "Converting SMILES to graph: 18396/19709\n",
            "Converting SMILES to graph: 18397/19709\n",
            "Converting SMILES to graph: 18398/19709\n",
            "Converting SMILES to graph: 18399/19709\n",
            "Converting SMILES to graph: 18400/19709\n",
            "Converting SMILES to graph: 18401/19709\n",
            "Converting SMILES to graph: 18402/19709\n",
            "Converting SMILES to graph: 18403/19709\n",
            "Converting SMILES to graph: 18404/19709\n",
            "Converting SMILES to graph: 18405/19709\n",
            "Converting SMILES to graph: 18406/19709\n",
            "Converting SMILES to graph: 18407/19709\n",
            "Converting SMILES to graph: 18408/19709\n",
            "Converting SMILES to graph: 18409/19709\n",
            "Converting SMILES to graph: 18410/19709\n",
            "Converting SMILES to graph: 18411/19709\n",
            "Converting SMILES to graph: 18412/19709\n",
            "Converting SMILES to graph: 18413/19709\n",
            "Converting SMILES to graph: 18414/19709\n",
            "Converting SMILES to graph: 18415/19709\n",
            "Converting SMILES to graph: 18416/19709\n",
            "Converting SMILES to graph: 18417/19709\n",
            "Converting SMILES to graph: 18418/19709\n",
            "Converting SMILES to graph: 18419/19709\n",
            "Converting SMILES to graph: 18420/19709\n",
            "Converting SMILES to graph: 18421/19709\n",
            "Converting SMILES to graph: 18422/19709\n",
            "Converting SMILES to graph: 18423/19709\n",
            "Converting SMILES to graph: 18424/19709\n",
            "Converting SMILES to graph: 18425/19709\n",
            "Converting SMILES to graph: 18426/19709\n",
            "Converting SMILES to graph: 18427/19709\n",
            "Converting SMILES to graph: 18428/19709\n",
            "Converting SMILES to graph: 18429/19709\n",
            "Converting SMILES to graph: 18430/19709\n",
            "Converting SMILES to graph: 18431/19709\n",
            "Converting SMILES to graph: 18432/19709\n",
            "Converting SMILES to graph: 18433/19709\n",
            "Converting SMILES to graph: 18434/19709\n",
            "Converting SMILES to graph: 18435/19709\n",
            "Converting SMILES to graph: 18436/19709\n",
            "Converting SMILES to graph: 18437/19709\n",
            "Converting SMILES to graph: 18438/19709\n",
            "Converting SMILES to graph: 18439/19709\n",
            "Converting SMILES to graph: 18440/19709\n",
            "Converting SMILES to graph: 18441/19709\n",
            "Converting SMILES to graph: 18442/19709\n",
            "Converting SMILES to graph: 18443/19709\n",
            "Converting SMILES to graph: 18444/19709\n",
            "Converting SMILES to graph: 18445/19709\n",
            "Converting SMILES to graph: 18446/19709\n",
            "Converting SMILES to graph: 18447/19709\n",
            "Converting SMILES to graph: 18448/19709\n",
            "Converting SMILES to graph: 18449/19709\n",
            "Converting SMILES to graph: 18450/19709\n",
            "Converting SMILES to graph: 18451/19709\n",
            "Converting SMILES to graph: 18452/19709\n",
            "Converting SMILES to graph: 18453/19709\n",
            "Converting SMILES to graph: 18454/19709\n",
            "Converting SMILES to graph: 18455/19709\n",
            "Converting SMILES to graph: 18456/19709\n",
            "Converting SMILES to graph: 18457/19709\n",
            "Converting SMILES to graph: 18458/19709\n",
            "Converting SMILES to graph: 18459/19709\n",
            "Converting SMILES to graph: 18460/19709\n",
            "Converting SMILES to graph: 18461/19709\n",
            "Converting SMILES to graph: 18462/19709\n",
            "Converting SMILES to graph: 18463/19709\n",
            "Converting SMILES to graph: 18464/19709\n",
            "Converting SMILES to graph: 18465/19709\n",
            "Converting SMILES to graph: 18466/19709\n",
            "Converting SMILES to graph: 18467/19709\n",
            "Converting SMILES to graph: 18468/19709\n",
            "Converting SMILES to graph: 18469/19709\n",
            "Converting SMILES to graph: 18470/19709\n",
            "Converting SMILES to graph: 18471/19709\n",
            "Converting SMILES to graph: 18472/19709\n",
            "Converting SMILES to graph: 18473/19709\n",
            "Converting SMILES to graph: 18474/19709\n",
            "Converting SMILES to graph: 18475/19709\n",
            "Converting SMILES to graph: 18476/19709\n",
            "Converting SMILES to graph: 18477/19709\n",
            "Converting SMILES to graph: 18478/19709\n",
            "Converting SMILES to graph: 18479/19709\n",
            "Converting SMILES to graph: 18480/19709\n",
            "Converting SMILES to graph: 18481/19709\n",
            "Converting SMILES to graph: 18482/19709\n",
            "Converting SMILES to graph: 18483/19709\n",
            "Converting SMILES to graph: 18484/19709\n",
            "Converting SMILES to graph: 18485/19709\n",
            "Converting SMILES to graph: 18486/19709\n",
            "Converting SMILES to graph: 18487/19709\n",
            "Converting SMILES to graph: 18488/19709\n",
            "Converting SMILES to graph: 18489/19709\n",
            "Converting SMILES to graph: 18490/19709\n",
            "Converting SMILES to graph: 18491/19709\n",
            "Converting SMILES to graph: 18492/19709\n",
            "Converting SMILES to graph: 18493/19709\n",
            "Converting SMILES to graph: 18494/19709\n",
            "Converting SMILES to graph: 18495/19709\n",
            "Converting SMILES to graph: 18496/19709\n",
            "Converting SMILES to graph: 18497/19709\n",
            "Converting SMILES to graph: 18498/19709\n",
            "Converting SMILES to graph: 18499/19709\n",
            "Converting SMILES to graph: 18500/19709\n",
            "Converting SMILES to graph: 18501/19709\n",
            "Converting SMILES to graph: 18502/19709\n",
            "Converting SMILES to graph: 18503/19709\n",
            "Converting SMILES to graph: 18504/19709\n",
            "Converting SMILES to graph: 18505/19709\n",
            "Converting SMILES to graph: 18506/19709\n",
            "Converting SMILES to graph: 18507/19709\n",
            "Converting SMILES to graph: 18508/19709\n",
            "Converting SMILES to graph: 18509/19709\n",
            "Converting SMILES to graph: 18510/19709\n",
            "Converting SMILES to graph: 18511/19709\n",
            "Converting SMILES to graph: 18512/19709\n",
            "Converting SMILES to graph: 18513/19709\n",
            "Converting SMILES to graph: 18514/19709\n",
            "Converting SMILES to graph: 18515/19709\n",
            "Converting SMILES to graph: 18516/19709\n",
            "Converting SMILES to graph: 18517/19709\n",
            "Converting SMILES to graph: 18518/19709\n",
            "Converting SMILES to graph: 18519/19709\n",
            "Converting SMILES to graph: 18520/19709\n",
            "Converting SMILES to graph: 18521/19709\n",
            "Converting SMILES to graph: 18522/19709\n",
            "Converting SMILES to graph: 18523/19709\n",
            "Converting SMILES to graph: 18524/19709\n",
            "Converting SMILES to graph: 18525/19709\n",
            "Converting SMILES to graph: 18526/19709\n",
            "Converting SMILES to graph: 18527/19709\n",
            "Converting SMILES to graph: 18528/19709\n",
            "Converting SMILES to graph: 18529/19709\n",
            "Converting SMILES to graph: 18530/19709\n",
            "Converting SMILES to graph: 18531/19709\n",
            "Converting SMILES to graph: 18532/19709\n",
            "Converting SMILES to graph: 18533/19709\n",
            "Converting SMILES to graph: 18534/19709\n",
            "Converting SMILES to graph: 18535/19709\n",
            "Converting SMILES to graph: 18536/19709\n",
            "Converting SMILES to graph: 18537/19709\n",
            "Converting SMILES to graph: 18538/19709\n",
            "Converting SMILES to graph: 18539/19709\n",
            "Converting SMILES to graph: 18540/19709\n",
            "Converting SMILES to graph: 18541/19709\n",
            "Converting SMILES to graph: 18542/19709\n",
            "Converting SMILES to graph: 18543/19709\n",
            "Converting SMILES to graph: 18544/19709\n",
            "Converting SMILES to graph: 18545/19709\n",
            "Converting SMILES to graph: 18546/19709\n",
            "Converting SMILES to graph: 18547/19709\n",
            "Converting SMILES to graph: 18548/19709\n",
            "Converting SMILES to graph: 18549/19709\n",
            "Converting SMILES to graph: 18550/19709\n",
            "Converting SMILES to graph: 18551/19709\n",
            "Converting SMILES to graph: 18552/19709\n",
            "Converting SMILES to graph: 18553/19709\n",
            "Converting SMILES to graph: 18554/19709\n",
            "Converting SMILES to graph: 18555/19709\n",
            "Converting SMILES to graph: 18556/19709\n",
            "Converting SMILES to graph: 18557/19709\n",
            "Converting SMILES to graph: 18558/19709\n",
            "Converting SMILES to graph: 18559/19709\n",
            "Converting SMILES to graph: 18560/19709\n",
            "Converting SMILES to graph: 18561/19709\n",
            "Converting SMILES to graph: 18562/19709\n",
            "Converting SMILES to graph: 18563/19709\n",
            "Converting SMILES to graph: 18564/19709\n",
            "Converting SMILES to graph: 18565/19709\n",
            "Converting SMILES to graph: 18566/19709\n",
            "Converting SMILES to graph: 18567/19709\n",
            "Converting SMILES to graph: 18568/19709\n",
            "Converting SMILES to graph: 18569/19709\n",
            "Converting SMILES to graph: 18570/19709\n",
            "Converting SMILES to graph: 18571/19709\n",
            "Converting SMILES to graph: 18572/19709\n",
            "Converting SMILES to graph: 18573/19709\n",
            "Converting SMILES to graph: 18574/19709\n",
            "Converting SMILES to graph: 18575/19709\n",
            "Converting SMILES to graph: 18576/19709\n",
            "Converting SMILES to graph: 18577/19709\n",
            "Converting SMILES to graph: 18578/19709\n",
            "Converting SMILES to graph: 18579/19709\n",
            "Converting SMILES to graph: 18580/19709\n",
            "Converting SMILES to graph: 18581/19709\n",
            "Converting SMILES to graph: 18582/19709\n",
            "Converting SMILES to graph: 18583/19709\n",
            "Converting SMILES to graph: 18584/19709\n",
            "Converting SMILES to graph: 18585/19709\n",
            "Converting SMILES to graph: 18586/19709\n",
            "Converting SMILES to graph: 18587/19709\n",
            "Converting SMILES to graph: 18588/19709\n",
            "Converting SMILES to graph: 18589/19709\n",
            "Converting SMILES to graph: 18590/19709\n",
            "Converting SMILES to graph: 18591/19709\n",
            "Converting SMILES to graph: 18592/19709\n",
            "Converting SMILES to graph: 18593/19709\n",
            "Converting SMILES to graph: 18594/19709\n",
            "Converting SMILES to graph: 18595/19709\n",
            "Converting SMILES to graph: 18596/19709\n",
            "Converting SMILES to graph: 18597/19709\n",
            "Converting SMILES to graph: 18598/19709\n",
            "Converting SMILES to graph: 18599/19709\n",
            "Converting SMILES to graph: 18600/19709\n",
            "Converting SMILES to graph: 18601/19709\n",
            "Converting SMILES to graph: 18602/19709\n",
            "Converting SMILES to graph: 18603/19709\n",
            "Converting SMILES to graph: 18604/19709\n",
            "Converting SMILES to graph: 18605/19709\n",
            "Converting SMILES to graph: 18606/19709\n",
            "Converting SMILES to graph: 18607/19709\n",
            "Converting SMILES to graph: 18608/19709\n",
            "Converting SMILES to graph: 18609/19709\n",
            "Converting SMILES to graph: 18610/19709\n",
            "Converting SMILES to graph: 18611/19709\n",
            "Converting SMILES to graph: 18612/19709\n",
            "Converting SMILES to graph: 18613/19709\n",
            "Converting SMILES to graph: 18614/19709\n",
            "Converting SMILES to graph: 18615/19709\n",
            "Converting SMILES to graph: 18616/19709\n",
            "Converting SMILES to graph: 18617/19709\n",
            "Converting SMILES to graph: 18618/19709\n",
            "Converting SMILES to graph: 18619/19709\n",
            "Converting SMILES to graph: 18620/19709\n",
            "Converting SMILES to graph: 18621/19709\n",
            "Converting SMILES to graph: 18622/19709\n",
            "Converting SMILES to graph: 18623/19709\n",
            "Converting SMILES to graph: 18624/19709\n",
            "Converting SMILES to graph: 18625/19709\n",
            "Converting SMILES to graph: 18626/19709\n",
            "Converting SMILES to graph: 18627/19709\n",
            "Converting SMILES to graph: 18628/19709\n",
            "Converting SMILES to graph: 18629/19709\n",
            "Converting SMILES to graph: 18630/19709\n",
            "Converting SMILES to graph: 18631/19709\n",
            "Converting SMILES to graph: 18632/19709\n",
            "Converting SMILES to graph: 18633/19709\n",
            "Converting SMILES to graph: 18634/19709\n",
            "Converting SMILES to graph: 18635/19709\n",
            "Converting SMILES to graph: 18636/19709\n",
            "Converting SMILES to graph: 18637/19709\n",
            "Converting SMILES to graph: 18638/19709\n",
            "Converting SMILES to graph: 18639/19709\n",
            "Converting SMILES to graph: 18640/19709\n",
            "Converting SMILES to graph: 18641/19709\n",
            "Converting SMILES to graph: 18642/19709\n",
            "Converting SMILES to graph: 18643/19709\n",
            "Converting SMILES to graph: 18644/19709\n",
            "Converting SMILES to graph: 18645/19709\n",
            "Converting SMILES to graph: 18646/19709\n",
            "Converting SMILES to graph: 18647/19709\n",
            "Converting SMILES to graph: 18648/19709\n",
            "Converting SMILES to graph: 18649/19709\n",
            "Converting SMILES to graph: 18650/19709\n",
            "Converting SMILES to graph: 18651/19709\n",
            "Converting SMILES to graph: 18652/19709\n",
            "Converting SMILES to graph: 18653/19709\n",
            "Converting SMILES to graph: 18654/19709\n",
            "Converting SMILES to graph: 18655/19709\n",
            "Converting SMILES to graph: 18656/19709\n",
            "Converting SMILES to graph: 18657/19709\n",
            "Converting SMILES to graph: 18658/19709\n",
            "Converting SMILES to graph: 18659/19709\n",
            "Converting SMILES to graph: 18660/19709\n",
            "Converting SMILES to graph: 18661/19709\n",
            "Converting SMILES to graph: 18662/19709\n",
            "Converting SMILES to graph: 18663/19709\n",
            "Converting SMILES to graph: 18664/19709\n",
            "Converting SMILES to graph: 18665/19709\n",
            "Converting SMILES to graph: 18666/19709\n",
            "Converting SMILES to graph: 18667/19709\n",
            "Converting SMILES to graph: 18668/19709\n",
            "Converting SMILES to graph: 18669/19709\n",
            "Converting SMILES to graph: 18670/19709\n",
            "Converting SMILES to graph: 18671/19709\n",
            "Converting SMILES to graph: 18672/19709\n",
            "Converting SMILES to graph: 18673/19709\n",
            "Converting SMILES to graph: 18674/19709\n",
            "Converting SMILES to graph: 18675/19709\n",
            "Converting SMILES to graph: 18676/19709\n",
            "Converting SMILES to graph: 18677/19709\n",
            "Converting SMILES to graph: 18678/19709\n",
            "Converting SMILES to graph: 18679/19709\n",
            "Converting SMILES to graph: 18680/19709\n",
            "Converting SMILES to graph: 18681/19709\n",
            "Converting SMILES to graph: 18682/19709\n",
            "Converting SMILES to graph: 18683/19709\n",
            "Converting SMILES to graph: 18684/19709\n",
            "Converting SMILES to graph: 18685/19709\n",
            "Converting SMILES to graph: 18686/19709\n",
            "Converting SMILES to graph: 18687/19709\n",
            "Converting SMILES to graph: 18688/19709\n",
            "Converting SMILES to graph: 18689/19709\n",
            "Converting SMILES to graph: 18690/19709\n",
            "Converting SMILES to graph: 18691/19709\n",
            "Converting SMILES to graph: 18692/19709\n",
            "Converting SMILES to graph: 18693/19709\n",
            "Converting SMILES to graph: 18694/19709\n",
            "Converting SMILES to graph: 18695/19709\n",
            "Converting SMILES to graph: 18696/19709\n",
            "Converting SMILES to graph: 18697/19709\n",
            "Converting SMILES to graph: 18698/19709\n",
            "Converting SMILES to graph: 18699/19709\n",
            "Converting SMILES to graph: 18700/19709\n",
            "Converting SMILES to graph: 18701/19709\n",
            "Converting SMILES to graph: 18702/19709\n",
            "Converting SMILES to graph: 18703/19709\n",
            "Converting SMILES to graph: 18704/19709\n",
            "Converting SMILES to graph: 18705/19709\n",
            "Converting SMILES to graph: 18706/19709\n",
            "Converting SMILES to graph: 18707/19709\n",
            "Converting SMILES to graph: 18708/19709\n",
            "Converting SMILES to graph: 18709/19709\n",
            "Converting SMILES to graph: 18710/19709\n",
            "Converting SMILES to graph: 18711/19709\n",
            "Converting SMILES to graph: 18712/19709\n",
            "Converting SMILES to graph: 18713/19709\n",
            "Converting SMILES to graph: 18714/19709\n",
            "Converting SMILES to graph: 18715/19709\n",
            "Converting SMILES to graph: 18716/19709\n",
            "Converting SMILES to graph: 18717/19709\n",
            "Converting SMILES to graph: 18718/19709\n",
            "Converting SMILES to graph: 18719/19709\n",
            "Converting SMILES to graph: 18720/19709\n",
            "Converting SMILES to graph: 18721/19709\n",
            "Converting SMILES to graph: 18722/19709\n",
            "Converting SMILES to graph: 18723/19709\n",
            "Converting SMILES to graph: 18724/19709\n",
            "Converting SMILES to graph: 18725/19709\n",
            "Converting SMILES to graph: 18726/19709\n",
            "Converting SMILES to graph: 18727/19709\n",
            "Converting SMILES to graph: 18728/19709\n",
            "Converting SMILES to graph: 18729/19709\n",
            "Converting SMILES to graph: 18730/19709\n",
            "Converting SMILES to graph: 18731/19709\n",
            "Converting SMILES to graph: 18732/19709\n",
            "Converting SMILES to graph: 18733/19709\n",
            "Converting SMILES to graph: 18734/19709\n",
            "Converting SMILES to graph: 18735/19709\n",
            "Converting SMILES to graph: 18736/19709\n",
            "Converting SMILES to graph: 18737/19709\n",
            "Converting SMILES to graph: 18738/19709\n",
            "Converting SMILES to graph: 18739/19709\n",
            "Converting SMILES to graph: 18740/19709\n",
            "Converting SMILES to graph: 18741/19709\n",
            "Converting SMILES to graph: 18742/19709\n",
            "Converting SMILES to graph: 18743/19709\n",
            "Converting SMILES to graph: 18744/19709\n",
            "Converting SMILES to graph: 18745/19709\n",
            "Converting SMILES to graph: 18746/19709\n",
            "Converting SMILES to graph: 18747/19709\n",
            "Converting SMILES to graph: 18748/19709\n",
            "Converting SMILES to graph: 18749/19709\n",
            "Converting SMILES to graph: 18750/19709\n",
            "Converting SMILES to graph: 18751/19709\n",
            "Converting SMILES to graph: 18752/19709\n",
            "Converting SMILES to graph: 18753/19709\n",
            "Converting SMILES to graph: 18754/19709\n",
            "Converting SMILES to graph: 18755/19709\n",
            "Converting SMILES to graph: 18756/19709\n",
            "Converting SMILES to graph: 18757/19709\n",
            "Converting SMILES to graph: 18758/19709\n",
            "Converting SMILES to graph: 18759/19709\n",
            "Converting SMILES to graph: 18760/19709\n",
            "Converting SMILES to graph: 18761/19709\n",
            "Converting SMILES to graph: 18762/19709\n",
            "Converting SMILES to graph: 18763/19709\n",
            "Converting SMILES to graph: 18764/19709\n",
            "Converting SMILES to graph: 18765/19709\n",
            "Converting SMILES to graph: 18766/19709\n",
            "Converting SMILES to graph: 18767/19709\n",
            "Converting SMILES to graph: 18768/19709\n",
            "Converting SMILES to graph: 18769/19709\n",
            "Converting SMILES to graph: 18770/19709\n",
            "Converting SMILES to graph: 18771/19709\n",
            "Converting SMILES to graph: 18772/19709\n",
            "Converting SMILES to graph: 18773/19709\n",
            "Converting SMILES to graph: 18774/19709\n",
            "Converting SMILES to graph: 18775/19709\n",
            "Converting SMILES to graph: 18776/19709\n",
            "Converting SMILES to graph: 18777/19709\n",
            "Converting SMILES to graph: 18778/19709\n",
            "Converting SMILES to graph: 18779/19709\n",
            "Converting SMILES to graph: 18780/19709\n",
            "Converting SMILES to graph: 18781/19709\n",
            "Converting SMILES to graph: 18782/19709\n",
            "Converting SMILES to graph: 18783/19709\n",
            "Converting SMILES to graph: 18784/19709\n",
            "Converting SMILES to graph: 18785/19709\n",
            "Converting SMILES to graph: 18786/19709\n",
            "Converting SMILES to graph: 18787/19709\n",
            "Converting SMILES to graph: 18788/19709\n",
            "Converting SMILES to graph: 18789/19709\n",
            "Converting SMILES to graph: 18790/19709\n",
            "Converting SMILES to graph: 18791/19709\n",
            "Converting SMILES to graph: 18792/19709\n",
            "Converting SMILES to graph: 18793/19709\n",
            "Converting SMILES to graph: 18794/19709\n",
            "Converting SMILES to graph: 18795/19709\n",
            "Converting SMILES to graph: 18796/19709\n",
            "Converting SMILES to graph: 18797/19709\n",
            "Converting SMILES to graph: 18798/19709\n",
            "Converting SMILES to graph: 18799/19709\n",
            "Converting SMILES to graph: 18800/19709\n",
            "Converting SMILES to graph: 18801/19709\n",
            "Converting SMILES to graph: 18802/19709\n",
            "Converting SMILES to graph: 18803/19709\n",
            "Converting SMILES to graph: 18804/19709\n",
            "Converting SMILES to graph: 18805/19709\n",
            "Converting SMILES to graph: 18806/19709\n",
            "Converting SMILES to graph: 18807/19709\n",
            "Converting SMILES to graph: 18808/19709\n",
            "Converting SMILES to graph: 18809/19709\n",
            "Converting SMILES to graph: 18810/19709\n",
            "Converting SMILES to graph: 18811/19709\n",
            "Converting SMILES to graph: 18812/19709\n",
            "Converting SMILES to graph: 18813/19709\n",
            "Converting SMILES to graph: 18814/19709\n",
            "Converting SMILES to graph: 18815/19709\n",
            "Converting SMILES to graph: 18816/19709\n",
            "Converting SMILES to graph: 18817/19709\n",
            "Converting SMILES to graph: 18818/19709\n",
            "Converting SMILES to graph: 18819/19709\n",
            "Converting SMILES to graph: 18820/19709\n",
            "Converting SMILES to graph: 18821/19709\n",
            "Converting SMILES to graph: 18822/19709\n",
            "Converting SMILES to graph: 18823/19709\n",
            "Converting SMILES to graph: 18824/19709\n",
            "Converting SMILES to graph: 18825/19709\n",
            "Converting SMILES to graph: 18826/19709\n",
            "Converting SMILES to graph: 18827/19709\n",
            "Converting SMILES to graph: 18828/19709\n",
            "Converting SMILES to graph: 18829/19709\n",
            "Converting SMILES to graph: 18830/19709\n",
            "Converting SMILES to graph: 18831/19709\n",
            "Converting SMILES to graph: 18832/19709\n",
            "Converting SMILES to graph: 18833/19709\n",
            "Converting SMILES to graph: 18834/19709\n",
            "Converting SMILES to graph: 18835/19709\n",
            "Converting SMILES to graph: 18836/19709\n",
            "Converting SMILES to graph: 18837/19709\n",
            "Converting SMILES to graph: 18838/19709\n",
            "Converting SMILES to graph: 18839/19709\n",
            "Converting SMILES to graph: 18840/19709\n",
            "Converting SMILES to graph: 18841/19709\n",
            "Converting SMILES to graph: 18842/19709\n",
            "Converting SMILES to graph: 18843/19709\n",
            "Converting SMILES to graph: 18844/19709\n",
            "Converting SMILES to graph: 18845/19709\n",
            "Converting SMILES to graph: 18846/19709\n",
            "Converting SMILES to graph: 18847/19709\n",
            "Converting SMILES to graph: 18848/19709\n",
            "Converting SMILES to graph: 18849/19709\n",
            "Converting SMILES to graph: 18850/19709\n",
            "Converting SMILES to graph: 18851/19709\n",
            "Converting SMILES to graph: 18852/19709\n",
            "Converting SMILES to graph: 18853/19709\n",
            "Converting SMILES to graph: 18854/19709\n",
            "Converting SMILES to graph: 18855/19709\n",
            "Converting SMILES to graph: 18856/19709\n",
            "Converting SMILES to graph: 18857/19709\n",
            "Converting SMILES to graph: 18858/19709\n",
            "Converting SMILES to graph: 18859/19709\n",
            "Converting SMILES to graph: 18860/19709\n",
            "Converting SMILES to graph: 18861/19709\n",
            "Converting SMILES to graph: 18862/19709\n",
            "Converting SMILES to graph: 18863/19709\n",
            "Converting SMILES to graph: 18864/19709\n",
            "Converting SMILES to graph: 18865/19709\n",
            "Converting SMILES to graph: 18866/19709\n",
            "Converting SMILES to graph: 18867/19709\n",
            "Converting SMILES to graph: 18868/19709\n",
            "Converting SMILES to graph: 18869/19709\n",
            "Converting SMILES to graph: 18870/19709\n",
            "Converting SMILES to graph: 18871/19709\n",
            "Converting SMILES to graph: 18872/19709\n",
            "Converting SMILES to graph: 18873/19709\n",
            "Converting SMILES to graph: 18874/19709\n",
            "Converting SMILES to graph: 18875/19709\n",
            "Converting SMILES to graph: 18876/19709\n",
            "Converting SMILES to graph: 18877/19709\n",
            "Converting SMILES to graph: 18878/19709\n",
            "Converting SMILES to graph: 18879/19709\n",
            "Converting SMILES to graph: 18880/19709\n",
            "Converting SMILES to graph: 18881/19709\n",
            "Converting SMILES to graph: 18882/19709\n",
            "Converting SMILES to graph: 18883/19709\n",
            "Converting SMILES to graph: 18884/19709\n",
            "Converting SMILES to graph: 18885/19709\n",
            "Converting SMILES to graph: 18886/19709\n",
            "Converting SMILES to graph: 18887/19709\n",
            "Converting SMILES to graph: 18888/19709\n",
            "Converting SMILES to graph: 18889/19709\n",
            "Converting SMILES to graph: 18890/19709\n",
            "Converting SMILES to graph: 18891/19709\n",
            "Converting SMILES to graph: 18892/19709\n",
            "Converting SMILES to graph: 18893/19709\n",
            "Converting SMILES to graph: 18894/19709\n",
            "Converting SMILES to graph: 18895/19709\n",
            "Converting SMILES to graph: 18896/19709\n",
            "Converting SMILES to graph: 18897/19709\n",
            "Converting SMILES to graph: 18898/19709\n",
            "Converting SMILES to graph: 18899/19709\n",
            "Converting SMILES to graph: 18900/19709\n",
            "Converting SMILES to graph: 18901/19709\n",
            "Converting SMILES to graph: 18902/19709\n",
            "Converting SMILES to graph: 18903/19709\n",
            "Converting SMILES to graph: 18904/19709\n",
            "Converting SMILES to graph: 18905/19709\n",
            "Converting SMILES to graph: 18906/19709\n",
            "Converting SMILES to graph: 18907/19709\n",
            "Converting SMILES to graph: 18908/19709\n",
            "Converting SMILES to graph: 18909/19709\n",
            "Converting SMILES to graph: 18910/19709\n",
            "Converting SMILES to graph: 18911/19709\n",
            "Converting SMILES to graph: 18912/19709\n",
            "Converting SMILES to graph: 18913/19709\n",
            "Converting SMILES to graph: 18914/19709\n",
            "Converting SMILES to graph: 18915/19709\n",
            "Converting SMILES to graph: 18916/19709\n",
            "Converting SMILES to graph: 18917/19709\n",
            "Converting SMILES to graph: 18918/19709\n",
            "Converting SMILES to graph: 18919/19709\n",
            "Converting SMILES to graph: 18920/19709\n",
            "Converting SMILES to graph: 18921/19709\n",
            "Converting SMILES to graph: 18922/19709\n",
            "Converting SMILES to graph: 18923/19709\n",
            "Converting SMILES to graph: 18924/19709\n",
            "Converting SMILES to graph: 18925/19709\n",
            "Converting SMILES to graph: 18926/19709\n",
            "Converting SMILES to graph: 18927/19709\n",
            "Converting SMILES to graph: 18928/19709\n",
            "Converting SMILES to graph: 18929/19709\n",
            "Converting SMILES to graph: 18930/19709\n",
            "Converting SMILES to graph: 18931/19709\n",
            "Converting SMILES to graph: 18932/19709\n",
            "Converting SMILES to graph: 18933/19709\n",
            "Converting SMILES to graph: 18934/19709\n",
            "Converting SMILES to graph: 18935/19709\n",
            "Converting SMILES to graph: 18936/19709\n",
            "Converting SMILES to graph: 18937/19709\n",
            "Converting SMILES to graph: 18938/19709\n",
            "Converting SMILES to graph: 18939/19709\n",
            "Converting SMILES to graph: 18940/19709\n",
            "Converting SMILES to graph: 18941/19709\n",
            "Converting SMILES to graph: 18942/19709\n",
            "Converting SMILES to graph: 18943/19709\n",
            "Converting SMILES to graph: 18944/19709\n",
            "Converting SMILES to graph: 18945/19709\n",
            "Converting SMILES to graph: 18946/19709\n",
            "Converting SMILES to graph: 18947/19709\n",
            "Converting SMILES to graph: 18948/19709\n",
            "Converting SMILES to graph: 18949/19709\n",
            "Converting SMILES to graph: 18950/19709\n",
            "Converting SMILES to graph: 18951/19709\n",
            "Converting SMILES to graph: 18952/19709\n",
            "Converting SMILES to graph: 18953/19709\n",
            "Converting SMILES to graph: 18954/19709\n",
            "Converting SMILES to graph: 18955/19709\n",
            "Converting SMILES to graph: 18956/19709\n",
            "Converting SMILES to graph: 18957/19709\n",
            "Converting SMILES to graph: 18958/19709\n",
            "Converting SMILES to graph: 18959/19709\n",
            "Converting SMILES to graph: 18960/19709\n",
            "Converting SMILES to graph: 18961/19709\n",
            "Converting SMILES to graph: 18962/19709\n",
            "Converting SMILES to graph: 18963/19709\n",
            "Converting SMILES to graph: 18964/19709\n",
            "Converting SMILES to graph: 18965/19709\n",
            "Converting SMILES to graph: 18966/19709\n",
            "Converting SMILES to graph: 18967/19709\n",
            "Converting SMILES to graph: 18968/19709\n",
            "Converting SMILES to graph: 18969/19709\n",
            "Converting SMILES to graph: 18970/19709\n",
            "Converting SMILES to graph: 18971/19709\n",
            "Converting SMILES to graph: 18972/19709\n",
            "Converting SMILES to graph: 18973/19709\n",
            "Converting SMILES to graph: 18974/19709\n",
            "Converting SMILES to graph: 18975/19709\n",
            "Converting SMILES to graph: 18976/19709\n",
            "Converting SMILES to graph: 18977/19709\n",
            "Converting SMILES to graph: 18978/19709\n",
            "Converting SMILES to graph: 18979/19709\n",
            "Converting SMILES to graph: 18980/19709\n",
            "Converting SMILES to graph: 18981/19709\n",
            "Converting SMILES to graph: 18982/19709\n",
            "Converting SMILES to graph: 18983/19709\n",
            "Converting SMILES to graph: 18984/19709\n",
            "Converting SMILES to graph: 18985/19709\n",
            "Converting SMILES to graph: 18986/19709\n",
            "Converting SMILES to graph: 18987/19709\n",
            "Converting SMILES to graph: 18988/19709\n",
            "Converting SMILES to graph: 18989/19709\n",
            "Converting SMILES to graph: 18990/19709\n",
            "Converting SMILES to graph: 18991/19709\n",
            "Converting SMILES to graph: 18992/19709\n",
            "Converting SMILES to graph: 18993/19709\n",
            "Converting SMILES to graph: 18994/19709\n",
            "Converting SMILES to graph: 18995/19709\n",
            "Converting SMILES to graph: 18996/19709\n",
            "Converting SMILES to graph: 18997/19709\n",
            "Converting SMILES to graph: 18998/19709\n",
            "Converting SMILES to graph: 18999/19709\n",
            "Converting SMILES to graph: 19000/19709\n",
            "Converting SMILES to graph: 19001/19709\n",
            "Converting SMILES to graph: 19002/19709\n",
            "Converting SMILES to graph: 19003/19709\n",
            "Converting SMILES to graph: 19004/19709\n",
            "Converting SMILES to graph: 19005/19709\n",
            "Converting SMILES to graph: 19006/19709\n",
            "Converting SMILES to graph: 19007/19709\n",
            "Converting SMILES to graph: 19008/19709\n",
            "Converting SMILES to graph: 19009/19709\n",
            "Converting SMILES to graph: 19010/19709\n",
            "Converting SMILES to graph: 19011/19709\n",
            "Converting SMILES to graph: 19012/19709\n",
            "Converting SMILES to graph: 19013/19709\n",
            "Converting SMILES to graph: 19014/19709\n",
            "Converting SMILES to graph: 19015/19709\n",
            "Converting SMILES to graph: 19016/19709\n",
            "Converting SMILES to graph: 19017/19709\n",
            "Converting SMILES to graph: 19018/19709\n",
            "Converting SMILES to graph: 19019/19709\n",
            "Converting SMILES to graph: 19020/19709\n",
            "Converting SMILES to graph: 19021/19709\n",
            "Converting SMILES to graph: 19022/19709\n",
            "Converting SMILES to graph: 19023/19709\n",
            "Converting SMILES to graph: 19024/19709\n",
            "Converting SMILES to graph: 19025/19709\n",
            "Converting SMILES to graph: 19026/19709\n",
            "Converting SMILES to graph: 19027/19709\n",
            "Converting SMILES to graph: 19028/19709\n",
            "Converting SMILES to graph: 19029/19709\n",
            "Converting SMILES to graph: 19030/19709\n",
            "Converting SMILES to graph: 19031/19709\n",
            "Converting SMILES to graph: 19032/19709\n",
            "Converting SMILES to graph: 19033/19709\n",
            "Converting SMILES to graph: 19034/19709\n",
            "Converting SMILES to graph: 19035/19709\n",
            "Converting SMILES to graph: 19036/19709\n",
            "Converting SMILES to graph: 19037/19709\n",
            "Converting SMILES to graph: 19038/19709\n",
            "Converting SMILES to graph: 19039/19709\n",
            "Converting SMILES to graph: 19040/19709\n",
            "Converting SMILES to graph: 19041/19709\n",
            "Converting SMILES to graph: 19042/19709\n",
            "Converting SMILES to graph: 19043/19709\n",
            "Converting SMILES to graph: 19044/19709\n",
            "Converting SMILES to graph: 19045/19709\n",
            "Converting SMILES to graph: 19046/19709\n",
            "Converting SMILES to graph: 19047/19709\n",
            "Converting SMILES to graph: 19048/19709\n",
            "Converting SMILES to graph: 19049/19709\n",
            "Converting SMILES to graph: 19050/19709\n",
            "Converting SMILES to graph: 19051/19709\n",
            "Converting SMILES to graph: 19052/19709\n",
            "Converting SMILES to graph: 19053/19709\n",
            "Converting SMILES to graph: 19054/19709\n",
            "Converting SMILES to graph: 19055/19709\n",
            "Converting SMILES to graph: 19056/19709\n",
            "Converting SMILES to graph: 19057/19709\n",
            "Converting SMILES to graph: 19058/19709\n",
            "Converting SMILES to graph: 19059/19709\n",
            "Converting SMILES to graph: 19060/19709\n",
            "Converting SMILES to graph: 19061/19709\n",
            "Converting SMILES to graph: 19062/19709\n",
            "Converting SMILES to graph: 19063/19709\n",
            "Converting SMILES to graph: 19064/19709\n",
            "Converting SMILES to graph: 19065/19709\n",
            "Converting SMILES to graph: 19066/19709\n",
            "Converting SMILES to graph: 19067/19709\n",
            "Converting SMILES to graph: 19068/19709\n",
            "Converting SMILES to graph: 19069/19709\n",
            "Converting SMILES to graph: 19070/19709\n",
            "Converting SMILES to graph: 19071/19709\n",
            "Converting SMILES to graph: 19072/19709\n",
            "Converting SMILES to graph: 19073/19709\n",
            "Converting SMILES to graph: 19074/19709\n",
            "Converting SMILES to graph: 19075/19709\n",
            "Converting SMILES to graph: 19076/19709\n",
            "Converting SMILES to graph: 19077/19709\n",
            "Converting SMILES to graph: 19078/19709\n",
            "Converting SMILES to graph: 19079/19709\n",
            "Converting SMILES to graph: 19080/19709\n",
            "Converting SMILES to graph: 19081/19709\n",
            "Converting SMILES to graph: 19082/19709\n",
            "Converting SMILES to graph: 19083/19709\n",
            "Converting SMILES to graph: 19084/19709\n",
            "Converting SMILES to graph: 19085/19709\n",
            "Converting SMILES to graph: 19086/19709\n",
            "Converting SMILES to graph: 19087/19709\n",
            "Converting SMILES to graph: 19088/19709\n",
            "Converting SMILES to graph: 19089/19709\n",
            "Converting SMILES to graph: 19090/19709\n",
            "Converting SMILES to graph: 19091/19709\n",
            "Converting SMILES to graph: 19092/19709\n",
            "Converting SMILES to graph: 19093/19709\n",
            "Converting SMILES to graph: 19094/19709\n",
            "Converting SMILES to graph: 19095/19709\n",
            "Converting SMILES to graph: 19096/19709\n",
            "Converting SMILES to graph: 19097/19709\n",
            "Converting SMILES to graph: 19098/19709\n",
            "Converting SMILES to graph: 19099/19709\n",
            "Converting SMILES to graph: 19100/19709\n",
            "Converting SMILES to graph: 19101/19709\n",
            "Converting SMILES to graph: 19102/19709\n",
            "Converting SMILES to graph: 19103/19709\n",
            "Converting SMILES to graph: 19104/19709\n",
            "Converting SMILES to graph: 19105/19709\n",
            "Converting SMILES to graph: 19106/19709\n",
            "Converting SMILES to graph: 19107/19709\n",
            "Converting SMILES to graph: 19108/19709\n",
            "Converting SMILES to graph: 19109/19709\n",
            "Converting SMILES to graph: 19110/19709\n",
            "Converting SMILES to graph: 19111/19709\n",
            "Converting SMILES to graph: 19112/19709\n",
            "Converting SMILES to graph: 19113/19709\n",
            "Converting SMILES to graph: 19114/19709\n",
            "Converting SMILES to graph: 19115/19709\n",
            "Converting SMILES to graph: 19116/19709\n",
            "Converting SMILES to graph: 19117/19709\n",
            "Converting SMILES to graph: 19118/19709\n",
            "Converting SMILES to graph: 19119/19709\n",
            "Converting SMILES to graph: 19120/19709\n",
            "Converting SMILES to graph: 19121/19709\n",
            "Converting SMILES to graph: 19122/19709\n",
            "Converting SMILES to graph: 19123/19709\n",
            "Converting SMILES to graph: 19124/19709\n",
            "Converting SMILES to graph: 19125/19709\n",
            "Converting SMILES to graph: 19126/19709\n",
            "Converting SMILES to graph: 19127/19709\n",
            "Converting SMILES to graph: 19128/19709\n",
            "Converting SMILES to graph: 19129/19709\n",
            "Converting SMILES to graph: 19130/19709\n",
            "Converting SMILES to graph: 19131/19709\n",
            "Converting SMILES to graph: 19132/19709\n",
            "Converting SMILES to graph: 19133/19709\n",
            "Converting SMILES to graph: 19134/19709\n",
            "Converting SMILES to graph: 19135/19709\n",
            "Converting SMILES to graph: 19136/19709\n",
            "Converting SMILES to graph: 19137/19709\n",
            "Converting SMILES to graph: 19138/19709\n",
            "Converting SMILES to graph: 19139/19709\n",
            "Converting SMILES to graph: 19140/19709\n",
            "Converting SMILES to graph: 19141/19709\n",
            "Converting SMILES to graph: 19142/19709\n",
            "Converting SMILES to graph: 19143/19709\n",
            "Converting SMILES to graph: 19144/19709\n",
            "Converting SMILES to graph: 19145/19709\n",
            "Converting SMILES to graph: 19146/19709\n",
            "Converting SMILES to graph: 19147/19709\n",
            "Converting SMILES to graph: 19148/19709\n",
            "Converting SMILES to graph: 19149/19709\n",
            "Converting SMILES to graph: 19150/19709\n",
            "Converting SMILES to graph: 19151/19709\n",
            "Converting SMILES to graph: 19152/19709\n",
            "Converting SMILES to graph: 19153/19709\n",
            "Converting SMILES to graph: 19154/19709\n",
            "Converting SMILES to graph: 19155/19709\n",
            "Converting SMILES to graph: 19156/19709\n",
            "Converting SMILES to graph: 19157/19709\n",
            "Converting SMILES to graph: 19158/19709\n",
            "Converting SMILES to graph: 19159/19709\n",
            "Converting SMILES to graph: 19160/19709\n",
            "Converting SMILES to graph: 19161/19709\n",
            "Converting SMILES to graph: 19162/19709\n",
            "Converting SMILES to graph: 19163/19709\n",
            "Converting SMILES to graph: 19164/19709\n",
            "Converting SMILES to graph: 19165/19709\n",
            "Converting SMILES to graph: 19166/19709\n",
            "Converting SMILES to graph: 19167/19709\n",
            "Converting SMILES to graph: 19168/19709\n",
            "Converting SMILES to graph: 19169/19709\n",
            "Converting SMILES to graph: 19170/19709\n",
            "Converting SMILES to graph: 19171/19709\n",
            "Converting SMILES to graph: 19172/19709\n",
            "Converting SMILES to graph: 19173/19709\n",
            "Converting SMILES to graph: 19174/19709\n",
            "Converting SMILES to graph: 19175/19709\n",
            "Converting SMILES to graph: 19176/19709\n",
            "Converting SMILES to graph: 19177/19709\n",
            "Converting SMILES to graph: 19178/19709\n",
            "Converting SMILES to graph: 19179/19709\n",
            "Converting SMILES to graph: 19180/19709\n",
            "Converting SMILES to graph: 19181/19709\n",
            "Converting SMILES to graph: 19182/19709\n",
            "Converting SMILES to graph: 19183/19709\n",
            "Converting SMILES to graph: 19184/19709\n",
            "Converting SMILES to graph: 19185/19709\n",
            "Converting SMILES to graph: 19186/19709\n",
            "Converting SMILES to graph: 19187/19709\n",
            "Converting SMILES to graph: 19188/19709\n",
            "Converting SMILES to graph: 19189/19709\n",
            "Converting SMILES to graph: 19190/19709\n",
            "Converting SMILES to graph: 19191/19709\n",
            "Converting SMILES to graph: 19192/19709\n",
            "Converting SMILES to graph: 19193/19709\n",
            "Converting SMILES to graph: 19194/19709\n",
            "Converting SMILES to graph: 19195/19709\n",
            "Converting SMILES to graph: 19196/19709\n",
            "Converting SMILES to graph: 19197/19709\n",
            "Converting SMILES to graph: 19198/19709\n",
            "Converting SMILES to graph: 19199/19709\n",
            "Converting SMILES to graph: 19200/19709\n",
            "Converting SMILES to graph: 19201/19709\n",
            "Converting SMILES to graph: 19202/19709\n",
            "Converting SMILES to graph: 19203/19709\n",
            "Converting SMILES to graph: 19204/19709\n",
            "Converting SMILES to graph: 19205/19709\n",
            "Converting SMILES to graph: 19206/19709\n",
            "Converting SMILES to graph: 19207/19709\n",
            "Converting SMILES to graph: 19208/19709\n",
            "Converting SMILES to graph: 19209/19709\n",
            "Converting SMILES to graph: 19210/19709\n",
            "Converting SMILES to graph: 19211/19709\n",
            "Converting SMILES to graph: 19212/19709\n",
            "Converting SMILES to graph: 19213/19709\n",
            "Converting SMILES to graph: 19214/19709\n",
            "Converting SMILES to graph: 19215/19709\n",
            "Converting SMILES to graph: 19216/19709\n",
            "Converting SMILES to graph: 19217/19709\n",
            "Converting SMILES to graph: 19218/19709\n",
            "Converting SMILES to graph: 19219/19709\n",
            "Converting SMILES to graph: 19220/19709\n",
            "Converting SMILES to graph: 19221/19709\n",
            "Converting SMILES to graph: 19222/19709\n",
            "Converting SMILES to graph: 19223/19709\n",
            "Converting SMILES to graph: 19224/19709\n",
            "Converting SMILES to graph: 19225/19709\n",
            "Converting SMILES to graph: 19226/19709\n",
            "Converting SMILES to graph: 19227/19709\n",
            "Converting SMILES to graph: 19228/19709\n",
            "Converting SMILES to graph: 19229/19709\n",
            "Converting SMILES to graph: 19230/19709\n",
            "Converting SMILES to graph: 19231/19709\n",
            "Converting SMILES to graph: 19232/19709\n",
            "Converting SMILES to graph: 19233/19709\n",
            "Converting SMILES to graph: 19234/19709\n",
            "Converting SMILES to graph: 19235/19709\n",
            "Converting SMILES to graph: 19236/19709\n",
            "Converting SMILES to graph: 19237/19709\n",
            "Converting SMILES to graph: 19238/19709\n",
            "Converting SMILES to graph: 19239/19709\n",
            "Converting SMILES to graph: 19240/19709\n",
            "Converting SMILES to graph: 19241/19709\n",
            "Converting SMILES to graph: 19242/19709\n",
            "Converting SMILES to graph: 19243/19709\n",
            "Converting SMILES to graph: 19244/19709\n",
            "Converting SMILES to graph: 19245/19709\n",
            "Converting SMILES to graph: 19246/19709\n",
            "Converting SMILES to graph: 19247/19709\n",
            "Converting SMILES to graph: 19248/19709\n",
            "Converting SMILES to graph: 19249/19709\n",
            "Converting SMILES to graph: 19250/19709\n",
            "Converting SMILES to graph: 19251/19709\n",
            "Converting SMILES to graph: 19252/19709\n",
            "Converting SMILES to graph: 19253/19709\n",
            "Converting SMILES to graph: 19254/19709\n",
            "Converting SMILES to graph: 19255/19709\n",
            "Converting SMILES to graph: 19256/19709\n",
            "Converting SMILES to graph: 19257/19709\n",
            "Converting SMILES to graph: 19258/19709\n",
            "Converting SMILES to graph: 19259/19709\n",
            "Converting SMILES to graph: 19260/19709\n",
            "Converting SMILES to graph: 19261/19709\n",
            "Converting SMILES to graph: 19262/19709\n",
            "Converting SMILES to graph: 19263/19709\n",
            "Converting SMILES to graph: 19264/19709\n",
            "Converting SMILES to graph: 19265/19709\n",
            "Converting SMILES to graph: 19266/19709\n",
            "Converting SMILES to graph: 19267/19709\n",
            "Converting SMILES to graph: 19268/19709\n",
            "Converting SMILES to graph: 19269/19709\n",
            "Converting SMILES to graph: 19270/19709\n",
            "Converting SMILES to graph: 19271/19709\n",
            "Converting SMILES to graph: 19272/19709\n",
            "Converting SMILES to graph: 19273/19709\n",
            "Converting SMILES to graph: 19274/19709\n",
            "Converting SMILES to graph: 19275/19709\n",
            "Converting SMILES to graph: 19276/19709\n",
            "Converting SMILES to graph: 19277/19709\n",
            "Converting SMILES to graph: 19278/19709\n",
            "Converting SMILES to graph: 19279/19709\n",
            "Converting SMILES to graph: 19280/19709\n",
            "Converting SMILES to graph: 19281/19709\n",
            "Converting SMILES to graph: 19282/19709\n",
            "Converting SMILES to graph: 19283/19709\n",
            "Converting SMILES to graph: 19284/19709\n",
            "Converting SMILES to graph: 19285/19709\n",
            "Converting SMILES to graph: 19286/19709\n",
            "Converting SMILES to graph: 19287/19709\n",
            "Converting SMILES to graph: 19288/19709\n",
            "Converting SMILES to graph: 19289/19709\n",
            "Converting SMILES to graph: 19290/19709\n",
            "Converting SMILES to graph: 19291/19709\n",
            "Converting SMILES to graph: 19292/19709\n",
            "Converting SMILES to graph: 19293/19709\n",
            "Converting SMILES to graph: 19294/19709\n",
            "Converting SMILES to graph: 19295/19709\n",
            "Converting SMILES to graph: 19296/19709\n",
            "Converting SMILES to graph: 19297/19709\n",
            "Converting SMILES to graph: 19298/19709\n",
            "Converting SMILES to graph: 19299/19709\n",
            "Converting SMILES to graph: 19300/19709\n",
            "Converting SMILES to graph: 19301/19709\n",
            "Converting SMILES to graph: 19302/19709\n",
            "Converting SMILES to graph: 19303/19709\n",
            "Converting SMILES to graph: 19304/19709\n",
            "Converting SMILES to graph: 19305/19709\n",
            "Converting SMILES to graph: 19306/19709\n",
            "Converting SMILES to graph: 19307/19709\n",
            "Converting SMILES to graph: 19308/19709\n",
            "Converting SMILES to graph: 19309/19709\n",
            "Converting SMILES to graph: 19310/19709\n",
            "Converting SMILES to graph: 19311/19709\n",
            "Converting SMILES to graph: 19312/19709\n",
            "Converting SMILES to graph: 19313/19709\n",
            "Converting SMILES to graph: 19314/19709\n",
            "Converting SMILES to graph: 19315/19709\n",
            "Converting SMILES to graph: 19316/19709\n",
            "Converting SMILES to graph: 19317/19709\n",
            "Converting SMILES to graph: 19318/19709\n",
            "Converting SMILES to graph: 19319/19709\n",
            "Converting SMILES to graph: 19320/19709\n",
            "Converting SMILES to graph: 19321/19709\n",
            "Converting SMILES to graph: 19322/19709\n",
            "Converting SMILES to graph: 19323/19709\n",
            "Converting SMILES to graph: 19324/19709\n",
            "Converting SMILES to graph: 19325/19709\n",
            "Converting SMILES to graph: 19326/19709\n",
            "Converting SMILES to graph: 19327/19709\n",
            "Converting SMILES to graph: 19328/19709\n",
            "Converting SMILES to graph: 19329/19709\n",
            "Converting SMILES to graph: 19330/19709\n",
            "Converting SMILES to graph: 19331/19709\n",
            "Converting SMILES to graph: 19332/19709\n",
            "Converting SMILES to graph: 19333/19709\n",
            "Converting SMILES to graph: 19334/19709\n",
            "Converting SMILES to graph: 19335/19709\n",
            "Converting SMILES to graph: 19336/19709\n",
            "Converting SMILES to graph: 19337/19709\n",
            "Converting SMILES to graph: 19338/19709\n",
            "Converting SMILES to graph: 19339/19709\n",
            "Converting SMILES to graph: 19340/19709\n",
            "Converting SMILES to graph: 19341/19709\n",
            "Converting SMILES to graph: 19342/19709\n",
            "Converting SMILES to graph: 19343/19709\n",
            "Converting SMILES to graph: 19344/19709\n",
            "Converting SMILES to graph: 19345/19709\n",
            "Converting SMILES to graph: 19346/19709\n",
            "Converting SMILES to graph: 19347/19709\n",
            "Converting SMILES to graph: 19348/19709\n",
            "Converting SMILES to graph: 19349/19709\n",
            "Converting SMILES to graph: 19350/19709\n",
            "Converting SMILES to graph: 19351/19709\n",
            "Converting SMILES to graph: 19352/19709\n",
            "Converting SMILES to graph: 19353/19709\n",
            "Converting SMILES to graph: 19354/19709\n",
            "Converting SMILES to graph: 19355/19709\n",
            "Converting SMILES to graph: 19356/19709\n",
            "Converting SMILES to graph: 19357/19709\n",
            "Converting SMILES to graph: 19358/19709\n",
            "Converting SMILES to graph: 19359/19709\n",
            "Converting SMILES to graph: 19360/19709\n",
            "Converting SMILES to graph: 19361/19709\n",
            "Converting SMILES to graph: 19362/19709\n",
            "Converting SMILES to graph: 19363/19709\n",
            "Converting SMILES to graph: 19364/19709\n",
            "Converting SMILES to graph: 19365/19709\n",
            "Converting SMILES to graph: 19366/19709\n",
            "Converting SMILES to graph: 19367/19709\n",
            "Converting SMILES to graph: 19368/19709\n",
            "Converting SMILES to graph: 19369/19709\n",
            "Converting SMILES to graph: 19370/19709\n",
            "Converting SMILES to graph: 19371/19709\n",
            "Converting SMILES to graph: 19372/19709\n",
            "Converting SMILES to graph: 19373/19709\n",
            "Converting SMILES to graph: 19374/19709\n",
            "Converting SMILES to graph: 19375/19709\n",
            "Converting SMILES to graph: 19376/19709\n",
            "Converting SMILES to graph: 19377/19709\n",
            "Converting SMILES to graph: 19378/19709\n",
            "Converting SMILES to graph: 19379/19709\n",
            "Converting SMILES to graph: 19380/19709\n",
            "Converting SMILES to graph: 19381/19709\n",
            "Converting SMILES to graph: 19382/19709\n",
            "Converting SMILES to graph: 19383/19709\n",
            "Converting SMILES to graph: 19384/19709\n",
            "Converting SMILES to graph: 19385/19709\n",
            "Converting SMILES to graph: 19386/19709\n",
            "Converting SMILES to graph: 19387/19709\n",
            "Converting SMILES to graph: 19388/19709\n",
            "Converting SMILES to graph: 19389/19709\n",
            "Converting SMILES to graph: 19390/19709\n",
            "Converting SMILES to graph: 19391/19709\n",
            "Converting SMILES to graph: 19392/19709\n",
            "Converting SMILES to graph: 19393/19709\n",
            "Converting SMILES to graph: 19394/19709\n",
            "Converting SMILES to graph: 19395/19709\n",
            "Converting SMILES to graph: 19396/19709\n",
            "Converting SMILES to graph: 19397/19709\n",
            "Converting SMILES to graph: 19398/19709\n",
            "Converting SMILES to graph: 19399/19709\n",
            "Converting SMILES to graph: 19400/19709\n",
            "Converting SMILES to graph: 19401/19709\n",
            "Converting SMILES to graph: 19402/19709\n",
            "Converting SMILES to graph: 19403/19709\n",
            "Converting SMILES to graph: 19404/19709\n",
            "Converting SMILES to graph: 19405/19709\n",
            "Converting SMILES to graph: 19406/19709\n",
            "Converting SMILES to graph: 19407/19709\n",
            "Converting SMILES to graph: 19408/19709\n",
            "Converting SMILES to graph: 19409/19709\n",
            "Converting SMILES to graph: 19410/19709\n",
            "Converting SMILES to graph: 19411/19709\n",
            "Converting SMILES to graph: 19412/19709\n",
            "Converting SMILES to graph: 19413/19709\n",
            "Converting SMILES to graph: 19414/19709\n",
            "Converting SMILES to graph: 19415/19709\n",
            "Converting SMILES to graph: 19416/19709\n",
            "Converting SMILES to graph: 19417/19709\n",
            "Converting SMILES to graph: 19418/19709\n",
            "Converting SMILES to graph: 19419/19709\n",
            "Converting SMILES to graph: 19420/19709\n",
            "Converting SMILES to graph: 19421/19709\n",
            "Converting SMILES to graph: 19422/19709\n",
            "Converting SMILES to graph: 19423/19709\n",
            "Converting SMILES to graph: 19424/19709\n",
            "Converting SMILES to graph: 19425/19709\n",
            "Converting SMILES to graph: 19426/19709\n",
            "Converting SMILES to graph: 19427/19709\n",
            "Converting SMILES to graph: 19428/19709\n",
            "Converting SMILES to graph: 19429/19709\n",
            "Converting SMILES to graph: 19430/19709\n",
            "Converting SMILES to graph: 19431/19709\n",
            "Converting SMILES to graph: 19432/19709\n",
            "Converting SMILES to graph: 19433/19709\n",
            "Converting SMILES to graph: 19434/19709\n",
            "Converting SMILES to graph: 19435/19709\n",
            "Converting SMILES to graph: 19436/19709\n",
            "Converting SMILES to graph: 19437/19709\n",
            "Converting SMILES to graph: 19438/19709\n",
            "Converting SMILES to graph: 19439/19709\n",
            "Converting SMILES to graph: 19440/19709\n",
            "Converting SMILES to graph: 19441/19709\n",
            "Converting SMILES to graph: 19442/19709\n",
            "Converting SMILES to graph: 19443/19709\n",
            "Converting SMILES to graph: 19444/19709\n",
            "Converting SMILES to graph: 19445/19709\n",
            "Converting SMILES to graph: 19446/19709\n",
            "Converting SMILES to graph: 19447/19709\n",
            "Converting SMILES to graph: 19448/19709\n",
            "Converting SMILES to graph: 19449/19709\n",
            "Converting SMILES to graph: 19450/19709\n",
            "Converting SMILES to graph: 19451/19709\n",
            "Converting SMILES to graph: 19452/19709\n",
            "Converting SMILES to graph: 19453/19709\n",
            "Converting SMILES to graph: 19454/19709\n",
            "Converting SMILES to graph: 19455/19709\n",
            "Converting SMILES to graph: 19456/19709\n",
            "Converting SMILES to graph: 19457/19709\n",
            "Converting SMILES to graph: 19458/19709\n",
            "Converting SMILES to graph: 19459/19709\n",
            "Converting SMILES to graph: 19460/19709\n",
            "Converting SMILES to graph: 19461/19709\n",
            "Converting SMILES to graph: 19462/19709\n",
            "Converting SMILES to graph: 19463/19709\n",
            "Converting SMILES to graph: 19464/19709\n",
            "Converting SMILES to graph: 19465/19709\n",
            "Converting SMILES to graph: 19466/19709\n",
            "Converting SMILES to graph: 19467/19709\n",
            "Converting SMILES to graph: 19468/19709\n",
            "Converting SMILES to graph: 19469/19709\n",
            "Converting SMILES to graph: 19470/19709\n",
            "Converting SMILES to graph: 19471/19709\n",
            "Converting SMILES to graph: 19472/19709\n",
            "Converting SMILES to graph: 19473/19709\n",
            "Converting SMILES to graph: 19474/19709\n",
            "Converting SMILES to graph: 19475/19709\n",
            "Converting SMILES to graph: 19476/19709\n",
            "Converting SMILES to graph: 19477/19709\n",
            "Converting SMILES to graph: 19478/19709\n",
            "Converting SMILES to graph: 19479/19709\n",
            "Converting SMILES to graph: 19480/19709\n",
            "Converting SMILES to graph: 19481/19709\n",
            "Converting SMILES to graph: 19482/19709\n",
            "Converting SMILES to graph: 19483/19709\n",
            "Converting SMILES to graph: 19484/19709\n",
            "Converting SMILES to graph: 19485/19709\n",
            "Converting SMILES to graph: 19486/19709\n",
            "Converting SMILES to graph: 19487/19709\n",
            "Converting SMILES to graph: 19488/19709\n",
            "Converting SMILES to graph: 19489/19709\n",
            "Converting SMILES to graph: 19490/19709\n",
            "Converting SMILES to graph: 19491/19709\n",
            "Converting SMILES to graph: 19492/19709\n",
            "Converting SMILES to graph: 19493/19709\n",
            "Converting SMILES to graph: 19494/19709\n",
            "Converting SMILES to graph: 19495/19709\n",
            "Converting SMILES to graph: 19496/19709\n",
            "Converting SMILES to graph: 19497/19709\n",
            "Converting SMILES to graph: 19498/19709\n",
            "Converting SMILES to graph: 19499/19709\n",
            "Converting SMILES to graph: 19500/19709\n",
            "Converting SMILES to graph: 19501/19709\n",
            "Converting SMILES to graph: 19502/19709\n",
            "Converting SMILES to graph: 19503/19709\n",
            "Converting SMILES to graph: 19504/19709\n",
            "Converting SMILES to graph: 19505/19709\n",
            "Converting SMILES to graph: 19506/19709\n",
            "Converting SMILES to graph: 19507/19709\n",
            "Converting SMILES to graph: 19508/19709\n",
            "Converting SMILES to graph: 19509/19709\n",
            "Converting SMILES to graph: 19510/19709\n",
            "Converting SMILES to graph: 19511/19709\n",
            "Converting SMILES to graph: 19512/19709\n",
            "Converting SMILES to graph: 19513/19709\n",
            "Converting SMILES to graph: 19514/19709\n",
            "Converting SMILES to graph: 19515/19709\n",
            "Converting SMILES to graph: 19516/19709\n",
            "Converting SMILES to graph: 19517/19709\n",
            "Converting SMILES to graph: 19518/19709\n",
            "Converting SMILES to graph: 19519/19709\n",
            "Converting SMILES to graph: 19520/19709\n",
            "Converting SMILES to graph: 19521/19709\n",
            "Converting SMILES to graph: 19522/19709\n",
            "Converting SMILES to graph: 19523/19709\n",
            "Converting SMILES to graph: 19524/19709\n",
            "Converting SMILES to graph: 19525/19709\n",
            "Converting SMILES to graph: 19526/19709\n",
            "Converting SMILES to graph: 19527/19709\n",
            "Converting SMILES to graph: 19528/19709\n",
            "Converting SMILES to graph: 19529/19709\n",
            "Converting SMILES to graph: 19530/19709\n",
            "Converting SMILES to graph: 19531/19709\n",
            "Converting SMILES to graph: 19532/19709\n",
            "Converting SMILES to graph: 19533/19709\n",
            "Converting SMILES to graph: 19534/19709\n",
            "Converting SMILES to graph: 19535/19709\n",
            "Converting SMILES to graph: 19536/19709\n",
            "Converting SMILES to graph: 19537/19709\n",
            "Converting SMILES to graph: 19538/19709\n",
            "Converting SMILES to graph: 19539/19709\n",
            "Converting SMILES to graph: 19540/19709\n",
            "Converting SMILES to graph: 19541/19709\n",
            "Converting SMILES to graph: 19542/19709\n",
            "Converting SMILES to graph: 19543/19709\n",
            "Converting SMILES to graph: 19544/19709\n",
            "Converting SMILES to graph: 19545/19709\n",
            "Converting SMILES to graph: 19546/19709\n",
            "Converting SMILES to graph: 19547/19709\n",
            "Converting SMILES to graph: 19548/19709\n",
            "Converting SMILES to graph: 19549/19709\n",
            "Converting SMILES to graph: 19550/19709\n",
            "Converting SMILES to graph: 19551/19709\n",
            "Converting SMILES to graph: 19552/19709\n",
            "Converting SMILES to graph: 19553/19709\n",
            "Converting SMILES to graph: 19554/19709\n",
            "Converting SMILES to graph: 19555/19709\n",
            "Converting SMILES to graph: 19556/19709\n",
            "Converting SMILES to graph: 19557/19709\n",
            "Converting SMILES to graph: 19558/19709\n",
            "Converting SMILES to graph: 19559/19709\n",
            "Converting SMILES to graph: 19560/19709\n",
            "Converting SMILES to graph: 19561/19709\n",
            "Converting SMILES to graph: 19562/19709\n",
            "Converting SMILES to graph: 19563/19709\n",
            "Converting SMILES to graph: 19564/19709\n",
            "Converting SMILES to graph: 19565/19709\n",
            "Converting SMILES to graph: 19566/19709\n",
            "Converting SMILES to graph: 19567/19709\n",
            "Converting SMILES to graph: 19568/19709\n",
            "Converting SMILES to graph: 19569/19709\n",
            "Converting SMILES to graph: 19570/19709\n",
            "Converting SMILES to graph: 19571/19709\n",
            "Converting SMILES to graph: 19572/19709\n",
            "Converting SMILES to graph: 19573/19709\n",
            "Converting SMILES to graph: 19574/19709\n",
            "Converting SMILES to graph: 19575/19709\n",
            "Converting SMILES to graph: 19576/19709\n",
            "Converting SMILES to graph: 19577/19709\n",
            "Converting SMILES to graph: 19578/19709\n",
            "Converting SMILES to graph: 19579/19709\n",
            "Converting SMILES to graph: 19580/19709\n",
            "Converting SMILES to graph: 19581/19709\n",
            "Converting SMILES to graph: 19582/19709\n",
            "Converting SMILES to graph: 19583/19709\n",
            "Converting SMILES to graph: 19584/19709\n",
            "Converting SMILES to graph: 19585/19709\n",
            "Converting SMILES to graph: 19586/19709\n",
            "Converting SMILES to graph: 19587/19709\n",
            "Converting SMILES to graph: 19588/19709\n",
            "Converting SMILES to graph: 19589/19709\n",
            "Converting SMILES to graph: 19590/19709\n",
            "Converting SMILES to graph: 19591/19709\n",
            "Converting SMILES to graph: 19592/19709\n",
            "Converting SMILES to graph: 19593/19709\n",
            "Converting SMILES to graph: 19594/19709\n",
            "Converting SMILES to graph: 19595/19709\n",
            "Converting SMILES to graph: 19596/19709\n",
            "Converting SMILES to graph: 19597/19709\n",
            "Converting SMILES to graph: 19598/19709\n",
            "Converting SMILES to graph: 19599/19709\n",
            "Converting SMILES to graph: 19600/19709\n",
            "Converting SMILES to graph: 19601/19709\n",
            "Converting SMILES to graph: 19602/19709\n",
            "Converting SMILES to graph: 19603/19709\n",
            "Converting SMILES to graph: 19604/19709\n",
            "Converting SMILES to graph: 19605/19709\n",
            "Converting SMILES to graph: 19606/19709\n",
            "Converting SMILES to graph: 19607/19709\n",
            "Converting SMILES to graph: 19608/19709\n",
            "Converting SMILES to graph: 19609/19709\n",
            "Converting SMILES to graph: 19610/19709\n",
            "Converting SMILES to graph: 19611/19709\n",
            "Converting SMILES to graph: 19612/19709\n",
            "Converting SMILES to graph: 19613/19709\n",
            "Converting SMILES to graph: 19614/19709\n",
            "Converting SMILES to graph: 19615/19709\n",
            "Converting SMILES to graph: 19616/19709\n",
            "Converting SMILES to graph: 19617/19709\n",
            "Converting SMILES to graph: 19618/19709\n",
            "Converting SMILES to graph: 19619/19709\n",
            "Converting SMILES to graph: 19620/19709\n",
            "Converting SMILES to graph: 19621/19709\n",
            "Converting SMILES to graph: 19622/19709\n",
            "Converting SMILES to graph: 19623/19709\n",
            "Converting SMILES to graph: 19624/19709\n",
            "Converting SMILES to graph: 19625/19709\n",
            "Converting SMILES to graph: 19626/19709\n",
            "Converting SMILES to graph: 19627/19709\n",
            "Converting SMILES to graph: 19628/19709\n",
            "Converting SMILES to graph: 19629/19709\n",
            "Converting SMILES to graph: 19630/19709\n",
            "Converting SMILES to graph: 19631/19709\n",
            "Converting SMILES to graph: 19632/19709\n",
            "Converting SMILES to graph: 19633/19709\n",
            "Converting SMILES to graph: 19634/19709\n",
            "Converting SMILES to graph: 19635/19709\n",
            "Converting SMILES to graph: 19636/19709\n",
            "Converting SMILES to graph: 19637/19709\n",
            "Converting SMILES to graph: 19638/19709\n",
            "Converting SMILES to graph: 19639/19709\n",
            "Converting SMILES to graph: 19640/19709\n",
            "Converting SMILES to graph: 19641/19709\n",
            "Converting SMILES to graph: 19642/19709\n",
            "Converting SMILES to graph: 19643/19709\n",
            "Converting SMILES to graph: 19644/19709\n",
            "Converting SMILES to graph: 19645/19709\n",
            "Converting SMILES to graph: 19646/19709\n",
            "Converting SMILES to graph: 19647/19709\n",
            "Converting SMILES to graph: 19648/19709\n",
            "Converting SMILES to graph: 19649/19709\n",
            "Converting SMILES to graph: 19650/19709\n",
            "Converting SMILES to graph: 19651/19709\n",
            "Converting SMILES to graph: 19652/19709\n",
            "Converting SMILES to graph: 19653/19709\n",
            "Converting SMILES to graph: 19654/19709\n",
            "Converting SMILES to graph: 19655/19709\n",
            "Converting SMILES to graph: 19656/19709\n",
            "Converting SMILES to graph: 19657/19709\n",
            "Converting SMILES to graph: 19658/19709\n",
            "Converting SMILES to graph: 19659/19709\n",
            "Converting SMILES to graph: 19660/19709\n",
            "Converting SMILES to graph: 19661/19709\n",
            "Converting SMILES to graph: 19662/19709\n",
            "Converting SMILES to graph: 19663/19709\n",
            "Converting SMILES to graph: 19664/19709\n",
            "Converting SMILES to graph: 19665/19709\n",
            "Converting SMILES to graph: 19666/19709\n",
            "Converting SMILES to graph: 19667/19709\n",
            "Converting SMILES to graph: 19668/19709\n",
            "Converting SMILES to graph: 19669/19709\n",
            "Converting SMILES to graph: 19670/19709\n",
            "Converting SMILES to graph: 19671/19709\n",
            "Converting SMILES to graph: 19672/19709\n",
            "Converting SMILES to graph: 19673/19709\n",
            "Converting SMILES to graph: 19674/19709\n",
            "Converting SMILES to graph: 19675/19709\n",
            "Converting SMILES to graph: 19676/19709\n",
            "Converting SMILES to graph: 19677/19709\n",
            "Converting SMILES to graph: 19678/19709\n",
            "Converting SMILES to graph: 19679/19709\n",
            "Converting SMILES to graph: 19680/19709\n",
            "Converting SMILES to graph: 19681/19709\n",
            "Converting SMILES to graph: 19682/19709\n",
            "Converting SMILES to graph: 19683/19709\n",
            "Converting SMILES to graph: 19684/19709\n",
            "Converting SMILES to graph: 19685/19709\n",
            "Converting SMILES to graph: 19686/19709\n",
            "Converting SMILES to graph: 19687/19709\n",
            "Converting SMILES to graph: 19688/19709\n",
            "Converting SMILES to graph: 19689/19709\n",
            "Converting SMILES to graph: 19690/19709\n",
            "Converting SMILES to graph: 19691/19709\n",
            "Converting SMILES to graph: 19692/19709\n",
            "Converting SMILES to graph: 19693/19709\n",
            "Converting SMILES to graph: 19694/19709\n",
            "Converting SMILES to graph: 19695/19709\n",
            "Converting SMILES to graph: 19696/19709\n",
            "Converting SMILES to graph: 19697/19709\n",
            "Converting SMILES to graph: 19698/19709\n",
            "Converting SMILES to graph: 19699/19709\n",
            "Converting SMILES to graph: 19700/19709\n",
            "Converting SMILES to graph: 19701/19709\n",
            "Converting SMILES to graph: 19702/19709\n",
            "Converting SMILES to graph: 19703/19709\n",
            "Converting SMILES to graph: 19704/19709\n",
            "Converting SMILES to graph: 19705/19709\n",
            "Converting SMILES to graph: 19706/19709\n",
            "Converting SMILES to graph: 19707/19709\n",
            "Converting SMILES to graph: 19708/19709\n",
            "Converting SMILES to graph: 19709/19709\n",
            "Graph construction done. Saving to file.\n",
            "data/processed/kiba_train.pt  and  data/processed/kiba_test.pt  have been created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training.py 0 0 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSDp9zw3uyrv",
        "outputId": "1306372b-ce85-47bd-da6c-31b2068a313b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda_name: cuda:0\n",
            "Learning rate:  0.0005\n",
            "Epochs:  1000\n",
            "\n",
            "running on  GINConvNet_davis\n",
            "Pre-processed data found: data/processed/davis_train.pt, loading ...\n",
            "Pre-processed data found: data/processed/davis_test.pt, loading ...\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "Training on 25046 samples...\n",
            "Train epoch: 1 [0/25046 (0%)]\tLoss: 29.580757\n",
            "Train epoch: 1 [330940/25046 (41%)]\tLoss: 0.994800\n",
            "Train epoch: 1 [663640/25046 (82%)]\tLoss: 0.927174\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  1 ; best_mse,best_ci: 2.3807282 0.5925068838289634 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 2 [0/25046 (0%)]\tLoss: 0.849187\n",
            "Train epoch: 2 [329560/25046 (41%)]\tLoss: 0.934688\n",
            "Train epoch: 2 [656200/25046 (82%)]\tLoss: 0.702352\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  2 ; best_mse,best_ci: 0.9390012 0.7534572297472077 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 3 [0/25046 (0%)]\tLoss: 0.676678\n",
            "Train epoch: 3 [325920/25046 (41%)]\tLoss: 0.649088\n",
            "Train epoch: 3 [653840/25046 (82%)]\tLoss: 0.636518\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  3 ; best_mse,best_ci: 0.5425189 0.7898546474096603 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 4 [0/25046 (0%)]\tLoss: 0.763127\n",
            "Train epoch: 4 [331240/25046 (41%)]\tLoss: 0.643538\n",
            "Train epoch: 4 [651600/25046 (82%)]\tLoss: 0.679952\n",
            "Make prediction for 5010 samples...\n",
            "0.67886454 No improvement since epoch  3 ; best_mse,best_ci: 0.5425189 0.7898546474096603 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 5 [0/25046 (0%)]\tLoss: 0.679919\n",
            "Train epoch: 5 [334120/25046 (41%)]\tLoss: 0.567444\n",
            "Train epoch: 5 [648040/25046 (82%)]\tLoss: 0.594847\n",
            "Make prediction for 5010 samples...\n",
            "0.94965345 No improvement since epoch  3 ; best_mse,best_ci: 0.5425189 0.7898546474096603 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 6 [0/25046 (0%)]\tLoss: 0.501886\n",
            "Train epoch: 6 [329200/25046 (41%)]\tLoss: 0.661353\n",
            "Train epoch: 6 [660280/25046 (82%)]\tLoss: 0.585560\n",
            "Make prediction for 5010 samples...\n",
            "0.95312303 No improvement since epoch  3 ; best_mse,best_ci: 0.5425189 0.7898546474096603 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 7 [0/25046 (0%)]\tLoss: 0.472441\n",
            "Train epoch: 7 [335560/25046 (41%)]\tLoss: 0.539769\n",
            "Train epoch: 7 [653080/25046 (82%)]\tLoss: 0.663548\n",
            "Make prediction for 5010 samples...\n",
            "0.65036976 No improvement since epoch  3 ; best_mse,best_ci: 0.5425189 0.7898546474096603 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 8 [0/25046 (0%)]\tLoss: 0.578758\n",
            "Train epoch: 8 [329920/25046 (41%)]\tLoss: 0.454753\n",
            "Train epoch: 8 [664000/25046 (82%)]\tLoss: 0.559786\n",
            "Make prediction for 5010 samples...\n",
            "0.72870606 No improvement since epoch  3 ; best_mse,best_ci: 0.5425189 0.7898546474096603 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 9 [0/25046 (0%)]\tLoss: 0.579231\n",
            "Train epoch: 9 [330260/25046 (41%)]\tLoss: 0.567193\n",
            "Train epoch: 9 [651600/25046 (82%)]\tLoss: 0.474243\n",
            "Make prediction for 5010 samples...\n",
            "0.7435499 No improvement since epoch  3 ; best_mse,best_ci: 0.5425189 0.7898546474096603 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 10 [0/25046 (0%)]\tLoss: 0.508702\n",
            "Train epoch: 10 [333560/25046 (41%)]\tLoss: 0.498859\n",
            "Train epoch: 10 [661280/25046 (82%)]\tLoss: 0.553394\n",
            "Make prediction for 5010 samples...\n",
            "0.9664806 No improvement since epoch  3 ; best_mse,best_ci: 0.5425189 0.7898546474096603 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 11 [0/25046 (0%)]\tLoss: 0.448442\n",
            "Train epoch: 11 [329860/25046 (41%)]\tLoss: 0.451515\n",
            "Train epoch: 11 [645840/25046 (82%)]\tLoss: 0.441813\n",
            "Make prediction for 5010 samples...\n",
            "0.6604342 No improvement since epoch  3 ; best_mse,best_ci: 0.5425189 0.7898546474096603 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 12 [0/25046 (0%)]\tLoss: 0.430871\n",
            "Train epoch: 12 [325880/25046 (41%)]\tLoss: 0.413417\n",
            "Train epoch: 12 [657080/25046 (82%)]\tLoss: 0.505353\n",
            "Make prediction for 5010 samples...\n",
            "0.60426164 No improvement since epoch  3 ; best_mse,best_ci: 0.5425189 0.7898546474096603 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 13 [0/25046 (0%)]\tLoss: 0.604241\n",
            "Train epoch: 13 [325400/25046 (41%)]\tLoss: 0.406990\n",
            "Train epoch: 13 [658240/25046 (82%)]\tLoss: 0.452441\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  13 ; best_mse,best_ci: 0.42204157 0.8414344706500549 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 14 [0/25046 (0%)]\tLoss: 0.416242\n",
            "Train epoch: 14 [330440/25046 (41%)]\tLoss: 0.454224\n",
            "Train epoch: 14 [666600/25046 (82%)]\tLoss: 0.438850\n",
            "Make prediction for 5010 samples...\n",
            "0.47516704 No improvement since epoch  13 ; best_mse,best_ci: 0.42204157 0.8414344706500549 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 15 [0/25046 (0%)]\tLoss: 0.443047\n",
            "Train epoch: 15 [329280/25046 (41%)]\tLoss: 0.463173\n",
            "Train epoch: 15 [662520/25046 (82%)]\tLoss: 0.377414\n",
            "Make prediction for 5010 samples...\n",
            "0.8277187 No improvement since epoch  13 ; best_mse,best_ci: 0.42204157 0.8414344706500549 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 16 [0/25046 (0%)]\tLoss: 0.385284\n",
            "Train epoch: 16 [325480/25046 (41%)]\tLoss: 0.403312\n",
            "Train epoch: 16 [671920/25046 (82%)]\tLoss: 0.437416\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  16 ; best_mse,best_ci: 0.4064741 0.8489961532647629 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 17 [0/25046 (0%)]\tLoss: 0.375920\n",
            "Train epoch: 17 [329820/25046 (41%)]\tLoss: 0.398835\n",
            "Train epoch: 17 [649720/25046 (82%)]\tLoss: 0.370892\n",
            "Make prediction for 5010 samples...\n",
            "0.53399366 No improvement since epoch  16 ; best_mse,best_ci: 0.4064741 0.8489961532647629 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 18 [0/25046 (0%)]\tLoss: 0.331926\n",
            "Train epoch: 18 [326260/25046 (41%)]\tLoss: 0.341831\n",
            "Train epoch: 18 [647840/25046 (82%)]\tLoss: 0.404664\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  18 ; best_mse,best_ci: 0.4060519 0.8407334143715082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 19 [0/25046 (0%)]\tLoss: 0.471744\n",
            "Train epoch: 19 [325520/25046 (41%)]\tLoss: 0.317162\n",
            "Train epoch: 19 [659640/25046 (82%)]\tLoss: 0.437244\n",
            "Make prediction for 5010 samples...\n",
            "0.52741235 No improvement since epoch  18 ; best_mse,best_ci: 0.4060519 0.8407334143715082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 20 [0/25046 (0%)]\tLoss: 0.371780\n",
            "Train epoch: 20 [323000/25046 (41%)]\tLoss: 0.401650\n",
            "Train epoch: 20 [658440/25046 (82%)]\tLoss: 0.423421\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  20 ; best_mse,best_ci: 0.39836505 0.8415573756557423 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 21 [0/25046 (0%)]\tLoss: 0.377344\n",
            "Train epoch: 21 [327160/25046 (41%)]\tLoss: 0.333921\n",
            "Train epoch: 21 [658800/25046 (82%)]\tLoss: 0.417643\n",
            "Make prediction for 5010 samples...\n",
            "0.5099573 No improvement since epoch  20 ; best_mse,best_ci: 0.39836505 0.8415573756557423 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 22 [0/25046 (0%)]\tLoss: 0.381017\n",
            "Train epoch: 22 [324980/25046 (41%)]\tLoss: 0.295497\n",
            "Train epoch: 22 [650040/25046 (82%)]\tLoss: 0.379193\n",
            "Make prediction for 5010 samples...\n",
            "0.57893384 No improvement since epoch  20 ; best_mse,best_ci: 0.39836505 0.8415573756557423 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 23 [0/25046 (0%)]\tLoss: 0.365852\n",
            "Train epoch: 23 [322100/25046 (41%)]\tLoss: 0.340422\n",
            "Train epoch: 23 [664880/25046 (82%)]\tLoss: 0.313454\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  23 ; best_mse,best_ci: 0.3843407 0.8512497180076739 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 24 [0/25046 (0%)]\tLoss: 0.308339\n",
            "Train epoch: 24 [324500/25046 (41%)]\tLoss: 0.353102\n",
            "Train epoch: 24 [654240/25046 (82%)]\tLoss: 0.374396\n",
            "Make prediction for 5010 samples...\n",
            "0.45737374 No improvement since epoch  23 ; best_mse,best_ci: 0.3843407 0.8512497180076739 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 25 [0/25046 (0%)]\tLoss: 0.309158\n",
            "Train epoch: 25 [328100/25046 (41%)]\tLoss: 0.330794\n",
            "Train epoch: 25 [664760/25046 (82%)]\tLoss: 0.398751\n",
            "Make prediction for 5010 samples...\n",
            "0.5661775 No improvement since epoch  23 ; best_mse,best_ci: 0.3843407 0.8512497180076739 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 26 [0/25046 (0%)]\tLoss: 0.329386\n",
            "Train epoch: 26 [332160/25046 (41%)]\tLoss: 0.324959\n",
            "Train epoch: 26 [654400/25046 (82%)]\tLoss: 0.301544\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 27 [0/25046 (0%)]\tLoss: 0.282160\n",
            "Train epoch: 27 [324380/25046 (41%)]\tLoss: 0.312694\n",
            "Train epoch: 27 [650400/25046 (82%)]\tLoss: 0.342326\n",
            "Make prediction for 5010 samples...\n",
            "0.5559553 No improvement since epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 28 [0/25046 (0%)]\tLoss: 0.331227\n",
            "Train epoch: 28 [326780/25046 (41%)]\tLoss: 0.278386\n",
            "Train epoch: 28 [653640/25046 (82%)]\tLoss: 0.418478\n",
            "Make prediction for 5010 samples...\n",
            "0.3971201 No improvement since epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 29 [0/25046 (0%)]\tLoss: 0.319182\n",
            "Train epoch: 29 [328420/25046 (41%)]\tLoss: 0.341461\n",
            "Train epoch: 29 [659040/25046 (82%)]\tLoss: 0.380083\n",
            "Make prediction for 5010 samples...\n",
            "0.47697788 No improvement since epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 30 [0/25046 (0%)]\tLoss: 0.276088\n",
            "Train epoch: 30 [325580/25046 (41%)]\tLoss: 0.309135\n",
            "Train epoch: 30 [655680/25046 (82%)]\tLoss: 0.329023\n",
            "Make prediction for 5010 samples...\n",
            "0.5502884 No improvement since epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 31 [0/25046 (0%)]\tLoss: 0.381103\n",
            "Train epoch: 31 [327420/25046 (41%)]\tLoss: 0.335504\n",
            "Train epoch: 31 [651280/25046 (82%)]\tLoss: 0.254576\n",
            "Make prediction for 5010 samples...\n",
            "0.51903415 No improvement since epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 32 [0/25046 (0%)]\tLoss: 0.335015\n",
            "Train epoch: 32 [327080/25046 (41%)]\tLoss: 0.326014\n",
            "Train epoch: 32 [653360/25046 (82%)]\tLoss: 0.252582\n",
            "Make prediction for 5010 samples...\n",
            "0.49617463 No improvement since epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 33 [0/25046 (0%)]\tLoss: 0.273534\n",
            "Train epoch: 33 [326560/25046 (41%)]\tLoss: 0.253903\n",
            "Train epoch: 33 [651560/25046 (82%)]\tLoss: 0.299903\n",
            "Make prediction for 5010 samples...\n",
            "0.39846262 No improvement since epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 34 [0/25046 (0%)]\tLoss: 0.291533\n",
            "Train epoch: 34 [328020/25046 (41%)]\tLoss: 0.258908\n",
            "Train epoch: 34 [664280/25046 (82%)]\tLoss: 0.270214\n",
            "Make prediction for 5010 samples...\n",
            "0.41570497 No improvement since epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 35 [0/25046 (0%)]\tLoss: 0.218112\n",
            "Train epoch: 35 [325400/25046 (41%)]\tLoss: 0.283104\n",
            "Train epoch: 35 [656720/25046 (82%)]\tLoss: 0.307160\n",
            "Make prediction for 5010 samples...\n",
            "0.44842386 No improvement since epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 36 [0/25046 (0%)]\tLoss: 0.278220\n",
            "Train epoch: 36 [323520/25046 (41%)]\tLoss: 0.245171\n",
            "Train epoch: 36 [653680/25046 (82%)]\tLoss: 0.303854\n",
            "Make prediction for 5010 samples...\n",
            "0.46157703 No improvement since epoch  26 ; best_mse,best_ci: 0.3819459 0.855705081896085 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 37 [0/25046 (0%)]\tLoss: 0.259040\n",
            "Train epoch: 37 [327520/25046 (41%)]\tLoss: 0.269058\n",
            "Train epoch: 37 [661080/25046 (82%)]\tLoss: 0.286508\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  37 ; best_mse,best_ci: 0.34609604 0.8557887032457488 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 38 [0/25046 (0%)]\tLoss: 0.266438\n",
            "Train epoch: 38 [330720/25046 (41%)]\tLoss: 0.299478\n",
            "Train epoch: 38 [652320/25046 (82%)]\tLoss: 0.325983\n",
            "Make prediction for 5010 samples...\n",
            "0.5074479 No improvement since epoch  37 ; best_mse,best_ci: 0.34609604 0.8557887032457488 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 39 [0/25046 (0%)]\tLoss: 0.309392\n",
            "Train epoch: 39 [326400/25046 (41%)]\tLoss: 0.267309\n",
            "Train epoch: 39 [667840/25046 (82%)]\tLoss: 0.309161\n",
            "Make prediction for 5010 samples...\n",
            "0.5333188 No improvement since epoch  37 ; best_mse,best_ci: 0.34609604 0.8557887032457488 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 40 [0/25046 (0%)]\tLoss: 0.246513\n",
            "Train epoch: 40 [326020/25046 (41%)]\tLoss: 0.339470\n",
            "Train epoch: 40 [657640/25046 (82%)]\tLoss: 0.303025\n",
            "Make prediction for 5010 samples...\n",
            "0.41392937 No improvement since epoch  37 ; best_mse,best_ci: 0.34609604 0.8557887032457488 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 41 [0/25046 (0%)]\tLoss: 0.306874\n",
            "Train epoch: 41 [324960/25046 (41%)]\tLoss: 0.240453\n",
            "Train epoch: 41 [648560/25046 (82%)]\tLoss: 0.302046\n",
            "Make prediction for 5010 samples...\n",
            "0.41580325 No improvement since epoch  37 ; best_mse,best_ci: 0.34609604 0.8557887032457488 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 42 [0/25046 (0%)]\tLoss: 0.195152\n",
            "Train epoch: 42 [321560/25046 (41%)]\tLoss: 0.255131\n",
            "Train epoch: 42 [657920/25046 (82%)]\tLoss: 0.250087\n",
            "Make prediction for 5010 samples...\n",
            "0.51435363 No improvement since epoch  37 ; best_mse,best_ci: 0.34609604 0.8557887032457488 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 43 [0/25046 (0%)]\tLoss: 0.309108\n",
            "Train epoch: 43 [323480/25046 (41%)]\tLoss: 0.262189\n",
            "Train epoch: 43 [658000/25046 (82%)]\tLoss: 0.236602\n",
            "Make prediction for 5010 samples...\n",
            "0.34611952 No improvement since epoch  37 ; best_mse,best_ci: 0.34609604 0.8557887032457488 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 44 [0/25046 (0%)]\tLoss: 0.208373\n",
            "Train epoch: 44 [326700/25046 (41%)]\tLoss: 0.248304\n",
            "Train epoch: 44 [662800/25046 (82%)]\tLoss: 0.282958\n",
            "Make prediction for 5010 samples...\n",
            "0.44478932 No improvement since epoch  37 ; best_mse,best_ci: 0.34609604 0.8557887032457488 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 45 [0/25046 (0%)]\tLoss: 0.234536\n",
            "Train epoch: 45 [328420/25046 (41%)]\tLoss: 0.248710\n",
            "Train epoch: 45 [658400/25046 (82%)]\tLoss: 0.228874\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 46 [0/25046 (0%)]\tLoss: 0.260112\n",
            "Train epoch: 46 [328280/25046 (41%)]\tLoss: 0.250734\n",
            "Train epoch: 46 [659160/25046 (82%)]\tLoss: 0.258155\n",
            "Make prediction for 5010 samples...\n",
            "0.38026527 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 47 [0/25046 (0%)]\tLoss: 0.227965\n",
            "Train epoch: 47 [330780/25046 (41%)]\tLoss: 0.240463\n",
            "Train epoch: 47 [654120/25046 (82%)]\tLoss: 0.240247\n",
            "Make prediction for 5010 samples...\n",
            "0.32024366 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 48 [0/25046 (0%)]\tLoss: 0.244696\n",
            "Train epoch: 48 [326640/25046 (41%)]\tLoss: 0.251460\n",
            "Train epoch: 48 [658600/25046 (82%)]\tLoss: 0.250694\n",
            "Make prediction for 5010 samples...\n",
            "0.32063258 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 49 [0/25046 (0%)]\tLoss: 0.212240\n",
            "Train epoch: 49 [324860/25046 (41%)]\tLoss: 0.209358\n",
            "Train epoch: 49 [654960/25046 (82%)]\tLoss: 0.260055\n",
            "Make prediction for 5010 samples...\n",
            "0.3740597 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 50 [0/25046 (0%)]\tLoss: 0.236346\n",
            "Train epoch: 50 [327080/25046 (41%)]\tLoss: 0.208461\n",
            "Train epoch: 50 [649800/25046 (82%)]\tLoss: 0.266991\n",
            "Make prediction for 5010 samples...\n",
            "0.32931784 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 51 [0/25046 (0%)]\tLoss: 0.177727\n",
            "Train epoch: 51 [324820/25046 (41%)]\tLoss: 0.244695\n",
            "Train epoch: 51 [663200/25046 (82%)]\tLoss: 0.207284\n",
            "Make prediction for 5010 samples...\n",
            "0.34082597 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 52 [0/25046 (0%)]\tLoss: 0.215316\n",
            "Train epoch: 52 [326480/25046 (41%)]\tLoss: 0.278107\n",
            "Train epoch: 52 [659280/25046 (82%)]\tLoss: 0.198882\n",
            "Make prediction for 5010 samples...\n",
            "0.34746546 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 53 [0/25046 (0%)]\tLoss: 0.217926\n",
            "Train epoch: 53 [326760/25046 (41%)]\tLoss: 0.267845\n",
            "Train epoch: 53 [654440/25046 (82%)]\tLoss: 0.260212\n",
            "Make prediction for 5010 samples...\n",
            "0.32736763 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 54 [0/25046 (0%)]\tLoss: 0.227390\n",
            "Train epoch: 54 [329980/25046 (41%)]\tLoss: 0.204161\n",
            "Train epoch: 54 [659320/25046 (82%)]\tLoss: 0.245742\n",
            "Make prediction for 5010 samples...\n",
            "0.37144864 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 55 [0/25046 (0%)]\tLoss: 0.247214\n",
            "Train epoch: 55 [330860/25046 (41%)]\tLoss: 0.228335\n",
            "Train epoch: 55 [651360/25046 (82%)]\tLoss: 0.274134\n",
            "Make prediction for 5010 samples...\n",
            "0.42144382 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 56 [0/25046 (0%)]\tLoss: 0.220698\n",
            "Train epoch: 56 [327900/25046 (41%)]\tLoss: 0.267258\n",
            "Train epoch: 56 [660440/25046 (82%)]\tLoss: 0.217487\n",
            "Make prediction for 5010 samples...\n",
            "0.34253657 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 57 [0/25046 (0%)]\tLoss: 0.229072\n",
            "Train epoch: 57 [326480/25046 (41%)]\tLoss: 0.209335\n",
            "Train epoch: 57 [661360/25046 (82%)]\tLoss: 0.249819\n",
            "Make prediction for 5010 samples...\n",
            "0.34150526 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 58 [0/25046 (0%)]\tLoss: 0.182928\n",
            "Train epoch: 58 [336940/25046 (41%)]\tLoss: 0.259173\n",
            "Train epoch: 58 [663960/25046 (82%)]\tLoss: 0.310332\n",
            "Make prediction for 5010 samples...\n",
            "0.41661644 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 59 [0/25046 (0%)]\tLoss: 0.293222\n",
            "Train epoch: 59 [330080/25046 (41%)]\tLoss: 0.226867\n",
            "Train epoch: 59 [664000/25046 (82%)]\tLoss: 0.232233\n",
            "Make prediction for 5010 samples...\n",
            "0.45616248 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 60 [0/25046 (0%)]\tLoss: 0.287826\n",
            "Train epoch: 60 [326980/25046 (41%)]\tLoss: 0.248997\n",
            "Train epoch: 60 [653400/25046 (82%)]\tLoss: 0.324263\n",
            "Make prediction for 5010 samples...\n",
            "0.31155398 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 61 [0/25046 (0%)]\tLoss: 0.224238\n",
            "Train epoch: 61 [327720/25046 (41%)]\tLoss: 0.345734\n",
            "Train epoch: 61 [662720/25046 (82%)]\tLoss: 0.280230\n",
            "Make prediction for 5010 samples...\n",
            "0.31900445 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 62 [0/25046 (0%)]\tLoss: 0.229078\n",
            "Train epoch: 62 [324260/25046 (41%)]\tLoss: 0.258593\n",
            "Train epoch: 62 [646440/25046 (82%)]\tLoss: 0.264832\n",
            "Make prediction for 5010 samples...\n",
            "0.313379 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 63 [0/25046 (0%)]\tLoss: 0.257742\n",
            "Train epoch: 63 [325000/25046 (41%)]\tLoss: 0.240002\n",
            "Train epoch: 63 [660280/25046 (82%)]\tLoss: 0.217540\n",
            "Make prediction for 5010 samples...\n",
            "0.29264268 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 64 [0/25046 (0%)]\tLoss: 0.201807\n",
            "Train epoch: 64 [322980/25046 (41%)]\tLoss: 0.199007\n",
            "Train epoch: 64 [657480/25046 (82%)]\tLoss: 0.209056\n",
            "Make prediction for 5010 samples...\n",
            "0.36798415 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 65 [0/25046 (0%)]\tLoss: 0.253163\n",
            "Train epoch: 65 [329500/25046 (41%)]\tLoss: 0.198745\n",
            "Train epoch: 65 [659440/25046 (82%)]\tLoss: 0.178896\n",
            "Make prediction for 5010 samples...\n",
            "0.36014888 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 66 [0/25046 (0%)]\tLoss: 0.222439\n",
            "Train epoch: 66 [329100/25046 (41%)]\tLoss: 0.189478\n",
            "Train epoch: 66 [657840/25046 (82%)]\tLoss: 0.237034\n",
            "Make prediction for 5010 samples...\n",
            "0.32352272 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 67 [0/25046 (0%)]\tLoss: 0.186900\n",
            "Train epoch: 67 [328640/25046 (41%)]\tLoss: 0.193359\n",
            "Train epoch: 67 [657560/25046 (82%)]\tLoss: 0.241045\n",
            "Make prediction for 5010 samples...\n",
            "0.36250842 No improvement since epoch  45 ; best_mse,best_ci: 0.2918741 0.8605528994630928 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 68 [0/25046 (0%)]\tLoss: 0.257105\n",
            "Train epoch: 68 [325700/25046 (41%)]\tLoss: 0.214338\n",
            "Train epoch: 68 [654600/25046 (82%)]\tLoss: 0.216200\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  68 ; best_mse,best_ci: 0.28937548 0.8674611562749782 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 69 [0/25046 (0%)]\tLoss: 0.182857\n",
            "Train epoch: 69 [331940/25046 (41%)]\tLoss: 0.212194\n",
            "Train epoch: 69 [648640/25046 (82%)]\tLoss: 0.216353\n",
            "Make prediction for 5010 samples...\n",
            "0.32598257 No improvement since epoch  68 ; best_mse,best_ci: 0.28937548 0.8674611562749782 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 70 [0/25046 (0%)]\tLoss: 0.196314\n",
            "Train epoch: 70 [325640/25046 (41%)]\tLoss: 0.185086\n",
            "Train epoch: 70 [664080/25046 (82%)]\tLoss: 0.213154\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 71 [0/25046 (0%)]\tLoss: 0.241924\n",
            "Train epoch: 71 [328760/25046 (41%)]\tLoss: 0.229567\n",
            "Train epoch: 71 [660360/25046 (82%)]\tLoss: 0.258885\n",
            "Make prediction for 5010 samples...\n",
            "0.35255632 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 72 [0/25046 (0%)]\tLoss: 0.181267\n",
            "Train epoch: 72 [330840/25046 (41%)]\tLoss: 0.216052\n",
            "Train epoch: 72 [657200/25046 (82%)]\tLoss: 0.206652\n",
            "Make prediction for 5010 samples...\n",
            "0.313664 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 73 [0/25046 (0%)]\tLoss: 0.206484\n",
            "Train epoch: 73 [329760/25046 (41%)]\tLoss: 0.216253\n",
            "Train epoch: 73 [655200/25046 (82%)]\tLoss: 0.236488\n",
            "Make prediction for 5010 samples...\n",
            "0.31300658 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 74 [0/25046 (0%)]\tLoss: 0.223831\n",
            "Train epoch: 74 [325940/25046 (41%)]\tLoss: 0.199281\n",
            "Train epoch: 74 [651800/25046 (82%)]\tLoss: 0.202730\n",
            "Make prediction for 5010 samples...\n",
            "0.3338323 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 75 [0/25046 (0%)]\tLoss: 0.179311\n",
            "Train epoch: 75 [334420/25046 (41%)]\tLoss: 0.247432\n",
            "Train epoch: 75 [660200/25046 (82%)]\tLoss: 0.234438\n",
            "Make prediction for 5010 samples...\n",
            "0.3002026 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 76 [0/25046 (0%)]\tLoss: 0.184910\n",
            "Train epoch: 76 [331120/25046 (41%)]\tLoss: 0.201823\n",
            "Train epoch: 76 [660960/25046 (82%)]\tLoss: 0.204436\n",
            "Make prediction for 5010 samples...\n",
            "0.3361338 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 77 [0/25046 (0%)]\tLoss: 0.231091\n",
            "Train epoch: 77 [329480/25046 (41%)]\tLoss: 0.220685\n",
            "Train epoch: 77 [654560/25046 (82%)]\tLoss: 0.194226\n",
            "Make prediction for 5010 samples...\n",
            "0.35226107 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 78 [0/25046 (0%)]\tLoss: 0.208431\n",
            "Train epoch: 78 [324040/25046 (41%)]\tLoss: 0.192018\n",
            "Train epoch: 78 [648960/25046 (82%)]\tLoss: 0.229768\n",
            "Make prediction for 5010 samples...\n",
            "0.2721517 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 79 [0/25046 (0%)]\tLoss: 0.206297\n",
            "Train epoch: 79 [329000/25046 (41%)]\tLoss: 0.235905\n",
            "Train epoch: 79 [644560/25046 (82%)]\tLoss: 0.190086\n",
            "Make prediction for 5010 samples...\n",
            "0.35860205 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 80 [0/25046 (0%)]\tLoss: 0.205515\n",
            "Train epoch: 80 [325320/25046 (41%)]\tLoss: 0.213574\n",
            "Train epoch: 80 [654960/25046 (82%)]\tLoss: 0.178077\n",
            "Make prediction for 5010 samples...\n",
            "0.29109955 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 81 [0/25046 (0%)]\tLoss: 0.207902\n",
            "Train epoch: 81 [325160/25046 (41%)]\tLoss: 0.205808\n",
            "Train epoch: 81 [656400/25046 (82%)]\tLoss: 0.213984\n",
            "Make prediction for 5010 samples...\n",
            "0.27833325 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 82 [0/25046 (0%)]\tLoss: 0.188360\n",
            "Train epoch: 82 [332540/25046 (41%)]\tLoss: 0.196802\n",
            "Train epoch: 82 [651320/25046 (82%)]\tLoss: 0.191061\n",
            "Make prediction for 5010 samples...\n",
            "0.28466168 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 83 [0/25046 (0%)]\tLoss: 0.199919\n",
            "Train epoch: 83 [326120/25046 (41%)]\tLoss: 0.168457\n",
            "Train epoch: 83 [665520/25046 (82%)]\tLoss: 0.229649\n",
            "Make prediction for 5010 samples...\n",
            "0.31510177 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 84 [0/25046 (0%)]\tLoss: 0.193679\n",
            "Train epoch: 84 [327420/25046 (41%)]\tLoss: 0.173476\n",
            "Train epoch: 84 [643960/25046 (82%)]\tLoss: 0.195170\n",
            "Make prediction for 5010 samples...\n",
            "0.2705842 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 85 [0/25046 (0%)]\tLoss: 0.201797\n",
            "Train epoch: 85 [328560/25046 (41%)]\tLoss: 0.187097\n",
            "Train epoch: 85 [662680/25046 (82%)]\tLoss: 0.203374\n",
            "Make prediction for 5010 samples...\n",
            "0.29132584 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 86 [0/25046 (0%)]\tLoss: 0.166220\n",
            "Train epoch: 86 [326400/25046 (41%)]\tLoss: 0.208614\n",
            "Train epoch: 86 [649400/25046 (82%)]\tLoss: 0.190030\n",
            "Make prediction for 5010 samples...\n",
            "0.27427924 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 87 [0/25046 (0%)]\tLoss: 0.193339\n",
            "Train epoch: 87 [326220/25046 (41%)]\tLoss: 0.197826\n",
            "Train epoch: 87 [654560/25046 (82%)]\tLoss: 0.233992\n",
            "Make prediction for 5010 samples...\n",
            "0.30999717 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 88 [0/25046 (0%)]\tLoss: 0.188141\n",
            "Train epoch: 88 [328100/25046 (41%)]\tLoss: 0.184166\n",
            "Train epoch: 88 [658120/25046 (82%)]\tLoss: 0.190704\n",
            "Make prediction for 5010 samples...\n",
            "0.2714846 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 89 [0/25046 (0%)]\tLoss: 0.199436\n",
            "Train epoch: 89 [327420/25046 (41%)]\tLoss: 0.165266\n",
            "Train epoch: 89 [665080/25046 (82%)]\tLoss: 0.181100\n",
            "Make prediction for 5010 samples...\n",
            "0.27513 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 90 [0/25046 (0%)]\tLoss: 0.172129\n",
            "Train epoch: 90 [326900/25046 (41%)]\tLoss: 0.181834\n",
            "Train epoch: 90 [656520/25046 (82%)]\tLoss: 0.187368\n",
            "Make prediction for 5010 samples...\n",
            "0.27269197 No improvement since epoch  70 ; best_mse,best_ci: 0.26764762 0.8684516710715923 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 91 [0/25046 (0%)]\tLoss: 0.207356\n",
            "Train epoch: 91 [327920/25046 (41%)]\tLoss: 0.200308\n",
            "Train epoch: 91 [660000/25046 (82%)]\tLoss: 0.190044\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  91 ; best_mse,best_ci: 0.2628244 0.8816507497664805 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 92 [0/25046 (0%)]\tLoss: 0.204793\n",
            "Train epoch: 92 [331880/25046 (41%)]\tLoss: 0.208072\n",
            "Train epoch: 92 [655000/25046 (82%)]\tLoss: 0.190506\n",
            "Make prediction for 5010 samples...\n",
            "0.3310978 No improvement since epoch  91 ; best_mse,best_ci: 0.2628244 0.8816507497664805 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 93 [0/25046 (0%)]\tLoss: 0.265091\n",
            "Train epoch: 93 [325400/25046 (41%)]\tLoss: 0.176155\n",
            "Train epoch: 93 [651320/25046 (82%)]\tLoss: 0.174401\n",
            "Make prediction for 5010 samples...\n",
            "0.29198772 No improvement since epoch  91 ; best_mse,best_ci: 0.2628244 0.8816507497664805 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 94 [0/25046 (0%)]\tLoss: 0.190017\n",
            "Train epoch: 94 [325120/25046 (41%)]\tLoss: 0.175829\n",
            "Train epoch: 94 [659160/25046 (82%)]\tLoss: 0.195486\n",
            "Make prediction for 5010 samples...\n",
            "0.3761785 No improvement since epoch  91 ; best_mse,best_ci: 0.2628244 0.8816507497664805 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 95 [0/25046 (0%)]\tLoss: 0.192318\n",
            "Train epoch: 95 [322640/25046 (41%)]\tLoss: 0.177161\n",
            "Train epoch: 95 [659480/25046 (82%)]\tLoss: 0.205411\n",
            "Make prediction for 5010 samples...\n",
            "0.30040205 No improvement since epoch  91 ; best_mse,best_ci: 0.2628244 0.8816507497664805 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 96 [0/25046 (0%)]\tLoss: 0.175769\n",
            "Train epoch: 96 [321740/25046 (41%)]\tLoss: 0.212160\n",
            "Train epoch: 96 [658240/25046 (82%)]\tLoss: 0.203660\n",
            "Make prediction for 5010 samples...\n",
            "0.32590756 No improvement since epoch  91 ; best_mse,best_ci: 0.2628244 0.8816507497664805 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 97 [0/25046 (0%)]\tLoss: 0.172092\n",
            "Train epoch: 97 [333560/25046 (41%)]\tLoss: 0.189242\n",
            "Train epoch: 97 [653160/25046 (82%)]\tLoss: 0.210818\n",
            "Make prediction for 5010 samples...\n",
            "0.28400254 No improvement since epoch  91 ; best_mse,best_ci: 0.2628244 0.8816507497664805 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 98 [0/25046 (0%)]\tLoss: 0.228509\n",
            "Train epoch: 98 [329660/25046 (41%)]\tLoss: 0.187168\n",
            "Train epoch: 98 [654560/25046 (82%)]\tLoss: 0.174942\n",
            "Make prediction for 5010 samples...\n",
            "0.26993144 No improvement since epoch  91 ; best_mse,best_ci: 0.2628244 0.8816507497664805 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 99 [0/25046 (0%)]\tLoss: 0.186466\n",
            "Train epoch: 99 [329740/25046 (41%)]\tLoss: 0.167934\n",
            "Train epoch: 99 [648920/25046 (82%)]\tLoss: 0.209627\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  99 ; best_mse,best_ci: 0.2603902 0.8773741916028543 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 100 [0/25046 (0%)]\tLoss: 0.232806\n",
            "Train epoch: 100 [329700/25046 (41%)]\tLoss: 0.205110\n",
            "Train epoch: 100 [652600/25046 (82%)]\tLoss: 0.192181\n",
            "Make prediction for 5010 samples...\n",
            "0.29250458 No improvement since epoch  99 ; best_mse,best_ci: 0.2603902 0.8773741916028543 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 101 [0/25046 (0%)]\tLoss: 0.217459\n",
            "Train epoch: 101 [327600/25046 (41%)]\tLoss: 0.180078\n",
            "Train epoch: 101 [650800/25046 (82%)]\tLoss: 0.191287\n",
            "Make prediction for 5010 samples...\n",
            "0.27242422 No improvement since epoch  99 ; best_mse,best_ci: 0.2603902 0.8773741916028543 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 102 [0/25046 (0%)]\tLoss: 0.176909\n",
            "Train epoch: 102 [337440/25046 (41%)]\tLoss: 0.193255\n",
            "Train epoch: 102 [664640/25046 (82%)]\tLoss: 0.165176\n",
            "Make prediction for 5010 samples...\n",
            "0.2695004 No improvement since epoch  99 ; best_mse,best_ci: 0.2603902 0.8773741916028543 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 103 [0/25046 (0%)]\tLoss: 0.164489\n",
            "Train epoch: 103 [323440/25046 (41%)]\tLoss: 0.175465\n",
            "Train epoch: 103 [668320/25046 (82%)]\tLoss: 0.215149\n",
            "Make prediction for 5010 samples...\n",
            "0.2726683 No improvement since epoch  99 ; best_mse,best_ci: 0.2603902 0.8773741916028543 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 104 [0/25046 (0%)]\tLoss: 0.187062\n",
            "Train epoch: 104 [332900/25046 (41%)]\tLoss: 0.203814\n",
            "Train epoch: 104 [654000/25046 (82%)]\tLoss: 0.217848\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 105 [0/25046 (0%)]\tLoss: 0.174906\n",
            "Train epoch: 105 [330820/25046 (41%)]\tLoss: 0.192294\n",
            "Train epoch: 105 [661080/25046 (82%)]\tLoss: 0.168893\n",
            "Make prediction for 5010 samples...\n",
            "0.26341793 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 106 [0/25046 (0%)]\tLoss: 0.190653\n",
            "Train epoch: 106 [328000/25046 (41%)]\tLoss: 0.190484\n",
            "Train epoch: 106 [650120/25046 (82%)]\tLoss: 0.186257\n",
            "Make prediction for 5010 samples...\n",
            "0.31396803 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 107 [0/25046 (0%)]\tLoss: 0.143381\n",
            "Train epoch: 107 [320740/25046 (41%)]\tLoss: 0.184332\n",
            "Train epoch: 107 [648960/25046 (82%)]\tLoss: 0.176607\n",
            "Make prediction for 5010 samples...\n",
            "0.26690125 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 108 [0/25046 (0%)]\tLoss: 0.161464\n",
            "Train epoch: 108 [325760/25046 (41%)]\tLoss: 0.205846\n",
            "Train epoch: 108 [657640/25046 (82%)]\tLoss: 0.158220\n",
            "Make prediction for 5010 samples...\n",
            "0.27260357 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 109 [0/25046 (0%)]\tLoss: 0.158084\n",
            "Train epoch: 109 [332280/25046 (41%)]\tLoss: 0.196161\n",
            "Train epoch: 109 [650520/25046 (82%)]\tLoss: 0.212628\n",
            "Make prediction for 5010 samples...\n",
            "0.32210317 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 110 [0/25046 (0%)]\tLoss: 0.163006\n",
            "Train epoch: 110 [328860/25046 (41%)]\tLoss: 0.188076\n",
            "Train epoch: 110 [658280/25046 (82%)]\tLoss: 0.175538\n",
            "Make prediction for 5010 samples...\n",
            "0.2637278 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 111 [0/25046 (0%)]\tLoss: 0.152726\n",
            "Train epoch: 111 [328760/25046 (41%)]\tLoss: 0.181298\n",
            "Train epoch: 111 [657080/25046 (82%)]\tLoss: 0.171348\n",
            "Make prediction for 5010 samples...\n",
            "0.26692578 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 112 [0/25046 (0%)]\tLoss: 0.165470\n",
            "Train epoch: 112 [323100/25046 (41%)]\tLoss: 0.185520\n",
            "Train epoch: 112 [652080/25046 (82%)]\tLoss: 0.186538\n",
            "Make prediction for 5010 samples...\n",
            "0.262301 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 113 [0/25046 (0%)]\tLoss: 0.163881\n",
            "Train epoch: 113 [321980/25046 (41%)]\tLoss: 0.161336\n",
            "Train epoch: 113 [664000/25046 (82%)]\tLoss: 0.198530\n",
            "Make prediction for 5010 samples...\n",
            "0.26765126 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 114 [0/25046 (0%)]\tLoss: 0.150911\n",
            "Train epoch: 114 [327200/25046 (41%)]\tLoss: 0.213929\n",
            "Train epoch: 114 [652160/25046 (82%)]\tLoss: 0.213164\n",
            "Make prediction for 5010 samples...\n",
            "0.30727553 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 115 [0/25046 (0%)]\tLoss: 0.182359\n",
            "Train epoch: 115 [329000/25046 (41%)]\tLoss: 0.203824\n",
            "Train epoch: 115 [653800/25046 (82%)]\tLoss: 0.155255\n",
            "Make prediction for 5010 samples...\n",
            "0.27505395 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 116 [0/25046 (0%)]\tLoss: 0.159066\n",
            "Train epoch: 116 [328780/25046 (41%)]\tLoss: 0.159207\n",
            "Train epoch: 116 [658200/25046 (82%)]\tLoss: 0.178670\n",
            "Make prediction for 5010 samples...\n",
            "0.2650398 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 117 [0/25046 (0%)]\tLoss: 0.196798\n",
            "Train epoch: 117 [326800/25046 (41%)]\tLoss: 0.165799\n",
            "Train epoch: 117 [656560/25046 (82%)]\tLoss: 0.225334\n",
            "Make prediction for 5010 samples...\n",
            "0.26223674 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 118 [0/25046 (0%)]\tLoss: 0.172526\n",
            "Train epoch: 118 [326600/25046 (41%)]\tLoss: 0.189357\n",
            "Train epoch: 118 [658240/25046 (82%)]\tLoss: 0.195511\n",
            "Make prediction for 5010 samples...\n",
            "0.26260746 No improvement since epoch  104 ; best_mse,best_ci: 0.25951394 0.877358416879383 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 119 [0/25046 (0%)]\tLoss: 0.146890\n",
            "Train epoch: 119 [331820/25046 (41%)]\tLoss: 0.147653\n",
            "Train epoch: 119 [656640/25046 (82%)]\tLoss: 0.195446\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  119 ; best_mse,best_ci: 0.254427 0.8765013746216556 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 120 [0/25046 (0%)]\tLoss: 0.147326\n",
            "Train epoch: 120 [327260/25046 (41%)]\tLoss: 0.163123\n",
            "Train epoch: 120 [652920/25046 (82%)]\tLoss: 0.206258\n",
            "Make prediction for 5010 samples...\n",
            "0.26371413 No improvement since epoch  119 ; best_mse,best_ci: 0.254427 0.8765013746216556 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 121 [0/25046 (0%)]\tLoss: 0.174422\n",
            "Train epoch: 121 [328040/25046 (41%)]\tLoss: 0.162375\n",
            "Train epoch: 121 [662520/25046 (82%)]\tLoss: 0.181459\n",
            "Make prediction for 5010 samples...\n",
            "0.27546728 No improvement since epoch  119 ; best_mse,best_ci: 0.254427 0.8765013746216556 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 122 [0/25046 (0%)]\tLoss: 0.140871\n",
            "Train epoch: 122 [324000/25046 (41%)]\tLoss: 0.151021\n",
            "Train epoch: 122 [645800/25046 (82%)]\tLoss: 0.172438\n",
            "Make prediction for 5010 samples...\n",
            "0.26352632 No improvement since epoch  119 ; best_mse,best_ci: 0.254427 0.8765013746216556 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 123 [0/25046 (0%)]\tLoss: 0.186746\n",
            "Train epoch: 123 [331900/25046 (41%)]\tLoss: 0.180016\n",
            "Train epoch: 123 [653400/25046 (82%)]\tLoss: 0.160299\n",
            "Make prediction for 5010 samples...\n",
            "0.260701 No improvement since epoch  119 ; best_mse,best_ci: 0.254427 0.8765013746216556 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 124 [0/25046 (0%)]\tLoss: 0.148704\n",
            "Train epoch: 124 [332560/25046 (41%)]\tLoss: 0.183719\n",
            "Train epoch: 124 [662960/25046 (82%)]\tLoss: 0.173705\n",
            "Make prediction for 5010 samples...\n",
            "0.2570736 No improvement since epoch  119 ; best_mse,best_ci: 0.254427 0.8765013746216556 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 125 [0/25046 (0%)]\tLoss: 0.157735\n",
            "Train epoch: 125 [329200/25046 (41%)]\tLoss: 0.191905\n",
            "Train epoch: 125 [656480/25046 (82%)]\tLoss: 0.150402\n",
            "Make prediction for 5010 samples...\n",
            "0.26796603 No improvement since epoch  119 ; best_mse,best_ci: 0.254427 0.8765013746216556 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 126 [0/25046 (0%)]\tLoss: 0.188990\n",
            "Train epoch: 126 [327900/25046 (41%)]\tLoss: 0.200713\n",
            "Train epoch: 126 [663680/25046 (82%)]\tLoss: 0.158091\n",
            "Make prediction for 5010 samples...\n",
            "0.30853176 No improvement since epoch  119 ; best_mse,best_ci: 0.254427 0.8765013746216556 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 127 [0/25046 (0%)]\tLoss: 0.156364\n",
            "Train epoch: 127 [324640/25046 (41%)]\tLoss: 0.151821\n",
            "Train epoch: 127 [650360/25046 (82%)]\tLoss: 0.202634\n",
            "Make prediction for 5010 samples...\n",
            "0.28424278 No improvement since epoch  119 ; best_mse,best_ci: 0.254427 0.8765013746216556 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 128 [0/25046 (0%)]\tLoss: 0.163927\n",
            "Train epoch: 128 [329320/25046 (41%)]\tLoss: 0.192005\n",
            "Train epoch: 128 [649360/25046 (82%)]\tLoss: 0.191687\n",
            "Make prediction for 5010 samples...\n",
            "0.280849 No improvement since epoch  119 ; best_mse,best_ci: 0.254427 0.8765013746216556 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 129 [0/25046 (0%)]\tLoss: 0.147397\n",
            "Train epoch: 129 [326960/25046 (41%)]\tLoss: 0.208936\n",
            "Train epoch: 129 [661400/25046 (82%)]\tLoss: 0.159173\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  129 ; best_mse,best_ci: 0.25128177 0.8787354889773736 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 130 [0/25046 (0%)]\tLoss: 0.172696\n",
            "Train epoch: 130 [331940/25046 (41%)]\tLoss: 0.176462\n",
            "Train epoch: 130 [662480/25046 (82%)]\tLoss: 0.184708\n",
            "Make prediction for 5010 samples...\n",
            "0.27093667 No improvement since epoch  129 ; best_mse,best_ci: 0.25128177 0.8787354889773736 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 131 [0/25046 (0%)]\tLoss: 0.164798\n",
            "Train epoch: 131 [325060/25046 (41%)]\tLoss: 0.151218\n",
            "Train epoch: 131 [654560/25046 (82%)]\tLoss: 0.176697\n",
            "Make prediction for 5010 samples...\n",
            "0.26174366 No improvement since epoch  129 ; best_mse,best_ci: 0.25128177 0.8787354889773736 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 132 [0/25046 (0%)]\tLoss: 0.155042\n",
            "Train epoch: 132 [324000/25046 (41%)]\tLoss: 0.163543\n",
            "Train epoch: 132 [656200/25046 (82%)]\tLoss: 0.213778\n",
            "Make prediction for 5010 samples...\n",
            "0.26763436 No improvement since epoch  129 ; best_mse,best_ci: 0.25128177 0.8787354889773736 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 133 [0/25046 (0%)]\tLoss: 0.136515\n",
            "Train epoch: 133 [329900/25046 (41%)]\tLoss: 0.153362\n",
            "Train epoch: 133 [658000/25046 (82%)]\tLoss: 0.206504\n",
            "Make prediction for 5010 samples...\n",
            "0.27292404 No improvement since epoch  129 ; best_mse,best_ci: 0.25128177 0.8787354889773736 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 134 [0/25046 (0%)]\tLoss: 0.140391\n",
            "Train epoch: 134 [325300/25046 (41%)]\tLoss: 0.145790\n",
            "Train epoch: 134 [656040/25046 (82%)]\tLoss: 0.144461\n",
            "Make prediction for 5010 samples...\n",
            "0.30444956 No improvement since epoch  129 ; best_mse,best_ci: 0.25128177 0.8787354889773736 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 135 [0/25046 (0%)]\tLoss: 0.174946\n",
            "Train epoch: 135 [328740/25046 (41%)]\tLoss: 0.170224\n",
            "Train epoch: 135 [650760/25046 (82%)]\tLoss: 0.181809\n",
            "Make prediction for 5010 samples...\n",
            "0.3635201 No improvement since epoch  129 ; best_mse,best_ci: 0.25128177 0.8787354889773736 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 136 [0/25046 (0%)]\tLoss: 0.186722\n",
            "Train epoch: 136 [327680/25046 (41%)]\tLoss: 0.170664\n",
            "Train epoch: 136 [669440/25046 (82%)]\tLoss: 0.141433\n",
            "Make prediction for 5010 samples...\n",
            "0.25458038 No improvement since epoch  129 ; best_mse,best_ci: 0.25128177 0.8787354889773736 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 137 [0/25046 (0%)]\tLoss: 0.176011\n",
            "Train epoch: 137 [330720/25046 (41%)]\tLoss: 0.156952\n",
            "Train epoch: 137 [656000/25046 (82%)]\tLoss: 0.160794\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 138 [0/25046 (0%)]\tLoss: 0.157793\n",
            "Train epoch: 138 [326780/25046 (41%)]\tLoss: 0.156246\n",
            "Train epoch: 138 [662000/25046 (82%)]\tLoss: 0.183454\n",
            "Make prediction for 5010 samples...\n",
            "0.25621682 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 139 [0/25046 (0%)]\tLoss: 0.151767\n",
            "Train epoch: 139 [331480/25046 (41%)]\tLoss: 0.155288\n",
            "Train epoch: 139 [649960/25046 (82%)]\tLoss: 0.176208\n",
            "Make prediction for 5010 samples...\n",
            "0.27181238 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 140 [0/25046 (0%)]\tLoss: 0.161435\n",
            "Train epoch: 140 [327960/25046 (41%)]\tLoss: 0.197834\n",
            "Train epoch: 140 [660800/25046 (82%)]\tLoss: 0.165056\n",
            "Make prediction for 5010 samples...\n",
            "0.2607076 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 141 [0/25046 (0%)]\tLoss: 0.154832\n",
            "Train epoch: 141 [320360/25046 (41%)]\tLoss: 0.174541\n",
            "Train epoch: 141 [656320/25046 (82%)]\tLoss: 0.193209\n",
            "Make prediction for 5010 samples...\n",
            "0.28200167 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 142 [0/25046 (0%)]\tLoss: 0.175807\n",
            "Train epoch: 142 [325500/25046 (41%)]\tLoss: 0.168816\n",
            "Train epoch: 142 [661640/25046 (82%)]\tLoss: 0.144081\n",
            "Make prediction for 5010 samples...\n",
            "0.26420397 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 143 [0/25046 (0%)]\tLoss: 0.157606\n",
            "Train epoch: 143 [326780/25046 (41%)]\tLoss: 0.184516\n",
            "Train epoch: 143 [662000/25046 (82%)]\tLoss: 0.214601\n",
            "Make prediction for 5010 samples...\n",
            "0.26012924 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 144 [0/25046 (0%)]\tLoss: 0.160547\n",
            "Train epoch: 144 [324600/25046 (41%)]\tLoss: 0.188219\n",
            "Train epoch: 144 [661320/25046 (82%)]\tLoss: 0.181021\n",
            "Make prediction for 5010 samples...\n",
            "0.29769766 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 145 [0/25046 (0%)]\tLoss: 0.167633\n",
            "Train epoch: 145 [331900/25046 (41%)]\tLoss: 0.154298\n",
            "Train epoch: 145 [660360/25046 (82%)]\tLoss: 0.159454\n",
            "Make prediction for 5010 samples...\n",
            "0.25500578 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 146 [0/25046 (0%)]\tLoss: 0.143509\n",
            "Train epoch: 146 [326720/25046 (41%)]\tLoss: 0.155763\n",
            "Train epoch: 146 [656320/25046 (82%)]\tLoss: 0.162854\n",
            "Make prediction for 5010 samples...\n",
            "0.31417647 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 147 [0/25046 (0%)]\tLoss: 0.182174\n",
            "Train epoch: 147 [330920/25046 (41%)]\tLoss: 0.142422\n",
            "Train epoch: 147 [662920/25046 (82%)]\tLoss: 0.145398\n",
            "Make prediction for 5010 samples...\n",
            "0.26671475 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 148 [0/25046 (0%)]\tLoss: 0.192697\n",
            "Train epoch: 148 [325300/25046 (41%)]\tLoss: 0.157572\n",
            "Train epoch: 148 [665560/25046 (82%)]\tLoss: 0.176228\n",
            "Make prediction for 5010 samples...\n",
            "0.25080833 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 149 [0/25046 (0%)]\tLoss: 0.150813\n",
            "Train epoch: 149 [324660/25046 (41%)]\tLoss: 0.162385\n",
            "Train epoch: 149 [658120/25046 (82%)]\tLoss: 0.164689\n",
            "Make prediction for 5010 samples...\n",
            "0.2539624 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 150 [0/25046 (0%)]\tLoss: 0.169442\n",
            "Train epoch: 150 [327140/25046 (41%)]\tLoss: 0.159568\n",
            "Train epoch: 150 [660560/25046 (82%)]\tLoss: 0.153200\n",
            "Make prediction for 5010 samples...\n",
            "0.2857946 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 151 [0/25046 (0%)]\tLoss: 0.127195\n",
            "Train epoch: 151 [324560/25046 (41%)]\tLoss: 0.164758\n",
            "Train epoch: 151 [649440/25046 (82%)]\tLoss: 0.185717\n",
            "Make prediction for 5010 samples...\n",
            "0.25392014 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 152 [0/25046 (0%)]\tLoss: 0.164885\n",
            "Train epoch: 152 [328580/25046 (41%)]\tLoss: 0.162884\n",
            "Train epoch: 152 [649800/25046 (82%)]\tLoss: 0.213948\n",
            "Make prediction for 5010 samples...\n",
            "0.26021025 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 153 [0/25046 (0%)]\tLoss: 0.141643\n",
            "Train epoch: 153 [324580/25046 (41%)]\tLoss: 0.138566\n",
            "Train epoch: 153 [656800/25046 (82%)]\tLoss: 0.156877\n",
            "Make prediction for 5010 samples...\n",
            "0.27974835 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 154 [0/25046 (0%)]\tLoss: 0.156984\n",
            "Train epoch: 154 [327840/25046 (41%)]\tLoss: 0.173527\n",
            "Train epoch: 154 [651320/25046 (82%)]\tLoss: 0.144592\n",
            "Make prediction for 5010 samples...\n",
            "0.27989447 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 155 [0/25046 (0%)]\tLoss: 0.150189\n",
            "Train epoch: 155 [326920/25046 (41%)]\tLoss: 0.140610\n",
            "Train epoch: 155 [654200/25046 (82%)]\tLoss: 0.145452\n",
            "Make prediction for 5010 samples...\n",
            "0.31396914 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 156 [0/25046 (0%)]\tLoss: 0.167312\n",
            "Train epoch: 156 [329000/25046 (41%)]\tLoss: 0.163685\n",
            "Train epoch: 156 [662520/25046 (82%)]\tLoss: 0.213332\n",
            "Make prediction for 5010 samples...\n",
            "0.27962148 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 157 [0/25046 (0%)]\tLoss: 0.142911\n",
            "Train epoch: 157 [328040/25046 (41%)]\tLoss: 0.168686\n",
            "Train epoch: 157 [647480/25046 (82%)]\tLoss: 0.148550\n",
            "Make prediction for 5010 samples...\n",
            "0.25957838 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 158 [0/25046 (0%)]\tLoss: 0.159539\n",
            "Train epoch: 158 [329320/25046 (41%)]\tLoss: 0.161368\n",
            "Train epoch: 158 [649680/25046 (82%)]\tLoss: 0.145902\n",
            "Make prediction for 5010 samples...\n",
            "0.27651766 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 159 [0/25046 (0%)]\tLoss: 0.150842\n",
            "Train epoch: 159 [324560/25046 (41%)]\tLoss: 0.172058\n",
            "Train epoch: 159 [666280/25046 (82%)]\tLoss: 0.168440\n",
            "Make prediction for 5010 samples...\n",
            "0.2520052 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 160 [0/25046 (0%)]\tLoss: 0.173570\n",
            "Train epoch: 160 [328940/25046 (41%)]\tLoss: 0.135702\n",
            "Train epoch: 160 [650960/25046 (82%)]\tLoss: 0.143258\n",
            "Make prediction for 5010 samples...\n",
            "0.254421 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 161 [0/25046 (0%)]\tLoss: 0.126360\n",
            "Train epoch: 161 [331500/25046 (41%)]\tLoss: 0.143150\n",
            "Train epoch: 161 [661920/25046 (82%)]\tLoss: 0.169658\n",
            "Make prediction for 5010 samples...\n",
            "0.2991493 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 162 [0/25046 (0%)]\tLoss: 0.173257\n",
            "Train epoch: 162 [326260/25046 (41%)]\tLoss: 0.137666\n",
            "Train epoch: 162 [667120/25046 (82%)]\tLoss: 0.167166\n",
            "Make prediction for 5010 samples...\n",
            "0.2762631 No improvement since epoch  137 ; best_mse,best_ci: 0.24840894 0.8790974652776129 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 163 [0/25046 (0%)]\tLoss: 0.142471\n",
            "Train epoch: 163 [324720/25046 (41%)]\tLoss: 0.201814\n",
            "Train epoch: 163 [664880/25046 (82%)]\tLoss: 0.172634\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  163 ; best_mse,best_ci: 0.2477035 0.8775051371229324 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 164 [0/25046 (0%)]\tLoss: 0.164081\n",
            "Train epoch: 164 [332600/25046 (41%)]\tLoss: 0.140469\n",
            "Train epoch: 164 [649560/25046 (82%)]\tLoss: 0.138024\n",
            "Make prediction for 5010 samples...\n",
            "0.25962844 No improvement since epoch  163 ; best_mse,best_ci: 0.2477035 0.8775051371229324 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 165 [0/25046 (0%)]\tLoss: 0.134736\n",
            "Train epoch: 165 [324080/25046 (41%)]\tLoss: 0.139645\n",
            "Train epoch: 165 [659040/25046 (82%)]\tLoss: 0.146183\n",
            "Make prediction for 5010 samples...\n",
            "0.24835396 No improvement since epoch  163 ; best_mse,best_ci: 0.2477035 0.8775051371229324 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 166 [0/25046 (0%)]\tLoss: 0.167483\n",
            "Train epoch: 166 [327060/25046 (41%)]\tLoss: 0.153885\n",
            "Train epoch: 166 [654840/25046 (82%)]\tLoss: 0.179886\n",
            "Make prediction for 5010 samples...\n",
            "0.25980228 No improvement since epoch  163 ; best_mse,best_ci: 0.2477035 0.8775051371229324 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 167 [0/25046 (0%)]\tLoss: 0.185452\n",
            "Train epoch: 167 [329120/25046 (41%)]\tLoss: 0.142506\n",
            "Train epoch: 167 [663600/25046 (82%)]\tLoss: 0.168288\n",
            "Make prediction for 5010 samples...\n",
            "0.28324392 No improvement since epoch  163 ; best_mse,best_ci: 0.2477035 0.8775051371229324 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 168 [0/25046 (0%)]\tLoss: 0.139299\n",
            "Train epoch: 168 [326160/25046 (41%)]\tLoss: 0.134034\n",
            "Train epoch: 168 [652560/25046 (82%)]\tLoss: 0.128857\n",
            "Make prediction for 5010 samples...\n",
            "0.3017485 No improvement since epoch  163 ; best_mse,best_ci: 0.2477035 0.8775051371229324 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 169 [0/25046 (0%)]\tLoss: 0.164302\n",
            "Train epoch: 169 [333340/25046 (41%)]\tLoss: 0.166541\n",
            "Train epoch: 169 [652640/25046 (82%)]\tLoss: 0.158967\n",
            "Make prediction for 5010 samples...\n",
            "0.2606015 No improvement since epoch  163 ; best_mse,best_ci: 0.2477035 0.8775051371229324 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 170 [0/25046 (0%)]\tLoss: 0.152447\n",
            "Train epoch: 170 [329560/25046 (41%)]\tLoss: 0.174073\n",
            "Train epoch: 170 [662360/25046 (82%)]\tLoss: 0.152614\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 171 [0/25046 (0%)]\tLoss: 0.150380\n",
            "Train epoch: 171 [329960/25046 (41%)]\tLoss: 0.151479\n",
            "Train epoch: 171 [664280/25046 (82%)]\tLoss: 0.165746\n",
            "Make prediction for 5010 samples...\n",
            "0.25285214 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 172 [0/25046 (0%)]\tLoss: 0.175816\n",
            "Train epoch: 172 [333480/25046 (41%)]\tLoss: 0.147365\n",
            "Train epoch: 172 [659440/25046 (82%)]\tLoss: 0.168439\n",
            "Make prediction for 5010 samples...\n",
            "0.34125033 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 173 [0/25046 (0%)]\tLoss: 0.180403\n",
            "Train epoch: 173 [329980/25046 (41%)]\tLoss: 0.197379\n",
            "Train epoch: 173 [665360/25046 (82%)]\tLoss: 0.178737\n",
            "Make prediction for 5010 samples...\n",
            "0.26653606 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 174 [0/25046 (0%)]\tLoss: 0.141656\n",
            "Train epoch: 174 [324160/25046 (41%)]\tLoss: 0.144730\n",
            "Train epoch: 174 [655400/25046 (82%)]\tLoss: 0.147601\n",
            "Make prediction for 5010 samples...\n",
            "0.24905036 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 175 [0/25046 (0%)]\tLoss: 0.138320\n",
            "Train epoch: 175 [336920/25046 (41%)]\tLoss: 0.151466\n",
            "Train epoch: 175 [652240/25046 (82%)]\tLoss: 0.149101\n",
            "Make prediction for 5010 samples...\n",
            "0.24972945 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 176 [0/25046 (0%)]\tLoss: 0.134861\n",
            "Train epoch: 176 [326960/25046 (41%)]\tLoss: 0.154547\n",
            "Train epoch: 176 [654400/25046 (82%)]\tLoss: 0.181834\n",
            "Make prediction for 5010 samples...\n",
            "0.26269004 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 177 [0/25046 (0%)]\tLoss: 0.200143\n",
            "Train epoch: 177 [323200/25046 (41%)]\tLoss: 0.145711\n",
            "Train epoch: 177 [652360/25046 (82%)]\tLoss: 0.177344\n",
            "Make prediction for 5010 samples...\n",
            "0.25040764 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 178 [0/25046 (0%)]\tLoss: 0.181101\n",
            "Train epoch: 178 [324320/25046 (41%)]\tLoss: 0.124961\n",
            "Train epoch: 178 [664160/25046 (82%)]\tLoss: 0.166008\n",
            "Make prediction for 5010 samples...\n",
            "0.24826387 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 179 [0/25046 (0%)]\tLoss: 0.167838\n",
            "Train epoch: 179 [327300/25046 (41%)]\tLoss: 0.142955\n",
            "Train epoch: 179 [658160/25046 (82%)]\tLoss: 0.153832\n",
            "Make prediction for 5010 samples...\n",
            "0.258744 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 180 [0/25046 (0%)]\tLoss: 0.178395\n",
            "Train epoch: 180 [330400/25046 (41%)]\tLoss: 0.149120\n",
            "Train epoch: 180 [658440/25046 (82%)]\tLoss: 0.136226\n",
            "Make prediction for 5010 samples...\n",
            "0.24742356 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 181 [0/25046 (0%)]\tLoss: 0.168383\n",
            "Train epoch: 181 [328860/25046 (41%)]\tLoss: 0.150664\n",
            "Train epoch: 181 [652280/25046 (82%)]\tLoss: 0.140414\n",
            "Make prediction for 5010 samples...\n",
            "0.32499468 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 182 [0/25046 (0%)]\tLoss: 0.176695\n",
            "Train epoch: 182 [323940/25046 (41%)]\tLoss: 0.184338\n",
            "Train epoch: 182 [669240/25046 (82%)]\tLoss: 0.137773\n",
            "Make prediction for 5010 samples...\n",
            "0.28299573 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 183 [0/25046 (0%)]\tLoss: 0.167154\n",
            "Train epoch: 183 [329000/25046 (41%)]\tLoss: 0.157515\n",
            "Train epoch: 183 [654280/25046 (82%)]\tLoss: 0.151894\n",
            "Make prediction for 5010 samples...\n",
            "0.2710628 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 184 [0/25046 (0%)]\tLoss: 0.112185\n",
            "Train epoch: 184 [330080/25046 (41%)]\tLoss: 0.135004\n",
            "Train epoch: 184 [656480/25046 (82%)]\tLoss: 0.169201\n",
            "Make prediction for 5010 samples...\n",
            "0.29916394 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 185 [0/25046 (0%)]\tLoss: 0.154049\n",
            "Train epoch: 185 [330500/25046 (41%)]\tLoss: 0.144766\n",
            "Train epoch: 185 [661000/25046 (82%)]\tLoss: 0.185427\n",
            "Make prediction for 5010 samples...\n",
            "0.260314 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 186 [0/25046 (0%)]\tLoss: 0.167032\n",
            "Train epoch: 186 [326940/25046 (41%)]\tLoss: 0.149468\n",
            "Train epoch: 186 [666240/25046 (82%)]\tLoss: 0.193499\n",
            "Make prediction for 5010 samples...\n",
            "0.26485252 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 187 [0/25046 (0%)]\tLoss: 0.236603\n",
            "Train epoch: 187 [325860/25046 (41%)]\tLoss: 0.145440\n",
            "Train epoch: 187 [648000/25046 (82%)]\tLoss: 0.129610\n",
            "Make prediction for 5010 samples...\n",
            "0.28514698 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 188 [0/25046 (0%)]\tLoss: 0.139897\n",
            "Train epoch: 188 [330780/25046 (41%)]\tLoss: 0.179265\n",
            "Train epoch: 188 [651880/25046 (82%)]\tLoss: 0.152613\n",
            "Make prediction for 5010 samples...\n",
            "0.25496414 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 189 [0/25046 (0%)]\tLoss: 0.135242\n",
            "Train epoch: 189 [327520/25046 (41%)]\tLoss: 0.152638\n",
            "Train epoch: 189 [652040/25046 (82%)]\tLoss: 0.126361\n",
            "Make prediction for 5010 samples...\n",
            "0.27377525 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 190 [0/25046 (0%)]\tLoss: 0.151188\n",
            "Train epoch: 190 [323400/25046 (41%)]\tLoss: 0.189485\n",
            "Train epoch: 190 [665760/25046 (82%)]\tLoss: 0.145782\n",
            "Make prediction for 5010 samples...\n",
            "0.25557324 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 191 [0/25046 (0%)]\tLoss: 0.134665\n",
            "Train epoch: 191 [329180/25046 (41%)]\tLoss: 0.173835\n",
            "Train epoch: 191 [655480/25046 (82%)]\tLoss: 0.160568\n",
            "Make prediction for 5010 samples...\n",
            "0.2501654 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 192 [0/25046 (0%)]\tLoss: 0.128376\n",
            "Train epoch: 192 [329760/25046 (41%)]\tLoss: 0.160412\n",
            "Train epoch: 192 [662720/25046 (82%)]\tLoss: 0.138938\n",
            "Make prediction for 5010 samples...\n",
            "0.25239098 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 193 [0/25046 (0%)]\tLoss: 0.164250\n",
            "Train epoch: 193 [327300/25046 (41%)]\tLoss: 0.158556\n",
            "Train epoch: 193 [654440/25046 (82%)]\tLoss: 0.137977\n",
            "Make prediction for 5010 samples...\n",
            "0.27659026 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 194 [0/25046 (0%)]\tLoss: 0.154814\n",
            "Train epoch: 194 [329560/25046 (41%)]\tLoss: 0.157895\n",
            "Train epoch: 194 [652440/25046 (82%)]\tLoss: 0.177168\n",
            "Make prediction for 5010 samples...\n",
            "0.24804161 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 195 [0/25046 (0%)]\tLoss: 0.153876\n",
            "Train epoch: 195 [328780/25046 (41%)]\tLoss: 0.129103\n",
            "Train epoch: 195 [658080/25046 (82%)]\tLoss: 0.145798\n",
            "Make prediction for 5010 samples...\n",
            "0.25130486 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 196 [0/25046 (0%)]\tLoss: 0.114861\n",
            "Train epoch: 196 [330300/25046 (41%)]\tLoss: 0.131501\n",
            "Train epoch: 196 [657080/25046 (82%)]\tLoss: 0.161454\n",
            "Make prediction for 5010 samples...\n",
            "0.28108314 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 197 [0/25046 (0%)]\tLoss: 0.139401\n",
            "Train epoch: 197 [326320/25046 (41%)]\tLoss: 0.162644\n",
            "Train epoch: 197 [661920/25046 (82%)]\tLoss: 0.138988\n",
            "Make prediction for 5010 samples...\n",
            "0.25312665 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 198 [0/25046 (0%)]\tLoss: 0.154850\n",
            "Train epoch: 198 [329640/25046 (41%)]\tLoss: 0.155176\n",
            "Train epoch: 198 [655400/25046 (82%)]\tLoss: 0.148515\n",
            "Make prediction for 5010 samples...\n",
            "0.25029323 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 199 [0/25046 (0%)]\tLoss: 0.144612\n",
            "Train epoch: 199 [327180/25046 (41%)]\tLoss: 0.154809\n",
            "Train epoch: 199 [657720/25046 (82%)]\tLoss: 0.201493\n",
            "Make prediction for 5010 samples...\n",
            "0.24687824 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 200 [0/25046 (0%)]\tLoss: 0.146212\n",
            "Train epoch: 200 [329500/25046 (41%)]\tLoss: 0.184145\n",
            "Train epoch: 200 [658160/25046 (82%)]\tLoss: 0.174046\n",
            "Make prediction for 5010 samples...\n",
            "0.26422414 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 201 [0/25046 (0%)]\tLoss: 0.147872\n",
            "Train epoch: 201 [331840/25046 (41%)]\tLoss: 0.175811\n",
            "Train epoch: 201 [661240/25046 (82%)]\tLoss: 0.143047\n",
            "Make prediction for 5010 samples...\n",
            "0.26300684 No improvement since epoch  170 ; best_mse,best_ci: 0.24639101 0.8812839491576068 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 202 [0/25046 (0%)]\tLoss: 0.142722\n",
            "Train epoch: 202 [325420/25046 (41%)]\tLoss: 0.149801\n",
            "Train epoch: 202 [665080/25046 (82%)]\tLoss: 0.153338\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  202 ; best_mse,best_ci: 0.244891 0.8845569745489387 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 203 [0/25046 (0%)]\tLoss: 0.134504\n",
            "Train epoch: 203 [332700/25046 (41%)]\tLoss: 0.176252\n",
            "Train epoch: 203 [644080/25046 (82%)]\tLoss: 0.159941\n",
            "Make prediction for 5010 samples...\n",
            "0.272224 No improvement since epoch  202 ; best_mse,best_ci: 0.244891 0.8845569745489387 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 204 [0/25046 (0%)]\tLoss: 0.154125\n",
            "Train epoch: 204 [330260/25046 (41%)]\tLoss: 0.160679\n",
            "Train epoch: 204 [660280/25046 (82%)]\tLoss: 0.182734\n",
            "Make prediction for 5010 samples...\n",
            "0.2544309 No improvement since epoch  202 ; best_mse,best_ci: 0.244891 0.8845569745489387 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 205 [0/25046 (0%)]\tLoss: 0.122574\n",
            "Train epoch: 205 [326660/25046 (41%)]\tLoss: 0.162590\n",
            "Train epoch: 205 [664240/25046 (82%)]\tLoss: 0.172928\n",
            "Make prediction for 5010 samples...\n",
            "0.24990073 No improvement since epoch  202 ; best_mse,best_ci: 0.244891 0.8845569745489387 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 206 [0/25046 (0%)]\tLoss: 0.156944\n",
            "Train epoch: 206 [322840/25046 (41%)]\tLoss: 0.141910\n",
            "Train epoch: 206 [662840/25046 (82%)]\tLoss: 0.158829\n",
            "Make prediction for 5010 samples...\n",
            "0.2582575 No improvement since epoch  202 ; best_mse,best_ci: 0.244891 0.8845569745489387 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 207 [0/25046 (0%)]\tLoss: 0.128049\n",
            "Train epoch: 207 [332560/25046 (41%)]\tLoss: 0.139092\n",
            "Train epoch: 207 [664360/25046 (82%)]\tLoss: 0.140262\n",
            "Make prediction for 5010 samples...\n",
            "0.25913256 No improvement since epoch  202 ; best_mse,best_ci: 0.244891 0.8845569745489387 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 208 [0/25046 (0%)]\tLoss: 0.151174\n",
            "Train epoch: 208 [327840/25046 (41%)]\tLoss: 0.155878\n",
            "Train epoch: 208 [654800/25046 (82%)]\tLoss: 0.135750\n",
            "Make prediction for 5010 samples...\n",
            "0.2517081 No improvement since epoch  202 ; best_mse,best_ci: 0.244891 0.8845569745489387 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 209 [0/25046 (0%)]\tLoss: 0.136431\n",
            "Train epoch: 209 [317860/25046 (41%)]\tLoss: 0.155184\n",
            "Train epoch: 209 [658920/25046 (82%)]\tLoss: 0.204744\n",
            "Make prediction for 5010 samples...\n",
            "0.2626811 No improvement since epoch  202 ; best_mse,best_ci: 0.244891 0.8845569745489387 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 210 [0/25046 (0%)]\tLoss: 0.155712\n",
            "Train epoch: 210 [326800/25046 (41%)]\tLoss: 0.136015\n",
            "Train epoch: 210 [661280/25046 (82%)]\tLoss: 0.122629\n",
            "Make prediction for 5010 samples...\n",
            "0.2652198 No improvement since epoch  202 ; best_mse,best_ci: 0.244891 0.8845569745489387 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 211 [0/25046 (0%)]\tLoss: 0.125070\n",
            "Train epoch: 211 [332500/25046 (41%)]\tLoss: 0.166910\n",
            "Train epoch: 211 [658200/25046 (82%)]\tLoss: 0.166447\n",
            "Make prediction for 5010 samples...\n",
            "0.26465487 No improvement since epoch  202 ; best_mse,best_ci: 0.244891 0.8845569745489387 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 212 [0/25046 (0%)]\tLoss: 0.148920\n",
            "Train epoch: 212 [328020/25046 (41%)]\tLoss: 0.133630\n",
            "Train epoch: 212 [660160/25046 (82%)]\tLoss: 0.136574\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 213 [0/25046 (0%)]\tLoss: 0.155522\n",
            "Train epoch: 213 [327840/25046 (41%)]\tLoss: 0.170551\n",
            "Train epoch: 213 [656600/25046 (82%)]\tLoss: 0.182442\n",
            "Make prediction for 5010 samples...\n",
            "0.3007264 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 214 [0/25046 (0%)]\tLoss: 0.137656\n",
            "Train epoch: 214 [331000/25046 (41%)]\tLoss: 0.129930\n",
            "Train epoch: 214 [662760/25046 (82%)]\tLoss: 0.153998\n",
            "Make prediction for 5010 samples...\n",
            "0.27621529 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 215 [0/25046 (0%)]\tLoss: 0.167473\n",
            "Train epoch: 215 [331460/25046 (41%)]\tLoss: 0.161493\n",
            "Train epoch: 215 [643440/25046 (82%)]\tLoss: 0.126744\n",
            "Make prediction for 5010 samples...\n",
            "0.25153312 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 216 [0/25046 (0%)]\tLoss: 0.136313\n",
            "Train epoch: 216 [329080/25046 (41%)]\tLoss: 0.151245\n",
            "Train epoch: 216 [664720/25046 (82%)]\tLoss: 0.144002\n",
            "Make prediction for 5010 samples...\n",
            "0.25153688 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 217 [0/25046 (0%)]\tLoss: 0.130785\n",
            "Train epoch: 217 [330360/25046 (41%)]\tLoss: 0.172649\n",
            "Train epoch: 217 [651040/25046 (82%)]\tLoss: 0.129499\n",
            "Make prediction for 5010 samples...\n",
            "0.26966903 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 218 [0/25046 (0%)]\tLoss: 0.165628\n",
            "Train epoch: 218 [329580/25046 (41%)]\tLoss: 0.174760\n",
            "Train epoch: 218 [661760/25046 (82%)]\tLoss: 0.144465\n",
            "Make prediction for 5010 samples...\n",
            "0.2711293 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 219 [0/25046 (0%)]\tLoss: 0.148888\n",
            "Train epoch: 219 [330400/25046 (41%)]\tLoss: 0.135078\n",
            "Train epoch: 219 [660040/25046 (82%)]\tLoss: 0.158157\n",
            "Make prediction for 5010 samples...\n",
            "0.25469247 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 220 [0/25046 (0%)]\tLoss: 0.156603\n",
            "Train epoch: 220 [326460/25046 (41%)]\tLoss: 0.109678\n",
            "Train epoch: 220 [650880/25046 (82%)]\tLoss: 0.165586\n",
            "Make prediction for 5010 samples...\n",
            "0.25220764 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 221 [0/25046 (0%)]\tLoss: 0.122946\n",
            "Train epoch: 221 [321200/25046 (41%)]\tLoss: 0.127640\n",
            "Train epoch: 221 [657480/25046 (82%)]\tLoss: 0.151884\n",
            "Make prediction for 5010 samples...\n",
            "0.29168323 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 222 [0/25046 (0%)]\tLoss: 0.176580\n",
            "Train epoch: 222 [327800/25046 (41%)]\tLoss: 0.123300\n",
            "Train epoch: 222 [651600/25046 (82%)]\tLoss: 0.142812\n",
            "Make prediction for 5010 samples...\n",
            "0.24976668 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 223 [0/25046 (0%)]\tLoss: 0.152082\n",
            "Train epoch: 223 [330660/25046 (41%)]\tLoss: 0.159286\n",
            "Train epoch: 223 [654880/25046 (82%)]\tLoss: 0.134122\n",
            "Make prediction for 5010 samples...\n",
            "0.26866218 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 224 [0/25046 (0%)]\tLoss: 0.147768\n",
            "Train epoch: 224 [329900/25046 (41%)]\tLoss: 0.120232\n",
            "Train epoch: 224 [649200/25046 (82%)]\tLoss: 0.129406\n",
            "Make prediction for 5010 samples...\n",
            "0.25890908 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 225 [0/25046 (0%)]\tLoss: 0.115309\n",
            "Train epoch: 225 [335600/25046 (41%)]\tLoss: 0.146793\n",
            "Train epoch: 225 [656680/25046 (82%)]\tLoss: 0.104489\n",
            "Make prediction for 5010 samples...\n",
            "0.24763696 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 226 [0/25046 (0%)]\tLoss: 0.145257\n",
            "Train epoch: 226 [327980/25046 (41%)]\tLoss: 0.152583\n",
            "Train epoch: 226 [653600/25046 (82%)]\tLoss: 0.155362\n",
            "Make prediction for 5010 samples...\n",
            "0.26663592 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 227 [0/25046 (0%)]\tLoss: 0.144875\n",
            "Train epoch: 227 [335080/25046 (41%)]\tLoss: 0.147641\n",
            "Train epoch: 227 [648160/25046 (82%)]\tLoss: 0.173098\n",
            "Make prediction for 5010 samples...\n",
            "0.28528333 No improvement since epoch  212 ; best_mse,best_ci: 0.2437876 0.8825122334512048 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 228 [0/25046 (0%)]\tLoss: 0.138611\n",
            "Train epoch: 228 [329980/25046 (41%)]\tLoss: 0.126864\n",
            "Train epoch: 228 [645760/25046 (82%)]\tLoss: 0.126459\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 229 [0/25046 (0%)]\tLoss: 0.129231\n",
            "Train epoch: 229 [328880/25046 (41%)]\tLoss: 0.137836\n",
            "Train epoch: 229 [653960/25046 (82%)]\tLoss: 0.141489\n",
            "Make prediction for 5010 samples...\n",
            "0.24649037 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 230 [0/25046 (0%)]\tLoss: 0.139328\n",
            "Train epoch: 230 [325320/25046 (41%)]\tLoss: 0.168810\n",
            "Train epoch: 230 [657280/25046 (82%)]\tLoss: 0.142815\n",
            "Make prediction for 5010 samples...\n",
            "0.27933964 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 231 [0/25046 (0%)]\tLoss: 0.134441\n",
            "Train epoch: 231 [325600/25046 (41%)]\tLoss: 0.135186\n",
            "Train epoch: 231 [662280/25046 (82%)]\tLoss: 0.161634\n",
            "Make prediction for 5010 samples...\n",
            "0.25483614 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 232 [0/25046 (0%)]\tLoss: 0.110711\n",
            "Train epoch: 232 [328820/25046 (41%)]\tLoss: 0.140421\n",
            "Train epoch: 232 [663240/25046 (82%)]\tLoss: 0.176911\n",
            "Make prediction for 5010 samples...\n",
            "0.24635442 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 233 [0/25046 (0%)]\tLoss: 0.156441\n",
            "Train epoch: 233 [328500/25046 (41%)]\tLoss: 0.128700\n",
            "Train epoch: 233 [653960/25046 (82%)]\tLoss: 0.113144\n",
            "Make prediction for 5010 samples...\n",
            "0.3297215 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 234 [0/25046 (0%)]\tLoss: 0.155208\n",
            "Train epoch: 234 [333060/25046 (41%)]\tLoss: 0.149649\n",
            "Train epoch: 234 [656840/25046 (82%)]\tLoss: 0.147244\n",
            "Make prediction for 5010 samples...\n",
            "0.2604579 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 235 [0/25046 (0%)]\tLoss: 0.190677\n",
            "Train epoch: 235 [330220/25046 (41%)]\tLoss: 0.169537\n",
            "Train epoch: 235 [659520/25046 (82%)]\tLoss: 0.116764\n",
            "Make prediction for 5010 samples...\n",
            "0.25862098 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 236 [0/25046 (0%)]\tLoss: 0.136461\n",
            "Train epoch: 236 [328000/25046 (41%)]\tLoss: 0.139748\n",
            "Train epoch: 236 [648440/25046 (82%)]\tLoss: 0.178542\n",
            "Make prediction for 5010 samples...\n",
            "0.25343525 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 237 [0/25046 (0%)]\tLoss: 0.119882\n",
            "Train epoch: 237 [330260/25046 (41%)]\tLoss: 0.184542\n",
            "Train epoch: 237 [653240/25046 (82%)]\tLoss: 0.159162\n",
            "Make prediction for 5010 samples...\n",
            "0.26943156 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 238 [0/25046 (0%)]\tLoss: 0.168861\n",
            "Train epoch: 238 [326220/25046 (41%)]\tLoss: 0.161755\n",
            "Train epoch: 238 [664120/25046 (82%)]\tLoss: 0.161861\n",
            "Make prediction for 5010 samples...\n",
            "0.29698646 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 239 [0/25046 (0%)]\tLoss: 0.165309\n",
            "Train epoch: 239 [325100/25046 (41%)]\tLoss: 0.141861\n",
            "Train epoch: 239 [648440/25046 (82%)]\tLoss: 0.136235\n",
            "Make prediction for 5010 samples...\n",
            "0.24277851 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 240 [0/25046 (0%)]\tLoss: 0.116629\n",
            "Train epoch: 240 [332160/25046 (41%)]\tLoss: 0.139037\n",
            "Train epoch: 240 [656440/25046 (82%)]\tLoss: 0.144359\n",
            "Make prediction for 5010 samples...\n",
            "0.29843953 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 241 [0/25046 (0%)]\tLoss: 0.113707\n",
            "Train epoch: 241 [332400/25046 (41%)]\tLoss: 0.172686\n",
            "Train epoch: 241 [651880/25046 (82%)]\tLoss: 0.158071\n",
            "Make prediction for 5010 samples...\n",
            "0.24984851 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 242 [0/25046 (0%)]\tLoss: 0.136625\n",
            "Train epoch: 242 [329780/25046 (41%)]\tLoss: 0.145291\n",
            "Train epoch: 242 [649040/25046 (82%)]\tLoss: 0.131137\n",
            "Make prediction for 5010 samples...\n",
            "0.247222 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 243 [0/25046 (0%)]\tLoss: 0.120706\n",
            "Train epoch: 243 [324740/25046 (41%)]\tLoss: 0.132790\n",
            "Train epoch: 243 [650240/25046 (82%)]\tLoss: 0.172449\n",
            "Make prediction for 5010 samples...\n",
            "0.26796037 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 244 [0/25046 (0%)]\tLoss: 0.135641\n",
            "Train epoch: 244 [327740/25046 (41%)]\tLoss: 0.118935\n",
            "Train epoch: 244 [657280/25046 (82%)]\tLoss: 0.141497\n",
            "Make prediction for 5010 samples...\n",
            "0.24632443 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 245 [0/25046 (0%)]\tLoss: 0.142912\n",
            "Train epoch: 245 [328900/25046 (41%)]\tLoss: 0.119988\n",
            "Train epoch: 245 [655680/25046 (82%)]\tLoss: 0.127907\n",
            "Make prediction for 5010 samples...\n",
            "0.24488376 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 246 [0/25046 (0%)]\tLoss: 0.113998\n",
            "Train epoch: 246 [332320/25046 (41%)]\tLoss: 0.127298\n",
            "Train epoch: 246 [664160/25046 (82%)]\tLoss: 0.138837\n",
            "Make prediction for 5010 samples...\n",
            "0.2455213 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 247 [0/25046 (0%)]\tLoss: 0.219976\n",
            "Train epoch: 247 [332520/25046 (41%)]\tLoss: 0.160926\n",
            "Train epoch: 247 [651040/25046 (82%)]\tLoss: 0.138884\n",
            "Make prediction for 5010 samples...\n",
            "0.26729566 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 248 [0/25046 (0%)]\tLoss: 0.115758\n",
            "Train epoch: 248 [326920/25046 (41%)]\tLoss: 0.134579\n",
            "Train epoch: 248 [643560/25046 (82%)]\tLoss: 0.120652\n",
            "Make prediction for 5010 samples...\n",
            "0.29750815 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 249 [0/25046 (0%)]\tLoss: 0.133213\n",
            "Train epoch: 249 [330560/25046 (41%)]\tLoss: 0.156482\n",
            "Train epoch: 249 [657640/25046 (82%)]\tLoss: 0.155775\n",
            "Make prediction for 5010 samples...\n",
            "0.25854027 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 250 [0/25046 (0%)]\tLoss: 0.115985\n",
            "Train epoch: 250 [329240/25046 (41%)]\tLoss: 0.103906\n",
            "Train epoch: 250 [659320/25046 (82%)]\tLoss: 0.123218\n",
            "Make prediction for 5010 samples...\n",
            "0.24394052 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 251 [0/25046 (0%)]\tLoss: 0.147996\n",
            "Train epoch: 251 [331440/25046 (41%)]\tLoss: 0.127616\n",
            "Train epoch: 251 [655240/25046 (82%)]\tLoss: 0.175727\n",
            "Make prediction for 5010 samples...\n",
            "0.24332339 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 252 [0/25046 (0%)]\tLoss: 0.122360\n",
            "Train epoch: 252 [327500/25046 (41%)]\tLoss: 0.152543\n",
            "Train epoch: 252 [638560/25046 (82%)]\tLoss: 0.129882\n",
            "Make prediction for 5010 samples...\n",
            "0.2915833 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 253 [0/25046 (0%)]\tLoss: 0.154604\n",
            "Train epoch: 253 [333000/25046 (41%)]\tLoss: 0.160235\n",
            "Train epoch: 253 [653840/25046 (82%)]\tLoss: 0.108810\n",
            "Make prediction for 5010 samples...\n",
            "0.24443045 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 254 [0/25046 (0%)]\tLoss: 0.123617\n",
            "Train epoch: 254 [327020/25046 (41%)]\tLoss: 0.180956\n",
            "Train epoch: 254 [657240/25046 (82%)]\tLoss: 0.124358\n",
            "Make prediction for 5010 samples...\n",
            "0.25188455 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 255 [0/25046 (0%)]\tLoss: 0.129361\n",
            "Train epoch: 255 [329360/25046 (41%)]\tLoss: 0.131663\n",
            "Train epoch: 255 [664480/25046 (82%)]\tLoss: 0.173538\n",
            "Make prediction for 5010 samples...\n",
            "0.26458693 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 256 [0/25046 (0%)]\tLoss: 0.127251\n",
            "Train epoch: 256 [333140/25046 (41%)]\tLoss: 0.125194\n",
            "Train epoch: 256 [656160/25046 (82%)]\tLoss: 0.144218\n",
            "Make prediction for 5010 samples...\n",
            "0.2568369 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 257 [0/25046 (0%)]\tLoss: 0.128084\n",
            "Train epoch: 257 [328060/25046 (41%)]\tLoss: 0.128054\n",
            "Train epoch: 257 [653120/25046 (82%)]\tLoss: 0.118435\n",
            "Make prediction for 5010 samples...\n",
            "0.268407 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 258 [0/25046 (0%)]\tLoss: 0.128655\n",
            "Train epoch: 258 [326680/25046 (41%)]\tLoss: 0.117029\n",
            "Train epoch: 258 [661760/25046 (82%)]\tLoss: 0.133196\n",
            "Make prediction for 5010 samples...\n",
            "0.25934416 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 259 [0/25046 (0%)]\tLoss: 0.128886\n",
            "Train epoch: 259 [330720/25046 (41%)]\tLoss: 0.139134\n",
            "Train epoch: 259 [663400/25046 (82%)]\tLoss: 0.138551\n",
            "Make prediction for 5010 samples...\n",
            "0.24267514 No improvement since epoch  228 ; best_mse,best_ci: 0.24069826 0.8820722258732113 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 260 [0/25046 (0%)]\tLoss: 0.121405\n",
            "Train epoch: 260 [330560/25046 (41%)]\tLoss: 0.099134\n",
            "Train epoch: 260 [647280/25046 (82%)]\tLoss: 0.127368\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 261 [0/25046 (0%)]\tLoss: 0.146373\n",
            "Train epoch: 261 [325960/25046 (41%)]\tLoss: 0.140677\n",
            "Train epoch: 261 [656720/25046 (82%)]\tLoss: 0.176876\n",
            "Make prediction for 5010 samples...\n",
            "0.2728172 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 262 [0/25046 (0%)]\tLoss: 0.149184\n",
            "Train epoch: 262 [326360/25046 (41%)]\tLoss: 0.188803\n",
            "Train epoch: 262 [655600/25046 (82%)]\tLoss: 0.140705\n",
            "Make prediction for 5010 samples...\n",
            "0.24903893 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 263 [0/25046 (0%)]\tLoss: 0.114824\n",
            "Train epoch: 263 [332900/25046 (41%)]\tLoss: 0.150604\n",
            "Train epoch: 263 [654640/25046 (82%)]\tLoss: 0.166779\n",
            "Make prediction for 5010 samples...\n",
            "0.2515154 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 264 [0/25046 (0%)]\tLoss: 0.145765\n",
            "Train epoch: 264 [325320/25046 (41%)]\tLoss: 0.145703\n",
            "Train epoch: 264 [660960/25046 (82%)]\tLoss: 0.161055\n",
            "Make prediction for 5010 samples...\n",
            "0.24733528 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 265 [0/25046 (0%)]\tLoss: 0.143699\n",
            "Train epoch: 265 [332180/25046 (41%)]\tLoss: 0.115193\n",
            "Train epoch: 265 [651720/25046 (82%)]\tLoss: 0.144343\n",
            "Make prediction for 5010 samples...\n",
            "0.24471399 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 266 [0/25046 (0%)]\tLoss: 0.137608\n",
            "Train epoch: 266 [323800/25046 (41%)]\tLoss: 0.140061\n",
            "Train epoch: 266 [651640/25046 (82%)]\tLoss: 0.165208\n",
            "Make prediction for 5010 samples...\n",
            "0.25637004 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 267 [0/25046 (0%)]\tLoss: 0.133699\n",
            "Train epoch: 267 [328240/25046 (41%)]\tLoss: 0.121972\n",
            "Train epoch: 267 [655960/25046 (82%)]\tLoss: 0.113088\n",
            "Make prediction for 5010 samples...\n",
            "0.26948345 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 268 [0/25046 (0%)]\tLoss: 0.116773\n",
            "Train epoch: 268 [328660/25046 (41%)]\tLoss: 0.102105\n",
            "Train epoch: 268 [650520/25046 (82%)]\tLoss: 0.153148\n",
            "Make prediction for 5010 samples...\n",
            "0.27007395 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 269 [0/25046 (0%)]\tLoss: 0.121682\n",
            "Train epoch: 269 [328540/25046 (41%)]\tLoss: 0.146456\n",
            "Train epoch: 269 [656680/25046 (82%)]\tLoss: 0.155156\n",
            "Make prediction for 5010 samples...\n",
            "0.24440713 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 270 [0/25046 (0%)]\tLoss: 0.124614\n",
            "Train epoch: 270 [327580/25046 (41%)]\tLoss: 0.120098\n",
            "Train epoch: 270 [649400/25046 (82%)]\tLoss: 0.116546\n",
            "Make prediction for 5010 samples...\n",
            "0.29061756 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 271 [0/25046 (0%)]\tLoss: 0.144832\n",
            "Train epoch: 271 [336680/25046 (41%)]\tLoss: 0.164320\n",
            "Train epoch: 271 [659240/25046 (82%)]\tLoss: 0.132168\n",
            "Make prediction for 5010 samples...\n",
            "0.25806838 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 272 [0/25046 (0%)]\tLoss: 0.115405\n",
            "Train epoch: 272 [331360/25046 (41%)]\tLoss: 0.109769\n",
            "Train epoch: 272 [653960/25046 (82%)]\tLoss: 0.124158\n",
            "Make prediction for 5010 samples...\n",
            "0.25472006 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 273 [0/25046 (0%)]\tLoss: 0.123183\n",
            "Train epoch: 273 [330120/25046 (41%)]\tLoss: 0.131132\n",
            "Train epoch: 273 [658280/25046 (82%)]\tLoss: 0.150363\n",
            "Make prediction for 5010 samples...\n",
            "0.24789454 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 274 [0/25046 (0%)]\tLoss: 0.144009\n",
            "Train epoch: 274 [331560/25046 (41%)]\tLoss: 0.130020\n",
            "Train epoch: 274 [657880/25046 (82%)]\tLoss: 0.127375\n",
            "Make prediction for 5010 samples...\n",
            "0.24374673 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 275 [0/25046 (0%)]\tLoss: 0.142234\n",
            "Train epoch: 275 [327480/25046 (41%)]\tLoss: 0.147501\n",
            "Train epoch: 275 [663080/25046 (82%)]\tLoss: 0.144300\n",
            "Make prediction for 5010 samples...\n",
            "0.2441145 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 276 [0/25046 (0%)]\tLoss: 0.122858\n",
            "Train epoch: 276 [332700/25046 (41%)]\tLoss: 0.127931\n",
            "Train epoch: 276 [651240/25046 (82%)]\tLoss: 0.151033\n",
            "Make prediction for 5010 samples...\n",
            "0.24584861 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 277 [0/25046 (0%)]\tLoss: 0.114935\n",
            "Train epoch: 277 [326560/25046 (41%)]\tLoss: 0.130529\n",
            "Train epoch: 277 [659240/25046 (82%)]\tLoss: 0.157178\n",
            "Make prediction for 5010 samples...\n",
            "0.25445276 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 278 [0/25046 (0%)]\tLoss: 0.142796\n",
            "Train epoch: 278 [327560/25046 (41%)]\tLoss: 0.135711\n",
            "Train epoch: 278 [659640/25046 (82%)]\tLoss: 0.190240\n",
            "Make prediction for 5010 samples...\n",
            "0.2562927 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 279 [0/25046 (0%)]\tLoss: 0.138022\n",
            "Train epoch: 279 [332860/25046 (41%)]\tLoss: 0.143746\n",
            "Train epoch: 279 [651720/25046 (82%)]\tLoss: 0.133290\n",
            "Make prediction for 5010 samples...\n",
            "0.2604959 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 280 [0/25046 (0%)]\tLoss: 0.148727\n",
            "Train epoch: 280 [333620/25046 (41%)]\tLoss: 0.102494\n",
            "Train epoch: 280 [659880/25046 (82%)]\tLoss: 0.149861\n",
            "Make prediction for 5010 samples...\n",
            "0.27028337 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 281 [0/25046 (0%)]\tLoss: 0.141062\n",
            "Train epoch: 281 [321440/25046 (41%)]\tLoss: 0.150117\n",
            "Train epoch: 281 [658640/25046 (82%)]\tLoss: 0.119325\n",
            "Make prediction for 5010 samples...\n",
            "0.25509778 No improvement since epoch  260 ; best_mse,best_ci: 0.24033305 0.8854082735821013 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 282 [0/25046 (0%)]\tLoss: 0.127945\n",
            "Train epoch: 282 [331100/25046 (41%)]\tLoss: 0.135659\n",
            "Train epoch: 282 [667800/25046 (82%)]\tLoss: 0.127539\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 283 [0/25046 (0%)]\tLoss: 0.142018\n",
            "Train epoch: 283 [332200/25046 (41%)]\tLoss: 0.115356\n",
            "Train epoch: 283 [648880/25046 (82%)]\tLoss: 0.147589\n",
            "Make prediction for 5010 samples...\n",
            "0.26996046 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 284 [0/25046 (0%)]\tLoss: 0.148843\n",
            "Train epoch: 284 [330740/25046 (41%)]\tLoss: 0.136227\n",
            "Train epoch: 284 [647560/25046 (82%)]\tLoss: 0.125926\n",
            "Make prediction for 5010 samples...\n",
            "0.24990548 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 285 [0/25046 (0%)]\tLoss: 0.201317\n",
            "Train epoch: 285 [325840/25046 (41%)]\tLoss: 0.113060\n",
            "Train epoch: 285 [660240/25046 (82%)]\tLoss: 0.117692\n",
            "Make prediction for 5010 samples...\n",
            "0.2733376 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 286 [0/25046 (0%)]\tLoss: 0.143707\n",
            "Train epoch: 286 [326600/25046 (41%)]\tLoss: 0.174855\n",
            "Train epoch: 286 [662440/25046 (82%)]\tLoss: 0.126132\n",
            "Make prediction for 5010 samples...\n",
            "0.24334647 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 287 [0/25046 (0%)]\tLoss: 0.144490\n",
            "Train epoch: 287 [329020/25046 (41%)]\tLoss: 0.135263\n",
            "Train epoch: 287 [661680/25046 (82%)]\tLoss: 0.126522\n",
            "Make prediction for 5010 samples...\n",
            "0.25175595 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 288 [0/25046 (0%)]\tLoss: 0.146752\n",
            "Train epoch: 288 [326120/25046 (41%)]\tLoss: 0.165506\n",
            "Train epoch: 288 [656240/25046 (82%)]\tLoss: 0.141091\n",
            "Make prediction for 5010 samples...\n",
            "0.2716815 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 289 [0/25046 (0%)]\tLoss: 0.141764\n",
            "Train epoch: 289 [323880/25046 (41%)]\tLoss: 0.119370\n",
            "Train epoch: 289 [667000/25046 (82%)]\tLoss: 0.123128\n",
            "Make prediction for 5010 samples...\n",
            "0.24427201 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 290 [0/25046 (0%)]\tLoss: 0.133534\n",
            "Train epoch: 290 [331280/25046 (41%)]\tLoss: 0.116136\n",
            "Train epoch: 290 [655520/25046 (82%)]\tLoss: 0.125719\n",
            "Make prediction for 5010 samples...\n",
            "0.2580563 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 291 [0/25046 (0%)]\tLoss: 0.147009\n",
            "Train epoch: 291 [326140/25046 (41%)]\tLoss: 0.142168\n",
            "Train epoch: 291 [648680/25046 (82%)]\tLoss: 0.181514\n",
            "Make prediction for 5010 samples...\n",
            "0.26408148 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 292 [0/25046 (0%)]\tLoss: 0.199059\n",
            "Train epoch: 292 [330400/25046 (41%)]\tLoss: 0.123484\n",
            "Train epoch: 292 [657040/25046 (82%)]\tLoss: 0.129248\n",
            "Make prediction for 5010 samples...\n",
            "0.23814344 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 293 [0/25046 (0%)]\tLoss: 0.122890\n",
            "Train epoch: 293 [324060/25046 (41%)]\tLoss: 0.141832\n",
            "Train epoch: 293 [658600/25046 (82%)]\tLoss: 0.149745\n",
            "Make prediction for 5010 samples...\n",
            "0.24978347 No improvement since epoch  282 ; best_mse,best_ci: 0.23754722 0.8844647000742637 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 294 [0/25046 (0%)]\tLoss: 0.110992\n",
            "Train epoch: 294 [326080/25046 (41%)]\tLoss: 0.115995\n",
            "Train epoch: 294 [652560/25046 (82%)]\tLoss: 0.121419\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 295 [0/25046 (0%)]\tLoss: 0.137495\n",
            "Train epoch: 295 [330220/25046 (41%)]\tLoss: 0.111119\n",
            "Train epoch: 295 [655280/25046 (82%)]\tLoss: 0.117252\n",
            "Make prediction for 5010 samples...\n",
            "0.25263926 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 296 [0/25046 (0%)]\tLoss: 0.110782\n",
            "Train epoch: 296 [322720/25046 (41%)]\tLoss: 0.117048\n",
            "Train epoch: 296 [661360/25046 (82%)]\tLoss: 0.113372\n",
            "Make prediction for 5010 samples...\n",
            "0.26549017 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 297 [0/25046 (0%)]\tLoss: 0.107772\n",
            "Train epoch: 297 [330120/25046 (41%)]\tLoss: 0.155879\n",
            "Train epoch: 297 [657960/25046 (82%)]\tLoss: 0.139273\n",
            "Make prediction for 5010 samples...\n",
            "0.24169393 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 298 [0/25046 (0%)]\tLoss: 0.108621\n",
            "Train epoch: 298 [334780/25046 (41%)]\tLoss: 0.097593\n",
            "Train epoch: 298 [646600/25046 (82%)]\tLoss: 0.122602\n",
            "Make prediction for 5010 samples...\n",
            "0.24185024 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 299 [0/25046 (0%)]\tLoss: 0.138941\n",
            "Train epoch: 299 [329580/25046 (41%)]\tLoss: 0.107676\n",
            "Train epoch: 299 [658880/25046 (82%)]\tLoss: 0.124853\n",
            "Make prediction for 5010 samples...\n",
            "0.2527731 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 300 [0/25046 (0%)]\tLoss: 0.106445\n",
            "Train epoch: 300 [330560/25046 (41%)]\tLoss: 0.161621\n",
            "Train epoch: 300 [655720/25046 (82%)]\tLoss: 0.160113\n",
            "Make prediction for 5010 samples...\n",
            "0.26631594 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 301 [0/25046 (0%)]\tLoss: 0.113374\n",
            "Train epoch: 301 [328660/25046 (41%)]\tLoss: 0.119068\n",
            "Train epoch: 301 [658680/25046 (82%)]\tLoss: 0.172872\n",
            "Make prediction for 5010 samples...\n",
            "0.24667649 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 302 [0/25046 (0%)]\tLoss: 0.094519\n",
            "Train epoch: 302 [332500/25046 (41%)]\tLoss: 0.125453\n",
            "Train epoch: 302 [656280/25046 (82%)]\tLoss: 0.157959\n",
            "Make prediction for 5010 samples...\n",
            "0.25086132 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 303 [0/25046 (0%)]\tLoss: 0.158372\n",
            "Train epoch: 303 [331320/25046 (41%)]\tLoss: 0.144702\n",
            "Train epoch: 303 [659720/25046 (82%)]\tLoss: 0.159955\n",
            "Make prediction for 5010 samples...\n",
            "0.24834818 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 304 [0/25046 (0%)]\tLoss: 0.106895\n",
            "Train epoch: 304 [328320/25046 (41%)]\tLoss: 0.173865\n",
            "Train epoch: 304 [645960/25046 (82%)]\tLoss: 0.135555\n",
            "Make prediction for 5010 samples...\n",
            "0.241007 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 305 [0/25046 (0%)]\tLoss: 0.102338\n",
            "Train epoch: 305 [329600/25046 (41%)]\tLoss: 0.101784\n",
            "Train epoch: 305 [646840/25046 (82%)]\tLoss: 0.110423\n",
            "Make prediction for 5010 samples...\n",
            "0.23938344 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 306 [0/25046 (0%)]\tLoss: 0.105125\n",
            "Train epoch: 306 [326100/25046 (41%)]\tLoss: 0.135094\n",
            "Train epoch: 306 [658120/25046 (82%)]\tLoss: 0.137005\n",
            "Make prediction for 5010 samples...\n",
            "0.26729465 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 307 [0/25046 (0%)]\tLoss: 0.121205\n",
            "Train epoch: 307 [329720/25046 (41%)]\tLoss: 0.115804\n",
            "Train epoch: 307 [651640/25046 (82%)]\tLoss: 0.112581\n",
            "Make prediction for 5010 samples...\n",
            "0.25242218 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 308 [0/25046 (0%)]\tLoss: 0.129468\n",
            "Train epoch: 308 [328060/25046 (41%)]\tLoss: 0.119653\n",
            "Train epoch: 308 [658440/25046 (82%)]\tLoss: 0.130293\n",
            "Make prediction for 5010 samples...\n",
            "0.2588112 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 309 [0/25046 (0%)]\tLoss: 0.125215\n",
            "Train epoch: 309 [328320/25046 (41%)]\tLoss: 0.127711\n",
            "Train epoch: 309 [661200/25046 (82%)]\tLoss: 0.128251\n",
            "Make prediction for 5010 samples...\n",
            "0.2501215 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 310 [0/25046 (0%)]\tLoss: 0.124966\n",
            "Train epoch: 310 [325740/25046 (41%)]\tLoss: 0.177612\n",
            "Train epoch: 310 [655920/25046 (82%)]\tLoss: 0.152708\n",
            "Make prediction for 5010 samples...\n",
            "0.23800439 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 311 [0/25046 (0%)]\tLoss: 0.130604\n",
            "Train epoch: 311 [328700/25046 (41%)]\tLoss: 0.128411\n",
            "Train epoch: 311 [652560/25046 (82%)]\tLoss: 0.122765\n",
            "Make prediction for 5010 samples...\n",
            "0.25023243 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 312 [0/25046 (0%)]\tLoss: 0.107455\n",
            "Train epoch: 312 [325220/25046 (41%)]\tLoss: 0.108973\n",
            "Train epoch: 312 [655840/25046 (82%)]\tLoss: 0.111786\n",
            "Make prediction for 5010 samples...\n",
            "0.2552754 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 313 [0/25046 (0%)]\tLoss: 0.103968\n",
            "Train epoch: 313 [331140/25046 (41%)]\tLoss: 0.122937\n",
            "Train epoch: 313 [648120/25046 (82%)]\tLoss: 0.135573\n",
            "Make prediction for 5010 samples...\n",
            "0.2568165 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 314 [0/25046 (0%)]\tLoss: 0.126163\n",
            "Train epoch: 314 [324440/25046 (41%)]\tLoss: 0.111733\n",
            "Train epoch: 314 [657040/25046 (82%)]\tLoss: 0.147037\n",
            "Make prediction for 5010 samples...\n",
            "0.28111833 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 315 [0/25046 (0%)]\tLoss: 0.186715\n",
            "Train epoch: 315 [326620/25046 (41%)]\tLoss: 0.116103\n",
            "Train epoch: 315 [646760/25046 (82%)]\tLoss: 0.119627\n",
            "Make prediction for 5010 samples...\n",
            "0.26553476 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 316 [0/25046 (0%)]\tLoss: 0.153334\n",
            "Train epoch: 316 [328640/25046 (41%)]\tLoss: 0.163922\n",
            "Train epoch: 316 [652400/25046 (82%)]\tLoss: 0.134096\n",
            "Make prediction for 5010 samples...\n",
            "0.24719867 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 317 [0/25046 (0%)]\tLoss: 0.098052\n",
            "Train epoch: 317 [329080/25046 (41%)]\tLoss: 0.104042\n",
            "Train epoch: 317 [658280/25046 (82%)]\tLoss: 0.110075\n",
            "Make prediction for 5010 samples...\n",
            "0.24585004 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 318 [0/25046 (0%)]\tLoss: 0.127562\n",
            "Train epoch: 318 [331540/25046 (41%)]\tLoss: 0.105780\n",
            "Train epoch: 318 [656360/25046 (82%)]\tLoss: 0.143183\n",
            "Make prediction for 5010 samples...\n",
            "0.2446696 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 319 [0/25046 (0%)]\tLoss: 0.132192\n",
            "Train epoch: 319 [327300/25046 (41%)]\tLoss: 0.119411\n",
            "Train epoch: 319 [655080/25046 (82%)]\tLoss: 0.110368\n",
            "Make prediction for 5010 samples...\n",
            "0.24505135 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 320 [0/25046 (0%)]\tLoss: 0.113725\n",
            "Train epoch: 320 [319560/25046 (41%)]\tLoss: 0.163717\n",
            "Train epoch: 320 [655680/25046 (82%)]\tLoss: 0.112970\n",
            "Make prediction for 5010 samples...\n",
            "0.24903102 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 321 [0/25046 (0%)]\tLoss: 0.123124\n",
            "Train epoch: 321 [330200/25046 (41%)]\tLoss: 0.109805\n",
            "Train epoch: 321 [647200/25046 (82%)]\tLoss: 0.113303\n",
            "Make prediction for 5010 samples...\n",
            "0.26040292 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 322 [0/25046 (0%)]\tLoss: 0.111249\n",
            "Train epoch: 322 [328280/25046 (41%)]\tLoss: 0.130037\n",
            "Train epoch: 322 [660640/25046 (82%)]\tLoss: 0.094682\n",
            "Make prediction for 5010 samples...\n",
            "0.2696196 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 323 [0/25046 (0%)]\tLoss: 0.117375\n",
            "Train epoch: 323 [331860/25046 (41%)]\tLoss: 0.140796\n",
            "Train epoch: 323 [660200/25046 (82%)]\tLoss: 0.125540\n",
            "Make prediction for 5010 samples...\n",
            "0.24620159 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 324 [0/25046 (0%)]\tLoss: 0.104471\n",
            "Train epoch: 324 [329320/25046 (41%)]\tLoss: 0.103725\n",
            "Train epoch: 324 [659840/25046 (82%)]\tLoss: 0.139571\n",
            "Make prediction for 5010 samples...\n",
            "0.28983375 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 325 [0/25046 (0%)]\tLoss: 0.137245\n",
            "Train epoch: 325 [328320/25046 (41%)]\tLoss: 0.125574\n",
            "Train epoch: 325 [660320/25046 (82%)]\tLoss: 0.144558\n",
            "Make prediction for 5010 samples...\n",
            "0.26830325 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 326 [0/25046 (0%)]\tLoss: 0.128792\n",
            "Train epoch: 326 [327600/25046 (41%)]\tLoss: 0.122468\n",
            "Train epoch: 326 [658360/25046 (82%)]\tLoss: 0.135710\n",
            "Make prediction for 5010 samples...\n",
            "0.2651178 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 327 [0/25046 (0%)]\tLoss: 0.161959\n",
            "Train epoch: 327 [335060/25046 (41%)]\tLoss: 0.129069\n",
            "Train epoch: 327 [661520/25046 (82%)]\tLoss: 0.163439\n",
            "Make prediction for 5010 samples...\n",
            "0.26400855 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 328 [0/25046 (0%)]\tLoss: 0.153632\n",
            "Train epoch: 328 [328300/25046 (41%)]\tLoss: 0.130198\n",
            "Train epoch: 328 [661240/25046 (82%)]\tLoss: 0.116467\n",
            "Make prediction for 5010 samples...\n",
            "0.2457109 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 329 [0/25046 (0%)]\tLoss: 0.100581\n",
            "Train epoch: 329 [326980/25046 (41%)]\tLoss: 0.108995\n",
            "Train epoch: 329 [658720/25046 (82%)]\tLoss: 0.108309\n",
            "Make prediction for 5010 samples...\n",
            "0.26641333 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 330 [0/25046 (0%)]\tLoss: 0.153964\n",
            "Train epoch: 330 [327920/25046 (41%)]\tLoss: 0.122275\n",
            "Train epoch: 330 [659960/25046 (82%)]\tLoss: 0.121276\n",
            "Make prediction for 5010 samples...\n",
            "0.24724886 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 331 [0/25046 (0%)]\tLoss: 0.134351\n",
            "Train epoch: 331 [325800/25046 (41%)]\tLoss: 0.118099\n",
            "Train epoch: 331 [651280/25046 (82%)]\tLoss: 0.141230\n",
            "Make prediction for 5010 samples...\n",
            "0.26221925 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 332 [0/25046 (0%)]\tLoss: 0.123976\n",
            "Train epoch: 332 [332640/25046 (41%)]\tLoss: 0.133655\n",
            "Train epoch: 332 [652800/25046 (82%)]\tLoss: 0.134653\n",
            "Make prediction for 5010 samples...\n",
            "0.25924996 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 333 [0/25046 (0%)]\tLoss: 0.145415\n",
            "Train epoch: 333 [329820/25046 (41%)]\tLoss: 0.111959\n",
            "Train epoch: 333 [664960/25046 (82%)]\tLoss: 0.122328\n",
            "Make prediction for 5010 samples...\n",
            "0.24820851 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 334 [0/25046 (0%)]\tLoss: 0.111546\n",
            "Train epoch: 334 [326400/25046 (41%)]\tLoss: 0.120760\n",
            "Train epoch: 334 [654240/25046 (82%)]\tLoss: 0.146015\n",
            "Make prediction for 5010 samples...\n",
            "0.2649376 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 335 [0/25046 (0%)]\tLoss: 0.125230\n",
            "Train epoch: 335 [324580/25046 (41%)]\tLoss: 0.123791\n",
            "Train epoch: 335 [655320/25046 (82%)]\tLoss: 0.172447\n",
            "Make prediction for 5010 samples...\n",
            "0.28691986 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 336 [0/25046 (0%)]\tLoss: 0.138801\n",
            "Train epoch: 336 [329540/25046 (41%)]\tLoss: 0.156881\n",
            "Train epoch: 336 [646080/25046 (82%)]\tLoss: 0.128358\n",
            "Make prediction for 5010 samples...\n",
            "0.2603881 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 337 [0/25046 (0%)]\tLoss: 0.115322\n",
            "Train epoch: 337 [326680/25046 (41%)]\tLoss: 0.123799\n",
            "Train epoch: 337 [657840/25046 (82%)]\tLoss: 0.129165\n",
            "Make prediction for 5010 samples...\n",
            "0.24172783 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 338 [0/25046 (0%)]\tLoss: 0.105071\n",
            "Train epoch: 338 [325060/25046 (41%)]\tLoss: 0.121982\n",
            "Train epoch: 338 [654960/25046 (82%)]\tLoss: 0.102463\n",
            "Make prediction for 5010 samples...\n",
            "0.23846592 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 339 [0/25046 (0%)]\tLoss: 0.111248\n",
            "Train epoch: 339 [322800/25046 (41%)]\tLoss: 0.123706\n",
            "Train epoch: 339 [661440/25046 (82%)]\tLoss: 0.112853\n",
            "Make prediction for 5010 samples...\n",
            "0.29234335 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 340 [0/25046 (0%)]\tLoss: 0.116744\n",
            "Train epoch: 340 [331600/25046 (41%)]\tLoss: 0.160666\n",
            "Train epoch: 340 [659320/25046 (82%)]\tLoss: 0.162076\n",
            "Make prediction for 5010 samples...\n",
            "0.24473125 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 341 [0/25046 (0%)]\tLoss: 0.135614\n",
            "Train epoch: 341 [325640/25046 (41%)]\tLoss: 0.123154\n",
            "Train epoch: 341 [648240/25046 (82%)]\tLoss: 0.123012\n",
            "Make prediction for 5010 samples...\n",
            "0.284536 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 342 [0/25046 (0%)]\tLoss: 0.142263\n",
            "Train epoch: 342 [331520/25046 (41%)]\tLoss: 0.108211\n",
            "Train epoch: 342 [647640/25046 (82%)]\tLoss: 0.118712\n",
            "Make prediction for 5010 samples...\n",
            "0.23469517 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 343 [0/25046 (0%)]\tLoss: 0.153927\n",
            "Train epoch: 343 [330560/25046 (41%)]\tLoss: 0.134340\n",
            "Train epoch: 343 [644880/25046 (82%)]\tLoss: 0.138144\n",
            "Make prediction for 5010 samples...\n",
            "0.2451994 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 344 [0/25046 (0%)]\tLoss: 0.102442\n",
            "Train epoch: 344 [328180/25046 (41%)]\tLoss: 0.153060\n",
            "Train epoch: 344 [657520/25046 (82%)]\tLoss: 0.122461\n",
            "Make prediction for 5010 samples...\n",
            "0.26254025 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 345 [0/25046 (0%)]\tLoss: 0.121720\n",
            "Train epoch: 345 [326000/25046 (41%)]\tLoss: 0.115620\n",
            "Train epoch: 345 [665680/25046 (82%)]\tLoss: 0.119575\n",
            "Make prediction for 5010 samples...\n",
            "0.23598666 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 346 [0/25046 (0%)]\tLoss: 0.113545\n",
            "Train epoch: 346 [329500/25046 (41%)]\tLoss: 0.121185\n",
            "Train epoch: 346 [652320/25046 (82%)]\tLoss: 0.162205\n",
            "Make prediction for 5010 samples...\n",
            "0.29944673 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 347 [0/25046 (0%)]\tLoss: 0.153678\n",
            "Train epoch: 347 [329900/25046 (41%)]\tLoss: 0.119072\n",
            "Train epoch: 347 [658240/25046 (82%)]\tLoss: 0.093649\n",
            "Make prediction for 5010 samples...\n",
            "0.24341561 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 348 [0/25046 (0%)]\tLoss: 0.122606\n",
            "Train epoch: 348 [330340/25046 (41%)]\tLoss: 0.093900\n",
            "Train epoch: 348 [658800/25046 (82%)]\tLoss: 0.151031\n",
            "Make prediction for 5010 samples...\n",
            "0.26100683 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 349 [0/25046 (0%)]\tLoss: 0.154647\n",
            "Train epoch: 349 [320960/25046 (41%)]\tLoss: 0.104232\n",
            "Train epoch: 349 [662400/25046 (82%)]\tLoss: 0.122377\n",
            "Make prediction for 5010 samples...\n",
            "0.2717914 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 350 [0/25046 (0%)]\tLoss: 0.121239\n",
            "Train epoch: 350 [326200/25046 (41%)]\tLoss: 0.112887\n",
            "Train epoch: 350 [655400/25046 (82%)]\tLoss: 0.123565\n",
            "Make prediction for 5010 samples...\n",
            "0.241233 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 351 [0/25046 (0%)]\tLoss: 0.136141\n",
            "Train epoch: 351 [331060/25046 (41%)]\tLoss: 0.140963\n",
            "Train epoch: 351 [656680/25046 (82%)]\tLoss: 0.169157\n",
            "Make prediction for 5010 samples...\n",
            "0.27061352 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 352 [0/25046 (0%)]\tLoss: 0.142372\n",
            "Train epoch: 352 [327320/25046 (41%)]\tLoss: 0.099211\n",
            "Train epoch: 352 [665640/25046 (82%)]\tLoss: 0.118537\n",
            "Make prediction for 5010 samples...\n",
            "0.25159004 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 353 [0/25046 (0%)]\tLoss: 0.085316\n",
            "Train epoch: 353 [334600/25046 (41%)]\tLoss: 0.126904\n",
            "Train epoch: 353 [652040/25046 (82%)]\tLoss: 0.107658\n",
            "Make prediction for 5010 samples...\n",
            "0.2373003 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 354 [0/25046 (0%)]\tLoss: 0.110188\n",
            "Train epoch: 354 [331300/25046 (41%)]\tLoss: 0.123675\n",
            "Train epoch: 354 [660520/25046 (82%)]\tLoss: 0.144235\n",
            "Make prediction for 5010 samples...\n",
            "0.23739995 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 355 [0/25046 (0%)]\tLoss: 0.120483\n",
            "Train epoch: 355 [328660/25046 (41%)]\tLoss: 0.090172\n",
            "Train epoch: 355 [653840/25046 (82%)]\tLoss: 0.126807\n",
            "Make prediction for 5010 samples...\n",
            "0.23942539 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 356 [0/25046 (0%)]\tLoss: 0.109396\n",
            "Train epoch: 356 [330340/25046 (41%)]\tLoss: 0.117523\n",
            "Train epoch: 356 [658720/25046 (82%)]\tLoss: 0.136777\n",
            "Make prediction for 5010 samples...\n",
            "0.23850502 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 357 [0/25046 (0%)]\tLoss: 0.109937\n",
            "Train epoch: 357 [336460/25046 (41%)]\tLoss: 0.110001\n",
            "Train epoch: 357 [655240/25046 (82%)]\tLoss: 0.109267\n",
            "Make prediction for 5010 samples...\n",
            "0.2552205 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 358 [0/25046 (0%)]\tLoss: 0.099807\n",
            "Train epoch: 358 [322020/25046 (41%)]\tLoss: 0.121558\n",
            "Train epoch: 358 [653280/25046 (82%)]\tLoss: 0.149218\n",
            "Make prediction for 5010 samples...\n",
            "0.28980172 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 359 [0/25046 (0%)]\tLoss: 0.119974\n",
            "Train epoch: 359 [330340/25046 (41%)]\tLoss: 0.120063\n",
            "Train epoch: 359 [654840/25046 (82%)]\tLoss: 0.120503\n",
            "Make prediction for 5010 samples...\n",
            "0.23978557 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 360 [0/25046 (0%)]\tLoss: 0.121064\n",
            "Train epoch: 360 [329000/25046 (41%)]\tLoss: 0.116451\n",
            "Train epoch: 360 [653640/25046 (82%)]\tLoss: 0.122381\n",
            "Make prediction for 5010 samples...\n",
            "0.25262043 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 361 [0/25046 (0%)]\tLoss: 0.162369\n",
            "Train epoch: 361 [336360/25046 (41%)]\tLoss: 0.152571\n",
            "Train epoch: 361 [651080/25046 (82%)]\tLoss: 0.118786\n",
            "Make prediction for 5010 samples...\n",
            "0.24852717 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 362 [0/25046 (0%)]\tLoss: 0.099809\n",
            "Train epoch: 362 [324060/25046 (41%)]\tLoss: 0.099098\n",
            "Train epoch: 362 [659680/25046 (82%)]\tLoss: 0.105656\n",
            "Make prediction for 5010 samples...\n",
            "0.24070957 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 363 [0/25046 (0%)]\tLoss: 0.116089\n",
            "Train epoch: 363 [331980/25046 (41%)]\tLoss: 0.121832\n",
            "Train epoch: 363 [658840/25046 (82%)]\tLoss: 0.106568\n",
            "Make prediction for 5010 samples...\n",
            "0.26957887 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 364 [0/25046 (0%)]\tLoss: 0.121808\n",
            "Train epoch: 364 [326100/25046 (41%)]\tLoss: 0.092653\n",
            "Train epoch: 364 [643200/25046 (82%)]\tLoss: 0.152429\n",
            "Make prediction for 5010 samples...\n",
            "0.2443761 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 365 [0/25046 (0%)]\tLoss: 0.101244\n",
            "Train epoch: 365 [332500/25046 (41%)]\tLoss: 0.107848\n",
            "Train epoch: 365 [663760/25046 (82%)]\tLoss: 0.143739\n",
            "Make prediction for 5010 samples...\n",
            "0.24789225 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 366 [0/25046 (0%)]\tLoss: 0.133999\n",
            "Train epoch: 366 [329580/25046 (41%)]\tLoss: 0.128050\n",
            "Train epoch: 366 [662000/25046 (82%)]\tLoss: 0.103633\n",
            "Make prediction for 5010 samples...\n",
            "0.25533396 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 367 [0/25046 (0%)]\tLoss: 0.113745\n",
            "Train epoch: 367 [327360/25046 (41%)]\tLoss: 0.112717\n",
            "Train epoch: 367 [665440/25046 (82%)]\tLoss: 0.108872\n",
            "Make prediction for 5010 samples...\n",
            "0.26171008 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 368 [0/25046 (0%)]\tLoss: 0.121998\n",
            "Train epoch: 368 [328940/25046 (41%)]\tLoss: 0.128027\n",
            "Train epoch: 368 [663440/25046 (82%)]\tLoss: 0.115898\n",
            "Make prediction for 5010 samples...\n",
            "0.24056377 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 369 [0/25046 (0%)]\tLoss: 0.113863\n",
            "Train epoch: 369 [330080/25046 (41%)]\tLoss: 0.121334\n",
            "Train epoch: 369 [666680/25046 (82%)]\tLoss: 0.122757\n",
            "Make prediction for 5010 samples...\n",
            "0.23976968 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 370 [0/25046 (0%)]\tLoss: 0.110145\n",
            "Train epoch: 370 [324660/25046 (41%)]\tLoss: 0.113337\n",
            "Train epoch: 370 [657120/25046 (82%)]\tLoss: 0.117154\n",
            "Make prediction for 5010 samples...\n",
            "0.23984028 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 371 [0/25046 (0%)]\tLoss: 0.122079\n",
            "Train epoch: 371 [326220/25046 (41%)]\tLoss: 0.099167\n",
            "Train epoch: 371 [659840/25046 (82%)]\tLoss: 0.100881\n",
            "Make prediction for 5010 samples...\n",
            "0.26864627 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 372 [0/25046 (0%)]\tLoss: 0.126043\n",
            "Train epoch: 372 [325680/25046 (41%)]\tLoss: 0.114640\n",
            "Train epoch: 372 [654440/25046 (82%)]\tLoss: 0.104598\n",
            "Make prediction for 5010 samples...\n",
            "0.25768334 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 373 [0/25046 (0%)]\tLoss: 0.110911\n",
            "Train epoch: 373 [326740/25046 (41%)]\tLoss: 0.108593\n",
            "Train epoch: 373 [647840/25046 (82%)]\tLoss: 0.144490\n",
            "Make prediction for 5010 samples...\n",
            "0.25417438 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 374 [0/25046 (0%)]\tLoss: 0.126942\n",
            "Train epoch: 374 [332660/25046 (41%)]\tLoss: 0.098707\n",
            "Train epoch: 374 [659880/25046 (82%)]\tLoss: 0.103009\n",
            "Make prediction for 5010 samples...\n",
            "0.24495062 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 375 [0/25046 (0%)]\tLoss: 0.106840\n",
            "Train epoch: 375 [325800/25046 (41%)]\tLoss: 0.113633\n",
            "Train epoch: 375 [650000/25046 (82%)]\tLoss: 0.117135\n",
            "Make prediction for 5010 samples...\n",
            "0.2461024 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 376 [0/25046 (0%)]\tLoss: 0.125275\n",
            "Train epoch: 376 [329200/25046 (41%)]\tLoss: 0.109255\n",
            "Train epoch: 376 [650760/25046 (82%)]\tLoss: 0.098786\n",
            "Make prediction for 5010 samples...\n",
            "0.24134019 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 377 [0/25046 (0%)]\tLoss: 0.126982\n",
            "Train epoch: 377 [320420/25046 (41%)]\tLoss: 0.101710\n",
            "Train epoch: 377 [660800/25046 (82%)]\tLoss: 0.120569\n",
            "Make prediction for 5010 samples...\n",
            "0.2617363 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 378 [0/25046 (0%)]\tLoss: 0.127124\n",
            "Train epoch: 378 [331580/25046 (41%)]\tLoss: 0.141813\n",
            "Train epoch: 378 [658880/25046 (82%)]\tLoss: 0.111232\n",
            "Make prediction for 5010 samples...\n",
            "0.25371277 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 379 [0/25046 (0%)]\tLoss: 0.111079\n",
            "Train epoch: 379 [329380/25046 (41%)]\tLoss: 0.126265\n",
            "Train epoch: 379 [659000/25046 (82%)]\tLoss: 0.108111\n",
            "Make prediction for 5010 samples...\n",
            "0.2465381 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 380 [0/25046 (0%)]\tLoss: 0.102707\n",
            "Train epoch: 380 [330020/25046 (41%)]\tLoss: 0.124887\n",
            "Train epoch: 380 [654320/25046 (82%)]\tLoss: 0.105355\n",
            "Make prediction for 5010 samples...\n",
            "0.25801557 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 381 [0/25046 (0%)]\tLoss: 0.095480\n",
            "Train epoch: 381 [329800/25046 (41%)]\tLoss: 0.099488\n",
            "Train epoch: 381 [662960/25046 (82%)]\tLoss: 0.103806\n",
            "Make prediction for 5010 samples...\n",
            "0.24449797 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 382 [0/25046 (0%)]\tLoss: 0.126260\n",
            "Train epoch: 382 [324520/25046 (41%)]\tLoss: 0.102016\n",
            "Train epoch: 382 [658640/25046 (82%)]\tLoss: 0.147170\n",
            "Make prediction for 5010 samples...\n",
            "0.2453779 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 383 [0/25046 (0%)]\tLoss: 0.125343\n",
            "Train epoch: 383 [327160/25046 (41%)]\tLoss: 0.099450\n",
            "Train epoch: 383 [657760/25046 (82%)]\tLoss: 0.112994\n",
            "Make prediction for 5010 samples...\n",
            "0.23756543 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 384 [0/25046 (0%)]\tLoss: 0.110661\n",
            "Train epoch: 384 [327360/25046 (41%)]\tLoss: 0.102771\n",
            "Train epoch: 384 [647760/25046 (82%)]\tLoss: 0.115506\n",
            "Make prediction for 5010 samples...\n",
            "0.3150351 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 385 [0/25046 (0%)]\tLoss: 0.150746\n",
            "Train epoch: 385 [328680/25046 (41%)]\tLoss: 0.128951\n",
            "Train epoch: 385 [659720/25046 (82%)]\tLoss: 0.113768\n",
            "Make prediction for 5010 samples...\n",
            "0.24605793 No improvement since epoch  294 ; best_mse,best_ci: 0.23319615 0.8878014369701014 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 386 [0/25046 (0%)]\tLoss: 0.092713\n",
            "Train epoch: 386 [325120/25046 (41%)]\tLoss: 0.119681\n",
            "Train epoch: 386 [658040/25046 (82%)]\tLoss: 0.096811\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 387 [0/25046 (0%)]\tLoss: 0.117109\n",
            "Train epoch: 387 [329780/25046 (41%)]\tLoss: 0.114087\n",
            "Train epoch: 387 [655240/25046 (82%)]\tLoss: 0.110059\n",
            "Make prediction for 5010 samples...\n",
            "0.24156797 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 388 [0/25046 (0%)]\tLoss: 0.131246\n",
            "Train epoch: 388 [328880/25046 (41%)]\tLoss: 0.100482\n",
            "Train epoch: 388 [659720/25046 (82%)]\tLoss: 0.111338\n",
            "Make prediction for 5010 samples...\n",
            "0.2464453 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 389 [0/25046 (0%)]\tLoss: 0.105351\n",
            "Train epoch: 389 [327700/25046 (41%)]\tLoss: 0.126382\n",
            "Train epoch: 389 [655480/25046 (82%)]\tLoss: 0.124240\n",
            "Make prediction for 5010 samples...\n",
            "0.2667102 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 390 [0/25046 (0%)]\tLoss: 0.090539\n",
            "Train epoch: 390 [327740/25046 (41%)]\tLoss: 0.095183\n",
            "Train epoch: 390 [660760/25046 (82%)]\tLoss: 0.140293\n",
            "Make prediction for 5010 samples...\n",
            "0.24242263 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 391 [0/25046 (0%)]\tLoss: 0.128251\n",
            "Train epoch: 391 [325880/25046 (41%)]\tLoss: 0.128684\n",
            "Train epoch: 391 [654520/25046 (82%)]\tLoss: 0.122990\n",
            "Make prediction for 5010 samples...\n",
            "0.25344437 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 392 [0/25046 (0%)]\tLoss: 0.109984\n",
            "Train epoch: 392 [330380/25046 (41%)]\tLoss: 0.113489\n",
            "Train epoch: 392 [648720/25046 (82%)]\tLoss: 0.097153\n",
            "Make prediction for 5010 samples...\n",
            "0.25001293 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 393 [0/25046 (0%)]\tLoss: 0.091226\n",
            "Train epoch: 393 [326440/25046 (41%)]\tLoss: 0.118796\n",
            "Train epoch: 393 [651840/25046 (82%)]\tLoss: 0.131212\n",
            "Make prediction for 5010 samples...\n",
            "0.25606796 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 394 [0/25046 (0%)]\tLoss: 0.132213\n",
            "Train epoch: 394 [324440/25046 (41%)]\tLoss: 0.108502\n",
            "Train epoch: 394 [655760/25046 (82%)]\tLoss: 0.136567\n",
            "Make prediction for 5010 samples...\n",
            "0.28734165 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 395 [0/25046 (0%)]\tLoss: 0.134529\n",
            "Train epoch: 395 [329980/25046 (41%)]\tLoss: 0.120943\n",
            "Train epoch: 395 [660160/25046 (82%)]\tLoss: 0.117733\n",
            "Make prediction for 5010 samples...\n",
            "0.2446362 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 396 [0/25046 (0%)]\tLoss: 0.113055\n",
            "Train epoch: 396 [326560/25046 (41%)]\tLoss: 0.118716\n",
            "Train epoch: 396 [657800/25046 (82%)]\tLoss: 0.126855\n",
            "Make prediction for 5010 samples...\n",
            "0.24020736 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 397 [0/25046 (0%)]\tLoss: 0.110052\n",
            "Train epoch: 397 [327880/25046 (41%)]\tLoss: 0.122765\n",
            "Train epoch: 397 [668040/25046 (82%)]\tLoss: 0.088697\n",
            "Make prediction for 5010 samples...\n",
            "0.24411154 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 398 [0/25046 (0%)]\tLoss: 0.129424\n",
            "Train epoch: 398 [327220/25046 (41%)]\tLoss: 0.117209\n",
            "Train epoch: 398 [652080/25046 (82%)]\tLoss: 0.107942\n",
            "Make prediction for 5010 samples...\n",
            "0.24636406 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 399 [0/25046 (0%)]\tLoss: 0.117076\n",
            "Train epoch: 399 [329180/25046 (41%)]\tLoss: 0.184074\n",
            "Train epoch: 399 [652560/25046 (82%)]\tLoss: 0.089925\n",
            "Make prediction for 5010 samples...\n",
            "0.26521906 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 400 [0/25046 (0%)]\tLoss: 0.085084\n",
            "Train epoch: 400 [331300/25046 (41%)]\tLoss: 0.123237\n",
            "Train epoch: 400 [662760/25046 (82%)]\tLoss: 0.115572\n",
            "Make prediction for 5010 samples...\n",
            "0.24057388 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 401 [0/25046 (0%)]\tLoss: 0.128995\n",
            "Train epoch: 401 [331000/25046 (41%)]\tLoss: 0.114042\n",
            "Train epoch: 401 [661600/25046 (82%)]\tLoss: 0.133040\n",
            "Make prediction for 5010 samples...\n",
            "0.24154784 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 402 [0/25046 (0%)]\tLoss: 0.099484\n",
            "Train epoch: 402 [331200/25046 (41%)]\tLoss: 0.128006\n",
            "Train epoch: 402 [652720/25046 (82%)]\tLoss: 0.119620\n",
            "Make prediction for 5010 samples...\n",
            "0.23786412 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 403 [0/25046 (0%)]\tLoss: 0.105520\n",
            "Train epoch: 403 [329300/25046 (41%)]\tLoss: 0.110311\n",
            "Train epoch: 403 [658360/25046 (82%)]\tLoss: 0.148607\n",
            "Make prediction for 5010 samples...\n",
            "0.24289039 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 404 [0/25046 (0%)]\tLoss: 0.131140\n",
            "Train epoch: 404 [330360/25046 (41%)]\tLoss: 0.113822\n",
            "Train epoch: 404 [648440/25046 (82%)]\tLoss: 0.115045\n",
            "Make prediction for 5010 samples...\n",
            "0.23980878 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 405 [0/25046 (0%)]\tLoss: 0.108652\n",
            "Train epoch: 405 [330740/25046 (41%)]\tLoss: 0.100324\n",
            "Train epoch: 405 [653800/25046 (82%)]\tLoss: 0.123298\n",
            "Make prediction for 5010 samples...\n",
            "0.2674427 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 406 [0/25046 (0%)]\tLoss: 0.120518\n",
            "Train epoch: 406 [327760/25046 (41%)]\tLoss: 0.108502\n",
            "Train epoch: 406 [652920/25046 (82%)]\tLoss: 0.098230\n",
            "Make prediction for 5010 samples...\n",
            "0.25104615 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 407 [0/25046 (0%)]\tLoss: 0.084755\n",
            "Train epoch: 407 [330360/25046 (41%)]\tLoss: 0.107094\n",
            "Train epoch: 407 [665800/25046 (82%)]\tLoss: 0.134303\n",
            "Make prediction for 5010 samples...\n",
            "0.24037586 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 408 [0/25046 (0%)]\tLoss: 0.106976\n",
            "Train epoch: 408 [326000/25046 (41%)]\tLoss: 0.142690\n",
            "Train epoch: 408 [660640/25046 (82%)]\tLoss: 0.102440\n",
            "Make prediction for 5010 samples...\n",
            "0.25697324 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 409 [0/25046 (0%)]\tLoss: 0.144610\n",
            "Train epoch: 409 [328140/25046 (41%)]\tLoss: 0.108142\n",
            "Train epoch: 409 [655720/25046 (82%)]\tLoss: 0.115678\n",
            "Make prediction for 5010 samples...\n",
            "0.238172 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 410 [0/25046 (0%)]\tLoss: 0.109790\n",
            "Train epoch: 410 [325880/25046 (41%)]\tLoss: 0.104653\n",
            "Train epoch: 410 [662440/25046 (82%)]\tLoss: 0.154167\n",
            "Make prediction for 5010 samples...\n",
            "0.2775746 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 411 [0/25046 (0%)]\tLoss: 0.094094\n",
            "Train epoch: 411 [333640/25046 (41%)]\tLoss: 0.095952\n",
            "Train epoch: 411 [659280/25046 (82%)]\tLoss: 0.129045\n",
            "Make prediction for 5010 samples...\n",
            "0.24210057 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 412 [0/25046 (0%)]\tLoss: 0.083896\n",
            "Train epoch: 412 [324700/25046 (41%)]\tLoss: 0.121077\n",
            "Train epoch: 412 [666080/25046 (82%)]\tLoss: 0.134794\n",
            "Make prediction for 5010 samples...\n",
            "0.24703442 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 413 [0/25046 (0%)]\tLoss: 0.095611\n",
            "Train epoch: 413 [323560/25046 (41%)]\tLoss: 0.163444\n",
            "Train epoch: 413 [658200/25046 (82%)]\tLoss: 0.116740\n",
            "Make prediction for 5010 samples...\n",
            "0.25026557 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 414 [0/25046 (0%)]\tLoss: 0.090090\n",
            "Train epoch: 414 [326000/25046 (41%)]\tLoss: 0.089895\n",
            "Train epoch: 414 [650840/25046 (82%)]\tLoss: 0.100392\n",
            "Make prediction for 5010 samples...\n",
            "0.2407118 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 415 [0/25046 (0%)]\tLoss: 0.091251\n",
            "Train epoch: 415 [326120/25046 (41%)]\tLoss: 0.103597\n",
            "Train epoch: 415 [657880/25046 (82%)]\tLoss: 0.131340\n",
            "Make prediction for 5010 samples...\n",
            "0.24465218 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 416 [0/25046 (0%)]\tLoss: 0.139949\n",
            "Train epoch: 416 [325380/25046 (41%)]\tLoss: 0.111317\n",
            "Train epoch: 416 [663920/25046 (82%)]\tLoss: 0.150515\n",
            "Make prediction for 5010 samples...\n",
            "0.2556858 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 417 [0/25046 (0%)]\tLoss: 0.145968\n",
            "Train epoch: 417 [330760/25046 (41%)]\tLoss: 0.109865\n",
            "Train epoch: 417 [655440/25046 (82%)]\tLoss: 0.124381\n",
            "Make prediction for 5010 samples...\n",
            "0.24332015 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 418 [0/25046 (0%)]\tLoss: 0.087672\n",
            "Train epoch: 418 [334920/25046 (41%)]\tLoss: 0.108685\n",
            "Train epoch: 418 [659880/25046 (82%)]\tLoss: 0.116745\n",
            "Make prediction for 5010 samples...\n",
            "0.23957273 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 419 [0/25046 (0%)]\tLoss: 0.084412\n",
            "Train epoch: 419 [332740/25046 (41%)]\tLoss: 0.110581\n",
            "Train epoch: 419 [668400/25046 (82%)]\tLoss: 0.098249\n",
            "Make prediction for 5010 samples...\n",
            "0.23874368 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 420 [0/25046 (0%)]\tLoss: 0.123848\n",
            "Train epoch: 420 [329680/25046 (41%)]\tLoss: 0.096761\n",
            "Train epoch: 420 [660640/25046 (82%)]\tLoss: 0.082218\n",
            "Make prediction for 5010 samples...\n",
            "0.286842 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 421 [0/25046 (0%)]\tLoss: 0.147462\n",
            "Train epoch: 421 [328800/25046 (41%)]\tLoss: 0.096362\n",
            "Train epoch: 421 [655200/25046 (82%)]\tLoss: 0.118475\n",
            "Make prediction for 5010 samples...\n",
            "0.25051135 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 422 [0/25046 (0%)]\tLoss: 0.096346\n",
            "Train epoch: 422 [330640/25046 (41%)]\tLoss: 0.108436\n",
            "Train epoch: 422 [657960/25046 (82%)]\tLoss: 0.130407\n",
            "Make prediction for 5010 samples...\n",
            "0.26066664 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 423 [0/25046 (0%)]\tLoss: 0.126772\n",
            "Train epoch: 423 [328660/25046 (41%)]\tLoss: 0.165619\n",
            "Train epoch: 423 [651560/25046 (82%)]\tLoss: 0.106866\n",
            "Make prediction for 5010 samples...\n",
            "0.24331996 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 424 [0/25046 (0%)]\tLoss: 0.103786\n",
            "Train epoch: 424 [329100/25046 (41%)]\tLoss: 0.107372\n",
            "Train epoch: 424 [649920/25046 (82%)]\tLoss: 0.094314\n",
            "Make prediction for 5010 samples...\n",
            "0.24775639 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 425 [0/25046 (0%)]\tLoss: 0.115202\n",
            "Train epoch: 425 [331740/25046 (41%)]\tLoss: 0.100419\n",
            "Train epoch: 425 [650640/25046 (82%)]\tLoss: 0.117066\n",
            "Make prediction for 5010 samples...\n",
            "0.25714833 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 426 [0/25046 (0%)]\tLoss: 0.116778\n",
            "Train epoch: 426 [328560/25046 (41%)]\tLoss: 0.127656\n",
            "Train epoch: 426 [657800/25046 (82%)]\tLoss: 0.114939\n",
            "Make prediction for 5010 samples...\n",
            "0.2465085 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 427 [0/25046 (0%)]\tLoss: 0.091961\n",
            "Train epoch: 427 [332220/25046 (41%)]\tLoss: 0.122307\n",
            "Train epoch: 427 [664480/25046 (82%)]\tLoss: 0.111672\n",
            "Make prediction for 5010 samples...\n",
            "0.24214664 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 428 [0/25046 (0%)]\tLoss: 0.095904\n",
            "Train epoch: 428 [328620/25046 (41%)]\tLoss: 0.130007\n",
            "Train epoch: 428 [659760/25046 (82%)]\tLoss: 0.145420\n",
            "Make prediction for 5010 samples...\n",
            "0.23491557 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 429 [0/25046 (0%)]\tLoss: 0.124661\n",
            "Train epoch: 429 [331580/25046 (41%)]\tLoss: 0.133459\n",
            "Train epoch: 429 [656160/25046 (82%)]\tLoss: 0.117387\n",
            "Make prediction for 5010 samples...\n",
            "0.23455593 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 430 [0/25046 (0%)]\tLoss: 0.093177\n",
            "Train epoch: 430 [329960/25046 (41%)]\tLoss: 0.138770\n",
            "Train epoch: 430 [655040/25046 (82%)]\tLoss: 0.092659\n",
            "Make prediction for 5010 samples...\n",
            "0.24522805 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 431 [0/25046 (0%)]\tLoss: 0.140941\n",
            "Train epoch: 431 [328240/25046 (41%)]\tLoss: 0.087335\n",
            "Train epoch: 431 [663320/25046 (82%)]\tLoss: 0.098097\n",
            "Make prediction for 5010 samples...\n",
            "0.24375568 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 432 [0/25046 (0%)]\tLoss: 0.136063\n",
            "Train epoch: 432 [324780/25046 (41%)]\tLoss: 0.087209\n",
            "Train epoch: 432 [647680/25046 (82%)]\tLoss: 0.108915\n",
            "Make prediction for 5010 samples...\n",
            "0.2408168 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 433 [0/25046 (0%)]\tLoss: 0.093615\n",
            "Train epoch: 433 [330460/25046 (41%)]\tLoss: 0.101499\n",
            "Train epoch: 433 [655080/25046 (82%)]\tLoss: 0.092004\n",
            "Make prediction for 5010 samples...\n",
            "0.23891127 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 434 [0/25046 (0%)]\tLoss: 0.088948\n",
            "Train epoch: 434 [332600/25046 (41%)]\tLoss: 0.113245\n",
            "Train epoch: 434 [656720/25046 (82%)]\tLoss: 0.083310\n",
            "Make prediction for 5010 samples...\n",
            "0.26285943 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 435 [0/25046 (0%)]\tLoss: 0.159005\n",
            "Train epoch: 435 [328820/25046 (41%)]\tLoss: 0.139692\n",
            "Train epoch: 435 [658560/25046 (82%)]\tLoss: 0.130718\n",
            "Make prediction for 5010 samples...\n",
            "0.23791246 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 436 [0/25046 (0%)]\tLoss: 0.103813\n",
            "Train epoch: 436 [331700/25046 (41%)]\tLoss: 0.095543\n",
            "Train epoch: 436 [650160/25046 (82%)]\tLoss: 0.086038\n",
            "Make prediction for 5010 samples...\n",
            "0.2473395 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 437 [0/25046 (0%)]\tLoss: 0.091701\n",
            "Train epoch: 437 [327920/25046 (41%)]\tLoss: 0.080917\n",
            "Train epoch: 437 [660400/25046 (82%)]\tLoss: 0.136657\n",
            "Make prediction for 5010 samples...\n",
            "0.24013755 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 438 [0/25046 (0%)]\tLoss: 0.120026\n",
            "Train epoch: 438 [324200/25046 (41%)]\tLoss: 0.086856\n",
            "Train epoch: 438 [653800/25046 (82%)]\tLoss: 0.096475\n",
            "Make prediction for 5010 samples...\n",
            "0.25683385 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 439 [0/25046 (0%)]\tLoss: 0.119779\n",
            "Train epoch: 439 [327760/25046 (41%)]\tLoss: 0.110324\n",
            "Train epoch: 439 [660200/25046 (82%)]\tLoss: 0.092000\n",
            "Make prediction for 5010 samples...\n",
            "0.26360542 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 440 [0/25046 (0%)]\tLoss: 0.096288\n",
            "Train epoch: 440 [324740/25046 (41%)]\tLoss: 0.096054\n",
            "Train epoch: 440 [656240/25046 (82%)]\tLoss: 0.084029\n",
            "Make prediction for 5010 samples...\n",
            "0.24278426 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 441 [0/25046 (0%)]\tLoss: 0.090938\n",
            "Train epoch: 441 [327900/25046 (41%)]\tLoss: 0.113296\n",
            "Train epoch: 441 [665960/25046 (82%)]\tLoss: 0.107617\n",
            "Make prediction for 5010 samples...\n",
            "0.2517944 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 442 [0/25046 (0%)]\tLoss: 0.128793\n",
            "Train epoch: 442 [326200/25046 (41%)]\tLoss: 0.149691\n",
            "Train epoch: 442 [668360/25046 (82%)]\tLoss: 0.106649\n",
            "Make prediction for 5010 samples...\n",
            "0.27684835 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 443 [0/25046 (0%)]\tLoss: 0.112340\n",
            "Train epoch: 443 [327600/25046 (41%)]\tLoss: 0.105174\n",
            "Train epoch: 443 [657480/25046 (82%)]\tLoss: 0.130230\n",
            "Make prediction for 5010 samples...\n",
            "0.25327086 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 444 [0/25046 (0%)]\tLoss: 0.107583\n",
            "Train epoch: 444 [327280/25046 (41%)]\tLoss: 0.085047\n",
            "Train epoch: 444 [661280/25046 (82%)]\tLoss: 0.120051\n",
            "Make prediction for 5010 samples...\n",
            "0.24278995 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 445 [0/25046 (0%)]\tLoss: 0.086790\n",
            "Train epoch: 445 [330440/25046 (41%)]\tLoss: 0.088915\n",
            "Train epoch: 445 [657120/25046 (82%)]\tLoss: 0.095021\n",
            "Make prediction for 5010 samples...\n",
            "0.24564096 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 446 [0/25046 (0%)]\tLoss: 0.099510\n",
            "Train epoch: 446 [326360/25046 (41%)]\tLoss: 0.124100\n",
            "Train epoch: 446 [661880/25046 (82%)]\tLoss: 0.105241\n",
            "Make prediction for 5010 samples...\n",
            "0.24026507 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 447 [0/25046 (0%)]\tLoss: 0.072641\n",
            "Train epoch: 447 [328740/25046 (41%)]\tLoss: 0.119759\n",
            "Train epoch: 447 [665120/25046 (82%)]\tLoss: 0.107263\n",
            "Make prediction for 5010 samples...\n",
            "0.23863328 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 448 [0/25046 (0%)]\tLoss: 0.109388\n",
            "Train epoch: 448 [331840/25046 (41%)]\tLoss: 0.100434\n",
            "Train epoch: 448 [655000/25046 (82%)]\tLoss: 0.133983\n",
            "Make prediction for 5010 samples...\n",
            "0.24547143 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 449 [0/25046 (0%)]\tLoss: 0.107262\n",
            "Train epoch: 449 [330020/25046 (41%)]\tLoss: 0.099456\n",
            "Train epoch: 449 [655880/25046 (82%)]\tLoss: 0.150279\n",
            "Make prediction for 5010 samples...\n",
            "0.26841867 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 450 [0/25046 (0%)]\tLoss: 0.159246\n",
            "Train epoch: 450 [326940/25046 (41%)]\tLoss: 0.090681\n",
            "Train epoch: 450 [662720/25046 (82%)]\tLoss: 0.089712\n",
            "Make prediction for 5010 samples...\n",
            "0.25612763 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 451 [0/25046 (0%)]\tLoss: 0.091583\n",
            "Train epoch: 451 [329360/25046 (41%)]\tLoss: 0.086449\n",
            "Train epoch: 451 [658560/25046 (82%)]\tLoss: 0.100275\n",
            "Make prediction for 5010 samples...\n",
            "0.25448498 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 452 [0/25046 (0%)]\tLoss: 0.108550\n",
            "Train epoch: 452 [327620/25046 (41%)]\tLoss: 0.096576\n",
            "Train epoch: 452 [660120/25046 (82%)]\tLoss: 0.115245\n",
            "Make prediction for 5010 samples...\n",
            "0.24405979 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 453 [0/25046 (0%)]\tLoss: 0.084282\n",
            "Train epoch: 453 [333160/25046 (41%)]\tLoss: 0.081374\n",
            "Train epoch: 453 [647840/25046 (82%)]\tLoss: 0.089699\n",
            "Make prediction for 5010 samples...\n",
            "0.25087118 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 454 [0/25046 (0%)]\tLoss: 0.065670\n",
            "Train epoch: 454 [333360/25046 (41%)]\tLoss: 0.137325\n",
            "Train epoch: 454 [651800/25046 (82%)]\tLoss: 0.101137\n",
            "Make prediction for 5010 samples...\n",
            "0.26847953 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 455 [0/25046 (0%)]\tLoss: 0.108553\n",
            "Train epoch: 455 [326700/25046 (41%)]\tLoss: 0.099160\n",
            "Train epoch: 455 [655760/25046 (82%)]\tLoss: 0.087790\n",
            "Make prediction for 5010 samples...\n",
            "0.24228583 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 456 [0/25046 (0%)]\tLoss: 0.104410\n",
            "Train epoch: 456 [328100/25046 (41%)]\tLoss: 0.119735\n",
            "Train epoch: 456 [650000/25046 (82%)]\tLoss: 0.086724\n",
            "Make prediction for 5010 samples...\n",
            "0.25213245 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 457 [0/25046 (0%)]\tLoss: 0.133399\n",
            "Train epoch: 457 [330300/25046 (41%)]\tLoss: 0.127987\n",
            "Train epoch: 457 [660160/25046 (82%)]\tLoss: 0.151834\n",
            "Make prediction for 5010 samples...\n",
            "0.23982465 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 458 [0/25046 (0%)]\tLoss: 0.104344\n",
            "Train epoch: 458 [326760/25046 (41%)]\tLoss: 0.098612\n",
            "Train epoch: 458 [654600/25046 (82%)]\tLoss: 0.108956\n",
            "Make prediction for 5010 samples...\n",
            "0.24267071 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 459 [0/25046 (0%)]\tLoss: 0.088424\n",
            "Train epoch: 459 [325780/25046 (41%)]\tLoss: 0.096745\n",
            "Train epoch: 459 [654840/25046 (82%)]\tLoss: 0.130326\n",
            "Make prediction for 5010 samples...\n",
            "0.23753557 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 460 [0/25046 (0%)]\tLoss: 0.091916\n",
            "Train epoch: 460 [331500/25046 (41%)]\tLoss: 0.079506\n",
            "Train epoch: 460 [661040/25046 (82%)]\tLoss: 0.091685\n",
            "Make prediction for 5010 samples...\n",
            "0.23804605 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 461 [0/25046 (0%)]\tLoss: 0.107428\n",
            "Train epoch: 461 [328140/25046 (41%)]\tLoss: 0.107504\n",
            "Train epoch: 461 [659840/25046 (82%)]\tLoss: 0.162919\n",
            "Make prediction for 5010 samples...\n",
            "0.2529668 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 462 [0/25046 (0%)]\tLoss: 0.104625\n",
            "Train epoch: 462 [328620/25046 (41%)]\tLoss: 0.112470\n",
            "Train epoch: 462 [649960/25046 (82%)]\tLoss: 0.094144\n",
            "Make prediction for 5010 samples...\n",
            "0.25055045 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 463 [0/25046 (0%)]\tLoss: 0.117125\n",
            "Train epoch: 463 [328120/25046 (41%)]\tLoss: 0.102289\n",
            "Train epoch: 463 [667320/25046 (82%)]\tLoss: 0.118986\n",
            "Make prediction for 5010 samples...\n",
            "0.24161083 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 464 [0/25046 (0%)]\tLoss: 0.100966\n",
            "Train epoch: 464 [329140/25046 (41%)]\tLoss: 0.108106\n",
            "Train epoch: 464 [653840/25046 (82%)]\tLoss: 0.112684\n",
            "Make prediction for 5010 samples...\n",
            "0.24187404 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 465 [0/25046 (0%)]\tLoss: 0.118134\n",
            "Train epoch: 465 [327020/25046 (41%)]\tLoss: 0.111227\n",
            "Train epoch: 465 [645800/25046 (82%)]\tLoss: 0.096411\n",
            "Make prediction for 5010 samples...\n",
            "0.23979086 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 466 [0/25046 (0%)]\tLoss: 0.140120\n",
            "Train epoch: 466 [331420/25046 (41%)]\tLoss: 0.091718\n",
            "Train epoch: 466 [655720/25046 (82%)]\tLoss: 0.111083\n",
            "Make prediction for 5010 samples...\n",
            "0.2627946 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 467 [0/25046 (0%)]\tLoss: 0.111189\n",
            "Train epoch: 467 [325440/25046 (41%)]\tLoss: 0.092997\n",
            "Train epoch: 467 [657600/25046 (82%)]\tLoss: 0.115332\n",
            "Make prediction for 5010 samples...\n",
            "0.2379303 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 468 [0/25046 (0%)]\tLoss: 0.085680\n",
            "Train epoch: 468 [327400/25046 (41%)]\tLoss: 0.101429\n",
            "Train epoch: 468 [658800/25046 (82%)]\tLoss: 0.114110\n",
            "Make prediction for 5010 samples...\n",
            "0.24672861 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 469 [0/25046 (0%)]\tLoss: 0.079689\n",
            "Train epoch: 469 [329140/25046 (41%)]\tLoss: 0.084411\n",
            "Train epoch: 469 [643080/25046 (82%)]\tLoss: 0.124225\n",
            "Make prediction for 5010 samples...\n",
            "0.24394587 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 470 [0/25046 (0%)]\tLoss: 0.091022\n",
            "Train epoch: 470 [329320/25046 (41%)]\tLoss: 0.119214\n",
            "Train epoch: 470 [661720/25046 (82%)]\tLoss: 0.107976\n",
            "Make prediction for 5010 samples...\n",
            "0.26519707 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 471 [0/25046 (0%)]\tLoss: 0.132068\n",
            "Train epoch: 471 [324040/25046 (41%)]\tLoss: 0.126709\n",
            "Train epoch: 471 [662480/25046 (82%)]\tLoss: 0.118240\n",
            "Make prediction for 5010 samples...\n",
            "0.2415514 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 472 [0/25046 (0%)]\tLoss: 0.104039\n",
            "Train epoch: 472 [326540/25046 (41%)]\tLoss: 0.090316\n",
            "Train epoch: 472 [660360/25046 (82%)]\tLoss: 0.166732\n",
            "Make prediction for 5010 samples...\n",
            "0.27418867 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 473 [0/25046 (0%)]\tLoss: 0.110131\n",
            "Train epoch: 473 [328680/25046 (41%)]\tLoss: 0.101359\n",
            "Train epoch: 473 [655360/25046 (82%)]\tLoss: 0.112767\n",
            "Make prediction for 5010 samples...\n",
            "0.27880737 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 474 [0/25046 (0%)]\tLoss: 0.110175\n",
            "Train epoch: 474 [329200/25046 (41%)]\tLoss: 0.105350\n",
            "Train epoch: 474 [661320/25046 (82%)]\tLoss: 0.092550\n",
            "Make prediction for 5010 samples...\n",
            "0.23717938 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 475 [0/25046 (0%)]\tLoss: 0.097862\n",
            "Train epoch: 475 [329320/25046 (41%)]\tLoss: 0.083612\n",
            "Train epoch: 475 [650120/25046 (82%)]\tLoss: 0.093051\n",
            "Make prediction for 5010 samples...\n",
            "0.24411201 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 476 [0/25046 (0%)]\tLoss: 0.082326\n",
            "Train epoch: 476 [329380/25046 (41%)]\tLoss: 0.095066\n",
            "Train epoch: 476 [666240/25046 (82%)]\tLoss: 0.113583\n",
            "Make prediction for 5010 samples...\n",
            "0.24045645 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 477 [0/25046 (0%)]\tLoss: 0.122209\n",
            "Train epoch: 477 [327320/25046 (41%)]\tLoss: 0.127377\n",
            "Train epoch: 477 [656800/25046 (82%)]\tLoss: 0.115498\n",
            "Make prediction for 5010 samples...\n",
            "0.35022962 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 478 [0/25046 (0%)]\tLoss: 0.160257\n",
            "Train epoch: 478 [326080/25046 (41%)]\tLoss: 0.094570\n",
            "Train epoch: 478 [652200/25046 (82%)]\tLoss: 0.092915\n",
            "Make prediction for 5010 samples...\n",
            "0.2566749 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 479 [0/25046 (0%)]\tLoss: 0.133234\n",
            "Train epoch: 479 [329920/25046 (41%)]\tLoss: 0.104916\n",
            "Train epoch: 479 [665400/25046 (82%)]\tLoss: 0.105525\n",
            "Make prediction for 5010 samples...\n",
            "0.24090953 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 480 [0/25046 (0%)]\tLoss: 0.066617\n",
            "Train epoch: 480 [332080/25046 (41%)]\tLoss: 0.149128\n",
            "Train epoch: 480 [669480/25046 (82%)]\tLoss: 0.122882\n",
            "Make prediction for 5010 samples...\n",
            "0.24240723 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 481 [0/25046 (0%)]\tLoss: 0.092057\n",
            "Train epoch: 481 [325100/25046 (41%)]\tLoss: 0.107667\n",
            "Train epoch: 481 [662120/25046 (82%)]\tLoss: 0.107840\n",
            "Make prediction for 5010 samples...\n",
            "0.27073064 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 482 [0/25046 (0%)]\tLoss: 0.096505\n",
            "Train epoch: 482 [329000/25046 (41%)]\tLoss: 0.119706\n",
            "Train epoch: 482 [660360/25046 (82%)]\tLoss: 0.098577\n",
            "Make prediction for 5010 samples...\n",
            "0.24432531 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 483 [0/25046 (0%)]\tLoss: 0.090031\n",
            "Train epoch: 483 [330720/25046 (41%)]\tLoss: 0.126217\n",
            "Train epoch: 483 [656520/25046 (82%)]\tLoss: 0.120274\n",
            "Make prediction for 5010 samples...\n",
            "0.24305773 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 484 [0/25046 (0%)]\tLoss: 0.093066\n",
            "Train epoch: 484 [330240/25046 (41%)]\tLoss: 0.101653\n",
            "Train epoch: 484 [654640/25046 (82%)]\tLoss: 0.087485\n",
            "Make prediction for 5010 samples...\n",
            "0.23781952 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 485 [0/25046 (0%)]\tLoss: 0.108146\n",
            "Train epoch: 485 [329160/25046 (41%)]\tLoss: 0.110581\n",
            "Train epoch: 485 [646560/25046 (82%)]\tLoss: 0.078917\n",
            "Make prediction for 5010 samples...\n",
            "0.28373614 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 486 [0/25046 (0%)]\tLoss: 0.125508\n",
            "Train epoch: 486 [326280/25046 (41%)]\tLoss: 0.114938\n",
            "Train epoch: 486 [653840/25046 (82%)]\tLoss: 0.104152\n",
            "Make prediction for 5010 samples...\n",
            "0.2377779 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 487 [0/25046 (0%)]\tLoss: 0.103491\n",
            "Train epoch: 487 [326460/25046 (41%)]\tLoss: 0.103572\n",
            "Train epoch: 487 [661400/25046 (82%)]\tLoss: 0.095302\n",
            "Make prediction for 5010 samples...\n",
            "0.2365056 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 488 [0/25046 (0%)]\tLoss: 0.090805\n",
            "Train epoch: 488 [329020/25046 (41%)]\tLoss: 0.099041\n",
            "Train epoch: 488 [657040/25046 (82%)]\tLoss: 0.110998\n",
            "Make prediction for 5010 samples...\n",
            "0.26895073 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 489 [0/25046 (0%)]\tLoss: 0.118862\n",
            "Train epoch: 489 [333400/25046 (41%)]\tLoss: 0.095689\n",
            "Train epoch: 489 [654560/25046 (82%)]\tLoss: 0.149038\n",
            "Make prediction for 5010 samples...\n",
            "0.25840768 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 490 [0/25046 (0%)]\tLoss: 0.093592\n",
            "Train epoch: 490 [325820/25046 (41%)]\tLoss: 0.096522\n",
            "Train epoch: 490 [654280/25046 (82%)]\tLoss: 0.098340\n",
            "Make prediction for 5010 samples...\n",
            "0.2376326 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 491 [0/25046 (0%)]\tLoss: 0.118527\n",
            "Train epoch: 491 [330260/25046 (41%)]\tLoss: 0.132863\n",
            "Train epoch: 491 [660800/25046 (82%)]\tLoss: 0.102251\n",
            "Make prediction for 5010 samples...\n",
            "0.25042775 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 492 [0/25046 (0%)]\tLoss: 0.101897\n",
            "Train epoch: 492 [330740/25046 (41%)]\tLoss: 0.134233\n",
            "Train epoch: 492 [653320/25046 (82%)]\tLoss: 0.099825\n",
            "Make prediction for 5010 samples...\n",
            "0.23745322 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 493 [0/25046 (0%)]\tLoss: 0.106336\n",
            "Train epoch: 493 [321620/25046 (41%)]\tLoss: 0.098669\n",
            "Train epoch: 493 [654880/25046 (82%)]\tLoss: 0.091040\n",
            "Make prediction for 5010 samples...\n",
            "0.23871885 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 494 [0/25046 (0%)]\tLoss: 0.112938\n",
            "Train epoch: 494 [325780/25046 (41%)]\tLoss: 0.134512\n",
            "Train epoch: 494 [656600/25046 (82%)]\tLoss: 0.113317\n",
            "Make prediction for 5010 samples...\n",
            "0.25674257 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 495 [0/25046 (0%)]\tLoss: 0.093489\n",
            "Train epoch: 495 [330000/25046 (41%)]\tLoss: 0.178208\n",
            "Train epoch: 495 [662200/25046 (82%)]\tLoss: 0.142442\n",
            "Make prediction for 5010 samples...\n",
            "0.2879765 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 496 [0/25046 (0%)]\tLoss: 0.110285\n",
            "Train epoch: 496 [330540/25046 (41%)]\tLoss: 0.081645\n",
            "Train epoch: 496 [657920/25046 (82%)]\tLoss: 0.089756\n",
            "Make prediction for 5010 samples...\n",
            "0.23385173 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 497 [0/25046 (0%)]\tLoss: 0.089315\n",
            "Train epoch: 497 [327120/25046 (41%)]\tLoss: 0.097143\n",
            "Train epoch: 497 [655120/25046 (82%)]\tLoss: 0.124491\n",
            "Make prediction for 5010 samples...\n",
            "0.23424369 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 498 [0/25046 (0%)]\tLoss: 0.093959\n",
            "Train epoch: 498 [327340/25046 (41%)]\tLoss: 0.085454\n",
            "Train epoch: 498 [659560/25046 (82%)]\tLoss: 0.111704\n",
            "Make prediction for 5010 samples...\n",
            "0.24570583 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 499 [0/25046 (0%)]\tLoss: 0.098400\n",
            "Train epoch: 499 [323220/25046 (41%)]\tLoss: 0.096283\n",
            "Train epoch: 499 [660000/25046 (82%)]\tLoss: 0.181244\n",
            "Make prediction for 5010 samples...\n",
            "0.26274267 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 500 [0/25046 (0%)]\tLoss: 0.101291\n",
            "Train epoch: 500 [323240/25046 (41%)]\tLoss: 0.099798\n",
            "Train epoch: 500 [657720/25046 (82%)]\tLoss: 0.115134\n",
            "Make prediction for 5010 samples...\n",
            "0.23680817 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 501 [0/25046 (0%)]\tLoss: 0.093763\n",
            "Train epoch: 501 [331080/25046 (41%)]\tLoss: 0.081228\n",
            "Train epoch: 501 [651640/25046 (82%)]\tLoss: 0.085472\n",
            "Make prediction for 5010 samples...\n",
            "0.25960296 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 502 [0/25046 (0%)]\tLoss: 0.118891\n",
            "Train epoch: 502 [325060/25046 (41%)]\tLoss: 0.085297\n",
            "Train epoch: 502 [658600/25046 (82%)]\tLoss: 0.076994\n",
            "Make prediction for 5010 samples...\n",
            "0.24111718 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 503 [0/25046 (0%)]\tLoss: 0.086659\n",
            "Train epoch: 503 [329440/25046 (41%)]\tLoss: 0.103794\n",
            "Train epoch: 503 [656800/25046 (82%)]\tLoss: 0.119805\n",
            "Make prediction for 5010 samples...\n",
            "0.24306163 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 504 [0/25046 (0%)]\tLoss: 0.103606\n",
            "Train epoch: 504 [327180/25046 (41%)]\tLoss: 0.086897\n",
            "Train epoch: 504 [655480/25046 (82%)]\tLoss: 0.091783\n",
            "Make prediction for 5010 samples...\n",
            "0.24036005 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 505 [0/25046 (0%)]\tLoss: 0.096372\n",
            "Train epoch: 505 [327460/25046 (41%)]\tLoss: 0.132504\n",
            "Train epoch: 505 [650640/25046 (82%)]\tLoss: 0.118237\n",
            "Make prediction for 5010 samples...\n",
            "0.23611905 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 506 [0/25046 (0%)]\tLoss: 0.131751\n",
            "Train epoch: 506 [326680/25046 (41%)]\tLoss: 0.101450\n",
            "Train epoch: 506 [660440/25046 (82%)]\tLoss: 0.095850\n",
            "Make prediction for 5010 samples...\n",
            "0.23695874 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 507 [0/25046 (0%)]\tLoss: 0.118410\n",
            "Train epoch: 507 [331220/25046 (41%)]\tLoss: 0.092907\n",
            "Train epoch: 507 [662360/25046 (82%)]\tLoss: 0.105932\n",
            "Make prediction for 5010 samples...\n",
            "0.26047328 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 508 [0/25046 (0%)]\tLoss: 0.086084\n",
            "Train epoch: 508 [333700/25046 (41%)]\tLoss: 0.106629\n",
            "Train epoch: 508 [661520/25046 (82%)]\tLoss: 0.069300\n",
            "Make prediction for 5010 samples...\n",
            "0.25649667 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 509 [0/25046 (0%)]\tLoss: 0.091148\n",
            "Train epoch: 509 [332360/25046 (41%)]\tLoss: 0.110107\n",
            "Train epoch: 509 [656880/25046 (82%)]\tLoss: 0.107771\n",
            "Make prediction for 5010 samples...\n",
            "0.24731572 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 510 [0/25046 (0%)]\tLoss: 0.079956\n",
            "Train epoch: 510 [330080/25046 (41%)]\tLoss: 0.123894\n",
            "Train epoch: 510 [657840/25046 (82%)]\tLoss: 0.130316\n",
            "Make prediction for 5010 samples...\n",
            "0.2664271 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 511 [0/25046 (0%)]\tLoss: 0.149937\n",
            "Train epoch: 511 [325960/25046 (41%)]\tLoss: 0.123452\n",
            "Train epoch: 511 [664240/25046 (82%)]\tLoss: 0.104288\n",
            "Make prediction for 5010 samples...\n",
            "0.26551422 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 512 [0/25046 (0%)]\tLoss: 0.091990\n",
            "Train epoch: 512 [324040/25046 (41%)]\tLoss: 0.124131\n",
            "Train epoch: 512 [654240/25046 (82%)]\tLoss: 0.112930\n",
            "Make prediction for 5010 samples...\n",
            "0.24534214 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 513 [0/25046 (0%)]\tLoss: 0.097198\n",
            "Train epoch: 513 [330980/25046 (41%)]\tLoss: 0.120458\n",
            "Train epoch: 513 [665640/25046 (82%)]\tLoss: 0.122155\n",
            "Make prediction for 5010 samples...\n",
            "0.25236812 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 514 [0/25046 (0%)]\tLoss: 0.099439\n",
            "Train epoch: 514 [325840/25046 (41%)]\tLoss: 0.075388\n",
            "Train epoch: 514 [661200/25046 (82%)]\tLoss: 0.101753\n",
            "Make prediction for 5010 samples...\n",
            "0.24847877 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 515 [0/25046 (0%)]\tLoss: 0.082160\n",
            "Train epoch: 515 [321600/25046 (41%)]\tLoss: 0.093098\n",
            "Train epoch: 515 [665240/25046 (82%)]\tLoss: 0.121968\n",
            "Make prediction for 5010 samples...\n",
            "0.23707663 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 516 [0/25046 (0%)]\tLoss: 0.101848\n",
            "Train epoch: 516 [329280/25046 (41%)]\tLoss: 0.110711\n",
            "Train epoch: 516 [656400/25046 (82%)]\tLoss: 0.116589\n",
            "Make prediction for 5010 samples...\n",
            "0.2743975 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 517 [0/25046 (0%)]\tLoss: 0.094711\n",
            "Train epoch: 517 [329440/25046 (41%)]\tLoss: 0.152938\n",
            "Train epoch: 517 [662920/25046 (82%)]\tLoss: 0.095835\n",
            "Make prediction for 5010 samples...\n",
            "0.2443738 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 518 [0/25046 (0%)]\tLoss: 0.107093\n",
            "Train epoch: 518 [326360/25046 (41%)]\tLoss: 0.135450\n",
            "Train epoch: 518 [655840/25046 (82%)]\tLoss: 0.124539\n",
            "Make prediction for 5010 samples...\n",
            "0.244057 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 519 [0/25046 (0%)]\tLoss: 0.106343\n",
            "Train epoch: 519 [324720/25046 (41%)]\tLoss: 0.095161\n",
            "Train epoch: 519 [656400/25046 (82%)]\tLoss: 0.114035\n",
            "Make prediction for 5010 samples...\n",
            "0.2332749 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 520 [0/25046 (0%)]\tLoss: 0.082109\n",
            "Train epoch: 520 [331960/25046 (41%)]\tLoss: 0.103171\n",
            "Train epoch: 520 [654080/25046 (82%)]\tLoss: 0.122494\n",
            "Make prediction for 5010 samples...\n",
            "0.24858087 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 521 [0/25046 (0%)]\tLoss: 0.108863\n",
            "Train epoch: 521 [328000/25046 (41%)]\tLoss: 0.119506\n",
            "Train epoch: 521 [659400/25046 (82%)]\tLoss: 0.100194\n",
            "Make prediction for 5010 samples...\n",
            "0.24243057 No improvement since epoch  386 ; best_mse,best_ci: 0.23285776 0.8887493753286082 GINConvNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 522 [0/25046 (0%)]\tLoss: 0.132097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training_validation.py 0 0 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5akr3ONuyog",
        "outputId": "31138a3a-78a6-4e3f-9b90-06a6e058c6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  169 ; best_test_mse,best_test_ci: 0.2749922 0.8724391535987888 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 170 [0/20036 (0%)]\tLoss: 0.145971\n",
            "Train epoch: 170 [325680/20036 (50%)]\tLoss: 0.147296\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2749922 No improvement since epoch  169 ; best_test_mse,best_test_ci: 0.2749922 0.8724391535987888 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 171 [0/20036 (0%)]\tLoss: 0.147927\n",
            "Train epoch: 171 [324160/20036 (50%)]\tLoss: 0.144878\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2749922 No improvement since epoch  169 ; best_test_mse,best_test_ci: 0.2749922 0.8724391535987888 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 172 [0/20036 (0%)]\tLoss: 0.163870\n",
            "Train epoch: 172 [325560/20036 (50%)]\tLoss: 0.200545\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2749922 No improvement since epoch  169 ; best_test_mse,best_test_ci: 0.2749922 0.8724391535987888 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 173 [0/20036 (0%)]\tLoss: 0.190696\n",
            "Train epoch: 173 [322060/20036 (50%)]\tLoss: 0.146968\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2749922 No improvement since epoch  169 ; best_test_mse,best_test_ci: 0.2749922 0.8724391535987888 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 174 [0/20036 (0%)]\tLoss: 0.172182\n",
            "Train epoch: 174 [328860/20036 (50%)]\tLoss: 0.165688\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2749922 No improvement since epoch  169 ; best_test_mse,best_test_ci: 0.2749922 0.8724391535987888 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 175 [0/20036 (0%)]\tLoss: 0.160744\n",
            "Train epoch: 175 [323220/20036 (50%)]\tLoss: 0.169587\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "predicting for test data\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 176 [0/20036 (0%)]\tLoss: 0.149626\n",
            "Train epoch: 176 [320000/20036 (50%)]\tLoss: 0.161054\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 177 [0/20036 (0%)]\tLoss: 0.194623\n",
            "Train epoch: 177 [327740/20036 (50%)]\tLoss: 0.202132\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 178 [0/20036 (0%)]\tLoss: 0.150225\n",
            "Train epoch: 178 [329880/20036 (50%)]\tLoss: 0.158776\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 179 [0/20036 (0%)]\tLoss: 0.152888\n",
            "Train epoch: 179 [326560/20036 (50%)]\tLoss: 0.161693\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 180 [0/20036 (0%)]\tLoss: 0.231341\n",
            "Train epoch: 180 [328820/20036 (50%)]\tLoss: 0.185629\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 181 [0/20036 (0%)]\tLoss: 0.148843\n",
            "Train epoch: 181 [330260/20036 (50%)]\tLoss: 0.159366\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 182 [0/20036 (0%)]\tLoss: 0.173725\n",
            "Train epoch: 182 [327660/20036 (50%)]\tLoss: 0.203114\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 183 [0/20036 (0%)]\tLoss: 0.151605\n",
            "Train epoch: 183 [333560/20036 (50%)]\tLoss: 0.152319\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 184 [0/20036 (0%)]\tLoss: 0.184840\n",
            "Train epoch: 184 [325360/20036 (50%)]\tLoss: 0.158967\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 185 [0/20036 (0%)]\tLoss: 0.163108\n",
            "Train epoch: 185 [322060/20036 (50%)]\tLoss: 0.152606\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 186 [0/20036 (0%)]\tLoss: 0.187847\n",
            "Train epoch: 186 [332800/20036 (50%)]\tLoss: 0.172331\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 187 [0/20036 (0%)]\tLoss: 0.176067\n",
            "Train epoch: 187 [325600/20036 (50%)]\tLoss: 0.145879\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 188 [0/20036 (0%)]\tLoss: 0.198798\n",
            "Train epoch: 188 [329100/20036 (50%)]\tLoss: 0.164858\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 189 [0/20036 (0%)]\tLoss: 0.159238\n",
            "Train epoch: 189 [332760/20036 (50%)]\tLoss: 0.212045\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 190 [0/20036 (0%)]\tLoss: 0.170814\n",
            "Train epoch: 190 [331880/20036 (50%)]\tLoss: 0.178521\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 191 [0/20036 (0%)]\tLoss: 0.178818\n",
            "Train epoch: 191 [329660/20036 (50%)]\tLoss: 0.184557\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 192 [0/20036 (0%)]\tLoss: 0.157320\n",
            "Train epoch: 192 [330600/20036 (50%)]\tLoss: 0.157291\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 193 [0/20036 (0%)]\tLoss: 0.149425\n",
            "Train epoch: 193 [332040/20036 (50%)]\tLoss: 0.175355\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 194 [0/20036 (0%)]\tLoss: 0.160185\n",
            "Train epoch: 194 [326360/20036 (50%)]\tLoss: 0.162817\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 195 [0/20036 (0%)]\tLoss: 0.140913\n",
            "Train epoch: 195 [327220/20036 (50%)]\tLoss: 0.127229\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 196 [0/20036 (0%)]\tLoss: 0.163498\n",
            "Train epoch: 196 [329600/20036 (50%)]\tLoss: 0.151654\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.27228898 No improvement since epoch  175 ; best_test_mse,best_test_ci: 0.27228898 0.8746812318925702 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 197 [0/20036 (0%)]\tLoss: 0.151431\n",
            "Train epoch: 197 [328520/20036 (50%)]\tLoss: 0.187366\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "predicting for test data\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 198 [0/20036 (0%)]\tLoss: 0.155279\n",
            "Train epoch: 198 [334100/20036 (50%)]\tLoss: 0.196314\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 199 [0/20036 (0%)]\tLoss: 0.169753\n",
            "Train epoch: 199 [336560/20036 (50%)]\tLoss: 0.151468\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 200 [0/20036 (0%)]\tLoss: 0.144019\n",
            "Train epoch: 200 [328960/20036 (50%)]\tLoss: 0.230602\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 201 [0/20036 (0%)]\tLoss: 0.162640\n",
            "Train epoch: 201 [329980/20036 (50%)]\tLoss: 0.158401\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 202 [0/20036 (0%)]\tLoss: 0.311323\n",
            "Train epoch: 202 [333360/20036 (50%)]\tLoss: 0.149202\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 203 [0/20036 (0%)]\tLoss: 0.283153\n",
            "Train epoch: 203 [331300/20036 (50%)]\tLoss: 0.185631\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 204 [0/20036 (0%)]\tLoss: 0.191213\n",
            "Train epoch: 204 [328660/20036 (50%)]\tLoss: 0.187952\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 205 [0/20036 (0%)]\tLoss: 0.127976\n",
            "Train epoch: 205 [329260/20036 (50%)]\tLoss: 0.182688\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 206 [0/20036 (0%)]\tLoss: 0.176052\n",
            "Train epoch: 206 [331900/20036 (50%)]\tLoss: 0.158926\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 207 [0/20036 (0%)]\tLoss: 0.163661\n",
            "Train epoch: 207 [325860/20036 (50%)]\tLoss: 0.150813\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 208 [0/20036 (0%)]\tLoss: 0.151599\n",
            "Train epoch: 208 [331780/20036 (50%)]\tLoss: 0.147806\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 209 [0/20036 (0%)]\tLoss: 0.137506\n",
            "Train epoch: 209 [327280/20036 (50%)]\tLoss: 0.157335\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 210 [0/20036 (0%)]\tLoss: 0.164263\n",
            "Train epoch: 210 [329840/20036 (50%)]\tLoss: 0.195155\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 211 [0/20036 (0%)]\tLoss: 0.153433\n",
            "Train epoch: 211 [329660/20036 (50%)]\tLoss: 0.200477\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 212 [0/20036 (0%)]\tLoss: 0.135016\n",
            "Train epoch: 212 [327640/20036 (50%)]\tLoss: 0.181188\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 213 [0/20036 (0%)]\tLoss: 0.153139\n",
            "Train epoch: 213 [328940/20036 (50%)]\tLoss: 0.150203\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 214 [0/20036 (0%)]\tLoss: 0.171087\n",
            "Train epoch: 214 [332360/20036 (50%)]\tLoss: 0.158461\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 215 [0/20036 (0%)]\tLoss: 0.138159\n",
            "Train epoch: 215 [326700/20036 (50%)]\tLoss: 0.138554\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 216 [0/20036 (0%)]\tLoss: 0.132617\n",
            "Train epoch: 216 [332240/20036 (50%)]\tLoss: 0.122462\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 217 [0/20036 (0%)]\tLoss: 0.136897\n",
            "Train epoch: 217 [325420/20036 (50%)]\tLoss: 0.198163\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 218 [0/20036 (0%)]\tLoss: 0.197896\n",
            "Train epoch: 218 [328180/20036 (50%)]\tLoss: 0.163115\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 219 [0/20036 (0%)]\tLoss: 0.204731\n",
            "Train epoch: 219 [327760/20036 (50%)]\tLoss: 0.167898\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 220 [0/20036 (0%)]\tLoss: 0.126226\n",
            "Train epoch: 220 [325720/20036 (50%)]\tLoss: 0.132604\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 221 [0/20036 (0%)]\tLoss: 0.118944\n",
            "Train epoch: 221 [326940/20036 (50%)]\tLoss: 0.146117\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 222 [0/20036 (0%)]\tLoss: 0.189930\n",
            "Train epoch: 222 [323480/20036 (50%)]\tLoss: 0.123495\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 223 [0/20036 (0%)]\tLoss: 0.145460\n",
            "Train epoch: 223 [331460/20036 (50%)]\tLoss: 0.141769\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 224 [0/20036 (0%)]\tLoss: 0.134862\n",
            "Train epoch: 224 [330080/20036 (50%)]\tLoss: 0.180918\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 225 [0/20036 (0%)]\tLoss: 0.221054\n",
            "Train epoch: 225 [331900/20036 (50%)]\tLoss: 0.158919\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 226 [0/20036 (0%)]\tLoss: 0.164184\n",
            "Train epoch: 226 [331500/20036 (50%)]\tLoss: 0.147633\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 227 [0/20036 (0%)]\tLoss: 0.236115\n",
            "Train epoch: 227 [326900/20036 (50%)]\tLoss: 0.139149\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 228 [0/20036 (0%)]\tLoss: 0.167694\n",
            "Train epoch: 228 [328580/20036 (50%)]\tLoss: 0.149193\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 229 [0/20036 (0%)]\tLoss: 0.137174\n",
            "Train epoch: 229 [323940/20036 (50%)]\tLoss: 0.163949\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 230 [0/20036 (0%)]\tLoss: 0.210677\n",
            "Train epoch: 230 [328880/20036 (50%)]\tLoss: 0.142245\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 231 [0/20036 (0%)]\tLoss: 0.169145\n",
            "Train epoch: 231 [329240/20036 (50%)]\tLoss: 0.140934\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 232 [0/20036 (0%)]\tLoss: 0.130966\n",
            "Train epoch: 232 [328240/20036 (50%)]\tLoss: 0.150116\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 233 [0/20036 (0%)]\tLoss: 0.123244\n",
            "Train epoch: 233 [325800/20036 (50%)]\tLoss: 0.183289\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 234 [0/20036 (0%)]\tLoss: 0.144773\n",
            "Train epoch: 234 [331340/20036 (50%)]\tLoss: 0.155947\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 235 [0/20036 (0%)]\tLoss: 0.151963\n",
            "Train epoch: 235 [325100/20036 (50%)]\tLoss: 0.174523\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 236 [0/20036 (0%)]\tLoss: 0.113748\n",
            "Train epoch: 236 [328300/20036 (50%)]\tLoss: 0.141085\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 237 [0/20036 (0%)]\tLoss: 0.169718\n",
            "Train epoch: 237 [331080/20036 (50%)]\tLoss: 0.173299\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 238 [0/20036 (0%)]\tLoss: 0.261363\n",
            "Train epoch: 238 [325540/20036 (50%)]\tLoss: 0.176608\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 239 [0/20036 (0%)]\tLoss: 0.144106\n",
            "Train epoch: 239 [326880/20036 (50%)]\tLoss: 0.179603\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 240 [0/20036 (0%)]\tLoss: 0.141581\n",
            "Train epoch: 240 [330800/20036 (50%)]\tLoss: 0.147605\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 241 [0/20036 (0%)]\tLoss: 0.170760\n",
            "Train epoch: 241 [333020/20036 (50%)]\tLoss: 0.148903\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 242 [0/20036 (0%)]\tLoss: 0.147868\n",
            "Train epoch: 242 [325020/20036 (50%)]\tLoss: 0.136093\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 243 [0/20036 (0%)]\tLoss: 0.142682\n",
            "Train epoch: 243 [327800/20036 (50%)]\tLoss: 0.172664\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 244 [0/20036 (0%)]\tLoss: 0.137431\n",
            "Train epoch: 244 [330200/20036 (50%)]\tLoss: 0.217246\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 245 [0/20036 (0%)]\tLoss: 0.151190\n",
            "Train epoch: 245 [330760/20036 (50%)]\tLoss: 0.133979\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 246 [0/20036 (0%)]\tLoss: 0.167015\n",
            "Train epoch: 246 [325720/20036 (50%)]\tLoss: 0.141172\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 247 [0/20036 (0%)]\tLoss: 0.132921\n",
            "Train epoch: 247 [324040/20036 (50%)]\tLoss: 0.171032\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 248 [0/20036 (0%)]\tLoss: 0.149276\n",
            "Train epoch: 248 [331660/20036 (50%)]\tLoss: 0.157759\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 249 [0/20036 (0%)]\tLoss: 0.158367\n",
            "Train epoch: 249 [326800/20036 (50%)]\tLoss: 0.161054\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 250 [0/20036 (0%)]\tLoss: 0.144351\n",
            "Train epoch: 250 [330560/20036 (50%)]\tLoss: 0.137431\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 251 [0/20036 (0%)]\tLoss: 0.114845\n",
            "Train epoch: 251 [330260/20036 (50%)]\tLoss: 0.153198\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 252 [0/20036 (0%)]\tLoss: 0.189327\n",
            "Train epoch: 252 [328880/20036 (50%)]\tLoss: 0.121324\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 253 [0/20036 (0%)]\tLoss: 0.143549\n",
            "Train epoch: 253 [327900/20036 (50%)]\tLoss: 0.120717\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 254 [0/20036 (0%)]\tLoss: 0.166258\n",
            "Train epoch: 254 [331280/20036 (50%)]\tLoss: 0.165091\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 255 [0/20036 (0%)]\tLoss: 0.183050\n",
            "Train epoch: 255 [326780/20036 (50%)]\tLoss: 0.146407\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 256 [0/20036 (0%)]\tLoss: 0.104804\n",
            "Train epoch: 256 [328760/20036 (50%)]\tLoss: 0.135996\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 257 [0/20036 (0%)]\tLoss: 0.131955\n",
            "Train epoch: 257 [329340/20036 (50%)]\tLoss: 0.110568\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 258 [0/20036 (0%)]\tLoss: 0.118043\n",
            "Train epoch: 258 [322180/20036 (50%)]\tLoss: 0.185161\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 259 [0/20036 (0%)]\tLoss: 0.130968\n",
            "Train epoch: 259 [334340/20036 (50%)]\tLoss: 0.121892\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 260 [0/20036 (0%)]\tLoss: 0.220346\n",
            "Train epoch: 260 [330980/20036 (50%)]\tLoss: 0.165159\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 261 [0/20036 (0%)]\tLoss: 0.165705\n",
            "Train epoch: 261 [327420/20036 (50%)]\tLoss: 0.131753\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 262 [0/20036 (0%)]\tLoss: 0.113699\n",
            "Train epoch: 262 [328900/20036 (50%)]\tLoss: 0.144847\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 263 [0/20036 (0%)]\tLoss: 0.217516\n",
            "Train epoch: 263 [330060/20036 (50%)]\tLoss: 0.137689\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 264 [0/20036 (0%)]\tLoss: 0.127319\n",
            "Train epoch: 264 [334480/20036 (50%)]\tLoss: 0.154246\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 265 [0/20036 (0%)]\tLoss: 0.171250\n",
            "Train epoch: 265 [327160/20036 (50%)]\tLoss: 0.117489\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 266 [0/20036 (0%)]\tLoss: 0.151366\n",
            "Train epoch: 266 [324680/20036 (50%)]\tLoss: 0.137442\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 267 [0/20036 (0%)]\tLoss: 0.138082\n",
            "Train epoch: 267 [332460/20036 (50%)]\tLoss: 0.141015\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 268 [0/20036 (0%)]\tLoss: 0.203449\n",
            "Train epoch: 268 [328800/20036 (50%)]\tLoss: 0.127751\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 269 [0/20036 (0%)]\tLoss: 0.144899\n",
            "Train epoch: 269 [330680/20036 (50%)]\tLoss: 0.151988\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 270 [0/20036 (0%)]\tLoss: 0.115566\n",
            "Train epoch: 270 [329120/20036 (50%)]\tLoss: 0.122087\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 271 [0/20036 (0%)]\tLoss: 0.153689\n",
            "Train epoch: 271 [328960/20036 (50%)]\tLoss: 0.155507\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 272 [0/20036 (0%)]\tLoss: 0.139531\n",
            "Train epoch: 272 [328840/20036 (50%)]\tLoss: 0.153884\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 273 [0/20036 (0%)]\tLoss: 0.128547\n",
            "Train epoch: 273 [328860/20036 (50%)]\tLoss: 0.146044\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 274 [0/20036 (0%)]\tLoss: 0.257904\n",
            "Train epoch: 274 [326580/20036 (50%)]\tLoss: 0.150167\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 275 [0/20036 (0%)]\tLoss: 0.124275\n",
            "Train epoch: 275 [321640/20036 (50%)]\tLoss: 0.135291\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 276 [0/20036 (0%)]\tLoss: 0.125583\n",
            "Train epoch: 276 [329160/20036 (50%)]\tLoss: 0.146389\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 277 [0/20036 (0%)]\tLoss: 0.155103\n",
            "Train epoch: 277 [325700/20036 (50%)]\tLoss: 0.159835\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 278 [0/20036 (0%)]\tLoss: 0.155738\n",
            "Train epoch: 278 [328260/20036 (50%)]\tLoss: 0.129210\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 279 [0/20036 (0%)]\tLoss: 0.154892\n",
            "Train epoch: 279 [323420/20036 (50%)]\tLoss: 0.108930\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 280 [0/20036 (0%)]\tLoss: 0.126247\n",
            "Train epoch: 280 [326200/20036 (50%)]\tLoss: 0.192842\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 281 [0/20036 (0%)]\tLoss: 0.152566\n",
            "Train epoch: 281 [326920/20036 (50%)]\tLoss: 0.128003\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 282 [0/20036 (0%)]\tLoss: 0.140721\n",
            "Train epoch: 282 [323580/20036 (50%)]\tLoss: 0.157990\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 283 [0/20036 (0%)]\tLoss: 0.166241\n",
            "Train epoch: 283 [322560/20036 (50%)]\tLoss: 0.116901\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 284 [0/20036 (0%)]\tLoss: 0.132844\n",
            "Train epoch: 284 [324500/20036 (50%)]\tLoss: 0.112661\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2759897 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.2759897 0.8717673494773589 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 285 [0/20036 (0%)]\tLoss: 0.116813\n",
            "Train epoch: 285 [327600/20036 (50%)]\tLoss: 0.139772\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "predicting for test data\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 286 [0/20036 (0%)]\tLoss: 0.129107\n",
            "Train epoch: 286 [327860/20036 (50%)]\tLoss: 0.139792\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 287 [0/20036 (0%)]\tLoss: 0.157224\n",
            "Train epoch: 287 [330440/20036 (50%)]\tLoss: 0.108545\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 288 [0/20036 (0%)]\tLoss: 0.184097\n",
            "Train epoch: 288 [329720/20036 (50%)]\tLoss: 0.140428\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 289 [0/20036 (0%)]\tLoss: 0.121750\n",
            "Train epoch: 289 [329800/20036 (50%)]\tLoss: 0.153431\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 290 [0/20036 (0%)]\tLoss: 0.136437\n",
            "Train epoch: 290 [328020/20036 (50%)]\tLoss: 0.164263\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 291 [0/20036 (0%)]\tLoss: 0.131888\n",
            "Train epoch: 291 [328620/20036 (50%)]\tLoss: 0.116199\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 292 [0/20036 (0%)]\tLoss: 0.136336\n",
            "Train epoch: 292 [328360/20036 (50%)]\tLoss: 0.155488\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 293 [0/20036 (0%)]\tLoss: 0.167803\n",
            "Train epoch: 293 [328660/20036 (50%)]\tLoss: 0.176016\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 294 [0/20036 (0%)]\tLoss: 0.136184\n",
            "Train epoch: 294 [334500/20036 (50%)]\tLoss: 0.112038\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 295 [0/20036 (0%)]\tLoss: 0.114753\n",
            "Train epoch: 295 [326600/20036 (50%)]\tLoss: 0.162449\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 296 [0/20036 (0%)]\tLoss: 0.119460\n",
            "Train epoch: 296 [330920/20036 (50%)]\tLoss: 0.140464\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 297 [0/20036 (0%)]\tLoss: 0.241849\n",
            "Train epoch: 297 [326440/20036 (50%)]\tLoss: 0.176876\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 298 [0/20036 (0%)]\tLoss: 0.132355\n",
            "Train epoch: 298 [328580/20036 (50%)]\tLoss: 0.119032\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 299 [0/20036 (0%)]\tLoss: 0.127301\n",
            "Train epoch: 299 [327580/20036 (50%)]\tLoss: 0.142240\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 300 [0/20036 (0%)]\tLoss: 0.173415\n",
            "Train epoch: 300 [324860/20036 (50%)]\tLoss: 0.173147\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 301 [0/20036 (0%)]\tLoss: 0.156206\n",
            "Train epoch: 301 [331960/20036 (50%)]\tLoss: 0.150121\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 302 [0/20036 (0%)]\tLoss: 0.135300\n",
            "Train epoch: 302 [329760/20036 (50%)]\tLoss: 0.130407\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 303 [0/20036 (0%)]\tLoss: 0.148136\n",
            "Train epoch: 303 [326980/20036 (50%)]\tLoss: 0.152016\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 304 [0/20036 (0%)]\tLoss: 0.157661\n",
            "Train epoch: 304 [329040/20036 (50%)]\tLoss: 0.127244\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 305 [0/20036 (0%)]\tLoss: 0.207406\n",
            "Train epoch: 305 [329580/20036 (50%)]\tLoss: 0.154419\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 306 [0/20036 (0%)]\tLoss: 0.141093\n",
            "Train epoch: 306 [331680/20036 (50%)]\tLoss: 0.145659\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 307 [0/20036 (0%)]\tLoss: 0.166162\n",
            "Train epoch: 307 [331080/20036 (50%)]\tLoss: 0.147729\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 308 [0/20036 (0%)]\tLoss: 0.108905\n",
            "Train epoch: 308 [323200/20036 (50%)]\tLoss: 0.107218\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 309 [0/20036 (0%)]\tLoss: 0.129594\n",
            "Train epoch: 309 [334860/20036 (50%)]\tLoss: 0.138504\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 310 [0/20036 (0%)]\tLoss: 0.198696\n",
            "Train epoch: 310 [330960/20036 (50%)]\tLoss: 0.133194\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 311 [0/20036 (0%)]\tLoss: 0.151928\n",
            "Train epoch: 311 [327720/20036 (50%)]\tLoss: 0.159035\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 312 [0/20036 (0%)]\tLoss: 0.127367\n",
            "Train epoch: 312 [327220/20036 (50%)]\tLoss: 0.152779\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 313 [0/20036 (0%)]\tLoss: 0.149841\n",
            "Train epoch: 313 [331920/20036 (50%)]\tLoss: 0.152737\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 314 [0/20036 (0%)]\tLoss: 0.150295\n",
            "Train epoch: 314 [326400/20036 (50%)]\tLoss: 0.119670\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 315 [0/20036 (0%)]\tLoss: 0.148248\n",
            "Train epoch: 315 [329780/20036 (50%)]\tLoss: 0.145867\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 316 [0/20036 (0%)]\tLoss: 0.117482\n",
            "Train epoch: 316 [327180/20036 (50%)]\tLoss: 0.114757\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 317 [0/20036 (0%)]\tLoss: 0.273243\n",
            "Train epoch: 317 [327040/20036 (50%)]\tLoss: 0.119034\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 318 [0/20036 (0%)]\tLoss: 0.117671\n",
            "Train epoch: 318 [324000/20036 (50%)]\tLoss: 0.125381\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 319 [0/20036 (0%)]\tLoss: 0.119746\n",
            "Train epoch: 319 [327200/20036 (50%)]\tLoss: 0.160814\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 320 [0/20036 (0%)]\tLoss: 0.129281\n",
            "Train epoch: 320 [327580/20036 (50%)]\tLoss: 0.142023\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 321 [0/20036 (0%)]\tLoss: 0.136900\n",
            "Train epoch: 321 [332160/20036 (50%)]\tLoss: 0.126125\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 322 [0/20036 (0%)]\tLoss: 0.110897\n",
            "Train epoch: 322 [331840/20036 (50%)]\tLoss: 0.168502\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 323 [0/20036 (0%)]\tLoss: 0.124257\n",
            "Train epoch: 323 [324440/20036 (50%)]\tLoss: 0.109433\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 324 [0/20036 (0%)]\tLoss: 0.145588\n",
            "Train epoch: 324 [324100/20036 (50%)]\tLoss: 0.121406\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 325 [0/20036 (0%)]\tLoss: 0.110489\n",
            "Train epoch: 325 [324260/20036 (50%)]\tLoss: 0.136691\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 326 [0/20036 (0%)]\tLoss: 0.212918\n",
            "Train epoch: 326 [323880/20036 (50%)]\tLoss: 0.134696\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 327 [0/20036 (0%)]\tLoss: 0.115077\n",
            "Train epoch: 327 [327340/20036 (50%)]\tLoss: 0.142944\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 328 [0/20036 (0%)]\tLoss: 0.143783\n",
            "Train epoch: 328 [328440/20036 (50%)]\tLoss: 0.146685\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 329 [0/20036 (0%)]\tLoss: 0.174535\n",
            "Train epoch: 329 [328200/20036 (50%)]\tLoss: 0.145809\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 330 [0/20036 (0%)]\tLoss: 0.154556\n",
            "Train epoch: 330 [329240/20036 (50%)]\tLoss: 0.131142\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 331 [0/20036 (0%)]\tLoss: 0.149316\n",
            "Train epoch: 331 [330260/20036 (50%)]\tLoss: 0.132246\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 332 [0/20036 (0%)]\tLoss: 0.113473\n",
            "Train epoch: 332 [326120/20036 (50%)]\tLoss: 0.115123\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 333 [0/20036 (0%)]\tLoss: 0.147451\n",
            "Train epoch: 333 [327080/20036 (50%)]\tLoss: 0.101804\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 334 [0/20036 (0%)]\tLoss: 0.146315\n",
            "Train epoch: 334 [334740/20036 (50%)]\tLoss: 0.130821\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 335 [0/20036 (0%)]\tLoss: 0.160129\n",
            "Train epoch: 335 [331000/20036 (50%)]\tLoss: 0.145038\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 336 [0/20036 (0%)]\tLoss: 0.162619\n",
            "Train epoch: 336 [332540/20036 (50%)]\tLoss: 0.122811\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 337 [0/20036 (0%)]\tLoss: 0.108240\n",
            "Train epoch: 337 [329120/20036 (50%)]\tLoss: 0.141464\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 338 [0/20036 (0%)]\tLoss: 0.278786\n",
            "Train epoch: 338 [328880/20036 (50%)]\tLoss: 0.135915\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 339 [0/20036 (0%)]\tLoss: 0.112655\n",
            "Train epoch: 339 [328760/20036 (50%)]\tLoss: 0.147755\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 340 [0/20036 (0%)]\tLoss: 0.126902\n",
            "Train epoch: 340 [326320/20036 (50%)]\tLoss: 0.137119\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 341 [0/20036 (0%)]\tLoss: 0.116564\n",
            "Train epoch: 341 [322960/20036 (50%)]\tLoss: 0.143343\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 342 [0/20036 (0%)]\tLoss: 0.128638\n",
            "Train epoch: 342 [329000/20036 (50%)]\tLoss: 0.151648\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 343 [0/20036 (0%)]\tLoss: 0.116434\n",
            "Train epoch: 343 [332700/20036 (50%)]\tLoss: 0.134063\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 344 [0/20036 (0%)]\tLoss: 0.151060\n",
            "Train epoch: 344 [329660/20036 (50%)]\tLoss: 0.129842\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 345 [0/20036 (0%)]\tLoss: 0.128526\n",
            "Train epoch: 345 [329100/20036 (50%)]\tLoss: 0.160874\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 346 [0/20036 (0%)]\tLoss: 0.118865\n",
            "Train epoch: 346 [327160/20036 (50%)]\tLoss: 0.126189\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 347 [0/20036 (0%)]\tLoss: 0.137829\n",
            "Train epoch: 347 [329420/20036 (50%)]\tLoss: 0.130257\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 348 [0/20036 (0%)]\tLoss: 0.122314\n",
            "Train epoch: 348 [327340/20036 (50%)]\tLoss: 0.151272\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 349 [0/20036 (0%)]\tLoss: 0.119426\n",
            "Train epoch: 349 [330700/20036 (50%)]\tLoss: 0.128252\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 350 [0/20036 (0%)]\tLoss: 0.126893\n",
            "Train epoch: 350 [327700/20036 (50%)]\tLoss: 0.124463\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 351 [0/20036 (0%)]\tLoss: 0.140057\n",
            "Train epoch: 351 [326780/20036 (50%)]\tLoss: 0.100851\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 352 [0/20036 (0%)]\tLoss: 0.146546\n",
            "Train epoch: 352 [326760/20036 (50%)]\tLoss: 0.140726\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 353 [0/20036 (0%)]\tLoss: 0.124066\n",
            "Train epoch: 353 [328880/20036 (50%)]\tLoss: 0.135385\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 354 [0/20036 (0%)]\tLoss: 0.170388\n",
            "Train epoch: 354 [328100/20036 (50%)]\tLoss: 0.161677\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 355 [0/20036 (0%)]\tLoss: 0.135809\n",
            "Train epoch: 355 [325760/20036 (50%)]\tLoss: 0.132479\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 356 [0/20036 (0%)]\tLoss: 0.231328\n",
            "Train epoch: 356 [329360/20036 (50%)]\tLoss: 0.140848\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 357 [0/20036 (0%)]\tLoss: 0.107643\n",
            "Train epoch: 357 [328260/20036 (50%)]\tLoss: 0.134301\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 358 [0/20036 (0%)]\tLoss: 0.155300\n",
            "Train epoch: 358 [329120/20036 (50%)]\tLoss: 0.142924\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 359 [0/20036 (0%)]\tLoss: 0.144810\n",
            "Train epoch: 359 [329200/20036 (50%)]\tLoss: 0.123355\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 360 [0/20036 (0%)]\tLoss: 0.096233\n",
            "Train epoch: 360 [322560/20036 (50%)]\tLoss: 0.136274\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 361 [0/20036 (0%)]\tLoss: 0.151503\n",
            "Train epoch: 361 [328220/20036 (50%)]\tLoss: 0.128378\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 362 [0/20036 (0%)]\tLoss: 0.139073\n",
            "Train epoch: 362 [328540/20036 (50%)]\tLoss: 0.145184\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 363 [0/20036 (0%)]\tLoss: 0.101647\n",
            "Train epoch: 363 [324040/20036 (50%)]\tLoss: 0.129519\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 364 [0/20036 (0%)]\tLoss: 0.157448\n",
            "Train epoch: 364 [329820/20036 (50%)]\tLoss: 0.121697\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 365 [0/20036 (0%)]\tLoss: 0.162810\n",
            "Train epoch: 365 [331880/20036 (50%)]\tLoss: 0.167960\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 366 [0/20036 (0%)]\tLoss: 0.114675\n",
            "Train epoch: 366 [332780/20036 (50%)]\tLoss: 0.106934\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 367 [0/20036 (0%)]\tLoss: 0.115758\n",
            "Train epoch: 367 [332220/20036 (50%)]\tLoss: 0.130288\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 368 [0/20036 (0%)]\tLoss: 0.120378\n",
            "Train epoch: 368 [330500/20036 (50%)]\tLoss: 0.126999\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 369 [0/20036 (0%)]\tLoss: 0.105191\n",
            "Train epoch: 369 [333820/20036 (50%)]\tLoss: 0.104286\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 370 [0/20036 (0%)]\tLoss: 0.120415\n",
            "Train epoch: 370 [330960/20036 (50%)]\tLoss: 0.096761\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 371 [0/20036 (0%)]\tLoss: 0.143401\n",
            "Train epoch: 371 [329520/20036 (50%)]\tLoss: 0.124548\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 372 [0/20036 (0%)]\tLoss: 0.107821\n",
            "Train epoch: 372 [326640/20036 (50%)]\tLoss: 0.119184\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 373 [0/20036 (0%)]\tLoss: 0.104620\n",
            "Train epoch: 373 [328660/20036 (50%)]\tLoss: 0.114672\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 374 [0/20036 (0%)]\tLoss: 0.154810\n",
            "Train epoch: 374 [329640/20036 (50%)]\tLoss: 0.140655\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 375 [0/20036 (0%)]\tLoss: 0.137885\n",
            "Train epoch: 375 [327280/20036 (50%)]\tLoss: 0.157268\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 376 [0/20036 (0%)]\tLoss: 0.151687\n",
            "Train epoch: 376 [327140/20036 (50%)]\tLoss: 0.131252\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 377 [0/20036 (0%)]\tLoss: 0.107836\n",
            "Train epoch: 377 [328980/20036 (50%)]\tLoss: 0.151502\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 378 [0/20036 (0%)]\tLoss: 0.164263\n",
            "Train epoch: 378 [325980/20036 (50%)]\tLoss: 0.120613\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 379 [0/20036 (0%)]\tLoss: 0.124903\n",
            "Train epoch: 379 [333600/20036 (50%)]\tLoss: 0.121396\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 380 [0/20036 (0%)]\tLoss: 0.126440\n",
            "Train epoch: 380 [327620/20036 (50%)]\tLoss: 0.092980\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 381 [0/20036 (0%)]\tLoss: 0.108573\n",
            "Train epoch: 381 [326180/20036 (50%)]\tLoss: 0.150186\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 382 [0/20036 (0%)]\tLoss: 0.091151\n",
            "Train epoch: 382 [326740/20036 (50%)]\tLoss: 0.108121\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 383 [0/20036 (0%)]\tLoss: 0.112304\n",
            "Train epoch: 383 [328080/20036 (50%)]\tLoss: 0.108699\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 384 [0/20036 (0%)]\tLoss: 0.145034\n",
            "Train epoch: 384 [329020/20036 (50%)]\tLoss: 0.116549\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 385 [0/20036 (0%)]\tLoss: 0.112059\n",
            "Train epoch: 385 [330060/20036 (50%)]\tLoss: 0.090161\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 386 [0/20036 (0%)]\tLoss: 0.137146\n",
            "Train epoch: 386 [328360/20036 (50%)]\tLoss: 0.192271\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 387 [0/20036 (0%)]\tLoss: 0.130492\n",
            "Train epoch: 387 [326660/20036 (50%)]\tLoss: 0.162478\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 388 [0/20036 (0%)]\tLoss: 0.121718\n",
            "Train epoch: 388 [326580/20036 (50%)]\tLoss: 0.123187\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 389 [0/20036 (0%)]\tLoss: 0.124997\n",
            "Train epoch: 389 [331100/20036 (50%)]\tLoss: 0.107194\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 390 [0/20036 (0%)]\tLoss: 0.125579\n",
            "Train epoch: 390 [330340/20036 (50%)]\tLoss: 0.125687\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 391 [0/20036 (0%)]\tLoss: 0.162887\n",
            "Train epoch: 391 [328420/20036 (50%)]\tLoss: 0.114995\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 392 [0/20036 (0%)]\tLoss: 0.096226\n",
            "Train epoch: 392 [332380/20036 (50%)]\tLoss: 0.163701\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 393 [0/20036 (0%)]\tLoss: 0.101232\n",
            "Train epoch: 393 [327080/20036 (50%)]\tLoss: 0.102870\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 394 [0/20036 (0%)]\tLoss: 0.132969\n",
            "Train epoch: 394 [323320/20036 (50%)]\tLoss: 0.116213\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 395 [0/20036 (0%)]\tLoss: 0.102105\n",
            "Train epoch: 395 [327060/20036 (50%)]\tLoss: 0.091121\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 396 [0/20036 (0%)]\tLoss: 0.142480\n",
            "Train epoch: 396 [329080/20036 (50%)]\tLoss: 0.143076\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 397 [0/20036 (0%)]\tLoss: 0.144025\n",
            "Train epoch: 397 [330560/20036 (50%)]\tLoss: 0.116665\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 398 [0/20036 (0%)]\tLoss: 0.125083\n",
            "Train epoch: 398 [328320/20036 (50%)]\tLoss: 0.166411\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 399 [0/20036 (0%)]\tLoss: 0.139615\n",
            "Train epoch: 399 [329180/20036 (50%)]\tLoss: 0.147417\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 400 [0/20036 (0%)]\tLoss: 0.107479\n",
            "Train epoch: 400 [330660/20036 (50%)]\tLoss: 0.120644\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 401 [0/20036 (0%)]\tLoss: 0.162132\n",
            "Train epoch: 401 [333620/20036 (50%)]\tLoss: 0.093663\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 402 [0/20036 (0%)]\tLoss: 0.150044\n",
            "Train epoch: 402 [325000/20036 (50%)]\tLoss: 0.109522\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 403 [0/20036 (0%)]\tLoss: 0.127271\n",
            "Train epoch: 403 [333460/20036 (50%)]\tLoss: 0.119716\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 404 [0/20036 (0%)]\tLoss: 0.128545\n",
            "Train epoch: 404 [323320/20036 (50%)]\tLoss: 0.152294\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 405 [0/20036 (0%)]\tLoss: 0.113636\n",
            "Train epoch: 405 [331020/20036 (50%)]\tLoss: 0.170205\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 406 [0/20036 (0%)]\tLoss: 0.131075\n",
            "Train epoch: 406 [326560/20036 (50%)]\tLoss: 0.130479\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 407 [0/20036 (0%)]\tLoss: 0.132250\n",
            "Train epoch: 407 [327940/20036 (50%)]\tLoss: 0.116787\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 408 [0/20036 (0%)]\tLoss: 0.133426\n",
            "Train epoch: 408 [332280/20036 (50%)]\tLoss: 0.139549\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 409 [0/20036 (0%)]\tLoss: 0.144127\n",
            "Train epoch: 409 [328460/20036 (50%)]\tLoss: 0.125636\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 410 [0/20036 (0%)]\tLoss: 0.152442\n",
            "Train epoch: 410 [324980/20036 (50%)]\tLoss: 0.159605\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 411 [0/20036 (0%)]\tLoss: 0.119884\n",
            "Train epoch: 411 [330520/20036 (50%)]\tLoss: 0.117419\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 412 [0/20036 (0%)]\tLoss: 0.130359\n",
            "Train epoch: 412 [327540/20036 (50%)]\tLoss: 0.131426\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 413 [0/20036 (0%)]\tLoss: 0.131340\n",
            "Train epoch: 413 [327440/20036 (50%)]\tLoss: 0.100867\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 414 [0/20036 (0%)]\tLoss: 0.133654\n",
            "Train epoch: 414 [329120/20036 (50%)]\tLoss: 0.113272\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 415 [0/20036 (0%)]\tLoss: 0.137348\n",
            "Train epoch: 415 [330200/20036 (50%)]\tLoss: 0.124109\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 416 [0/20036 (0%)]\tLoss: 0.141493\n",
            "Train epoch: 416 [325620/20036 (50%)]\tLoss: 0.116625\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 417 [0/20036 (0%)]\tLoss: 0.128802\n",
            "Train epoch: 417 [325580/20036 (50%)]\tLoss: 0.103926\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 418 [0/20036 (0%)]\tLoss: 0.127111\n",
            "Train epoch: 418 [325540/20036 (50%)]\tLoss: 0.095470\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 419 [0/20036 (0%)]\tLoss: 0.191076\n",
            "Train epoch: 419 [327060/20036 (50%)]\tLoss: 0.121071\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 420 [0/20036 (0%)]\tLoss: 0.169739\n",
            "Train epoch: 420 [328660/20036 (50%)]\tLoss: 0.135056\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 421 [0/20036 (0%)]\tLoss: 0.106417\n",
            "Train epoch: 421 [327540/20036 (50%)]\tLoss: 0.121376\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 422 [0/20036 (0%)]\tLoss: 0.149344\n",
            "Train epoch: 422 [332660/20036 (50%)]\tLoss: 0.147176\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 423 [0/20036 (0%)]\tLoss: 0.116311\n",
            "Train epoch: 423 [335400/20036 (50%)]\tLoss: 0.118319\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 424 [0/20036 (0%)]\tLoss: 0.135131\n",
            "Train epoch: 424 [330780/20036 (50%)]\tLoss: 0.103544\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 425 [0/20036 (0%)]\tLoss: 0.132213\n",
            "Train epoch: 425 [329920/20036 (50%)]\tLoss: 0.171067\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 426 [0/20036 (0%)]\tLoss: 0.118088\n",
            "Train epoch: 426 [322840/20036 (50%)]\tLoss: 0.124809\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.26372027 No improvement since epoch  285 ; best_test_mse,best_test_ci: 0.26372027 0.8717143586587074 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 427 [0/20036 (0%)]\tLoss: 0.120267\n",
            "Train epoch: 427 [325120/20036 (50%)]\tLoss: 0.137052\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "predicting for test data\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 428 [0/20036 (0%)]\tLoss: 0.122371\n",
            "Train epoch: 428 [327180/20036 (50%)]\tLoss: 0.115811\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 429 [0/20036 (0%)]\tLoss: 0.144134\n",
            "Train epoch: 429 [323420/20036 (50%)]\tLoss: 0.110266\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 430 [0/20036 (0%)]\tLoss: 0.134817\n",
            "Train epoch: 430 [329560/20036 (50%)]\tLoss: 0.138367\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 431 [0/20036 (0%)]\tLoss: 0.123777\n",
            "Train epoch: 431 [331620/20036 (50%)]\tLoss: 0.142447\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 432 [0/20036 (0%)]\tLoss: 0.142218\n",
            "Train epoch: 432 [330180/20036 (50%)]\tLoss: 0.103957\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 433 [0/20036 (0%)]\tLoss: 0.104613\n",
            "Train epoch: 433 [325200/20036 (50%)]\tLoss: 0.133478\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 434 [0/20036 (0%)]\tLoss: 0.153107\n",
            "Train epoch: 434 [330700/20036 (50%)]\tLoss: 0.127942\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 435 [0/20036 (0%)]\tLoss: 0.132438\n",
            "Train epoch: 435 [325400/20036 (50%)]\tLoss: 0.088970\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 436 [0/20036 (0%)]\tLoss: 0.227944\n",
            "Train epoch: 436 [325200/20036 (50%)]\tLoss: 0.120251\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 437 [0/20036 (0%)]\tLoss: 0.118630\n",
            "Train epoch: 437 [327240/20036 (50%)]\tLoss: 0.107946\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 438 [0/20036 (0%)]\tLoss: 0.117317\n",
            "Train epoch: 438 [328880/20036 (50%)]\tLoss: 0.121788\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 439 [0/20036 (0%)]\tLoss: 0.113729\n",
            "Train epoch: 439 [323940/20036 (50%)]\tLoss: 0.103804\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 440 [0/20036 (0%)]\tLoss: 0.135607\n",
            "Train epoch: 440 [325540/20036 (50%)]\tLoss: 0.101499\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 441 [0/20036 (0%)]\tLoss: 0.108009\n",
            "Train epoch: 441 [330360/20036 (50%)]\tLoss: 0.120294\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 442 [0/20036 (0%)]\tLoss: 0.166437\n",
            "Train epoch: 442 [326480/20036 (50%)]\tLoss: 0.153667\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 443 [0/20036 (0%)]\tLoss: 0.111024\n",
            "Train epoch: 443 [323620/20036 (50%)]\tLoss: 0.117034\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 444 [0/20036 (0%)]\tLoss: 0.110132\n",
            "Train epoch: 444 [331640/20036 (50%)]\tLoss: 0.100257\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 445 [0/20036 (0%)]\tLoss: 0.107784\n",
            "Train epoch: 445 [329420/20036 (50%)]\tLoss: 0.110843\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 446 [0/20036 (0%)]\tLoss: 0.134422\n",
            "Train epoch: 446 [328060/20036 (50%)]\tLoss: 0.102044\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 447 [0/20036 (0%)]\tLoss: 0.141665\n",
            "Train epoch: 447 [330120/20036 (50%)]\tLoss: 0.125491\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 448 [0/20036 (0%)]\tLoss: 0.120045\n",
            "Train epoch: 448 [326520/20036 (50%)]\tLoss: 0.139279\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 449 [0/20036 (0%)]\tLoss: 0.218633\n",
            "Train epoch: 449 [328540/20036 (50%)]\tLoss: 0.111679\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 450 [0/20036 (0%)]\tLoss: 0.152469\n",
            "Train epoch: 450 [328360/20036 (50%)]\tLoss: 0.130496\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 451 [0/20036 (0%)]\tLoss: 0.105569\n",
            "Train epoch: 451 [327340/20036 (50%)]\tLoss: 0.117146\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 452 [0/20036 (0%)]\tLoss: 0.110823\n",
            "Train epoch: 452 [326520/20036 (50%)]\tLoss: 0.100670\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 453 [0/20036 (0%)]\tLoss: 0.136119\n",
            "Train epoch: 453 [326100/20036 (50%)]\tLoss: 0.096718\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 454 [0/20036 (0%)]\tLoss: 0.132330\n",
            "Train epoch: 454 [332080/20036 (50%)]\tLoss: 0.128349\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 455 [0/20036 (0%)]\tLoss: 0.094226\n",
            "Train epoch: 455 [329540/20036 (50%)]\tLoss: 0.109284\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 456 [0/20036 (0%)]\tLoss: 0.097535\n",
            "Train epoch: 456 [329980/20036 (50%)]\tLoss: 0.120000\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 457 [0/20036 (0%)]\tLoss: 0.106690\n",
            "Train epoch: 457 [329540/20036 (50%)]\tLoss: 0.161300\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 458 [0/20036 (0%)]\tLoss: 0.092251\n",
            "Train epoch: 458 [331480/20036 (50%)]\tLoss: 0.107450\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 459 [0/20036 (0%)]\tLoss: 0.147433\n",
            "Train epoch: 459 [328420/20036 (50%)]\tLoss: 0.135668\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 460 [0/20036 (0%)]\tLoss: 0.127144\n",
            "Train epoch: 460 [331380/20036 (50%)]\tLoss: 0.125776\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 461 [0/20036 (0%)]\tLoss: 0.128577\n",
            "Train epoch: 461 [329360/20036 (50%)]\tLoss: 0.124079\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 462 [0/20036 (0%)]\tLoss: 0.127055\n",
            "Train epoch: 462 [328040/20036 (50%)]\tLoss: 0.153720\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 463 [0/20036 (0%)]\tLoss: 0.135774\n",
            "Train epoch: 463 [328060/20036 (50%)]\tLoss: 0.096520\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 464 [0/20036 (0%)]\tLoss: 0.100649\n",
            "Train epoch: 464 [327500/20036 (50%)]\tLoss: 0.146230\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 465 [0/20036 (0%)]\tLoss: 0.173550\n",
            "Train epoch: 465 [330680/20036 (50%)]\tLoss: 0.127109\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2550214 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.2550214 0.8759543133377737 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 466 [0/20036 (0%)]\tLoss: 0.127431\n",
            "Train epoch: 466 [329380/20036 (50%)]\tLoss: 0.097823\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "predicting for test data\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  466 ; best_test_mse,best_test_ci: 0.2545726 0.8824889542476353 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 467 [0/20036 (0%)]\tLoss: 0.113672\n",
            "Train epoch: 467 [328500/20036 (50%)]\tLoss: 0.125068\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.2545726 No improvement since epoch  466 ; best_test_mse,best_test_ci: 0.2545726 0.8824889542476353 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 468 [0/20036 (0%)]\tLoss: 0.102592\n",
            "Train epoch: 468 [329340/20036 (50%)]\tLoss: 0.106388\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "predicting for test data\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 469 [0/20036 (0%)]\tLoss: 0.126402\n",
            "Train epoch: 469 [328120/20036 (50%)]\tLoss: 0.127531\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 470 [0/20036 (0%)]\tLoss: 0.117046\n",
            "Train epoch: 470 [329160/20036 (50%)]\tLoss: 0.093656\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 471 [0/20036 (0%)]\tLoss: 0.114587\n",
            "Train epoch: 471 [327160/20036 (50%)]\tLoss: 0.097803\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 472 [0/20036 (0%)]\tLoss: 0.110596\n",
            "Train epoch: 472 [332860/20036 (50%)]\tLoss: 0.145522\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 473 [0/20036 (0%)]\tLoss: 0.131927\n",
            "Train epoch: 473 [330560/20036 (50%)]\tLoss: 0.103677\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 474 [0/20036 (0%)]\tLoss: 0.115148\n",
            "Train epoch: 474 [329160/20036 (50%)]\tLoss: 0.141360\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 475 [0/20036 (0%)]\tLoss: 0.133993\n",
            "Train epoch: 475 [331840/20036 (50%)]\tLoss: 0.084628\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 476 [0/20036 (0%)]\tLoss: 0.166877\n",
            "Train epoch: 476 [331900/20036 (50%)]\tLoss: 0.105910\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 477 [0/20036 (0%)]\tLoss: 0.105665\n",
            "Train epoch: 477 [326980/20036 (50%)]\tLoss: 0.100790\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 478 [0/20036 (0%)]\tLoss: 0.112246\n",
            "Train epoch: 478 [332780/20036 (50%)]\tLoss: 0.118042\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 479 [0/20036 (0%)]\tLoss: 0.162395\n",
            "Train epoch: 479 [325120/20036 (50%)]\tLoss: 0.095050\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 480 [0/20036 (0%)]\tLoss: 0.119974\n",
            "Train epoch: 480 [322600/20036 (50%)]\tLoss: 0.104589\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 481 [0/20036 (0%)]\tLoss: 0.101185\n",
            "Train epoch: 481 [330480/20036 (50%)]\tLoss: 0.095561\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 482 [0/20036 (0%)]\tLoss: 0.109921\n",
            "Train epoch: 482 [328980/20036 (50%)]\tLoss: 0.097571\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 483 [0/20036 (0%)]\tLoss: 0.095236\n",
            "Train epoch: 483 [327380/20036 (50%)]\tLoss: 0.120393\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 484 [0/20036 (0%)]\tLoss: 0.119864\n",
            "Train epoch: 484 [328640/20036 (50%)]\tLoss: 0.107324\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 485 [0/20036 (0%)]\tLoss: 0.122453\n",
            "Train epoch: 485 [331000/20036 (50%)]\tLoss: 0.154200\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 486 [0/20036 (0%)]\tLoss: 0.108091\n",
            "Train epoch: 486 [328960/20036 (50%)]\tLoss: 0.103581\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 487 [0/20036 (0%)]\tLoss: 0.126106\n",
            "Train epoch: 487 [328120/20036 (50%)]\tLoss: 0.095416\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 488 [0/20036 (0%)]\tLoss: 0.134448\n",
            "Train epoch: 488 [329700/20036 (50%)]\tLoss: 0.128809\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 489 [0/20036 (0%)]\tLoss: 0.203129\n",
            "Train epoch: 489 [328660/20036 (50%)]\tLoss: 0.101716\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 490 [0/20036 (0%)]\tLoss: 0.109872\n",
            "Train epoch: 490 [331460/20036 (50%)]\tLoss: 0.097061\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 491 [0/20036 (0%)]\tLoss: 0.119796\n",
            "Train epoch: 491 [326840/20036 (50%)]\tLoss: 0.097702\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 492 [0/20036 (0%)]\tLoss: 0.113585\n",
            "Train epoch: 492 [329060/20036 (50%)]\tLoss: 0.128186\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 493 [0/20036 (0%)]\tLoss: 0.129655\n",
            "Train epoch: 493 [328700/20036 (50%)]\tLoss: 0.095682\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 494 [0/20036 (0%)]\tLoss: 0.196268\n",
            "Train epoch: 494 [327280/20036 (50%)]\tLoss: 0.108428\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 495 [0/20036 (0%)]\tLoss: 0.114576\n",
            "Train epoch: 495 [332920/20036 (50%)]\tLoss: 0.107324\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 496 [0/20036 (0%)]\tLoss: 0.128175\n",
            "Train epoch: 496 [328820/20036 (50%)]\tLoss: 0.119053\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 497 [0/20036 (0%)]\tLoss: 0.095369\n",
            "Train epoch: 497 [326760/20036 (50%)]\tLoss: 0.100438\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 498 [0/20036 (0%)]\tLoss: 0.147963\n",
            "Train epoch: 498 [321820/20036 (50%)]\tLoss: 0.093487\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 499 [0/20036 (0%)]\tLoss: 0.100374\n",
            "Train epoch: 499 [328400/20036 (50%)]\tLoss: 0.103659\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 500 [0/20036 (0%)]\tLoss: 0.136875\n",
            "Train epoch: 500 [327420/20036 (50%)]\tLoss: 0.135368\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 501 [0/20036 (0%)]\tLoss: 0.120397\n",
            "Train epoch: 501 [325340/20036 (50%)]\tLoss: 0.110094\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 502 [0/20036 (0%)]\tLoss: 0.099123\n",
            "Train epoch: 502 [323480/20036 (50%)]\tLoss: 0.112378\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 503 [0/20036 (0%)]\tLoss: 0.090223\n",
            "Train epoch: 503 [326540/20036 (50%)]\tLoss: 0.155782\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 504 [0/20036 (0%)]\tLoss: 0.099361\n",
            "Train epoch: 504 [325720/20036 (50%)]\tLoss: 0.085033\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 505 [0/20036 (0%)]\tLoss: 0.104483\n",
            "Train epoch: 505 [330360/20036 (50%)]\tLoss: 0.117921\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 506 [0/20036 (0%)]\tLoss: 0.069914\n",
            "Train epoch: 506 [327500/20036 (50%)]\tLoss: 0.152608\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 507 [0/20036 (0%)]\tLoss: 0.117051\n",
            "Train epoch: 507 [334960/20036 (50%)]\tLoss: 0.118534\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 508 [0/20036 (0%)]\tLoss: 0.140006\n",
            "Train epoch: 508 [330780/20036 (50%)]\tLoss: 0.127199\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 509 [0/20036 (0%)]\tLoss: 0.160402\n",
            "Train epoch: 509 [326300/20036 (50%)]\tLoss: 0.100798\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 510 [0/20036 (0%)]\tLoss: 0.148274\n",
            "Train epoch: 510 [329880/20036 (50%)]\tLoss: 0.152376\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 511 [0/20036 (0%)]\tLoss: 0.105278\n",
            "Train epoch: 511 [329240/20036 (50%)]\tLoss: 0.118717\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 512 [0/20036 (0%)]\tLoss: 0.131141\n",
            "Train epoch: 512 [325720/20036 (50%)]\tLoss: 0.109482\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 513 [0/20036 (0%)]\tLoss: 0.135028\n",
            "Train epoch: 513 [329700/20036 (50%)]\tLoss: 0.118994\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 514 [0/20036 (0%)]\tLoss: 0.144059\n",
            "Train epoch: 514 [327760/20036 (50%)]\tLoss: 0.086174\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 515 [0/20036 (0%)]\tLoss: 0.131598\n",
            "Train epoch: 515 [330480/20036 (50%)]\tLoss: 0.102359\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 516 [0/20036 (0%)]\tLoss: 0.101485\n",
            "Train epoch: 516 [323980/20036 (50%)]\tLoss: 0.102341\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 517 [0/20036 (0%)]\tLoss: 0.216396\n",
            "Train epoch: 517 [331340/20036 (50%)]\tLoss: 0.167112\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 518 [0/20036 (0%)]\tLoss: 0.116296\n",
            "Train epoch: 518 [328840/20036 (50%)]\tLoss: 0.117621\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 519 [0/20036 (0%)]\tLoss: 0.121005\n",
            "Train epoch: 519 [328280/20036 (50%)]\tLoss: 0.115681\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 520 [0/20036 (0%)]\tLoss: 0.084421\n",
            "Train epoch: 520 [326240/20036 (50%)]\tLoss: 0.111275\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 521 [0/20036 (0%)]\tLoss: 0.104576\n",
            "Train epoch: 521 [327960/20036 (50%)]\tLoss: 0.079051\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 522 [0/20036 (0%)]\tLoss: 0.149100\n",
            "Train epoch: 522 [331840/20036 (50%)]\tLoss: 0.108268\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 523 [0/20036 (0%)]\tLoss: 0.168214\n",
            "Train epoch: 523 [325600/20036 (50%)]\tLoss: 0.138545\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 524 [0/20036 (0%)]\tLoss: 0.107403\n",
            "Train epoch: 524 [331660/20036 (50%)]\tLoss: 0.111948\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 525 [0/20036 (0%)]\tLoss: 0.112294\n",
            "Train epoch: 525 [324520/20036 (50%)]\tLoss: 0.111568\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 526 [0/20036 (0%)]\tLoss: 0.110125\n",
            "Train epoch: 526 [324920/20036 (50%)]\tLoss: 0.116529\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 527 [0/20036 (0%)]\tLoss: 0.107920\n",
            "Train epoch: 527 [332800/20036 (50%)]\tLoss: 0.098323\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 528 [0/20036 (0%)]\tLoss: 0.104229\n",
            "Train epoch: 528 [325560/20036 (50%)]\tLoss: 0.128491\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 529 [0/20036 (0%)]\tLoss: 0.097276\n",
            "Train epoch: 529 [327920/20036 (50%)]\tLoss: 0.136113\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 530 [0/20036 (0%)]\tLoss: 0.096662\n",
            "Train epoch: 530 [330940/20036 (50%)]\tLoss: 0.122024\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 531 [0/20036 (0%)]\tLoss: 0.091585\n",
            "Train epoch: 531 [327920/20036 (50%)]\tLoss: 0.098110\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 532 [0/20036 (0%)]\tLoss: 0.128658\n",
            "Train epoch: 532 [328680/20036 (50%)]\tLoss: 0.107560\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 533 [0/20036 (0%)]\tLoss: 0.109362\n",
            "Train epoch: 533 [329500/20036 (50%)]\tLoss: 0.093421\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 534 [0/20036 (0%)]\tLoss: 0.091187\n",
            "Train epoch: 534 [332000/20036 (50%)]\tLoss: 0.115573\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 535 [0/20036 (0%)]\tLoss: 0.109483\n",
            "Train epoch: 535 [327860/20036 (50%)]\tLoss: 0.104998\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 536 [0/20036 (0%)]\tLoss: 0.098048\n",
            "Train epoch: 536 [327120/20036 (50%)]\tLoss: 0.127950\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 537 [0/20036 (0%)]\tLoss: 0.109713\n",
            "Train epoch: 537 [324740/20036 (50%)]\tLoss: 0.097328\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 538 [0/20036 (0%)]\tLoss: 0.099584\n",
            "Train epoch: 538 [329440/20036 (50%)]\tLoss: 0.102326\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 539 [0/20036 (0%)]\tLoss: 0.110505\n",
            "Train epoch: 539 [327320/20036 (50%)]\tLoss: 0.107943\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 540 [0/20036 (0%)]\tLoss: 0.147036\n",
            "Train epoch: 540 [331280/20036 (50%)]\tLoss: 0.108352\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 541 [0/20036 (0%)]\tLoss: 0.087920\n",
            "Train epoch: 541 [323140/20036 (50%)]\tLoss: 0.108969\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 542 [0/20036 (0%)]\tLoss: 0.119547\n",
            "Train epoch: 542 [329300/20036 (50%)]\tLoss: 0.090997\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 543 [0/20036 (0%)]\tLoss: 0.100504\n",
            "Train epoch: 543 [325720/20036 (50%)]\tLoss: 0.095500\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 544 [0/20036 (0%)]\tLoss: 0.124953\n",
            "Train epoch: 544 [330140/20036 (50%)]\tLoss: 0.107718\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 545 [0/20036 (0%)]\tLoss: 0.122814\n",
            "Train epoch: 545 [331700/20036 (50%)]\tLoss: 0.110940\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 546 [0/20036 (0%)]\tLoss: 0.104954\n",
            "Train epoch: 546 [329360/20036 (50%)]\tLoss: 0.095150\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 547 [0/20036 (0%)]\tLoss: 0.104992\n",
            "Train epoch: 547 [330860/20036 (50%)]\tLoss: 0.116625\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 548 [0/20036 (0%)]\tLoss: 0.096994\n",
            "Train epoch: 548 [326420/20036 (50%)]\tLoss: 0.113950\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 549 [0/20036 (0%)]\tLoss: 0.088830\n",
            "Train epoch: 549 [331140/20036 (50%)]\tLoss: 0.113950\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 550 [0/20036 (0%)]\tLoss: 0.109766\n",
            "Train epoch: 550 [325580/20036 (50%)]\tLoss: 0.068637\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 551 [0/20036 (0%)]\tLoss: 0.100433\n",
            "Train epoch: 551 [329180/20036 (50%)]\tLoss: 0.091270\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 552 [0/20036 (0%)]\tLoss: 0.149725\n",
            "Train epoch: 552 [329780/20036 (50%)]\tLoss: 0.104847\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 553 [0/20036 (0%)]\tLoss: 0.188692\n",
            "Train epoch: 553 [326780/20036 (50%)]\tLoss: 0.098063\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 554 [0/20036 (0%)]\tLoss: 0.097266\n",
            "Train epoch: 554 [326860/20036 (50%)]\tLoss: 0.120210\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 555 [0/20036 (0%)]\tLoss: 0.112190\n",
            "Train epoch: 555 [328100/20036 (50%)]\tLoss: 0.096458\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 556 [0/20036 (0%)]\tLoss: 0.084082\n",
            "Train epoch: 556 [328800/20036 (50%)]\tLoss: 0.085695\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 557 [0/20036 (0%)]\tLoss: 0.119869\n",
            "Train epoch: 557 [333660/20036 (50%)]\tLoss: 0.116508\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 558 [0/20036 (0%)]\tLoss: 0.145560\n",
            "Train epoch: 558 [332580/20036 (50%)]\tLoss: 0.096921\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 559 [0/20036 (0%)]\tLoss: 0.091844\n",
            "Train epoch: 559 [326480/20036 (50%)]\tLoss: 0.109688\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 560 [0/20036 (0%)]\tLoss: 0.090273\n",
            "Train epoch: 560 [329100/20036 (50%)]\tLoss: 0.078369\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 561 [0/20036 (0%)]\tLoss: 0.115406\n",
            "Train epoch: 561 [326940/20036 (50%)]\tLoss: 0.095422\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 562 [0/20036 (0%)]\tLoss: 0.099747\n",
            "Train epoch: 562 [331500/20036 (50%)]\tLoss: 0.140609\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 563 [0/20036 (0%)]\tLoss: 0.089379\n",
            "Train epoch: 563 [329960/20036 (50%)]\tLoss: 0.115518\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 564 [0/20036 (0%)]\tLoss: 0.082635\n",
            "Train epoch: 564 [326240/20036 (50%)]\tLoss: 0.099949\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 565 [0/20036 (0%)]\tLoss: 0.101971\n",
            "Train epoch: 565 [331520/20036 (50%)]\tLoss: 0.100022\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 566 [0/20036 (0%)]\tLoss: 0.114651\n",
            "Train epoch: 566 [331020/20036 (50%)]\tLoss: 0.087280\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 567 [0/20036 (0%)]\tLoss: 0.167043\n",
            "Train epoch: 567 [331560/20036 (50%)]\tLoss: 0.096230\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 568 [0/20036 (0%)]\tLoss: 0.111572\n",
            "Train epoch: 568 [330640/20036 (50%)]\tLoss: 0.083613\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 569 [0/20036 (0%)]\tLoss: 0.107666\n",
            "Train epoch: 569 [327940/20036 (50%)]\tLoss: 0.109394\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 570 [0/20036 (0%)]\tLoss: 0.140259\n",
            "Train epoch: 570 [328200/20036 (50%)]\tLoss: 0.115225\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 571 [0/20036 (0%)]\tLoss: 0.106501\n",
            "Train epoch: 571 [327920/20036 (50%)]\tLoss: 0.086510\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 572 [0/20036 (0%)]\tLoss: 0.150936\n",
            "Train epoch: 572 [327220/20036 (50%)]\tLoss: 0.096526\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 573 [0/20036 (0%)]\tLoss: 0.095706\n",
            "Train epoch: 573 [330260/20036 (50%)]\tLoss: 0.112168\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 574 [0/20036 (0%)]\tLoss: 0.090329\n",
            "Train epoch: 574 [329360/20036 (50%)]\tLoss: 0.124455\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 575 [0/20036 (0%)]\tLoss: 0.095779\n",
            "Train epoch: 575 [329300/20036 (50%)]\tLoss: 0.128665\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 576 [0/20036 (0%)]\tLoss: 0.091301\n",
            "Train epoch: 576 [330760/20036 (50%)]\tLoss: 0.110910\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 577 [0/20036 (0%)]\tLoss: 0.083058\n",
            "Train epoch: 577 [323380/20036 (50%)]\tLoss: 0.145675\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 578 [0/20036 (0%)]\tLoss: 0.120928\n",
            "Train epoch: 578 [329780/20036 (50%)]\tLoss: 0.112444\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 579 [0/20036 (0%)]\tLoss: 0.080924\n",
            "Train epoch: 579 [327140/20036 (50%)]\tLoss: 0.085768\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 580 [0/20036 (0%)]\tLoss: 0.095958\n",
            "Train epoch: 580 [327840/20036 (50%)]\tLoss: 0.136523\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 581 [0/20036 (0%)]\tLoss: 0.090493\n",
            "Train epoch: 581 [332700/20036 (50%)]\tLoss: 0.077448\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 582 [0/20036 (0%)]\tLoss: 0.119630\n",
            "Train epoch: 582 [328400/20036 (50%)]\tLoss: 0.093380\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 583 [0/20036 (0%)]\tLoss: 0.127294\n",
            "Train epoch: 583 [327080/20036 (50%)]\tLoss: 0.089602\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 584 [0/20036 (0%)]\tLoss: 0.108406\n",
            "Train epoch: 584 [325260/20036 (50%)]\tLoss: 0.099521\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 585 [0/20036 (0%)]\tLoss: 0.085284\n",
            "Train epoch: 585 [328720/20036 (50%)]\tLoss: 0.115837\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 586 [0/20036 (0%)]\tLoss: 0.116285\n",
            "Train epoch: 586 [323620/20036 (50%)]\tLoss: 0.111358\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 587 [0/20036 (0%)]\tLoss: 0.115334\n",
            "Train epoch: 587 [331140/20036 (50%)]\tLoss: 0.102874\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 588 [0/20036 (0%)]\tLoss: 0.093265\n",
            "Train epoch: 588 [332300/20036 (50%)]\tLoss: 0.109644\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 589 [0/20036 (0%)]\tLoss: 0.105698\n",
            "Train epoch: 589 [332400/20036 (50%)]\tLoss: 0.082574\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 590 [0/20036 (0%)]\tLoss: 0.084710\n",
            "Train epoch: 590 [333240/20036 (50%)]\tLoss: 0.093885\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 591 [0/20036 (0%)]\tLoss: 0.121918\n",
            "Train epoch: 591 [331560/20036 (50%)]\tLoss: 0.133879\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 592 [0/20036 (0%)]\tLoss: 0.109136\n",
            "Train epoch: 592 [332120/20036 (50%)]\tLoss: 0.122855\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 593 [0/20036 (0%)]\tLoss: 0.084957\n",
            "Train epoch: 593 [323380/20036 (50%)]\tLoss: 0.122036\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 594 [0/20036 (0%)]\tLoss: 0.107696\n",
            "Train epoch: 594 [332060/20036 (50%)]\tLoss: 0.112870\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 595 [0/20036 (0%)]\tLoss: 0.084653\n",
            "Train epoch: 595 [328460/20036 (50%)]\tLoss: 0.105943\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 596 [0/20036 (0%)]\tLoss: 0.096409\n",
            "Train epoch: 596 [328640/20036 (50%)]\tLoss: 0.113369\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 597 [0/20036 (0%)]\tLoss: 0.084492\n",
            "Train epoch: 597 [329720/20036 (50%)]\tLoss: 0.084083\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 598 [0/20036 (0%)]\tLoss: 0.104112\n",
            "Train epoch: 598 [325400/20036 (50%)]\tLoss: 0.125114\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 599 [0/20036 (0%)]\tLoss: 0.149185\n",
            "Train epoch: 599 [326700/20036 (50%)]\tLoss: 0.102715\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 600 [0/20036 (0%)]\tLoss: 0.102825\n",
            "Train epoch: 600 [329600/20036 (50%)]\tLoss: 0.087787\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 601 [0/20036 (0%)]\tLoss: 0.085016\n",
            "Train epoch: 601 [331420/20036 (50%)]\tLoss: 0.109078\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 602 [0/20036 (0%)]\tLoss: 0.091999\n",
            "Train epoch: 602 [324020/20036 (50%)]\tLoss: 0.111136\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 603 [0/20036 (0%)]\tLoss: 0.139227\n",
            "Train epoch: 603 [329560/20036 (50%)]\tLoss: 0.116622\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 604 [0/20036 (0%)]\tLoss: 0.142797\n",
            "Train epoch: 604 [327220/20036 (50%)]\tLoss: 0.079200\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 605 [0/20036 (0%)]\tLoss: 0.124075\n",
            "Train epoch: 605 [326980/20036 (50%)]\tLoss: 0.094082\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 606 [0/20036 (0%)]\tLoss: 0.085688\n",
            "Train epoch: 606 [324120/20036 (50%)]\tLoss: 0.093675\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 607 [0/20036 (0%)]\tLoss: 0.103455\n",
            "Train epoch: 607 [330840/20036 (50%)]\tLoss: 0.092537\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 608 [0/20036 (0%)]\tLoss: 0.109400\n",
            "Train epoch: 608 [325460/20036 (50%)]\tLoss: 0.096894\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 609 [0/20036 (0%)]\tLoss: 0.082519\n",
            "Train epoch: 609 [332240/20036 (50%)]\tLoss: 0.104891\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 610 [0/20036 (0%)]\tLoss: 0.085655\n",
            "Train epoch: 610 [331640/20036 (50%)]\tLoss: 0.092590\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 611 [0/20036 (0%)]\tLoss: 0.092191\n",
            "Train epoch: 611 [328840/20036 (50%)]\tLoss: 0.112974\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 612 [0/20036 (0%)]\tLoss: 0.124213\n",
            "Train epoch: 612 [328480/20036 (50%)]\tLoss: 0.115869\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 613 [0/20036 (0%)]\tLoss: 0.137842\n",
            "Train epoch: 613 [326580/20036 (50%)]\tLoss: 0.114737\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 614 [0/20036 (0%)]\tLoss: 0.103946\n",
            "Train epoch: 614 [326840/20036 (50%)]\tLoss: 0.118580\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 615 [0/20036 (0%)]\tLoss: 0.112000\n",
            "Train epoch: 615 [325260/20036 (50%)]\tLoss: 0.102926\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 616 [0/20036 (0%)]\tLoss: 0.089524\n",
            "Train epoch: 616 [330240/20036 (50%)]\tLoss: 0.089753\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 617 [0/20036 (0%)]\tLoss: 0.115507\n",
            "Train epoch: 617 [330180/20036 (50%)]\tLoss: 0.116380\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 618 [0/20036 (0%)]\tLoss: 0.122857\n",
            "Train epoch: 618 [329240/20036 (50%)]\tLoss: 0.083170\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 619 [0/20036 (0%)]\tLoss: 0.099521\n",
            "Train epoch: 619 [331680/20036 (50%)]\tLoss: 0.138727\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 620 [0/20036 (0%)]\tLoss: 0.102085\n",
            "Train epoch: 620 [328440/20036 (50%)]\tLoss: 0.126260\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 621 [0/20036 (0%)]\tLoss: 0.079671\n",
            "Train epoch: 621 [327780/20036 (50%)]\tLoss: 0.125251\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 622 [0/20036 (0%)]\tLoss: 0.088002\n",
            "Train epoch: 622 [325980/20036 (50%)]\tLoss: 0.095608\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 623 [0/20036 (0%)]\tLoss: 0.090067\n",
            "Train epoch: 623 [324980/20036 (50%)]\tLoss: 0.101218\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 624 [0/20036 (0%)]\tLoss: 0.092246\n",
            "Train epoch: 624 [323280/20036 (50%)]\tLoss: 0.104969\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 625 [0/20036 (0%)]\tLoss: 0.080134\n",
            "Train epoch: 625 [326780/20036 (50%)]\tLoss: 0.143417\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 626 [0/20036 (0%)]\tLoss: 0.096931\n",
            "Train epoch: 626 [329000/20036 (50%)]\tLoss: 0.120308\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 627 [0/20036 (0%)]\tLoss: 0.128320\n",
            "Train epoch: 627 [329540/20036 (50%)]\tLoss: 0.092701\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 628 [0/20036 (0%)]\tLoss: 0.110614\n",
            "Train epoch: 628 [329580/20036 (50%)]\tLoss: 0.076291\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 629 [0/20036 (0%)]\tLoss: 0.108114\n",
            "Train epoch: 629 [325200/20036 (50%)]\tLoss: 0.098087\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 630 [0/20036 (0%)]\tLoss: 0.101053\n",
            "Train epoch: 630 [328620/20036 (50%)]\tLoss: 0.094331\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 631 [0/20036 (0%)]\tLoss: 0.089676\n",
            "Train epoch: 631 [326200/20036 (50%)]\tLoss: 0.119292\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 632 [0/20036 (0%)]\tLoss: 0.090737\n",
            "Train epoch: 632 [331420/20036 (50%)]\tLoss: 0.112182\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 633 [0/20036 (0%)]\tLoss: 0.107774\n",
            "Train epoch: 633 [329240/20036 (50%)]\tLoss: 0.100446\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 634 [0/20036 (0%)]\tLoss: 0.161717\n",
            "Train epoch: 634 [329020/20036 (50%)]\tLoss: 0.126243\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 635 [0/20036 (0%)]\tLoss: 0.105346\n",
            "Train epoch: 635 [326980/20036 (50%)]\tLoss: 0.112555\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 636 [0/20036 (0%)]\tLoss: 0.070313\n",
            "Train epoch: 636 [327720/20036 (50%)]\tLoss: 0.083155\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 637 [0/20036 (0%)]\tLoss: 0.102130\n",
            "Train epoch: 637 [328280/20036 (50%)]\tLoss: 0.116355\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 638 [0/20036 (0%)]\tLoss: 0.093238\n",
            "Train epoch: 638 [325800/20036 (50%)]\tLoss: 0.069373\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 639 [0/20036 (0%)]\tLoss: 0.089221\n",
            "Train epoch: 639 [329100/20036 (50%)]\tLoss: 0.081452\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 640 [0/20036 (0%)]\tLoss: 0.102752\n",
            "Train epoch: 640 [322980/20036 (50%)]\tLoss: 0.104492\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 641 [0/20036 (0%)]\tLoss: 0.088055\n",
            "Train epoch: 641 [329320/20036 (50%)]\tLoss: 0.097155\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 642 [0/20036 (0%)]\tLoss: 0.099451\n",
            "Train epoch: 642 [323960/20036 (50%)]\tLoss: 0.099620\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 643 [0/20036 (0%)]\tLoss: 0.103237\n",
            "Train epoch: 643 [328220/20036 (50%)]\tLoss: 0.079151\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 644 [0/20036 (0%)]\tLoss: 0.120959\n",
            "Train epoch: 644 [328440/20036 (50%)]\tLoss: 0.124111\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 645 [0/20036 (0%)]\tLoss: 0.101459\n",
            "Train epoch: 645 [330780/20036 (50%)]\tLoss: 0.065167\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 646 [0/20036 (0%)]\tLoss: 0.102495\n",
            "Train epoch: 646 [326580/20036 (50%)]\tLoss: 0.085335\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 647 [0/20036 (0%)]\tLoss: 0.146723\n",
            "Train epoch: 647 [329680/20036 (50%)]\tLoss: 0.102314\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 648 [0/20036 (0%)]\tLoss: 0.117187\n",
            "Train epoch: 648 [328880/20036 (50%)]\tLoss: 0.127806\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 649 [0/20036 (0%)]\tLoss: 0.102484\n",
            "Train epoch: 649 [324180/20036 (50%)]\tLoss: 0.066335\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 650 [0/20036 (0%)]\tLoss: 0.076162\n",
            "Train epoch: 650 [326780/20036 (50%)]\tLoss: 0.067365\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 651 [0/20036 (0%)]\tLoss: 0.090831\n",
            "Train epoch: 651 [331440/20036 (50%)]\tLoss: 0.089742\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 652 [0/20036 (0%)]\tLoss: 0.104657\n",
            "Train epoch: 652 [328420/20036 (50%)]\tLoss: 0.079970\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 653 [0/20036 (0%)]\tLoss: 0.089696\n",
            "Train epoch: 653 [328360/20036 (50%)]\tLoss: 0.090337\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 654 [0/20036 (0%)]\tLoss: 0.093018\n",
            "Train epoch: 654 [332680/20036 (50%)]\tLoss: 0.105898\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 655 [0/20036 (0%)]\tLoss: 0.106166\n",
            "Train epoch: 655 [327820/20036 (50%)]\tLoss: 0.106865\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 656 [0/20036 (0%)]\tLoss: 0.084114\n",
            "Train epoch: 656 [325280/20036 (50%)]\tLoss: 0.088843\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 657 [0/20036 (0%)]\tLoss: 0.091941\n",
            "Train epoch: 657 [323400/20036 (50%)]\tLoss: 0.090149\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 658 [0/20036 (0%)]\tLoss: 0.088948\n",
            "Train epoch: 658 [327120/20036 (50%)]\tLoss: 0.079188\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 659 [0/20036 (0%)]\tLoss: 0.091714\n",
            "Train epoch: 659 [330360/20036 (50%)]\tLoss: 0.114030\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 660 [0/20036 (0%)]\tLoss: 0.085803\n",
            "Train epoch: 660 [326060/20036 (50%)]\tLoss: 0.080066\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 661 [0/20036 (0%)]\tLoss: 0.177296\n",
            "Train epoch: 661 [335260/20036 (50%)]\tLoss: 0.084430\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 662 [0/20036 (0%)]\tLoss: 0.101949\n",
            "Train epoch: 662 [329220/20036 (50%)]\tLoss: 0.118464\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 663 [0/20036 (0%)]\tLoss: 0.125193\n",
            "Train epoch: 663 [329660/20036 (50%)]\tLoss: 0.125983\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 664 [0/20036 (0%)]\tLoss: 0.086292\n",
            "Train epoch: 664 [324720/20036 (50%)]\tLoss: 0.085433\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 665 [0/20036 (0%)]\tLoss: 0.100721\n",
            "Train epoch: 665 [329540/20036 (50%)]\tLoss: 0.094581\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 666 [0/20036 (0%)]\tLoss: 0.086738\n",
            "Train epoch: 666 [325740/20036 (50%)]\tLoss: 0.119185\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 667 [0/20036 (0%)]\tLoss: 0.093155\n",
            "Train epoch: 667 [323360/20036 (50%)]\tLoss: 0.069100\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 668 [0/20036 (0%)]\tLoss: 0.095249\n",
            "Train epoch: 668 [329140/20036 (50%)]\tLoss: 0.122898\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 669 [0/20036 (0%)]\tLoss: 0.110532\n",
            "Train epoch: 669 [328020/20036 (50%)]\tLoss: 0.083421\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 670 [0/20036 (0%)]\tLoss: 0.117015\n",
            "Train epoch: 670 [326300/20036 (50%)]\tLoss: 0.086903\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 671 [0/20036 (0%)]\tLoss: 0.096885\n",
            "Train epoch: 671 [328200/20036 (50%)]\tLoss: 0.116732\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 672 [0/20036 (0%)]\tLoss: 0.109629\n",
            "Train epoch: 672 [333760/20036 (50%)]\tLoss: 0.126618\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 673 [0/20036 (0%)]\tLoss: 0.108593\n",
            "Train epoch: 673 [329140/20036 (50%)]\tLoss: 0.107243\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 674 [0/20036 (0%)]\tLoss: 0.093032\n",
            "Train epoch: 674 [329580/20036 (50%)]\tLoss: 0.107036\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 675 [0/20036 (0%)]\tLoss: 0.111214\n",
            "Train epoch: 675 [326020/20036 (50%)]\tLoss: 0.080999\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 676 [0/20036 (0%)]\tLoss: 0.082916\n",
            "Train epoch: 676 [325580/20036 (50%)]\tLoss: 0.093654\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 677 [0/20036 (0%)]\tLoss: 0.112112\n",
            "Train epoch: 677 [325600/20036 (50%)]\tLoss: 0.105842\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 678 [0/20036 (0%)]\tLoss: 0.106089\n",
            "Train epoch: 678 [324920/20036 (50%)]\tLoss: 0.110152\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 679 [0/20036 (0%)]\tLoss: 0.129711\n",
            "Train epoch: 679 [324420/20036 (50%)]\tLoss: 0.123111\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 680 [0/20036 (0%)]\tLoss: 0.090137\n",
            "Train epoch: 680 [326600/20036 (50%)]\tLoss: 0.083485\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 681 [0/20036 (0%)]\tLoss: 0.110368\n",
            "Train epoch: 681 [326660/20036 (50%)]\tLoss: 0.079176\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 682 [0/20036 (0%)]\tLoss: 0.109013\n",
            "Train epoch: 682 [328600/20036 (50%)]\tLoss: 0.092831\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 683 [0/20036 (0%)]\tLoss: 0.135754\n",
            "Train epoch: 683 [325220/20036 (50%)]\tLoss: 0.100240\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 684 [0/20036 (0%)]\tLoss: 0.119982\n",
            "Train epoch: 684 [331920/20036 (50%)]\tLoss: 0.094012\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 685 [0/20036 (0%)]\tLoss: 0.065493\n",
            "Train epoch: 685 [327560/20036 (50%)]\tLoss: 0.071126\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 686 [0/20036 (0%)]\tLoss: 0.108491\n",
            "Train epoch: 686 [325180/20036 (50%)]\tLoss: 0.082136\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 687 [0/20036 (0%)]\tLoss: 0.073975\n",
            "Train epoch: 687 [332160/20036 (50%)]\tLoss: 0.085291\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 688 [0/20036 (0%)]\tLoss: 0.120890\n",
            "Train epoch: 688 [332260/20036 (50%)]\tLoss: 0.079923\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 689 [0/20036 (0%)]\tLoss: 0.080455\n",
            "Train epoch: 689 [325400/20036 (50%)]\tLoss: 0.092996\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 690 [0/20036 (0%)]\tLoss: 0.079450\n",
            "Train epoch: 690 [330820/20036 (50%)]\tLoss: 0.088109\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 691 [0/20036 (0%)]\tLoss: 0.127970\n",
            "Train epoch: 691 [327160/20036 (50%)]\tLoss: 0.103418\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 692 [0/20036 (0%)]\tLoss: 0.076969\n",
            "Train epoch: 692 [334800/20036 (50%)]\tLoss: 0.143209\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 693 [0/20036 (0%)]\tLoss: 0.083217\n",
            "Train epoch: 693 [326320/20036 (50%)]\tLoss: 0.077093\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 694 [0/20036 (0%)]\tLoss: 0.133347\n",
            "Train epoch: 694 [324440/20036 (50%)]\tLoss: 0.122110\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 695 [0/20036 (0%)]\tLoss: 0.114359\n",
            "Train epoch: 695 [324660/20036 (50%)]\tLoss: 0.080871\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 696 [0/20036 (0%)]\tLoss: 0.090310\n",
            "Train epoch: 696 [326100/20036 (50%)]\tLoss: 0.103524\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 697 [0/20036 (0%)]\tLoss: 0.096857\n",
            "Train epoch: 697 [326740/20036 (50%)]\tLoss: 0.091409\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 698 [0/20036 (0%)]\tLoss: 0.095533\n",
            "Train epoch: 698 [334040/20036 (50%)]\tLoss: 0.104004\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 699 [0/20036 (0%)]\tLoss: 0.075129\n",
            "Train epoch: 699 [328360/20036 (50%)]\tLoss: 0.118763\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 700 [0/20036 (0%)]\tLoss: 0.077241\n",
            "Train epoch: 700 [333360/20036 (50%)]\tLoss: 0.084840\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 701 [0/20036 (0%)]\tLoss: 0.079627\n",
            "Train epoch: 701 [327400/20036 (50%)]\tLoss: 0.107908\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 702 [0/20036 (0%)]\tLoss: 0.079940\n",
            "Train epoch: 702 [330160/20036 (50%)]\tLoss: 0.116813\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 703 [0/20036 (0%)]\tLoss: 0.088073\n",
            "Train epoch: 703 [326660/20036 (50%)]\tLoss: 0.108084\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 704 [0/20036 (0%)]\tLoss: 0.096015\n",
            "Train epoch: 704 [324640/20036 (50%)]\tLoss: 0.109316\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 705 [0/20036 (0%)]\tLoss: 0.140052\n",
            "Train epoch: 705 [328040/20036 (50%)]\tLoss: 0.092772\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 706 [0/20036 (0%)]\tLoss: 0.099871\n",
            "Train epoch: 706 [328580/20036 (50%)]\tLoss: 0.091638\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 707 [0/20036 (0%)]\tLoss: 0.091923\n",
            "Train epoch: 707 [330440/20036 (50%)]\tLoss: 0.084880\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 708 [0/20036 (0%)]\tLoss: 0.094913\n",
            "Train epoch: 708 [328640/20036 (50%)]\tLoss: 0.084536\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 709 [0/20036 (0%)]\tLoss: 0.098782\n",
            "Train epoch: 709 [329260/20036 (50%)]\tLoss: 0.103027\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 710 [0/20036 (0%)]\tLoss: 0.078891\n",
            "Train epoch: 710 [330380/20036 (50%)]\tLoss: 0.077119\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 711 [0/20036 (0%)]\tLoss: 0.106130\n",
            "Train epoch: 711 [329180/20036 (50%)]\tLoss: 0.089478\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 712 [0/20036 (0%)]\tLoss: 0.071350\n",
            "Train epoch: 712 [330420/20036 (50%)]\tLoss: 0.094513\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 713 [0/20036 (0%)]\tLoss: 0.072348\n",
            "Train epoch: 713 [325980/20036 (50%)]\tLoss: 0.079503\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 714 [0/20036 (0%)]\tLoss: 0.108138\n",
            "Train epoch: 714 [329700/20036 (50%)]\tLoss: 0.093711\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 715 [0/20036 (0%)]\tLoss: 0.069267\n",
            "Train epoch: 715 [332740/20036 (50%)]\tLoss: 0.085732\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 716 [0/20036 (0%)]\tLoss: 0.098183\n",
            "Train epoch: 716 [331220/20036 (50%)]\tLoss: 0.085818\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 717 [0/20036 (0%)]\tLoss: 0.095441\n",
            "Train epoch: 717 [329540/20036 (50%)]\tLoss: 0.116272\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 718 [0/20036 (0%)]\tLoss: 0.068279\n",
            "Train epoch: 718 [328420/20036 (50%)]\tLoss: 0.094825\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 719 [0/20036 (0%)]\tLoss: 0.108804\n",
            "Train epoch: 719 [325680/20036 (50%)]\tLoss: 0.083332\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 720 [0/20036 (0%)]\tLoss: 0.168329\n",
            "Train epoch: 720 [330180/20036 (50%)]\tLoss: 0.091323\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 721 [0/20036 (0%)]\tLoss: 0.141463\n",
            "Train epoch: 721 [327240/20036 (50%)]\tLoss: 0.139536\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 722 [0/20036 (0%)]\tLoss: 0.088266\n",
            "Train epoch: 722 [326760/20036 (50%)]\tLoss: 0.090942\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 723 [0/20036 (0%)]\tLoss: 0.100617\n",
            "Train epoch: 723 [326400/20036 (50%)]\tLoss: 0.062963\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 724 [0/20036 (0%)]\tLoss: 0.095154\n",
            "Train epoch: 724 [329360/20036 (50%)]\tLoss: 0.077366\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 725 [0/20036 (0%)]\tLoss: 0.066449\n",
            "Train epoch: 725 [330260/20036 (50%)]\tLoss: 0.078991\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 726 [0/20036 (0%)]\tLoss: 0.093869\n",
            "Train epoch: 726 [323640/20036 (50%)]\tLoss: 0.097951\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 727 [0/20036 (0%)]\tLoss: 0.068282\n",
            "Train epoch: 727 [326200/20036 (50%)]\tLoss: 0.079409\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 728 [0/20036 (0%)]\tLoss: 0.091365\n",
            "Train epoch: 728 [330320/20036 (50%)]\tLoss: 0.074929\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 729 [0/20036 (0%)]\tLoss: 0.122923\n",
            "Train epoch: 729 [326980/20036 (50%)]\tLoss: 0.104608\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 730 [0/20036 (0%)]\tLoss: 0.081477\n",
            "Train epoch: 730 [328540/20036 (50%)]\tLoss: 0.074824\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 731 [0/20036 (0%)]\tLoss: 0.135258\n",
            "Train epoch: 731 [322380/20036 (50%)]\tLoss: 0.081567\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 732 [0/20036 (0%)]\tLoss: 0.096775\n",
            "Train epoch: 732 [329060/20036 (50%)]\tLoss: 0.115502\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 733 [0/20036 (0%)]\tLoss: 0.094180\n",
            "Train epoch: 733 [323660/20036 (50%)]\tLoss: 0.084009\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 734 [0/20036 (0%)]\tLoss: 0.099586\n",
            "Train epoch: 734 [326480/20036 (50%)]\tLoss: 0.093291\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 735 [0/20036 (0%)]\tLoss: 0.073610\n",
            "Train epoch: 735 [324520/20036 (50%)]\tLoss: 0.070600\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 736 [0/20036 (0%)]\tLoss: 0.099080\n",
            "Train epoch: 736 [326620/20036 (50%)]\tLoss: 0.079495\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 737 [0/20036 (0%)]\tLoss: 0.083791\n",
            "Train epoch: 737 [324720/20036 (50%)]\tLoss: 0.064617\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 738 [0/20036 (0%)]\tLoss: 0.095806\n",
            "Train epoch: 738 [326160/20036 (50%)]\tLoss: 0.088886\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 739 [0/20036 (0%)]\tLoss: 0.113493\n",
            "Train epoch: 739 [325760/20036 (50%)]\tLoss: 0.097306\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 740 [0/20036 (0%)]\tLoss: 0.105499\n",
            "Train epoch: 740 [328160/20036 (50%)]\tLoss: 0.088619\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 741 [0/20036 (0%)]\tLoss: 0.104412\n",
            "Train epoch: 741 [329540/20036 (50%)]\tLoss: 0.093746\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 742 [0/20036 (0%)]\tLoss: 0.124553\n",
            "Train epoch: 742 [327120/20036 (50%)]\tLoss: 0.125402\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 743 [0/20036 (0%)]\tLoss: 0.083628\n",
            "Train epoch: 743 [332840/20036 (50%)]\tLoss: 0.075150\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 744 [0/20036 (0%)]\tLoss: 0.141979\n",
            "Train epoch: 744 [330640/20036 (50%)]\tLoss: 0.081460\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 745 [0/20036 (0%)]\tLoss: 0.083950\n",
            "Train epoch: 745 [324400/20036 (50%)]\tLoss: 0.127179\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 746 [0/20036 (0%)]\tLoss: 0.087286\n",
            "Train epoch: 746 [325300/20036 (50%)]\tLoss: 0.085372\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 747 [0/20036 (0%)]\tLoss: 0.090867\n",
            "Train epoch: 747 [326740/20036 (50%)]\tLoss: 0.103710\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 748 [0/20036 (0%)]\tLoss: 0.099485\n",
            "Train epoch: 748 [328040/20036 (50%)]\tLoss: 0.084722\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 749 [0/20036 (0%)]\tLoss: 0.118279\n",
            "Train epoch: 749 [328380/20036 (50%)]\tLoss: 0.097102\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 750 [0/20036 (0%)]\tLoss: 0.087215\n",
            "Train epoch: 750 [328440/20036 (50%)]\tLoss: 0.082769\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 751 [0/20036 (0%)]\tLoss: 0.098021\n",
            "Train epoch: 751 [327040/20036 (50%)]\tLoss: 0.091118\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 752 [0/20036 (0%)]\tLoss: 0.116572\n",
            "Train epoch: 752 [333100/20036 (50%)]\tLoss: 0.086690\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 753 [0/20036 (0%)]\tLoss: 0.089652\n",
            "Train epoch: 753 [326980/20036 (50%)]\tLoss: 0.101728\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 754 [0/20036 (0%)]\tLoss: 0.096855\n",
            "Train epoch: 754 [322620/20036 (50%)]\tLoss: 0.095688\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 755 [0/20036 (0%)]\tLoss: 0.094898\n",
            "Train epoch: 755 [332280/20036 (50%)]\tLoss: 0.135239\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 756 [0/20036 (0%)]\tLoss: 0.080846\n",
            "Train epoch: 756 [325020/20036 (50%)]\tLoss: 0.083437\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 757 [0/20036 (0%)]\tLoss: 0.109812\n",
            "Train epoch: 757 [332440/20036 (50%)]\tLoss: 0.107314\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 758 [0/20036 (0%)]\tLoss: 0.066650\n",
            "Train epoch: 758 [326020/20036 (50%)]\tLoss: 0.075011\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 759 [0/20036 (0%)]\tLoss: 0.080419\n",
            "Train epoch: 759 [328720/20036 (50%)]\tLoss: 0.084313\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 760 [0/20036 (0%)]\tLoss: 0.087510\n",
            "Train epoch: 760 [328680/20036 (50%)]\tLoss: 0.104533\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 761 [0/20036 (0%)]\tLoss: 0.087972\n",
            "Train epoch: 761 [324980/20036 (50%)]\tLoss: 0.106792\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 762 [0/20036 (0%)]\tLoss: 0.107478\n",
            "Train epoch: 762 [325440/20036 (50%)]\tLoss: 0.084106\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 763 [0/20036 (0%)]\tLoss: 0.084537\n",
            "Train epoch: 763 [328900/20036 (50%)]\tLoss: 0.094989\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 764 [0/20036 (0%)]\tLoss: 0.072468\n",
            "Train epoch: 764 [325920/20036 (50%)]\tLoss: 0.079347\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 765 [0/20036 (0%)]\tLoss: 0.074718\n",
            "Train epoch: 765 [328040/20036 (50%)]\tLoss: 0.089136\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 766 [0/20036 (0%)]\tLoss: 0.081135\n",
            "Train epoch: 766 [329360/20036 (50%)]\tLoss: 0.090037\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 767 [0/20036 (0%)]\tLoss: 0.106262\n",
            "Train epoch: 767 [328120/20036 (50%)]\tLoss: 0.084974\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 768 [0/20036 (0%)]\tLoss: 0.108753\n",
            "Train epoch: 768 [333120/20036 (50%)]\tLoss: 0.125509\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 769 [0/20036 (0%)]\tLoss: 0.087059\n",
            "Train epoch: 769 [333620/20036 (50%)]\tLoss: 0.113640\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 770 [0/20036 (0%)]\tLoss: 0.073622\n",
            "Train epoch: 770 [330380/20036 (50%)]\tLoss: 0.071902\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 771 [0/20036 (0%)]\tLoss: 0.097347\n",
            "Train epoch: 771 [333440/20036 (50%)]\tLoss: 0.092070\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 772 [0/20036 (0%)]\tLoss: 0.108450\n",
            "Train epoch: 772 [326600/20036 (50%)]\tLoss: 0.067765\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 773 [0/20036 (0%)]\tLoss: 0.090198\n",
            "Train epoch: 773 [328260/20036 (50%)]\tLoss: 0.102427\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 774 [0/20036 (0%)]\tLoss: 0.065022\n",
            "Train epoch: 774 [326020/20036 (50%)]\tLoss: 0.067994\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 775 [0/20036 (0%)]\tLoss: 0.096994\n",
            "Train epoch: 775 [330180/20036 (50%)]\tLoss: 0.092702\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 776 [0/20036 (0%)]\tLoss: 0.067589\n",
            "Train epoch: 776 [324400/20036 (50%)]\tLoss: 0.100428\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 777 [0/20036 (0%)]\tLoss: 0.073119\n",
            "Train epoch: 777 [327220/20036 (50%)]\tLoss: 0.109159\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 778 [0/20036 (0%)]\tLoss: 0.080894\n",
            "Train epoch: 778 [325580/20036 (50%)]\tLoss: 0.079711\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 779 [0/20036 (0%)]\tLoss: 0.095219\n",
            "Train epoch: 779 [330540/20036 (50%)]\tLoss: 0.085436\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 780 [0/20036 (0%)]\tLoss: 0.080750\n",
            "Train epoch: 780 [328640/20036 (50%)]\tLoss: 0.087341\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 781 [0/20036 (0%)]\tLoss: 0.085003\n",
            "Train epoch: 781 [328240/20036 (50%)]\tLoss: 0.078240\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 782 [0/20036 (0%)]\tLoss: 0.076623\n",
            "Train epoch: 782 [323360/20036 (50%)]\tLoss: 0.069848\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 783 [0/20036 (0%)]\tLoss: 0.080022\n",
            "Train epoch: 783 [326740/20036 (50%)]\tLoss: 0.090339\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 784 [0/20036 (0%)]\tLoss: 0.064586\n",
            "Train epoch: 784 [327660/20036 (50%)]\tLoss: 0.105500\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 785 [0/20036 (0%)]\tLoss: 0.099505\n",
            "Train epoch: 785 [325300/20036 (50%)]\tLoss: 0.111198\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 786 [0/20036 (0%)]\tLoss: 0.147792\n",
            "Train epoch: 786 [327460/20036 (50%)]\tLoss: 0.070090\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 787 [0/20036 (0%)]\tLoss: 0.079910\n",
            "Train epoch: 787 [325560/20036 (50%)]\tLoss: 0.071898\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 788 [0/20036 (0%)]\tLoss: 0.086639\n",
            "Train epoch: 788 [330980/20036 (50%)]\tLoss: 0.074822\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 789 [0/20036 (0%)]\tLoss: 0.120187\n",
            "Train epoch: 789 [329840/20036 (50%)]\tLoss: 0.107833\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 790 [0/20036 (0%)]\tLoss: 0.093282\n",
            "Train epoch: 790 [333100/20036 (50%)]\tLoss: 0.096507\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 791 [0/20036 (0%)]\tLoss: 0.079180\n",
            "Train epoch: 791 [331800/20036 (50%)]\tLoss: 0.095817\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 792 [0/20036 (0%)]\tLoss: 0.093312\n",
            "Train epoch: 792 [321940/20036 (50%)]\tLoss: 0.066356\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 793 [0/20036 (0%)]\tLoss: 0.076626\n",
            "Train epoch: 793 [325200/20036 (50%)]\tLoss: 0.097688\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 794 [0/20036 (0%)]\tLoss: 0.084918\n",
            "Train epoch: 794 [326040/20036 (50%)]\tLoss: 0.069847\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 795 [0/20036 (0%)]\tLoss: 0.092690\n",
            "Train epoch: 795 [327980/20036 (50%)]\tLoss: 0.077101\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 796 [0/20036 (0%)]\tLoss: 0.074403\n",
            "Train epoch: 796 [327600/20036 (50%)]\tLoss: 0.079994\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 797 [0/20036 (0%)]\tLoss: 0.085815\n",
            "Train epoch: 797 [326360/20036 (50%)]\tLoss: 0.085001\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 798 [0/20036 (0%)]\tLoss: 0.095351\n",
            "Train epoch: 798 [330900/20036 (50%)]\tLoss: 0.085155\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 799 [0/20036 (0%)]\tLoss: 0.070889\n",
            "Train epoch: 799 [327980/20036 (50%)]\tLoss: 0.086688\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 800 [0/20036 (0%)]\tLoss: 0.094097\n",
            "Train epoch: 800 [329020/20036 (50%)]\tLoss: 0.092599\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 801 [0/20036 (0%)]\tLoss: 0.072839\n",
            "Train epoch: 801 [329460/20036 (50%)]\tLoss: 0.080053\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 802 [0/20036 (0%)]\tLoss: 0.103684\n",
            "Train epoch: 802 [328940/20036 (50%)]\tLoss: 0.088048\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 803 [0/20036 (0%)]\tLoss: 0.065826\n",
            "Train epoch: 803 [324820/20036 (50%)]\tLoss: 0.092877\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 804 [0/20036 (0%)]\tLoss: 0.210359\n",
            "Train epoch: 804 [329320/20036 (50%)]\tLoss: 0.086675\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 805 [0/20036 (0%)]\tLoss: 0.084493\n",
            "Train epoch: 805 [331620/20036 (50%)]\tLoss: 0.077972\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 806 [0/20036 (0%)]\tLoss: 0.100659\n",
            "Train epoch: 806 [325460/20036 (50%)]\tLoss: 0.086295\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 807 [0/20036 (0%)]\tLoss: 0.087512\n",
            "Train epoch: 807 [330600/20036 (50%)]\tLoss: 0.077035\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 808 [0/20036 (0%)]\tLoss: 0.082423\n",
            "Train epoch: 808 [325480/20036 (50%)]\tLoss: 0.081693\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 809 [0/20036 (0%)]\tLoss: 0.055296\n",
            "Train epoch: 809 [329680/20036 (50%)]\tLoss: 0.070007\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 810 [0/20036 (0%)]\tLoss: 0.079472\n",
            "Train epoch: 810 [325980/20036 (50%)]\tLoss: 0.064726\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 811 [0/20036 (0%)]\tLoss: 0.095690\n",
            "Train epoch: 811 [326700/20036 (50%)]\tLoss: 0.090660\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 812 [0/20036 (0%)]\tLoss: 0.101864\n",
            "Train epoch: 812 [325540/20036 (50%)]\tLoss: 0.076342\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 813 [0/20036 (0%)]\tLoss: 0.079316\n",
            "Train epoch: 813 [330140/20036 (50%)]\tLoss: 0.075507\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 814 [0/20036 (0%)]\tLoss: 0.121842\n",
            "Train epoch: 814 [326800/20036 (50%)]\tLoss: 0.123086\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 815 [0/20036 (0%)]\tLoss: 0.085702\n",
            "Train epoch: 815 [332020/20036 (50%)]\tLoss: 0.081616\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 816 [0/20036 (0%)]\tLoss: 0.070551\n",
            "Train epoch: 816 [329460/20036 (50%)]\tLoss: 0.114840\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 817 [0/20036 (0%)]\tLoss: 0.076118\n",
            "Train epoch: 817 [330180/20036 (50%)]\tLoss: 0.064916\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 818 [0/20036 (0%)]\tLoss: 0.100220\n",
            "Train epoch: 818 [329360/20036 (50%)]\tLoss: 0.085419\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 819 [0/20036 (0%)]\tLoss: 0.086748\n",
            "Train epoch: 819 [325220/20036 (50%)]\tLoss: 0.082071\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 820 [0/20036 (0%)]\tLoss: 0.092285\n",
            "Train epoch: 820 [327460/20036 (50%)]\tLoss: 0.092112\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 821 [0/20036 (0%)]\tLoss: 0.090645\n",
            "Train epoch: 821 [326820/20036 (50%)]\tLoss: 0.084616\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 822 [0/20036 (0%)]\tLoss: 0.078593\n",
            "Train epoch: 822 [327140/20036 (50%)]\tLoss: 0.096625\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 823 [0/20036 (0%)]\tLoss: 0.073176\n",
            "Train epoch: 823 [330200/20036 (50%)]\tLoss: 0.081902\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 824 [0/20036 (0%)]\tLoss: 0.067028\n",
            "Train epoch: 824 [328580/20036 (50%)]\tLoss: 0.086886\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 825 [0/20036 (0%)]\tLoss: 0.102043\n",
            "Train epoch: 825 [330040/20036 (50%)]\tLoss: 0.084052\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 826 [0/20036 (0%)]\tLoss: 0.076470\n",
            "Train epoch: 826 [328140/20036 (50%)]\tLoss: 0.078291\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 827 [0/20036 (0%)]\tLoss: 0.076673\n",
            "Train epoch: 827 [329120/20036 (50%)]\tLoss: 0.068701\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 828 [0/20036 (0%)]\tLoss: 0.089396\n",
            "Train epoch: 828 [327800/20036 (50%)]\tLoss: 0.069820\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 829 [0/20036 (0%)]\tLoss: 0.082285\n",
            "Train epoch: 829 [331980/20036 (50%)]\tLoss: 0.078509\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 830 [0/20036 (0%)]\tLoss: 0.075077\n",
            "Train epoch: 830 [330080/20036 (50%)]\tLoss: 0.070282\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 831 [0/20036 (0%)]\tLoss: 0.120577\n",
            "Train epoch: 831 [330160/20036 (50%)]\tLoss: 0.074188\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 832 [0/20036 (0%)]\tLoss: 0.078507\n",
            "Train epoch: 832 [325760/20036 (50%)]\tLoss: 0.105893\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 833 [0/20036 (0%)]\tLoss: 0.114920\n",
            "Train epoch: 833 [323220/20036 (50%)]\tLoss: 0.054805\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 834 [0/20036 (0%)]\tLoss: 0.068798\n",
            "Train epoch: 834 [326960/20036 (50%)]\tLoss: 0.080885\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 835 [0/20036 (0%)]\tLoss: 0.084948\n",
            "Train epoch: 835 [327840/20036 (50%)]\tLoss: 0.086132\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 836 [0/20036 (0%)]\tLoss: 0.083534\n",
            "Train epoch: 836 [328720/20036 (50%)]\tLoss: 0.080330\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 837 [0/20036 (0%)]\tLoss: 0.073223\n",
            "Train epoch: 837 [326380/20036 (50%)]\tLoss: 0.076616\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 838 [0/20036 (0%)]\tLoss: 0.120366\n",
            "Train epoch: 838 [326040/20036 (50%)]\tLoss: 0.054195\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 839 [0/20036 (0%)]\tLoss: 0.080948\n",
            "Train epoch: 839 [332880/20036 (50%)]\tLoss: 0.106720\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 840 [0/20036 (0%)]\tLoss: 0.078167\n",
            "Train epoch: 840 [329420/20036 (50%)]\tLoss: 0.115307\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 841 [0/20036 (0%)]\tLoss: 0.131198\n",
            "Train epoch: 841 [326900/20036 (50%)]\tLoss: 0.097455\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 842 [0/20036 (0%)]\tLoss: 0.089192\n",
            "Train epoch: 842 [330440/20036 (50%)]\tLoss: 0.079343\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 843 [0/20036 (0%)]\tLoss: 0.132910\n",
            "Train epoch: 843 [331600/20036 (50%)]\tLoss: 0.088732\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 844 [0/20036 (0%)]\tLoss: 0.106212\n",
            "Train epoch: 844 [329160/20036 (50%)]\tLoss: 0.088979\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 845 [0/20036 (0%)]\tLoss: 0.084479\n",
            "Train epoch: 845 [326000/20036 (50%)]\tLoss: 0.072609\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 846 [0/20036 (0%)]\tLoss: 0.083141\n",
            "Train epoch: 846 [329700/20036 (50%)]\tLoss: 0.088728\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 847 [0/20036 (0%)]\tLoss: 0.088072\n",
            "Train epoch: 847 [327480/20036 (50%)]\tLoss: 0.079846\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 848 [0/20036 (0%)]\tLoss: 0.136931\n",
            "Train epoch: 848 [328780/20036 (50%)]\tLoss: 0.079152\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 849 [0/20036 (0%)]\tLoss: 0.080433\n",
            "Train epoch: 849 [325120/20036 (50%)]\tLoss: 0.100856\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 850 [0/20036 (0%)]\tLoss: 0.105791\n",
            "Train epoch: 850 [328340/20036 (50%)]\tLoss: 0.072223\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 851 [0/20036 (0%)]\tLoss: 0.095409\n",
            "Train epoch: 851 [326160/20036 (50%)]\tLoss: 0.058495\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 852 [0/20036 (0%)]\tLoss: 0.082136\n",
            "Train epoch: 852 [323020/20036 (50%)]\tLoss: 0.097294\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 853 [0/20036 (0%)]\tLoss: 0.074931\n",
            "Train epoch: 853 [329640/20036 (50%)]\tLoss: 0.100531\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 854 [0/20036 (0%)]\tLoss: 0.092308\n",
            "Train epoch: 854 [328540/20036 (50%)]\tLoss: 0.068363\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 855 [0/20036 (0%)]\tLoss: 0.076404\n",
            "Train epoch: 855 [324900/20036 (50%)]\tLoss: 0.097189\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 856 [0/20036 (0%)]\tLoss: 0.102715\n",
            "Train epoch: 856 [327440/20036 (50%)]\tLoss: 0.073205\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 857 [0/20036 (0%)]\tLoss: 0.070431\n",
            "Train epoch: 857 [333360/20036 (50%)]\tLoss: 0.108061\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 858 [0/20036 (0%)]\tLoss: 0.099923\n",
            "Train epoch: 858 [325080/20036 (50%)]\tLoss: 0.118254\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 859 [0/20036 (0%)]\tLoss: 0.082609\n",
            "Train epoch: 859 [328360/20036 (50%)]\tLoss: 0.086214\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 860 [0/20036 (0%)]\tLoss: 0.082951\n",
            "Train epoch: 860 [326080/20036 (50%)]\tLoss: 0.080242\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 861 [0/20036 (0%)]\tLoss: 0.093220\n",
            "Train epoch: 861 [325920/20036 (50%)]\tLoss: 0.072948\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 862 [0/20036 (0%)]\tLoss: 0.060138\n",
            "Train epoch: 862 [330200/20036 (50%)]\tLoss: 0.073966\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 863 [0/20036 (0%)]\tLoss: 0.075378\n",
            "Train epoch: 863 [328300/20036 (50%)]\tLoss: 0.089053\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 864 [0/20036 (0%)]\tLoss: 0.057373\n",
            "Train epoch: 864 [328300/20036 (50%)]\tLoss: 0.093055\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 865 [0/20036 (0%)]\tLoss: 0.065090\n",
            "Train epoch: 865 [329620/20036 (50%)]\tLoss: 0.112154\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 866 [0/20036 (0%)]\tLoss: 0.067218\n",
            "Train epoch: 866 [331260/20036 (50%)]\tLoss: 0.088558\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 867 [0/20036 (0%)]\tLoss: 0.073934\n",
            "Train epoch: 867 [327640/20036 (50%)]\tLoss: 0.078671\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 868 [0/20036 (0%)]\tLoss: 0.059836\n",
            "Train epoch: 868 [323500/20036 (50%)]\tLoss: 0.090263\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 869 [0/20036 (0%)]\tLoss: 0.080272\n",
            "Train epoch: 869 [328920/20036 (50%)]\tLoss: 0.082596\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 870 [0/20036 (0%)]\tLoss: 0.084316\n",
            "Train epoch: 870 [330140/20036 (50%)]\tLoss: 0.079410\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 871 [0/20036 (0%)]\tLoss: 0.066569\n",
            "Train epoch: 871 [332580/20036 (50%)]\tLoss: 0.070593\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 872 [0/20036 (0%)]\tLoss: 0.067530\n",
            "Train epoch: 872 [332120/20036 (50%)]\tLoss: 0.078736\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 873 [0/20036 (0%)]\tLoss: 0.084606\n",
            "Train epoch: 873 [330460/20036 (50%)]\tLoss: 0.066115\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 874 [0/20036 (0%)]\tLoss: 0.078705\n",
            "Train epoch: 874 [323340/20036 (50%)]\tLoss: 0.089701\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 875 [0/20036 (0%)]\tLoss: 0.094608\n",
            "Train epoch: 875 [330100/20036 (50%)]\tLoss: 0.095578\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 876 [0/20036 (0%)]\tLoss: 0.126107\n",
            "Train epoch: 876 [326780/20036 (50%)]\tLoss: 0.093589\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 877 [0/20036 (0%)]\tLoss: 0.084472\n",
            "Train epoch: 877 [326080/20036 (50%)]\tLoss: 0.092061\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 878 [0/20036 (0%)]\tLoss: 0.114644\n",
            "Train epoch: 878 [327580/20036 (50%)]\tLoss: 0.136461\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 879 [0/20036 (0%)]\tLoss: 0.074899\n",
            "Train epoch: 879 [325040/20036 (50%)]\tLoss: 0.102750\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 880 [0/20036 (0%)]\tLoss: 0.072496\n",
            "Train epoch: 880 [328920/20036 (50%)]\tLoss: 0.076077\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 881 [0/20036 (0%)]\tLoss: 0.064944\n",
            "Train epoch: 881 [328280/20036 (50%)]\tLoss: 0.072820\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 882 [0/20036 (0%)]\tLoss: 0.076282\n",
            "Train epoch: 882 [327220/20036 (50%)]\tLoss: 0.065334\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 883 [0/20036 (0%)]\tLoss: 0.078420\n",
            "Train epoch: 883 [325480/20036 (50%)]\tLoss: 0.120185\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 884 [0/20036 (0%)]\tLoss: 0.070878\n",
            "Train epoch: 884 [324500/20036 (50%)]\tLoss: 0.092931\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 885 [0/20036 (0%)]\tLoss: 0.080673\n",
            "Train epoch: 885 [329240/20036 (50%)]\tLoss: 0.079205\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 886 [0/20036 (0%)]\tLoss: 0.077642\n",
            "Train epoch: 886 [327840/20036 (50%)]\tLoss: 0.069777\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 887 [0/20036 (0%)]\tLoss: 0.079288\n",
            "Train epoch: 887 [329620/20036 (50%)]\tLoss: 0.076950\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 888 [0/20036 (0%)]\tLoss: 0.127391\n",
            "Train epoch: 888 [328840/20036 (50%)]\tLoss: 0.085043\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 889 [0/20036 (0%)]\tLoss: 0.091934\n",
            "Train epoch: 889 [325460/20036 (50%)]\tLoss: 0.082274\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 890 [0/20036 (0%)]\tLoss: 0.070969\n",
            "Train epoch: 890 [335360/20036 (50%)]\tLoss: 0.088680\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 891 [0/20036 (0%)]\tLoss: 0.074931\n",
            "Train epoch: 891 [324320/20036 (50%)]\tLoss: 0.076722\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 892 [0/20036 (0%)]\tLoss: 0.071462\n",
            "Train epoch: 892 [329220/20036 (50%)]\tLoss: 0.078426\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 893 [0/20036 (0%)]\tLoss: 0.086254\n",
            "Train epoch: 893 [328700/20036 (50%)]\tLoss: 0.073382\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 894 [0/20036 (0%)]\tLoss: 0.095907\n",
            "Train epoch: 894 [327840/20036 (50%)]\tLoss: 0.069290\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 895 [0/20036 (0%)]\tLoss: 0.070425\n",
            "Train epoch: 895 [329900/20036 (50%)]\tLoss: 0.075118\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 896 [0/20036 (0%)]\tLoss: 0.078139\n",
            "Train epoch: 896 [328700/20036 (50%)]\tLoss: 0.076691\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 897 [0/20036 (0%)]\tLoss: 0.091871\n",
            "Train epoch: 897 [328100/20036 (50%)]\tLoss: 0.079041\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 898 [0/20036 (0%)]\tLoss: 0.103412\n",
            "Train epoch: 898 [324540/20036 (50%)]\tLoss: 0.073108\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 899 [0/20036 (0%)]\tLoss: 0.098032\n",
            "Train epoch: 899 [324560/20036 (50%)]\tLoss: 0.089177\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 900 [0/20036 (0%)]\tLoss: 0.103050\n",
            "Train epoch: 900 [326860/20036 (50%)]\tLoss: 0.112739\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 901 [0/20036 (0%)]\tLoss: 0.095944\n",
            "Train epoch: 901 [322320/20036 (50%)]\tLoss: 0.070456\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 902 [0/20036 (0%)]\tLoss: 0.115071\n",
            "Train epoch: 902 [327860/20036 (50%)]\tLoss: 0.143460\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 903 [0/20036 (0%)]\tLoss: 0.091457\n",
            "Train epoch: 903 [329700/20036 (50%)]\tLoss: 0.075216\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 904 [0/20036 (0%)]\tLoss: 0.099943\n",
            "Train epoch: 904 [327840/20036 (50%)]\tLoss: 0.078548\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 905 [0/20036 (0%)]\tLoss: 0.073433\n",
            "Train epoch: 905 [327860/20036 (50%)]\tLoss: 0.060586\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 906 [0/20036 (0%)]\tLoss: 0.062441\n",
            "Train epoch: 906 [325780/20036 (50%)]\tLoss: 0.077034\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 907 [0/20036 (0%)]\tLoss: 0.070994\n",
            "Train epoch: 907 [329220/20036 (50%)]\tLoss: 0.072448\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 908 [0/20036 (0%)]\tLoss: 0.068832\n",
            "Train epoch: 908 [326140/20036 (50%)]\tLoss: 0.115849\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 909 [0/20036 (0%)]\tLoss: 0.136968\n",
            "Train epoch: 909 [327680/20036 (50%)]\tLoss: 0.057092\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 910 [0/20036 (0%)]\tLoss: 0.102055\n",
            "Train epoch: 910 [333180/20036 (50%)]\tLoss: 0.065454\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 911 [0/20036 (0%)]\tLoss: 0.076221\n",
            "Train epoch: 911 [328800/20036 (50%)]\tLoss: 0.086733\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 912 [0/20036 (0%)]\tLoss: 0.089885\n",
            "Train epoch: 912 [333300/20036 (50%)]\tLoss: 0.119482\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 913 [0/20036 (0%)]\tLoss: 0.077435\n",
            "Train epoch: 913 [330660/20036 (50%)]\tLoss: 0.103413\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 914 [0/20036 (0%)]\tLoss: 0.084073\n",
            "Train epoch: 914 [328480/20036 (50%)]\tLoss: 0.101770\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 915 [0/20036 (0%)]\tLoss: 0.076277\n",
            "Train epoch: 915 [327560/20036 (50%)]\tLoss: 0.064211\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 916 [0/20036 (0%)]\tLoss: 0.065543\n",
            "Train epoch: 916 [323880/20036 (50%)]\tLoss: 0.054081\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 917 [0/20036 (0%)]\tLoss: 0.075498\n",
            "Train epoch: 917 [332040/20036 (50%)]\tLoss: 0.094775\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 918 [0/20036 (0%)]\tLoss: 0.098448\n",
            "Train epoch: 918 [330720/20036 (50%)]\tLoss: 0.070056\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 919 [0/20036 (0%)]\tLoss: 0.059045\n",
            "Train epoch: 919 [334660/20036 (50%)]\tLoss: 0.071617\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 920 [0/20036 (0%)]\tLoss: 0.084641\n",
            "Train epoch: 920 [329800/20036 (50%)]\tLoss: 0.069421\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 921 [0/20036 (0%)]\tLoss: 0.100770\n",
            "Train epoch: 921 [328220/20036 (50%)]\tLoss: 0.116210\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 922 [0/20036 (0%)]\tLoss: 0.071704\n",
            "Train epoch: 922 [325600/20036 (50%)]\tLoss: 0.068774\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 923 [0/20036 (0%)]\tLoss: 0.066142\n",
            "Train epoch: 923 [332960/20036 (50%)]\tLoss: 0.079031\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 924 [0/20036 (0%)]\tLoss: 0.070068\n",
            "Train epoch: 924 [326900/20036 (50%)]\tLoss: 0.056723\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 925 [0/20036 (0%)]\tLoss: 0.063355\n",
            "Train epoch: 925 [331420/20036 (50%)]\tLoss: 0.073190\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 926 [0/20036 (0%)]\tLoss: 0.079812\n",
            "Train epoch: 926 [325100/20036 (50%)]\tLoss: 0.103596\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 927 [0/20036 (0%)]\tLoss: 0.071825\n",
            "Train epoch: 927 [327560/20036 (50%)]\tLoss: 0.066260\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 928 [0/20036 (0%)]\tLoss: 0.080184\n",
            "Train epoch: 928 [329300/20036 (50%)]\tLoss: 0.069982\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 929 [0/20036 (0%)]\tLoss: 0.080593\n",
            "Train epoch: 929 [327120/20036 (50%)]\tLoss: 0.079367\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 930 [0/20036 (0%)]\tLoss: 0.088335\n",
            "Train epoch: 930 [326080/20036 (50%)]\tLoss: 0.069054\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 931 [0/20036 (0%)]\tLoss: 0.083290\n",
            "Train epoch: 931 [330780/20036 (50%)]\tLoss: 0.085435\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 932 [0/20036 (0%)]\tLoss: 0.088502\n",
            "Train epoch: 932 [326820/20036 (50%)]\tLoss: 0.064206\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 933 [0/20036 (0%)]\tLoss: 0.065992\n",
            "Train epoch: 933 [333280/20036 (50%)]\tLoss: 0.067223\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 934 [0/20036 (0%)]\tLoss: 0.091793\n",
            "Train epoch: 934 [326220/20036 (50%)]\tLoss: 0.066946\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 935 [0/20036 (0%)]\tLoss: 0.092988\n",
            "Train epoch: 935 [326680/20036 (50%)]\tLoss: 0.069336\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 936 [0/20036 (0%)]\tLoss: 0.118492\n",
            "Train epoch: 936 [327720/20036 (50%)]\tLoss: 0.066927\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 937 [0/20036 (0%)]\tLoss: 0.060506\n",
            "Train epoch: 937 [332500/20036 (50%)]\tLoss: 0.096667\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 938 [0/20036 (0%)]\tLoss: 0.082882\n",
            "Train epoch: 938 [326600/20036 (50%)]\tLoss: 0.110536\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 939 [0/20036 (0%)]\tLoss: 0.059497\n",
            "Train epoch: 939 [327360/20036 (50%)]\tLoss: 0.072102\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 940 [0/20036 (0%)]\tLoss: 0.076657\n",
            "Train epoch: 940 [327520/20036 (50%)]\tLoss: 0.080747\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 941 [0/20036 (0%)]\tLoss: 0.126489\n",
            "Train epoch: 941 [329460/20036 (50%)]\tLoss: 0.067839\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 942 [0/20036 (0%)]\tLoss: 0.080872\n",
            "Train epoch: 942 [326200/20036 (50%)]\tLoss: 0.107977\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 943 [0/20036 (0%)]\tLoss: 0.083199\n",
            "Train epoch: 943 [329700/20036 (50%)]\tLoss: 0.070925\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 944 [0/20036 (0%)]\tLoss: 0.088861\n",
            "Train epoch: 944 [328340/20036 (50%)]\tLoss: 0.093883\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 945 [0/20036 (0%)]\tLoss: 0.084975\n",
            "Train epoch: 945 [334020/20036 (50%)]\tLoss: 0.061901\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 946 [0/20036 (0%)]\tLoss: 0.079061\n",
            "Train epoch: 946 [327660/20036 (50%)]\tLoss: 0.059955\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 947 [0/20036 (0%)]\tLoss: 0.086309\n",
            "Train epoch: 947 [326780/20036 (50%)]\tLoss: 0.093815\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 948 [0/20036 (0%)]\tLoss: 0.081893\n",
            "Train epoch: 948 [331080/20036 (50%)]\tLoss: 0.086986\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 949 [0/20036 (0%)]\tLoss: 0.048900\n",
            "Train epoch: 949 [326340/20036 (50%)]\tLoss: 0.079930\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 950 [0/20036 (0%)]\tLoss: 0.062495\n",
            "Train epoch: 950 [327460/20036 (50%)]\tLoss: 0.058027\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 951 [0/20036 (0%)]\tLoss: 0.078997\n",
            "Train epoch: 951 [322800/20036 (50%)]\tLoss: 0.086450\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 952 [0/20036 (0%)]\tLoss: 0.079518\n",
            "Train epoch: 952 [332940/20036 (50%)]\tLoss: 0.071815\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 953 [0/20036 (0%)]\tLoss: 0.069658\n",
            "Train epoch: 953 [329460/20036 (50%)]\tLoss: 0.071255\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 954 [0/20036 (0%)]\tLoss: 0.096684\n",
            "Train epoch: 954 [328080/20036 (50%)]\tLoss: 0.055672\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 955 [0/20036 (0%)]\tLoss: 0.074363\n",
            "Train epoch: 955 [328340/20036 (50%)]\tLoss: 0.081763\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 956 [0/20036 (0%)]\tLoss: 0.079868\n",
            "Train epoch: 956 [330600/20036 (50%)]\tLoss: 0.067063\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 957 [0/20036 (0%)]\tLoss: 0.072085\n",
            "Train epoch: 957 [326460/20036 (50%)]\tLoss: 0.065240\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 958 [0/20036 (0%)]\tLoss: 0.076831\n",
            "Train epoch: 958 [331720/20036 (50%)]\tLoss: 0.055160\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 959 [0/20036 (0%)]\tLoss: 0.099954\n",
            "Train epoch: 959 [326200/20036 (50%)]\tLoss: 0.054685\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 960 [0/20036 (0%)]\tLoss: 0.065453\n",
            "Train epoch: 960 [328140/20036 (50%)]\tLoss: 0.095595\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 961 [0/20036 (0%)]\tLoss: 0.082834\n",
            "Train epoch: 961 [327780/20036 (50%)]\tLoss: 0.068679\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 962 [0/20036 (0%)]\tLoss: 0.086044\n",
            "Train epoch: 962 [332480/20036 (50%)]\tLoss: 0.080973\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 963 [0/20036 (0%)]\tLoss: 0.084149\n",
            "Train epoch: 963 [327340/20036 (50%)]\tLoss: 0.090560\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 964 [0/20036 (0%)]\tLoss: 0.092143\n",
            "Train epoch: 964 [330120/20036 (50%)]\tLoss: 0.065963\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 965 [0/20036 (0%)]\tLoss: 0.093531\n",
            "Train epoch: 965 [328320/20036 (50%)]\tLoss: 0.061964\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 966 [0/20036 (0%)]\tLoss: 0.160461\n",
            "Train epoch: 966 [327600/20036 (50%)]\tLoss: 0.103638\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 967 [0/20036 (0%)]\tLoss: 0.055861\n",
            "Train epoch: 967 [323100/20036 (50%)]\tLoss: 0.075160\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 968 [0/20036 (0%)]\tLoss: 0.076157\n",
            "Train epoch: 968 [326220/20036 (50%)]\tLoss: 0.071989\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 969 [0/20036 (0%)]\tLoss: 0.075756\n",
            "Train epoch: 969 [323960/20036 (50%)]\tLoss: 0.082596\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 970 [0/20036 (0%)]\tLoss: 0.086340\n",
            "Train epoch: 970 [328700/20036 (50%)]\tLoss: 0.079962\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 971 [0/20036 (0%)]\tLoss: 0.092853\n",
            "Train epoch: 971 [326340/20036 (50%)]\tLoss: 0.067760\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 972 [0/20036 (0%)]\tLoss: 0.055608\n",
            "Train epoch: 972 [330300/20036 (50%)]\tLoss: 0.065872\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 973 [0/20036 (0%)]\tLoss: 0.083048\n",
            "Train epoch: 973 [323320/20036 (50%)]\tLoss: 0.089376\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 974 [0/20036 (0%)]\tLoss: 0.079691\n",
            "Train epoch: 974 [323200/20036 (50%)]\tLoss: 0.081570\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 975 [0/20036 (0%)]\tLoss: 0.086906\n",
            "Train epoch: 975 [330160/20036 (50%)]\tLoss: 0.090290\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 976 [0/20036 (0%)]\tLoss: 0.043084\n",
            "Train epoch: 976 [332020/20036 (50%)]\tLoss: 0.078993\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 977 [0/20036 (0%)]\tLoss: 0.069963\n",
            "Train epoch: 977 [330020/20036 (50%)]\tLoss: 0.068315\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 978 [0/20036 (0%)]\tLoss: 0.074824\n",
            "Train epoch: 978 [330840/20036 (50%)]\tLoss: 0.055396\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 979 [0/20036 (0%)]\tLoss: 0.092017\n",
            "Train epoch: 979 [330840/20036 (50%)]\tLoss: 0.096336\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 980 [0/20036 (0%)]\tLoss: 0.101469\n",
            "Train epoch: 980 [330040/20036 (50%)]\tLoss: 0.055970\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 981 [0/20036 (0%)]\tLoss: 0.075932\n",
            "Train epoch: 981 [330380/20036 (50%)]\tLoss: 0.064748\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 982 [0/20036 (0%)]\tLoss: 0.097739\n",
            "Train epoch: 982 [331060/20036 (50%)]\tLoss: 0.053027\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 983 [0/20036 (0%)]\tLoss: 0.098199\n",
            "Train epoch: 983 [327480/20036 (50%)]\tLoss: 0.126222\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 984 [0/20036 (0%)]\tLoss: 0.077962\n",
            "Train epoch: 984 [328200/20036 (50%)]\tLoss: 0.077001\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 985 [0/20036 (0%)]\tLoss: 0.058458\n",
            "Train epoch: 985 [326380/20036 (50%)]\tLoss: 0.057656\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 986 [0/20036 (0%)]\tLoss: 0.068206\n",
            "Train epoch: 986 [330280/20036 (50%)]\tLoss: 0.078375\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 987 [0/20036 (0%)]\tLoss: 0.066863\n",
            "Train epoch: 987 [320860/20036 (50%)]\tLoss: 0.086931\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 988 [0/20036 (0%)]\tLoss: 0.091734\n",
            "Train epoch: 988 [324260/20036 (50%)]\tLoss: 0.083666\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 989 [0/20036 (0%)]\tLoss: 0.069374\n",
            "Train epoch: 989 [332880/20036 (50%)]\tLoss: 0.078435\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 990 [0/20036 (0%)]\tLoss: 0.091378\n",
            "Train epoch: 990 [331500/20036 (50%)]\tLoss: 0.084639\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 991 [0/20036 (0%)]\tLoss: 0.056476\n",
            "Train epoch: 991 [327460/20036 (50%)]\tLoss: 0.057498\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 992 [0/20036 (0%)]\tLoss: 0.072511\n",
            "Train epoch: 992 [323460/20036 (50%)]\tLoss: 0.065257\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 993 [0/20036 (0%)]\tLoss: 0.069262\n",
            "Train epoch: 993 [334140/20036 (50%)]\tLoss: 0.067128\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 994 [0/20036 (0%)]\tLoss: 0.093998\n",
            "Train epoch: 994 [327120/20036 (50%)]\tLoss: 0.065933\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 995 [0/20036 (0%)]\tLoss: 0.076962\n",
            "Train epoch: 995 [331780/20036 (50%)]\tLoss: 0.071132\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 996 [0/20036 (0%)]\tLoss: 0.066054\n",
            "Train epoch: 996 [326700/20036 (50%)]\tLoss: 0.079975\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 997 [0/20036 (0%)]\tLoss: 0.076405\n",
            "Train epoch: 997 [336380/20036 (50%)]\tLoss: 0.098490\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 998 [0/20036 (0%)]\tLoss: 0.155931\n",
            "Train epoch: 998 [330600/20036 (50%)]\tLoss: 0.075912\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 999 [0/20036 (0%)]\tLoss: 0.068361\n",
            "Train epoch: 999 [330140/20036 (50%)]\tLoss: 0.065155\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n",
            "Training on 20036 samples...\n",
            "Train epoch: 1000 [0/20036 (0%)]\tLoss: 0.059904\n",
            "Train epoch: 1000 [327720/20036 (50%)]\tLoss: 0.063652\n",
            "predicting for valid data\n",
            "Make prediction for 5010 samples...\n",
            "0.25480992 No improvement since epoch  468 ; best_test_mse,best_test_ci: 0.25480992 0.8805958342784128 GINConvNet davis\n"
          ]
        }
      ]
    }
  ]
}