{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rgo8cLB7Ayqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f9d193-6cb5-4077-d0f4-539cb07acf8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_Et0csGA4of",
        "outputId": "94be9805-4ff9-4405-92e2-99113bab11f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCJG-aZCA4lg",
        "outputId": "82853f8b-e3a5-4237-9e17-3ba1f3e22225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive  Othercomputers\n"
          ]
        }
      ],
      "source": [
        "!ls drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqBB0ST7A4i_",
        "outputId": "44f052f4-2c64-451d-e4aa-f8ef2139c32f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GraphDTA-master\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/GraphDTA-master'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xsOYH5eqLNn"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3b_OMfravpyX"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYc3W8E4A4fw",
        "outputId": "3f31be1a-3e75-4560-b597-06cdd0f07a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=a34f10132d52a5612afd983c512dfbd776879d69e28fe0d701db1b8b4ae19de3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I6H3tkEBMmf",
        "outputId": "3df0fcd8-e1b3-4dda-cbbb-b43da5fadfb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision numpy pandas scikit-learn tqdm matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SqX64FABMhW",
        "outputId": "056bc0b7-ec69-497c-f6a6-11255afe719c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QwFW6ZtGBMdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab84d78-ade4-460a-a7a9-30dcc1510e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.1-cp310-cp310-manylinux1_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DbTx4r7DqzrX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "from random import shuffle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from models.gat import GATNet\n",
        "from models.gat_gcn import GAT_GATNet\n",
        "from models.gcn import GCNNet\n",
        "from models.ginconv import GINConvNet\n",
        "from utils import *\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SglIrZyXq5C4"
      },
      "outputs": [],
      "source": [
        "\n",
        "#import dataloader as dataloader\n",
        "# training function at each epoch\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    print('Training on {} samples...'.format(len(train_loader.dataset)))\n",
        "    model.train()\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, data.y.view(-1, 1).float().to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % LOG_INTERVAL == 0:\n",
        "            print('Train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,\n",
        "                                            batch_idx * len(data.x),\n",
        "                                            len(train_loader.dataset),\n",
        "                                            100. * batch_idx / len(train_loader),\n",
        "                                            loss.item()))\n",
        "\n",
        "def predicting(model, device, loader):\n",
        "    model.eval()\n",
        "    total_preds = torch.Tensor()\n",
        "    total_labels = torch.Tensor()\n",
        "    print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "            total_preds = torch.cat((total_preds, output.cpu()), 0)\n",
        "            total_labels = torch.cat((total_labels, data.y.view(-1, 1).cpu()), 0)\n",
        "    return total_labels.numpy().flatten(),total_preds.numpy().flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dvwYgB5W0fK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe2b461-d90d-4beb-e6c5-65ea2ea114dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.4.14)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from Tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->Tensorflow) (0.41.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->Tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->Tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->Tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->Tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->Tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->Tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->Tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->Tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->Tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->Tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->Tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->Tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->Tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->Tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->Tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->Tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->Tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->Tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->Tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VkCLVf2Q0kBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12db4205-d472-4e7e-8277-d5e60b3b5d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from Scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from Scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from Scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from Scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: Matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: Seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from Matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from Matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from Matplotlib) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from Matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from Matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from Matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from Matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from Matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from Matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from Seaborn) (1.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->Seaborn) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->Matplotlib) (1.16.0)\n",
            "Collecting subword_nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Collecting periodictable\n",
            "  Downloading periodictable-1.6.1-py2.py3-none-any.whl (752 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m752.5/752.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mock (from subword_nmt)\n",
            "  Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from subword_nmt) (4.66.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from periodictable) (3.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from periodictable) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, periodictable, mock, tensorflow_addons, subword_nmt\n",
            "Successfully installed mock-5.1.0 periodictable-1.6.1 subword_nmt-0.3.8 tensorflow_addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install Scikit-learn\n",
        "!pip install Matplotlib Seaborn\n",
        "!pip install subword_nmt periodictable tensorflow_addons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HTSE-Gwnz86t"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import json\n",
        "import itertools\n",
        "import periodictable as pt\n",
        "import re\n",
        "from itertools import chain\n",
        "from operator import itemgetter\n",
        "from subword_nmt.apply_bpe import BPE\n",
        "import codecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PilPO5CR0fG5"
      },
      "outputs": [],
      "source": [
        "!python '/content/drive/MyDrive/GraphDTA-master/create_data.py'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training.py 0 2 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdz_KEYE0oq8",
        "outputId": "9c877626-2cf7-483c-d578-d176eaee7e5d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda_name: cuda:0\n",
            "Learning rate:  0.0005\n",
            "Epochs:  1000\n",
            "\n",
            "running on  GAT_GATNet_davis\n",
            "Pre-processed data found: data/processed/davis_train.pt, loading ...\n",
            "Pre-processed data found: data/processed/davis_test.pt, loading ...\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "Training on 25046 samples...\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/scatter.py:93: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n",
            "Train epoch: 1 [0/25046 (0%)]\tLoss: 30.639332\n",
            "Train epoch: 1 [322700/25046 (41%)]\tLoss: 1.464669\n",
            "Train epoch: 1 [664360/25046 (82%)]\tLoss: 0.971416\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  1 ; best_mse,best_ci: 0.8356921 0.6224880475839173 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 2 [0/25046 (0%)]\tLoss: 0.776760\n",
            "Train epoch: 2 [328220/25046 (41%)]\tLoss: 0.767836\n",
            "Train epoch: 2 [671400/25046 (82%)]\tLoss: 1.024132\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  2 ; best_mse,best_ci: 0.7380422 0.6732784454637945 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 3 [0/25046 (0%)]\tLoss: 0.855084\n",
            "Train epoch: 3 [323120/25046 (41%)]\tLoss: 0.689690\n",
            "Train epoch: 3 [656480/25046 (82%)]\tLoss: 0.846569\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  3 ; best_mse,best_ci: 0.6450526 0.7414276247263737 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 4 [0/25046 (0%)]\tLoss: 0.671565\n",
            "Train epoch: 4 [324500/25046 (41%)]\tLoss: 0.678817\n",
            "Train epoch: 4 [639520/25046 (82%)]\tLoss: 0.879228\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  4 ; best_mse,best_ci: 0.5878295 0.7772274407287738 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 5 [0/25046 (0%)]\tLoss: 0.626549\n",
            "Train epoch: 5 [327200/25046 (41%)]\tLoss: 0.695553\n",
            "Train epoch: 5 [659800/25046 (82%)]\tLoss: 0.687039\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  5 ; best_mse,best_ci: 0.5830402 0.7857614129741434 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 6 [0/25046 (0%)]\tLoss: 0.540790\n",
            "Train epoch: 6 [324540/25046 (41%)]\tLoss: 0.605135\n",
            "Train epoch: 6 [661840/25046 (82%)]\tLoss: 0.556279\n",
            "Make prediction for 5010 samples...\n",
            "0.59164155 No improvement since epoch  5 ; best_mse,best_ci: 0.5830402 0.7857614129741434 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 7 [0/25046 (0%)]\tLoss: 0.702659\n",
            "Train epoch: 7 [328840/25046 (41%)]\tLoss: 0.611135\n",
            "Train epoch: 7 [667600/25046 (82%)]\tLoss: 0.581798\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  7 ; best_mse,best_ci: 0.5509364 0.7921944370973713 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 8 [0/25046 (0%)]\tLoss: 0.734826\n",
            "Train epoch: 8 [329720/25046 (41%)]\tLoss: 0.549665\n",
            "Train epoch: 8 [650640/25046 (82%)]\tLoss: 0.654238\n",
            "Make prediction for 5010 samples...\n",
            "0.60989404 No improvement since epoch  7 ; best_mse,best_ci: 0.5509364 0.7921944370973713 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 9 [0/25046 (0%)]\tLoss: 0.650095\n",
            "Train epoch: 9 [331740/25046 (41%)]\tLoss: 0.631446\n",
            "Train epoch: 9 [657360/25046 (82%)]\tLoss: 0.481728\n",
            "Make prediction for 5010 samples...\n",
            "0.5544242 No improvement since epoch  7 ; best_mse,best_ci: 0.5509364 0.7921944370973713 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 10 [0/25046 (0%)]\tLoss: 0.756754\n",
            "Train epoch: 10 [325760/25046 (41%)]\tLoss: 0.630656\n",
            "Train epoch: 10 [661080/25046 (82%)]\tLoss: 0.550143\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  10 ; best_mse,best_ci: 0.51598525 0.7978015855281768 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 11 [0/25046 (0%)]\tLoss: 0.540953\n",
            "Train epoch: 11 [326020/25046 (41%)]\tLoss: 0.696379\n",
            "Train epoch: 11 [652680/25046 (82%)]\tLoss: 0.592156\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  11 ; best_mse,best_ci: 0.5084616 0.8022070982273652 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 12 [0/25046 (0%)]\tLoss: 0.552219\n",
            "Train epoch: 12 [326580/25046 (41%)]\tLoss: 0.591301\n",
            "Train epoch: 12 [655120/25046 (82%)]\tLoss: 0.531512\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  12 ; best_mse,best_ci: 0.5013688 0.8000620421405656 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 13 [0/25046 (0%)]\tLoss: 0.684243\n",
            "Train epoch: 13 [326900/25046 (41%)]\tLoss: 0.673459\n",
            "Train epoch: 13 [651600/25046 (82%)]\tLoss: 0.715316\n",
            "Make prediction for 5010 samples...\n",
            "0.59216654 No improvement since epoch  12 ; best_mse,best_ci: 0.5013688 0.8000620421405656 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 14 [0/25046 (0%)]\tLoss: 0.646578\n",
            "Train epoch: 14 [328500/25046 (41%)]\tLoss: 0.545405\n",
            "Train epoch: 14 [647920/25046 (82%)]\tLoss: 0.574459\n",
            "Make prediction for 5010 samples...\n",
            "0.5043621 No improvement since epoch  12 ; best_mse,best_ci: 0.5013688 0.8000620421405656 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 15 [0/25046 (0%)]\tLoss: 0.554674\n",
            "Train epoch: 15 [330580/25046 (41%)]\tLoss: 0.444240\n",
            "Train epoch: 15 [654840/25046 (82%)]\tLoss: 0.617733\n",
            "Make prediction for 5010 samples...\n",
            "0.505692 No improvement since epoch  12 ; best_mse,best_ci: 0.5013688 0.8000620421405656 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 16 [0/25046 (0%)]\tLoss: 0.546632\n",
            "Train epoch: 16 [331780/25046 (41%)]\tLoss: 0.592608\n",
            "Train epoch: 16 [648120/25046 (82%)]\tLoss: 0.590748\n",
            "Make prediction for 5010 samples...\n",
            "0.5403063 No improvement since epoch  12 ; best_mse,best_ci: 0.5013688 0.8000620421405656 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 17 [0/25046 (0%)]\tLoss: 0.510750\n",
            "Train epoch: 17 [330540/25046 (41%)]\tLoss: 0.540173\n",
            "Train epoch: 17 [652640/25046 (82%)]\tLoss: 0.459198\n",
            "Make prediction for 5010 samples...\n",
            "0.5215975 No improvement since epoch  12 ; best_mse,best_ci: 0.5013688 0.8000620421405656 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 18 [0/25046 (0%)]\tLoss: 0.559306\n",
            "Train epoch: 18 [332480/25046 (41%)]\tLoss: 0.611883\n",
            "Train epoch: 18 [649760/25046 (82%)]\tLoss: 0.522672\n",
            "Make prediction for 5010 samples...\n",
            "0.5418326 No improvement since epoch  12 ; best_mse,best_ci: 0.5013688 0.8000620421405656 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 19 [0/25046 (0%)]\tLoss: 0.505682\n",
            "Train epoch: 19 [327740/25046 (41%)]\tLoss: 0.572122\n",
            "Train epoch: 19 [660280/25046 (82%)]\tLoss: 0.636944\n",
            "Make prediction for 5010 samples...\n",
            "0.5199025 No improvement since epoch  12 ; best_mse,best_ci: 0.5013688 0.8000620421405656 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 20 [0/25046 (0%)]\tLoss: 0.639187\n",
            "Train epoch: 20 [331480/25046 (41%)]\tLoss: 0.530597\n",
            "Train epoch: 20 [653920/25046 (82%)]\tLoss: 0.515429\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  20 ; best_mse,best_ci: 0.4969602 0.8157275677689012 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 21 [0/25046 (0%)]\tLoss: 0.642745\n",
            "Train epoch: 21 [330300/25046 (41%)]\tLoss: 0.454432\n",
            "Train epoch: 21 [659080/25046 (82%)]\tLoss: 0.584982\n",
            "Make prediction for 5010 samples...\n",
            "0.516984 No improvement since epoch  20 ; best_mse,best_ci: 0.4969602 0.8157275677689012 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 22 [0/25046 (0%)]\tLoss: 0.515165\n",
            "Train epoch: 22 [332220/25046 (41%)]\tLoss: 0.460666\n",
            "Train epoch: 22 [651360/25046 (82%)]\tLoss: 0.570525\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  22 ; best_mse,best_ci: 0.4955816 0.8252045774878155 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 23 [0/25046 (0%)]\tLoss: 0.525933\n",
            "Train epoch: 23 [323480/25046 (41%)]\tLoss: 0.487376\n",
            "Train epoch: 23 [666360/25046 (82%)]\tLoss: 0.577667\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  23 ; best_mse,best_ci: 0.49132717 0.826473753540315 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 24 [0/25046 (0%)]\tLoss: 0.464388\n",
            "Train epoch: 24 [332480/25046 (41%)]\tLoss: 0.512623\n",
            "Train epoch: 24 [652440/25046 (82%)]\tLoss: 0.395548\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  24 ; best_mse,best_ci: 0.48030818 0.8223593074620721 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 25 [0/25046 (0%)]\tLoss: 0.519115\n",
            "Train epoch: 25 [332140/25046 (41%)]\tLoss: 0.374006\n",
            "Train epoch: 25 [652080/25046 (82%)]\tLoss: 0.530386\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  25 ; best_mse,best_ci: 0.47031254 0.8258341114764483 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 26 [0/25046 (0%)]\tLoss: 0.452099\n",
            "Train epoch: 26 [328060/25046 (41%)]\tLoss: 0.610697\n",
            "Train epoch: 26 [657480/25046 (82%)]\tLoss: 0.412720\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  26 ; best_mse,best_ci: 0.44918844 0.8298274138045371 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 27 [0/25046 (0%)]\tLoss: 0.325265\n",
            "Train epoch: 27 [328760/25046 (41%)]\tLoss: 0.531014\n",
            "Train epoch: 27 [656440/25046 (82%)]\tLoss: 0.555465\n",
            "Make prediction for 5010 samples...\n",
            "0.5140961 No improvement since epoch  26 ; best_mse,best_ci: 0.44918844 0.8298274138045371 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 28 [0/25046 (0%)]\tLoss: 0.579634\n",
            "Train epoch: 28 [332880/25046 (41%)]\tLoss: 0.453450\n",
            "Train epoch: 28 [651040/25046 (82%)]\tLoss: 0.457820\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  28 ; best_mse,best_ci: 0.44466063 0.8297981616474203 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 29 [0/25046 (0%)]\tLoss: 0.503999\n",
            "Train epoch: 29 [327280/25046 (41%)]\tLoss: 0.395254\n",
            "Train epoch: 29 [655240/25046 (82%)]\tLoss: 0.534338\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  29 ; best_mse,best_ci: 0.4290915 0.8344122682628032 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 30 [0/25046 (0%)]\tLoss: 0.408305\n",
            "Train epoch: 30 [326920/25046 (41%)]\tLoss: 0.491186\n",
            "Train epoch: 30 [640000/25046 (82%)]\tLoss: 0.461481\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  30 ; best_mse,best_ci: 0.42413172 0.836002758585623 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 31 [0/25046 (0%)]\tLoss: 0.389952\n",
            "Train epoch: 31 [329900/25046 (41%)]\tLoss: 0.529273\n",
            "Train epoch: 31 [657320/25046 (82%)]\tLoss: 0.578022\n",
            "Make prediction for 5010 samples...\n",
            "0.4303672 No improvement since epoch  30 ; best_mse,best_ci: 0.42413172 0.836002758585623 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 32 [0/25046 (0%)]\tLoss: 0.382511\n",
            "Train epoch: 32 [330880/25046 (41%)]\tLoss: 0.404405\n",
            "Train epoch: 32 [658600/25046 (82%)]\tLoss: 0.565672\n",
            "Make prediction for 5010 samples...\n",
            "0.46152797 No improvement since epoch  30 ; best_mse,best_ci: 0.42413172 0.836002758585623 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 33 [0/25046 (0%)]\tLoss: 0.454680\n",
            "Train epoch: 33 [327760/25046 (41%)]\tLoss: 0.342369\n",
            "Train epoch: 33 [647280/25046 (82%)]\tLoss: 0.402995\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  33 ; best_mse,best_ci: 0.41825432 0.8378291805735659 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 34 [0/25046 (0%)]\tLoss: 0.344963\n",
            "Train epoch: 34 [326240/25046 (41%)]\tLoss: 0.475150\n",
            "Train epoch: 34 [656040/25046 (82%)]\tLoss: 0.408867\n",
            "Make prediction for 5010 samples...\n",
            "0.45243546 No improvement since epoch  33 ; best_mse,best_ci: 0.41825432 0.8378291805735659 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 35 [0/25046 (0%)]\tLoss: 0.501025\n",
            "Train epoch: 35 [326480/25046 (41%)]\tLoss: 0.426753\n",
            "Train epoch: 35 [656640/25046 (82%)]\tLoss: 0.620296\n",
            "Make prediction for 5010 samples...\n",
            "0.4662179 No improvement since epoch  33 ; best_mse,best_ci: 0.41825432 0.8378291805735659 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 36 [0/25046 (0%)]\tLoss: 0.401487\n",
            "Train epoch: 36 [327520/25046 (41%)]\tLoss: 0.389351\n",
            "Train epoch: 36 [653840/25046 (82%)]\tLoss: 0.539559\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  36 ; best_mse,best_ci: 0.4130073 0.8441945112232563 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 37 [0/25046 (0%)]\tLoss: 0.392934\n",
            "Train epoch: 37 [326620/25046 (41%)]\tLoss: 0.471297\n",
            "Train epoch: 37 [662160/25046 (82%)]\tLoss: 0.575440\n",
            "Make prediction for 5010 samples...\n",
            "0.41924652 No improvement since epoch  36 ; best_mse,best_ci: 0.4130073 0.8441945112232563 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 38 [0/25046 (0%)]\tLoss: 0.486523\n",
            "Train epoch: 38 [331320/25046 (41%)]\tLoss: 0.397785\n",
            "Train epoch: 38 [651240/25046 (82%)]\tLoss: 0.391580\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  38 ; best_mse,best_ci: 0.38537556 0.840924166003388 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 39 [0/25046 (0%)]\tLoss: 0.319005\n",
            "Train epoch: 39 [329920/25046 (41%)]\tLoss: 0.434689\n",
            "Train epoch: 39 [655840/25046 (82%)]\tLoss: 0.424361\n",
            "Make prediction for 5010 samples...\n",
            "0.39831683 No improvement since epoch  38 ; best_mse,best_ci: 0.38537556 0.840924166003388 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 40 [0/25046 (0%)]\tLoss: 0.339271\n",
            "Train epoch: 40 [332080/25046 (41%)]\tLoss: 0.353210\n",
            "Train epoch: 40 [666240/25046 (82%)]\tLoss: 0.438172\n",
            "Make prediction for 5010 samples...\n",
            "0.3956826 No improvement since epoch  38 ; best_mse,best_ci: 0.38537556 0.840924166003388 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 41 [0/25046 (0%)]\tLoss: 0.358172\n",
            "Train epoch: 41 [328120/25046 (41%)]\tLoss: 0.386597\n",
            "Train epoch: 41 [661160/25046 (82%)]\tLoss: 0.382714\n",
            "Make prediction for 5010 samples...\n",
            "0.38551146 No improvement since epoch  38 ; best_mse,best_ci: 0.38537556 0.840924166003388 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 42 [0/25046 (0%)]\tLoss: 0.408801\n",
            "Train epoch: 42 [329560/25046 (41%)]\tLoss: 0.420390\n",
            "Train epoch: 42 [651040/25046 (82%)]\tLoss: 0.440030\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  42 ; best_mse,best_ci: 0.37298846 0.8503877748649844 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 43 [0/25046 (0%)]\tLoss: 0.365726\n",
            "Train epoch: 43 [329420/25046 (41%)]\tLoss: 0.445926\n",
            "Train epoch: 43 [660520/25046 (82%)]\tLoss: 0.278930\n",
            "Make prediction for 5010 samples...\n",
            "0.400123 No improvement since epoch  42 ; best_mse,best_ci: 0.37298846 0.8503877748649844 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 44 [0/25046 (0%)]\tLoss: 0.382481\n",
            "Train epoch: 44 [331780/25046 (41%)]\tLoss: 0.395791\n",
            "Train epoch: 44 [654880/25046 (82%)]\tLoss: 0.360872\n",
            "Make prediction for 5010 samples...\n",
            "0.37316647 No improvement since epoch  42 ; best_mse,best_ci: 0.37298846 0.8503877748649844 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 45 [0/25046 (0%)]\tLoss: 0.405370\n",
            "Train epoch: 45 [327860/25046 (41%)]\tLoss: 0.391652\n",
            "Train epoch: 45 [655400/25046 (82%)]\tLoss: 0.365286\n",
            "Make prediction for 5010 samples...\n",
            "0.4156365 No improvement since epoch  42 ; best_mse,best_ci: 0.37298846 0.8503877748649844 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 46 [0/25046 (0%)]\tLoss: 0.378539\n",
            "Train epoch: 46 [332760/25046 (41%)]\tLoss: 0.427926\n",
            "Train epoch: 46 [658280/25046 (82%)]\tLoss: 0.335733\n",
            "Make prediction for 5010 samples...\n",
            "0.37998378 No improvement since epoch  42 ; best_mse,best_ci: 0.37298846 0.8503877748649844 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 47 [0/25046 (0%)]\tLoss: 0.364260\n",
            "Train epoch: 47 [327500/25046 (41%)]\tLoss: 0.319580\n",
            "Train epoch: 47 [672000/25046 (82%)]\tLoss: 0.353353\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  47 ; best_mse,best_ci: 0.35836545 0.8502060592397532 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 48 [0/25046 (0%)]\tLoss: 0.392586\n",
            "Train epoch: 48 [333120/25046 (41%)]\tLoss: 0.315410\n",
            "Train epoch: 48 [651440/25046 (82%)]\tLoss: 0.412744\n",
            "Make prediction for 5010 samples...\n",
            "0.36591372 No improvement since epoch  47 ; best_mse,best_ci: 0.35836545 0.8502060592397532 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 49 [0/25046 (0%)]\tLoss: 0.312728\n",
            "Train epoch: 49 [326300/25046 (41%)]\tLoss: 0.331521\n",
            "Train epoch: 49 [653760/25046 (82%)]\tLoss: 0.314034\n",
            "Make prediction for 5010 samples...\n",
            "0.38714382 No improvement since epoch  47 ; best_mse,best_ci: 0.35836545 0.8502060592397532 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 50 [0/25046 (0%)]\tLoss: 0.366453\n",
            "Train epoch: 50 [328560/25046 (41%)]\tLoss: 0.371663\n",
            "Train epoch: 50 [659280/25046 (82%)]\tLoss: 0.299837\n",
            "Make prediction for 5010 samples...\n",
            "0.38856062 No improvement since epoch  47 ; best_mse,best_ci: 0.35836545 0.8502060592397532 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 51 [0/25046 (0%)]\tLoss: 0.366517\n",
            "Train epoch: 51 [329900/25046 (41%)]\tLoss: 0.291305\n",
            "Train epoch: 51 [647000/25046 (82%)]\tLoss: 0.429665\n",
            "Make prediction for 5010 samples...\n",
            "0.3671086 No improvement since epoch  47 ; best_mse,best_ci: 0.35836545 0.8502060592397532 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 52 [0/25046 (0%)]\tLoss: 0.345224\n",
            "Train epoch: 52 [331300/25046 (41%)]\tLoss: 0.417305\n",
            "Train epoch: 52 [652760/25046 (82%)]\tLoss: 0.334279\n",
            "Make prediction for 5010 samples...\n",
            "0.38419434 No improvement since epoch  47 ; best_mse,best_ci: 0.35836545 0.8502060592397532 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 53 [0/25046 (0%)]\tLoss: 0.370907\n",
            "Train epoch: 53 [329680/25046 (41%)]\tLoss: 0.583445\n",
            "Train epoch: 53 [659960/25046 (82%)]\tLoss: 0.347240\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  53 ; best_mse,best_ci: 0.3553807 0.8565185522234473 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 54 [0/25046 (0%)]\tLoss: 0.356043\n",
            "Train epoch: 54 [330580/25046 (41%)]\tLoss: 0.390306\n",
            "Train epoch: 54 [655640/25046 (82%)]\tLoss: 0.361377\n",
            "Make prediction for 5010 samples...\n",
            "0.36425743 No improvement since epoch  53 ; best_mse,best_ci: 0.3553807 0.8565185522234473 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 55 [0/25046 (0%)]\tLoss: 0.343008\n",
            "Train epoch: 55 [331520/25046 (41%)]\tLoss: 0.405848\n",
            "Train epoch: 55 [651400/25046 (82%)]\tLoss: 0.395866\n",
            "Make prediction for 5010 samples...\n",
            "0.38861358 No improvement since epoch  53 ; best_mse,best_ci: 0.3553807 0.8565185522234473 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 56 [0/25046 (0%)]\tLoss: 0.372918\n",
            "Train epoch: 56 [330500/25046 (41%)]\tLoss: 0.379955\n",
            "Train epoch: 56 [663160/25046 (82%)]\tLoss: 0.349597\n",
            "Make prediction for 5010 samples...\n",
            "0.3566563 No improvement since epoch  53 ; best_mse,best_ci: 0.3553807 0.8565185522234473 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 57 [0/25046 (0%)]\tLoss: 0.319112\n",
            "Train epoch: 57 [327440/25046 (41%)]\tLoss: 0.421511\n",
            "Train epoch: 57 [651440/25046 (82%)]\tLoss: 0.360670\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  57 ; best_mse,best_ci: 0.3508643 0.8559762386718724 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 58 [0/25046 (0%)]\tLoss: 0.353500\n",
            "Train epoch: 58 [328440/25046 (41%)]\tLoss: 0.362432\n",
            "Train epoch: 58 [662640/25046 (82%)]\tLoss: 0.374413\n",
            "Make prediction for 5010 samples...\n",
            "0.3574643 No improvement since epoch  57 ; best_mse,best_ci: 0.3508643 0.8559762386718724 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 59 [0/25046 (0%)]\tLoss: 0.311371\n",
            "Train epoch: 59 [327720/25046 (41%)]\tLoss: 0.352914\n",
            "Train epoch: 59 [657080/25046 (82%)]\tLoss: 0.353663\n",
            "Make prediction for 5010 samples...\n",
            "0.3513847 No improvement since epoch  57 ; best_mse,best_ci: 0.3508643 0.8559762386718724 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 60 [0/25046 (0%)]\tLoss: 0.320124\n",
            "Train epoch: 60 [328100/25046 (41%)]\tLoss: 0.315556\n",
            "Train epoch: 60 [655240/25046 (82%)]\tLoss: 0.374646\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  60 ; best_mse,best_ci: 0.34727013 0.8549639761982396 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 61 [0/25046 (0%)]\tLoss: 0.286611\n",
            "Train epoch: 61 [326820/25046 (41%)]\tLoss: 0.366169\n",
            "Train epoch: 61 [648560/25046 (82%)]\tLoss: 0.350840\n",
            "Make prediction for 5010 samples...\n",
            "0.4147489 No improvement since epoch  60 ; best_mse,best_ci: 0.34727013 0.8549639761982396 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 62 [0/25046 (0%)]\tLoss: 0.376441\n",
            "Train epoch: 62 [328940/25046 (41%)]\tLoss: 0.341821\n",
            "Train epoch: 62 [659400/25046 (82%)]\tLoss: 0.298769\n",
            "Make prediction for 5010 samples...\n",
            "0.35247883 No improvement since epoch  60 ; best_mse,best_ci: 0.34727013 0.8549639761982396 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 63 [0/25046 (0%)]\tLoss: 0.312589\n",
            "Train epoch: 63 [324340/25046 (41%)]\tLoss: 0.303802\n",
            "Train epoch: 63 [653080/25046 (82%)]\tLoss: 0.314458\n",
            "Make prediction for 5010 samples...\n",
            "0.37808627 No improvement since epoch  60 ; best_mse,best_ci: 0.34727013 0.8549639761982396 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 64 [0/25046 (0%)]\tLoss: 0.363343\n",
            "Train epoch: 64 [329120/25046 (41%)]\tLoss: 0.287313\n",
            "Train epoch: 64 [650640/25046 (82%)]\tLoss: 0.276852\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  64 ; best_mse,best_ci: 0.33823994 0.8512546188926359 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 65 [0/25046 (0%)]\tLoss: 0.378348\n",
            "Train epoch: 65 [331300/25046 (41%)]\tLoss: 0.349779\n",
            "Train epoch: 65 [659040/25046 (82%)]\tLoss: 0.386273\n",
            "Make prediction for 5010 samples...\n",
            "0.40410534 No improvement since epoch  64 ; best_mse,best_ci: 0.33823994 0.8512546188926359 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 66 [0/25046 (0%)]\tLoss: 0.337040\n",
            "Train epoch: 66 [327840/25046 (41%)]\tLoss: 0.344844\n",
            "Train epoch: 66 [658200/25046 (82%)]\tLoss: 0.322541\n",
            "Make prediction for 5010 samples...\n",
            "0.35300067 No improvement since epoch  64 ; best_mse,best_ci: 0.33823994 0.8512546188926359 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 67 [0/25046 (0%)]\tLoss: 0.298711\n",
            "Train epoch: 67 [332740/25046 (41%)]\tLoss: 0.317817\n",
            "Train epoch: 67 [654880/25046 (82%)]\tLoss: 0.334486\n",
            "Make prediction for 5010 samples...\n",
            "0.3646603 No improvement since epoch  64 ; best_mse,best_ci: 0.33823994 0.8512546188926359 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 68 [0/25046 (0%)]\tLoss: 0.310995\n",
            "Train epoch: 68 [332260/25046 (41%)]\tLoss: 0.292634\n",
            "Train epoch: 68 [650800/25046 (82%)]\tLoss: 0.276097\n",
            "Make prediction for 5010 samples...\n",
            "0.34015173 No improvement since epoch  64 ; best_mse,best_ci: 0.33823994 0.8512546188926359 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 69 [0/25046 (0%)]\tLoss: 0.286725\n",
            "Train epoch: 69 [325820/25046 (41%)]\tLoss: 0.270950\n",
            "Train epoch: 69 [649440/25046 (82%)]\tLoss: 0.296155\n",
            "Make prediction for 5010 samples...\n",
            "0.33828118 No improvement since epoch  64 ; best_mse,best_ci: 0.33823994 0.8512546188926359 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 70 [0/25046 (0%)]\tLoss: 0.301774\n",
            "Train epoch: 70 [331280/25046 (41%)]\tLoss: 0.296445\n",
            "Train epoch: 70 [654280/25046 (82%)]\tLoss: 0.263304\n",
            "Make prediction for 5010 samples...\n",
            "0.3429152 No improvement since epoch  64 ; best_mse,best_ci: 0.33823994 0.8512546188926359 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 71 [0/25046 (0%)]\tLoss: 0.252414\n",
            "Train epoch: 71 [324400/25046 (41%)]\tLoss: 0.302738\n",
            "Train epoch: 71 [654200/25046 (82%)]\tLoss: 0.303997\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  71 ; best_mse,best_ci: 0.3279565 0.8534570306487562 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 72 [0/25046 (0%)]\tLoss: 0.235092\n",
            "Train epoch: 72 [324340/25046 (41%)]\tLoss: 0.294972\n",
            "Train epoch: 72 [659880/25046 (82%)]\tLoss: 0.267209\n",
            "Make prediction for 5010 samples...\n",
            "0.35447937 No improvement since epoch  71 ; best_mse,best_ci: 0.3279565 0.8534570306487562 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 73 [0/25046 (0%)]\tLoss: 0.308864\n",
            "Train epoch: 73 [329040/25046 (41%)]\tLoss: 0.358289\n",
            "Train epoch: 73 [655040/25046 (82%)]\tLoss: 0.313739\n",
            "Make prediction for 5010 samples...\n",
            "0.33633944 No improvement since epoch  71 ; best_mse,best_ci: 0.3279565 0.8534570306487562 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 74 [0/25046 (0%)]\tLoss: 0.265884\n",
            "Train epoch: 74 [330720/25046 (41%)]\tLoss: 0.317889\n",
            "Train epoch: 74 [660640/25046 (82%)]\tLoss: 0.297032\n",
            "Make prediction for 5010 samples...\n",
            "0.3535492 No improvement since epoch  71 ; best_mse,best_ci: 0.3279565 0.8534570306487562 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 75 [0/25046 (0%)]\tLoss: 0.296672\n",
            "Train epoch: 75 [327620/25046 (41%)]\tLoss: 0.284791\n",
            "Train epoch: 75 [650880/25046 (82%)]\tLoss: 0.281335\n",
            "Make prediction for 5010 samples...\n",
            "0.37186325 No improvement since epoch  71 ; best_mse,best_ci: 0.3279565 0.8534570306487562 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 76 [0/25046 (0%)]\tLoss: 0.338928\n",
            "Train epoch: 76 [331240/25046 (41%)]\tLoss: 0.324288\n",
            "Train epoch: 76 [653680/25046 (82%)]\tLoss: 0.296733\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  76 ; best_mse,best_ci: 0.32216027 0.8575211660798112 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 77 [0/25046 (0%)]\tLoss: 0.239938\n",
            "Train epoch: 77 [331460/25046 (41%)]\tLoss: 0.358671\n",
            "Train epoch: 77 [655440/25046 (82%)]\tLoss: 0.314433\n",
            "Make prediction for 5010 samples...\n",
            "0.3600911 No improvement since epoch  76 ; best_mse,best_ci: 0.32216027 0.8575211660798112 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 78 [0/25046 (0%)]\tLoss: 0.299655\n",
            "Train epoch: 78 [330220/25046 (41%)]\tLoss: 0.394507\n",
            "Train epoch: 78 [650080/25046 (82%)]\tLoss: 0.285987\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  78 ; best_mse,best_ci: 0.3198116 0.8603904810723993 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 79 [0/25046 (0%)]\tLoss: 0.234991\n",
            "Train epoch: 79 [331360/25046 (41%)]\tLoss: 0.265060\n",
            "Train epoch: 79 [663760/25046 (82%)]\tLoss: 0.269547\n",
            "Make prediction for 5010 samples...\n",
            "0.3317482 No improvement since epoch  78 ; best_mse,best_ci: 0.3198116 0.8603904810723993 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 80 [0/25046 (0%)]\tLoss: 0.255394\n",
            "Train epoch: 80 [332280/25046 (41%)]\tLoss: 0.266657\n",
            "Train epoch: 80 [652600/25046 (82%)]\tLoss: 0.284932\n",
            "Make prediction for 5010 samples...\n",
            "0.32187775 No improvement since epoch  78 ; best_mse,best_ci: 0.3198116 0.8603904810723993 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 81 [0/25046 (0%)]\tLoss: 0.268291\n",
            "Train epoch: 81 [325640/25046 (41%)]\tLoss: 0.292750\n",
            "Train epoch: 81 [647280/25046 (82%)]\tLoss: 0.292030\n",
            "Make prediction for 5010 samples...\n",
            "0.4126864 No improvement since epoch  78 ; best_mse,best_ci: 0.3198116 0.8603904810723993 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 82 [0/25046 (0%)]\tLoss: 0.290032\n",
            "Train epoch: 82 [329880/25046 (41%)]\tLoss: 0.285178\n",
            "Train epoch: 82 [659640/25046 (82%)]\tLoss: 0.337457\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  82 ; best_mse,best_ci: 0.3112819 0.8540943754227971 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 83 [0/25046 (0%)]\tLoss: 0.216931\n",
            "Train epoch: 83 [321600/25046 (41%)]\tLoss: 0.331433\n",
            "Train epoch: 83 [659800/25046 (82%)]\tLoss: 0.311350\n",
            "Make prediction for 5010 samples...\n",
            "0.3355826 No improvement since epoch  82 ; best_mse,best_ci: 0.3112819 0.8540943754227971 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 84 [0/25046 (0%)]\tLoss: 0.256105\n",
            "Train epoch: 84 [330660/25046 (41%)]\tLoss: 0.255335\n",
            "Train epoch: 84 [655840/25046 (82%)]\tLoss: 0.317069\n",
            "Make prediction for 5010 samples...\n",
            "0.34243345 No improvement since epoch  82 ; best_mse,best_ci: 0.3112819 0.8540943754227971 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 85 [0/25046 (0%)]\tLoss: 0.238476\n",
            "Train epoch: 85 [327880/25046 (41%)]\tLoss: 0.275279\n",
            "Train epoch: 85 [658920/25046 (82%)]\tLoss: 0.269510\n",
            "Make prediction for 5010 samples...\n",
            "0.3180989 No improvement since epoch  82 ; best_mse,best_ci: 0.3112819 0.8540943754227971 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 86 [0/25046 (0%)]\tLoss: 0.259073\n",
            "Train epoch: 86 [325360/25046 (41%)]\tLoss: 0.216126\n",
            "Train epoch: 86 [653280/25046 (82%)]\tLoss: 0.357263\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  86 ; best_mse,best_ci: 0.30990145 0.8611907802714264 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 87 [0/25046 (0%)]\tLoss: 0.218884\n",
            "Train epoch: 87 [328500/25046 (41%)]\tLoss: 0.327069\n",
            "Train epoch: 87 [657200/25046 (82%)]\tLoss: 0.240563\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 88 [0/25046 (0%)]\tLoss: 0.249819\n",
            "Train epoch: 88 [328460/25046 (41%)]\tLoss: 0.204700\n",
            "Train epoch: 88 [666040/25046 (82%)]\tLoss: 0.301384\n",
            "Make prediction for 5010 samples...\n",
            "0.30551076 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 89 [0/25046 (0%)]\tLoss: 0.231227\n",
            "Train epoch: 89 [332540/25046 (41%)]\tLoss: 0.290848\n",
            "Train epoch: 89 [647360/25046 (82%)]\tLoss: 0.278813\n",
            "Make prediction for 5010 samples...\n",
            "0.3295715 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 90 [0/25046 (0%)]\tLoss: 0.228567\n",
            "Train epoch: 90 [328920/25046 (41%)]\tLoss: 0.309883\n",
            "Train epoch: 90 [660360/25046 (82%)]\tLoss: 0.294292\n",
            "Make prediction for 5010 samples...\n",
            "0.38994297 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 91 [0/25046 (0%)]\tLoss: 0.249960\n",
            "Train epoch: 91 [331420/25046 (41%)]\tLoss: 0.293802\n",
            "Train epoch: 91 [654080/25046 (82%)]\tLoss: 0.246549\n",
            "Make prediction for 5010 samples...\n",
            "0.3091993 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 92 [0/25046 (0%)]\tLoss: 0.213707\n",
            "Train epoch: 92 [326840/25046 (41%)]\tLoss: 0.232426\n",
            "Train epoch: 92 [654560/25046 (82%)]\tLoss: 0.239678\n",
            "Make prediction for 5010 samples...\n",
            "0.31938022 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 93 [0/25046 (0%)]\tLoss: 0.208591\n",
            "Train epoch: 93 [324960/25046 (41%)]\tLoss: 0.246421\n",
            "Train epoch: 93 [648120/25046 (82%)]\tLoss: 0.232590\n",
            "Make prediction for 5010 samples...\n",
            "0.34831494 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 94 [0/25046 (0%)]\tLoss: 0.238106\n",
            "Train epoch: 94 [323000/25046 (41%)]\tLoss: 0.248808\n",
            "Train epoch: 94 [651200/25046 (82%)]\tLoss: 0.329120\n",
            "Make prediction for 5010 samples...\n",
            "0.35250396 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 95 [0/25046 (0%)]\tLoss: 0.257603\n",
            "Train epoch: 95 [327100/25046 (41%)]\tLoss: 0.309336\n",
            "Train epoch: 95 [659200/25046 (82%)]\tLoss: 0.195006\n",
            "Make prediction for 5010 samples...\n",
            "0.3248209 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 96 [0/25046 (0%)]\tLoss: 0.270371\n",
            "Train epoch: 96 [324280/25046 (41%)]\tLoss: 0.211065\n",
            "Train epoch: 96 [651920/25046 (82%)]\tLoss: 0.240616\n",
            "Make prediction for 5010 samples...\n",
            "0.3088971 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 97 [0/25046 (0%)]\tLoss: 0.259136\n",
            "Train epoch: 97 [322020/25046 (41%)]\tLoss: 0.242250\n",
            "Train epoch: 97 [643840/25046 (82%)]\tLoss: 0.247222\n",
            "Make prediction for 5010 samples...\n",
            "0.34938732 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 98 [0/25046 (0%)]\tLoss: 0.223259\n",
            "Train epoch: 98 [327340/25046 (41%)]\tLoss: 0.287816\n",
            "Train epoch: 98 [656240/25046 (82%)]\tLoss: 0.249630\n",
            "Make prediction for 5010 samples...\n",
            "0.30727538 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 99 [0/25046 (0%)]\tLoss: 0.219936\n",
            "Train epoch: 99 [325160/25046 (41%)]\tLoss: 0.249266\n",
            "Train epoch: 99 [659800/25046 (82%)]\tLoss: 0.226126\n",
            "Make prediction for 5010 samples...\n",
            "0.33675197 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 100 [0/25046 (0%)]\tLoss: 0.296170\n",
            "Train epoch: 100 [328460/25046 (41%)]\tLoss: 0.248641\n",
            "Train epoch: 100 [650840/25046 (82%)]\tLoss: 0.290364\n",
            "Make prediction for 5010 samples...\n",
            "0.3135264 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 101 [0/25046 (0%)]\tLoss: 0.215967\n",
            "Train epoch: 101 [331420/25046 (41%)]\tLoss: 0.270791\n",
            "Train epoch: 101 [655920/25046 (82%)]\tLoss: 0.274452\n",
            "Make prediction for 5010 samples...\n",
            "0.35979676 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 102 [0/25046 (0%)]\tLoss: 0.211528\n",
            "Train epoch: 102 [327060/25046 (41%)]\tLoss: 0.264519\n",
            "Train epoch: 102 [658200/25046 (82%)]\tLoss: 0.286643\n",
            "Make prediction for 5010 samples...\n",
            "0.30689275 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 103 [0/25046 (0%)]\tLoss: 0.172884\n",
            "Train epoch: 103 [328380/25046 (41%)]\tLoss: 0.230830\n",
            "Train epoch: 103 [655880/25046 (82%)]\tLoss: 0.226015\n",
            "Make prediction for 5010 samples...\n",
            "0.30822587 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 104 [0/25046 (0%)]\tLoss: 0.196371\n",
            "Train epoch: 104 [322340/25046 (41%)]\tLoss: 0.282580\n",
            "Train epoch: 104 [656400/25046 (82%)]\tLoss: 0.228574\n",
            "Make prediction for 5010 samples...\n",
            "0.31196147 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 105 [0/25046 (0%)]\tLoss: 0.196922\n",
            "Train epoch: 105 [329540/25046 (41%)]\tLoss: 0.252454\n",
            "Train epoch: 105 [657480/25046 (82%)]\tLoss: 0.223784\n",
            "Make prediction for 5010 samples...\n",
            "0.30201072 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 106 [0/25046 (0%)]\tLoss: 0.209561\n",
            "Train epoch: 106 [331280/25046 (41%)]\tLoss: 0.248558\n",
            "Train epoch: 106 [655640/25046 (82%)]\tLoss: 0.256406\n",
            "Make prediction for 5010 samples...\n",
            "0.30433685 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 107 [0/25046 (0%)]\tLoss: 0.206281\n",
            "Train epoch: 107 [324420/25046 (41%)]\tLoss: 0.212744\n",
            "Train epoch: 107 [664400/25046 (82%)]\tLoss: 0.261501\n",
            "Make prediction for 5010 samples...\n",
            "0.30469614 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 108 [0/25046 (0%)]\tLoss: 0.226500\n",
            "Train epoch: 108 [326680/25046 (41%)]\tLoss: 0.247088\n",
            "Train epoch: 108 [657160/25046 (82%)]\tLoss: 0.252752\n",
            "Make prediction for 5010 samples...\n",
            "0.3072951 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 109 [0/25046 (0%)]\tLoss: 0.220625\n",
            "Train epoch: 109 [327840/25046 (41%)]\tLoss: 0.214335\n",
            "Train epoch: 109 [653560/25046 (82%)]\tLoss: 0.292181\n",
            "Make prediction for 5010 samples...\n",
            "0.3351602 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 110 [0/25046 (0%)]\tLoss: 0.173242\n",
            "Train epoch: 110 [326100/25046 (41%)]\tLoss: 0.231807\n",
            "Train epoch: 110 [660280/25046 (82%)]\tLoss: 0.294275\n",
            "Make prediction for 5010 samples...\n",
            "0.37918323 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 111 [0/25046 (0%)]\tLoss: 0.288156\n",
            "Train epoch: 111 [323320/25046 (41%)]\tLoss: 0.230810\n",
            "Train epoch: 111 [655720/25046 (82%)]\tLoss: 0.202899\n",
            "Make prediction for 5010 samples...\n",
            "0.32084957 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 112 [0/25046 (0%)]\tLoss: 0.239141\n",
            "Train epoch: 112 [328820/25046 (41%)]\tLoss: 0.241376\n",
            "Train epoch: 112 [656680/25046 (82%)]\tLoss: 0.222999\n",
            "Make prediction for 5010 samples...\n",
            "0.31717795 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 113 [0/25046 (0%)]\tLoss: 0.247221\n",
            "Train epoch: 113 [326380/25046 (41%)]\tLoss: 0.201509\n",
            "Train epoch: 113 [648800/25046 (82%)]\tLoss: 0.210745\n",
            "Make prediction for 5010 samples...\n",
            "0.3644127 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 114 [0/25046 (0%)]\tLoss: 0.236378\n",
            "Train epoch: 114 [328000/25046 (41%)]\tLoss: 0.265675\n",
            "Train epoch: 114 [658120/25046 (82%)]\tLoss: 0.211162\n",
            "Make prediction for 5010 samples...\n",
            "0.32397506 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 115 [0/25046 (0%)]\tLoss: 0.211101\n",
            "Train epoch: 115 [326340/25046 (41%)]\tLoss: 0.166918\n",
            "Train epoch: 115 [658960/25046 (82%)]\tLoss: 0.223088\n",
            "Make prediction for 5010 samples...\n",
            "0.3193129 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 116 [0/25046 (0%)]\tLoss: 0.186313\n",
            "Train epoch: 116 [324120/25046 (41%)]\tLoss: 0.214188\n",
            "Train epoch: 116 [662840/25046 (82%)]\tLoss: 0.229308\n",
            "Make prediction for 5010 samples...\n",
            "0.34821582 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 117 [0/25046 (0%)]\tLoss: 0.250529\n",
            "Train epoch: 117 [328820/25046 (41%)]\tLoss: 0.188704\n",
            "Train epoch: 117 [661960/25046 (82%)]\tLoss: 0.200405\n",
            "Make prediction for 5010 samples...\n",
            "0.32467735 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 118 [0/25046 (0%)]\tLoss: 0.240657\n",
            "Train epoch: 118 [324740/25046 (41%)]\tLoss: 0.203231\n",
            "Train epoch: 118 [666720/25046 (82%)]\tLoss: 0.235965\n",
            "Make prediction for 5010 samples...\n",
            "0.3175087 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 119 [0/25046 (0%)]\tLoss: 0.248183\n",
            "Train epoch: 119 [324560/25046 (41%)]\tLoss: 0.183615\n",
            "Train epoch: 119 [650560/25046 (82%)]\tLoss: 0.203916\n",
            "Make prediction for 5010 samples...\n",
            "0.30396143 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 120 [0/25046 (0%)]\tLoss: 0.248745\n",
            "Train epoch: 120 [323120/25046 (41%)]\tLoss: 0.207586\n",
            "Train epoch: 120 [655400/25046 (82%)]\tLoss: 0.199971\n",
            "Make prediction for 5010 samples...\n",
            "0.31330022 No improvement since epoch  87 ; best_mse,best_ci: 0.3007642 0.8590386791624939 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 121 [0/25046 (0%)]\tLoss: 0.258883\n",
            "Train epoch: 121 [324720/25046 (41%)]\tLoss: 0.232784\n",
            "Train epoch: 121 [662160/25046 (82%)]\tLoss: 0.210705\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 122 [0/25046 (0%)]\tLoss: 0.233091\n",
            "Train epoch: 122 [331980/25046 (41%)]\tLoss: 0.195755\n",
            "Train epoch: 122 [657160/25046 (82%)]\tLoss: 0.269590\n",
            "Make prediction for 5010 samples...\n",
            "0.3164158 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 123 [0/25046 (0%)]\tLoss: 0.196617\n",
            "Train epoch: 123 [331540/25046 (41%)]\tLoss: 0.185589\n",
            "Train epoch: 123 [659080/25046 (82%)]\tLoss: 0.232608\n",
            "Make prediction for 5010 samples...\n",
            "0.310441 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 124 [0/25046 (0%)]\tLoss: 0.163669\n",
            "Train epoch: 124 [324900/25046 (41%)]\tLoss: 0.199237\n",
            "Train epoch: 124 [663960/25046 (82%)]\tLoss: 0.196122\n",
            "Make prediction for 5010 samples...\n",
            "0.30554152 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 125 [0/25046 (0%)]\tLoss: 0.178758\n",
            "Train epoch: 125 [332440/25046 (41%)]\tLoss: 0.216278\n",
            "Train epoch: 125 [656600/25046 (82%)]\tLoss: 0.250496\n",
            "Make prediction for 5010 samples...\n",
            "0.30257738 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 126 [0/25046 (0%)]\tLoss: 0.209158\n",
            "Train epoch: 126 [327040/25046 (41%)]\tLoss: 0.226287\n",
            "Train epoch: 126 [658360/25046 (82%)]\tLoss: 0.240969\n",
            "Make prediction for 5010 samples...\n",
            "0.31715503 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 127 [0/25046 (0%)]\tLoss: 0.218029\n",
            "Train epoch: 127 [326180/25046 (41%)]\tLoss: 0.217879\n",
            "Train epoch: 127 [654960/25046 (82%)]\tLoss: 0.222824\n",
            "Make prediction for 5010 samples...\n",
            "0.30369344 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 128 [0/25046 (0%)]\tLoss: 0.171407\n",
            "Train epoch: 128 [325720/25046 (41%)]\tLoss: 0.268947\n",
            "Train epoch: 128 [661680/25046 (82%)]\tLoss: 0.210456\n",
            "Make prediction for 5010 samples...\n",
            "0.37426072 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 129 [0/25046 (0%)]\tLoss: 0.209953\n",
            "Train epoch: 129 [332100/25046 (41%)]\tLoss: 0.200439\n",
            "Train epoch: 129 [655000/25046 (82%)]\tLoss: 0.217256\n",
            "Make prediction for 5010 samples...\n",
            "0.3660458 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 130 [0/25046 (0%)]\tLoss: 0.204314\n",
            "Train epoch: 130 [326360/25046 (41%)]\tLoss: 0.226019\n",
            "Train epoch: 130 [645280/25046 (82%)]\tLoss: 0.179630\n",
            "Make prediction for 5010 samples...\n",
            "0.32533196 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 131 [0/25046 (0%)]\tLoss: 0.219926\n",
            "Train epoch: 131 [326780/25046 (41%)]\tLoss: 0.189160\n",
            "Train epoch: 131 [658440/25046 (82%)]\tLoss: 0.216637\n",
            "Make prediction for 5010 samples...\n",
            "0.3031801 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 132 [0/25046 (0%)]\tLoss: 0.147402\n",
            "Train epoch: 132 [329380/25046 (41%)]\tLoss: 0.209747\n",
            "Train epoch: 132 [649960/25046 (82%)]\tLoss: 0.166682\n",
            "Make prediction for 5010 samples...\n",
            "0.30303568 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 133 [0/25046 (0%)]\tLoss: 0.201147\n",
            "Train epoch: 133 [334080/25046 (41%)]\tLoss: 0.209996\n",
            "Train epoch: 133 [658920/25046 (82%)]\tLoss: 0.219783\n",
            "Make prediction for 5010 samples...\n",
            "0.31244987 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 134 [0/25046 (0%)]\tLoss: 0.169513\n",
            "Train epoch: 134 [322620/25046 (41%)]\tLoss: 0.192677\n",
            "Train epoch: 134 [666120/25046 (82%)]\tLoss: 0.204057\n",
            "Make prediction for 5010 samples...\n",
            "0.3024175 No improvement since epoch  121 ; best_mse,best_ci: 0.29831114 0.8592717775034984 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 135 [0/25046 (0%)]\tLoss: 0.189779\n",
            "Train epoch: 135 [328360/25046 (41%)]\tLoss: 0.204144\n",
            "Train epoch: 135 [661760/25046 (82%)]\tLoss: 0.289357\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  135 ; best_mse,best_ci: 0.2977163 0.8700001209905975 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 136 [0/25046 (0%)]\tLoss: 0.158859\n",
            "Train epoch: 136 [324760/25046 (41%)]\tLoss: 0.176656\n",
            "Train epoch: 136 [655560/25046 (82%)]\tLoss: 0.185007\n",
            "Make prediction for 5010 samples...\n",
            "0.3108326 No improvement since epoch  135 ; best_mse,best_ci: 0.2977163 0.8700001209905975 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 137 [0/25046 (0%)]\tLoss: 0.182324\n",
            "Train epoch: 137 [328460/25046 (41%)]\tLoss: 0.195968\n",
            "Train epoch: 137 [657680/25046 (82%)]\tLoss: 0.229919\n",
            "Make prediction for 5010 samples...\n",
            "0.30453765 No improvement since epoch  135 ; best_mse,best_ci: 0.2977163 0.8700001209905975 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 138 [0/25046 (0%)]\tLoss: 0.215366\n",
            "Train epoch: 138 [324840/25046 (41%)]\tLoss: 0.198910\n",
            "Train epoch: 138 [647760/25046 (82%)]\tLoss: 0.204278\n",
            "Make prediction for 5010 samples...\n",
            "0.3137007 No improvement since epoch  135 ; best_mse,best_ci: 0.2977163 0.8700001209905975 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 139 [0/25046 (0%)]\tLoss: 0.161086\n",
            "Train epoch: 139 [330120/25046 (41%)]\tLoss: 0.160016\n",
            "Train epoch: 139 [649480/25046 (82%)]\tLoss: 0.199154\n",
            "Make prediction for 5010 samples...\n",
            "0.3224019 No improvement since epoch  135 ; best_mse,best_ci: 0.2977163 0.8700001209905975 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 140 [0/25046 (0%)]\tLoss: 0.183822\n",
            "Train epoch: 140 [327920/25046 (41%)]\tLoss: 0.225548\n",
            "Train epoch: 140 [652840/25046 (82%)]\tLoss: 0.189824\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  140 ; best_mse,best_ci: 0.29302198 0.8577224086685628 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 141 [0/25046 (0%)]\tLoss: 0.177774\n",
            "Train epoch: 141 [327800/25046 (41%)]\tLoss: 0.203266\n",
            "Train epoch: 141 [656760/25046 (82%)]\tLoss: 0.169126\n",
            "Make prediction for 5010 samples...\n",
            "0.30386347 No improvement since epoch  140 ; best_mse,best_ci: 0.29302198 0.8577224086685628 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 142 [0/25046 (0%)]\tLoss: 0.164210\n",
            "Train epoch: 142 [330340/25046 (41%)]\tLoss: 0.325344\n",
            "Train epoch: 142 [662080/25046 (82%)]\tLoss: 0.182618\n",
            "Make prediction for 5010 samples...\n",
            "0.3113165 No improvement since epoch  140 ; best_mse,best_ci: 0.29302198 0.8577224086685628 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 143 [0/25046 (0%)]\tLoss: 0.190544\n",
            "Train epoch: 143 [330780/25046 (41%)]\tLoss: 0.168545\n",
            "Train epoch: 143 [661360/25046 (82%)]\tLoss: 0.194602\n",
            "Make prediction for 5010 samples...\n",
            "0.3783829 No improvement since epoch  140 ; best_mse,best_ci: 0.29302198 0.8577224086685628 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 144 [0/25046 (0%)]\tLoss: 0.210083\n",
            "Train epoch: 144 [334940/25046 (41%)]\tLoss: 0.192781\n",
            "Train epoch: 144 [653440/25046 (82%)]\tLoss: 0.164146\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 145 [0/25046 (0%)]\tLoss: 0.157457\n",
            "Train epoch: 145 [326940/25046 (41%)]\tLoss: 0.189994\n",
            "Train epoch: 145 [658080/25046 (82%)]\tLoss: 0.229957\n",
            "Make prediction for 5010 samples...\n",
            "0.37777087 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 146 [0/25046 (0%)]\tLoss: 0.255560\n",
            "Train epoch: 146 [327380/25046 (41%)]\tLoss: 0.172375\n",
            "Train epoch: 146 [656520/25046 (82%)]\tLoss: 0.182740\n",
            "Make prediction for 5010 samples...\n",
            "0.3145635 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 147 [0/25046 (0%)]\tLoss: 0.174580\n",
            "Train epoch: 147 [326260/25046 (41%)]\tLoss: 0.163654\n",
            "Train epoch: 147 [642000/25046 (82%)]\tLoss: 0.249283\n",
            "Make prediction for 5010 samples...\n",
            "0.29306245 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 148 [0/25046 (0%)]\tLoss: 0.193169\n",
            "Train epoch: 148 [327680/25046 (41%)]\tLoss: 0.179807\n",
            "Train epoch: 148 [661760/25046 (82%)]\tLoss: 0.165896\n",
            "Make prediction for 5010 samples...\n",
            "0.30706593 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 149 [0/25046 (0%)]\tLoss: 0.172473\n",
            "Train epoch: 149 [324880/25046 (41%)]\tLoss: 0.180646\n",
            "Train epoch: 149 [656960/25046 (82%)]\tLoss: 0.176454\n",
            "Make prediction for 5010 samples...\n",
            "0.308127 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 150 [0/25046 (0%)]\tLoss: 0.195312\n",
            "Train epoch: 150 [328520/25046 (41%)]\tLoss: 0.169867\n",
            "Train epoch: 150 [649640/25046 (82%)]\tLoss: 0.186564\n",
            "Make prediction for 5010 samples...\n",
            "0.30132592 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 151 [0/25046 (0%)]\tLoss: 0.207379\n",
            "Train epoch: 151 [323280/25046 (41%)]\tLoss: 0.194025\n",
            "Train epoch: 151 [658720/25046 (82%)]\tLoss: 0.205926\n",
            "Make prediction for 5010 samples...\n",
            "0.29489523 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 152 [0/25046 (0%)]\tLoss: 0.163783\n",
            "Train epoch: 152 [330820/25046 (41%)]\tLoss: 0.186777\n",
            "Train epoch: 152 [652160/25046 (82%)]\tLoss: 0.236600\n",
            "Make prediction for 5010 samples...\n",
            "0.29582953 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 153 [0/25046 (0%)]\tLoss: 0.161845\n",
            "Train epoch: 153 [329140/25046 (41%)]\tLoss: 0.155641\n",
            "Train epoch: 153 [655000/25046 (82%)]\tLoss: 0.167967\n",
            "Make prediction for 5010 samples...\n",
            "0.3059044 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 154 [0/25046 (0%)]\tLoss: 0.135896\n",
            "Train epoch: 154 [331860/25046 (41%)]\tLoss: 0.169811\n",
            "Train epoch: 154 [665000/25046 (82%)]\tLoss: 0.251489\n",
            "Make prediction for 5010 samples...\n",
            "0.29733643 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 155 [0/25046 (0%)]\tLoss: 0.174303\n",
            "Train epoch: 155 [332920/25046 (41%)]\tLoss: 0.219630\n",
            "Train epoch: 155 [648520/25046 (82%)]\tLoss: 0.172440\n",
            "Make prediction for 5010 samples...\n",
            "0.31185433 No improvement since epoch  144 ; best_mse,best_ci: 0.29288706 0.8670644908983675 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 156 [0/25046 (0%)]\tLoss: 0.201565\n",
            "Train epoch: 156 [326000/25046 (41%)]\tLoss: 0.199396\n",
            "Train epoch: 156 [660080/25046 (82%)]\tLoss: 0.203070\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 157 [0/25046 (0%)]\tLoss: 0.212266\n",
            "Train epoch: 157 [328440/25046 (41%)]\tLoss: 0.172461\n",
            "Train epoch: 157 [647520/25046 (82%)]\tLoss: 0.229551\n",
            "Make prediction for 5010 samples...\n",
            "0.39091372 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 158 [0/25046 (0%)]\tLoss: 0.281941\n",
            "Train epoch: 158 [322960/25046 (41%)]\tLoss: 0.206922\n",
            "Train epoch: 158 [647760/25046 (82%)]\tLoss: 0.159419\n",
            "Make prediction for 5010 samples...\n",
            "0.32031542 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 159 [0/25046 (0%)]\tLoss: 0.154122\n",
            "Train epoch: 159 [330220/25046 (41%)]\tLoss: 0.156935\n",
            "Train epoch: 159 [658840/25046 (82%)]\tLoss: 0.172015\n",
            "Make prediction for 5010 samples...\n",
            "0.29221088 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 160 [0/25046 (0%)]\tLoss: 0.168496\n",
            "Train epoch: 160 [330220/25046 (41%)]\tLoss: 0.189945\n",
            "Train epoch: 160 [650280/25046 (82%)]\tLoss: 0.171584\n",
            "Make prediction for 5010 samples...\n",
            "0.30167258 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 161 [0/25046 (0%)]\tLoss: 0.170335\n",
            "Train epoch: 161 [329540/25046 (41%)]\tLoss: 0.180434\n",
            "Train epoch: 161 [658200/25046 (82%)]\tLoss: 0.174568\n",
            "Make prediction for 5010 samples...\n",
            "0.2996536 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 162 [0/25046 (0%)]\tLoss: 0.176682\n",
            "Train epoch: 162 [329540/25046 (41%)]\tLoss: 0.169494\n",
            "Train epoch: 162 [660480/25046 (82%)]\tLoss: 0.192662\n",
            "Make prediction for 5010 samples...\n",
            "0.29243806 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 163 [0/25046 (0%)]\tLoss: 0.187815\n",
            "Train epoch: 163 [333780/25046 (41%)]\tLoss: 0.205086\n",
            "Train epoch: 163 [654160/25046 (82%)]\tLoss: 0.190274\n",
            "Make prediction for 5010 samples...\n",
            "0.29337177 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 164 [0/25046 (0%)]\tLoss: 0.164289\n",
            "Train epoch: 164 [331280/25046 (41%)]\tLoss: 0.162856\n",
            "Train epoch: 164 [658400/25046 (82%)]\tLoss: 0.253257\n",
            "Make prediction for 5010 samples...\n",
            "0.29337162 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 165 [0/25046 (0%)]\tLoss: 0.143385\n",
            "Train epoch: 165 [326980/25046 (41%)]\tLoss: 0.155673\n",
            "Train epoch: 165 [657720/25046 (82%)]\tLoss: 0.171338\n",
            "Make prediction for 5010 samples...\n",
            "0.30529448 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 166 [0/25046 (0%)]\tLoss: 0.203381\n",
            "Train epoch: 166 [329600/25046 (41%)]\tLoss: 0.174715\n",
            "Train epoch: 166 [654360/25046 (82%)]\tLoss: 0.180808\n",
            "Make prediction for 5010 samples...\n",
            "0.3083354 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 167 [0/25046 (0%)]\tLoss: 0.139994\n",
            "Train epoch: 167 [330420/25046 (41%)]\tLoss: 0.173235\n",
            "Train epoch: 167 [653200/25046 (82%)]\tLoss: 0.216441\n",
            "Make prediction for 5010 samples...\n",
            "0.32531554 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 168 [0/25046 (0%)]\tLoss: 0.218068\n",
            "Train epoch: 168 [327140/25046 (41%)]\tLoss: 0.177483\n",
            "Train epoch: 168 [652440/25046 (82%)]\tLoss: 0.269660\n",
            "Make prediction for 5010 samples...\n",
            "0.32885927 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 169 [0/25046 (0%)]\tLoss: 0.188554\n",
            "Train epoch: 169 [328600/25046 (41%)]\tLoss: 0.229545\n",
            "Train epoch: 169 [657760/25046 (82%)]\tLoss: 0.196543\n",
            "Make prediction for 5010 samples...\n",
            "0.3035071 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 170 [0/25046 (0%)]\tLoss: 0.162553\n",
            "Train epoch: 170 [329460/25046 (41%)]\tLoss: 0.172262\n",
            "Train epoch: 170 [657880/25046 (82%)]\tLoss: 0.196383\n",
            "Make prediction for 5010 samples...\n",
            "0.3199556 No improvement since epoch  156 ; best_mse,best_ci: 0.2888743 0.855684176558669 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 171 [0/25046 (0%)]\tLoss: 0.176500\n",
            "Train epoch: 171 [328840/25046 (41%)]\tLoss: 0.158069\n",
            "Train epoch: 171 [658200/25046 (82%)]\tLoss: 0.176972\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 172 [0/25046 (0%)]\tLoss: 0.148733\n",
            "Train epoch: 172 [329560/25046 (41%)]\tLoss: 0.210720\n",
            "Train epoch: 172 [650120/25046 (82%)]\tLoss: 0.163693\n",
            "Make prediction for 5010 samples...\n",
            "0.35682312 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 173 [0/25046 (0%)]\tLoss: 0.225068\n",
            "Train epoch: 173 [333980/25046 (41%)]\tLoss: 0.187471\n",
            "Train epoch: 173 [658040/25046 (82%)]\tLoss: 0.155189\n",
            "Make prediction for 5010 samples...\n",
            "0.30323946 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 174 [0/25046 (0%)]\tLoss: 0.169354\n",
            "Train epoch: 174 [328180/25046 (41%)]\tLoss: 0.173206\n",
            "Train epoch: 174 [654480/25046 (82%)]\tLoss: 0.140713\n",
            "Make prediction for 5010 samples...\n",
            "0.28107378 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 175 [0/25046 (0%)]\tLoss: 0.187518\n",
            "Train epoch: 175 [326820/25046 (41%)]\tLoss: 0.178934\n",
            "Train epoch: 175 [651880/25046 (82%)]\tLoss: 0.176890\n",
            "Make prediction for 5010 samples...\n",
            "0.29360798 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 176 [0/25046 (0%)]\tLoss: 0.206013\n",
            "Train epoch: 176 [330300/25046 (41%)]\tLoss: 0.154848\n",
            "Train epoch: 176 [662960/25046 (82%)]\tLoss: 0.146213\n",
            "Make prediction for 5010 samples...\n",
            "0.28298452 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 177 [0/25046 (0%)]\tLoss: 0.168995\n",
            "Train epoch: 177 [328280/25046 (41%)]\tLoss: 0.150803\n",
            "Train epoch: 177 [655240/25046 (82%)]\tLoss: 0.182197\n",
            "Make prediction for 5010 samples...\n",
            "0.34123632 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 178 [0/25046 (0%)]\tLoss: 0.191500\n",
            "Train epoch: 178 [325860/25046 (41%)]\tLoss: 0.162649\n",
            "Train epoch: 178 [651440/25046 (82%)]\tLoss: 0.215328\n",
            "Make prediction for 5010 samples...\n",
            "0.3137979 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 179 [0/25046 (0%)]\tLoss: 0.169620\n",
            "Train epoch: 179 [328560/25046 (41%)]\tLoss: 0.186245\n",
            "Train epoch: 179 [659320/25046 (82%)]\tLoss: 0.158305\n",
            "Make prediction for 5010 samples...\n",
            "0.28223377 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 180 [0/25046 (0%)]\tLoss: 0.158945\n",
            "Train epoch: 180 [326860/25046 (41%)]\tLoss: 0.131510\n",
            "Train epoch: 180 [657400/25046 (82%)]\tLoss: 0.194192\n",
            "Make prediction for 5010 samples...\n",
            "0.28484476 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 181 [0/25046 (0%)]\tLoss: 0.147637\n",
            "Train epoch: 181 [327300/25046 (41%)]\tLoss: 0.202344\n",
            "Train epoch: 181 [649040/25046 (82%)]\tLoss: 0.162879\n",
            "Make prediction for 5010 samples...\n",
            "0.34732917 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 182 [0/25046 (0%)]\tLoss: 0.193141\n",
            "Train epoch: 182 [325960/25046 (41%)]\tLoss: 0.202754\n",
            "Train epoch: 182 [662360/25046 (82%)]\tLoss: 0.149873\n",
            "Make prediction for 5010 samples...\n",
            "0.2821151 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 183 [0/25046 (0%)]\tLoss: 0.173266\n",
            "Train epoch: 183 [328000/25046 (41%)]\tLoss: 0.195501\n",
            "Train epoch: 183 [658080/25046 (82%)]\tLoss: 0.178138\n",
            "Make prediction for 5010 samples...\n",
            "0.30021533 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 184 [0/25046 (0%)]\tLoss: 0.174638\n",
            "Train epoch: 184 [328640/25046 (41%)]\tLoss: 0.152161\n",
            "Train epoch: 184 [656080/25046 (82%)]\tLoss: 0.165390\n",
            "Make prediction for 5010 samples...\n",
            "0.29093805 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 185 [0/25046 (0%)]\tLoss: 0.176017\n",
            "Train epoch: 185 [331200/25046 (41%)]\tLoss: 0.164206\n",
            "Train epoch: 185 [648920/25046 (82%)]\tLoss: 0.197950\n",
            "Make prediction for 5010 samples...\n",
            "0.28923443 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 186 [0/25046 (0%)]\tLoss: 0.159430\n",
            "Train epoch: 186 [324820/25046 (41%)]\tLoss: 0.180159\n",
            "Train epoch: 186 [651120/25046 (82%)]\tLoss: 0.171799\n",
            "Make prediction for 5010 samples...\n",
            "0.28893226 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 187 [0/25046 (0%)]\tLoss: 0.167113\n",
            "Train epoch: 187 [325140/25046 (41%)]\tLoss: 0.152711\n",
            "Train epoch: 187 [659280/25046 (82%)]\tLoss: 0.177589\n",
            "Make prediction for 5010 samples...\n",
            "0.3489533 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 188 [0/25046 (0%)]\tLoss: 0.187221\n",
            "Train epoch: 188 [328840/25046 (41%)]\tLoss: 0.162004\n",
            "Train epoch: 188 [656160/25046 (82%)]\tLoss: 0.151439\n",
            "Make prediction for 5010 samples...\n",
            "0.29299727 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 189 [0/25046 (0%)]\tLoss: 0.156988\n",
            "Train epoch: 189 [322040/25046 (41%)]\tLoss: 0.192588\n",
            "Train epoch: 189 [653080/25046 (82%)]\tLoss: 0.187003\n",
            "Make prediction for 5010 samples...\n",
            "0.28226483 No improvement since epoch  171 ; best_mse,best_ci: 0.28067335 0.8726269953302224 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 190 [0/25046 (0%)]\tLoss: 0.158076\n",
            "Train epoch: 190 [324500/25046 (41%)]\tLoss: 0.176550\n",
            "Train epoch: 190 [659080/25046 (82%)]\tLoss: 0.181634\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 191 [0/25046 (0%)]\tLoss: 0.139319\n",
            "Train epoch: 191 [335100/25046 (41%)]\tLoss: 0.202288\n",
            "Train epoch: 191 [663320/25046 (82%)]\tLoss: 0.166467\n",
            "Make prediction for 5010 samples...\n",
            "0.3027376 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 192 [0/25046 (0%)]\tLoss: 0.130293\n",
            "Train epoch: 192 [327380/25046 (41%)]\tLoss: 0.151722\n",
            "Train epoch: 192 [661840/25046 (82%)]\tLoss: 0.130758\n",
            "Make prediction for 5010 samples...\n",
            "0.28164613 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 193 [0/25046 (0%)]\tLoss: 0.151102\n",
            "Train epoch: 193 [329220/25046 (41%)]\tLoss: 0.171346\n",
            "Train epoch: 193 [663160/25046 (82%)]\tLoss: 0.191600\n",
            "Make prediction for 5010 samples...\n",
            "0.29466534 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 194 [0/25046 (0%)]\tLoss: 0.146914\n",
            "Train epoch: 194 [323080/25046 (41%)]\tLoss: 0.189900\n",
            "Train epoch: 194 [661320/25046 (82%)]\tLoss: 0.159241\n",
            "Make prediction for 5010 samples...\n",
            "0.27888167 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 195 [0/25046 (0%)]\tLoss: 0.178875\n",
            "Train epoch: 195 [331620/25046 (41%)]\tLoss: 0.169752\n",
            "Train epoch: 195 [655840/25046 (82%)]\tLoss: 0.150588\n",
            "Make prediction for 5010 samples...\n",
            "0.29104567 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 196 [0/25046 (0%)]\tLoss: 0.147776\n",
            "Train epoch: 196 [328300/25046 (41%)]\tLoss: 0.146205\n",
            "Train epoch: 196 [655400/25046 (82%)]\tLoss: 0.177647\n",
            "Make prediction for 5010 samples...\n",
            "0.30560282 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 197 [0/25046 (0%)]\tLoss: 0.159015\n",
            "Train epoch: 197 [327900/25046 (41%)]\tLoss: 0.160194\n",
            "Train epoch: 197 [651640/25046 (82%)]\tLoss: 0.158377\n",
            "Make prediction for 5010 samples...\n",
            "0.2900832 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 198 [0/25046 (0%)]\tLoss: 0.179246\n",
            "Train epoch: 198 [327820/25046 (41%)]\tLoss: 0.180717\n",
            "Train epoch: 198 [668320/25046 (82%)]\tLoss: 0.157569\n",
            "Make prediction for 5010 samples...\n",
            "0.31734332 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 199 [0/25046 (0%)]\tLoss: 0.153406\n",
            "Train epoch: 199 [329180/25046 (41%)]\tLoss: 0.177481\n",
            "Train epoch: 199 [660560/25046 (82%)]\tLoss: 0.180601\n",
            "Make prediction for 5010 samples...\n",
            "0.29646748 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 200 [0/25046 (0%)]\tLoss: 0.176089\n",
            "Train epoch: 200 [327980/25046 (41%)]\tLoss: 0.151683\n",
            "Train epoch: 200 [660720/25046 (82%)]\tLoss: 0.175942\n",
            "Make prediction for 5010 samples...\n",
            "0.28108642 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 201 [0/25046 (0%)]\tLoss: 0.188404\n",
            "Train epoch: 201 [328360/25046 (41%)]\tLoss: 0.141431\n",
            "Train epoch: 201 [659560/25046 (82%)]\tLoss: 0.206620\n",
            "Make prediction for 5010 samples...\n",
            "0.2832509 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 202 [0/25046 (0%)]\tLoss: 0.148252\n",
            "Train epoch: 202 [329060/25046 (41%)]\tLoss: 0.143661\n",
            "Train epoch: 202 [655160/25046 (82%)]\tLoss: 0.190968\n",
            "Make prediction for 5010 samples...\n",
            "0.27726474 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 203 [0/25046 (0%)]\tLoss: 0.149997\n",
            "Train epoch: 203 [329000/25046 (41%)]\tLoss: 0.171628\n",
            "Train epoch: 203 [659720/25046 (82%)]\tLoss: 0.163479\n",
            "Make prediction for 5010 samples...\n",
            "0.28017387 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 204 [0/25046 (0%)]\tLoss: 0.148460\n",
            "Train epoch: 204 [328020/25046 (41%)]\tLoss: 0.165284\n",
            "Train epoch: 204 [660760/25046 (82%)]\tLoss: 0.175340\n",
            "Make prediction for 5010 samples...\n",
            "0.29667073 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 205 [0/25046 (0%)]\tLoss: 0.159393\n",
            "Train epoch: 205 [329160/25046 (41%)]\tLoss: 0.142202\n",
            "Train epoch: 205 [653160/25046 (82%)]\tLoss: 0.160236\n",
            "Make prediction for 5010 samples...\n",
            "0.2844171 No improvement since epoch  190 ; best_mse,best_ci: 0.27714404 0.8699782967372511 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 206 [0/25046 (0%)]\tLoss: 0.156597\n",
            "Train epoch: 206 [328540/25046 (41%)]\tLoss: 0.155921\n",
            "Train epoch: 206 [660320/25046 (82%)]\tLoss: 0.151850\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 207 [0/25046 (0%)]\tLoss: 0.171352\n",
            "Train epoch: 207 [326520/25046 (41%)]\tLoss: 0.175367\n",
            "Train epoch: 207 [659920/25046 (82%)]\tLoss: 0.168601\n",
            "Make prediction for 5010 samples...\n",
            "0.28035486 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 208 [0/25046 (0%)]\tLoss: 0.110450\n",
            "Train epoch: 208 [329000/25046 (41%)]\tLoss: 0.182746\n",
            "Train epoch: 208 [659000/25046 (82%)]\tLoss: 0.169932\n",
            "Make prediction for 5010 samples...\n",
            "0.27970818 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 209 [0/25046 (0%)]\tLoss: 0.140259\n",
            "Train epoch: 209 [327500/25046 (41%)]\tLoss: 0.117462\n",
            "Train epoch: 209 [648080/25046 (82%)]\tLoss: 0.129450\n",
            "Make prediction for 5010 samples...\n",
            "0.29216856 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 210 [0/25046 (0%)]\tLoss: 0.154371\n",
            "Train epoch: 210 [327640/25046 (41%)]\tLoss: 0.136037\n",
            "Train epoch: 210 [666520/25046 (82%)]\tLoss: 0.261258\n",
            "Make prediction for 5010 samples...\n",
            "0.29720774 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 211 [0/25046 (0%)]\tLoss: 0.185779\n",
            "Train epoch: 211 [326100/25046 (41%)]\tLoss: 0.158590\n",
            "Train epoch: 211 [667080/25046 (82%)]\tLoss: 0.155557\n",
            "Make prediction for 5010 samples...\n",
            "0.28033274 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 212 [0/25046 (0%)]\tLoss: 0.132842\n",
            "Train epoch: 212 [331360/25046 (41%)]\tLoss: 0.147215\n",
            "Train epoch: 212 [655600/25046 (82%)]\tLoss: 0.186184\n",
            "Make prediction for 5010 samples...\n",
            "0.28994033 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 213 [0/25046 (0%)]\tLoss: 0.168484\n",
            "Train epoch: 213 [331340/25046 (41%)]\tLoss: 0.116917\n",
            "Train epoch: 213 [650880/25046 (82%)]\tLoss: 0.137656\n",
            "Make prediction for 5010 samples...\n",
            "0.28799897 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 214 [0/25046 (0%)]\tLoss: 0.143434\n",
            "Train epoch: 214 [331000/25046 (41%)]\tLoss: 0.155224\n",
            "Train epoch: 214 [650960/25046 (82%)]\tLoss: 0.123134\n",
            "Make prediction for 5010 samples...\n",
            "0.28739938 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 215 [0/25046 (0%)]\tLoss: 0.158139\n",
            "Train epoch: 215 [324280/25046 (41%)]\tLoss: 0.132365\n",
            "Train epoch: 215 [664400/25046 (82%)]\tLoss: 0.144733\n",
            "Make prediction for 5010 samples...\n",
            "0.32429975 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 216 [0/25046 (0%)]\tLoss: 0.184806\n",
            "Train epoch: 216 [325720/25046 (41%)]\tLoss: 0.131395\n",
            "Train epoch: 216 [651840/25046 (82%)]\tLoss: 0.147157\n",
            "Make prediction for 5010 samples...\n",
            "0.32042035 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 217 [0/25046 (0%)]\tLoss: 0.155705\n",
            "Train epoch: 217 [335860/25046 (41%)]\tLoss: 0.157256\n",
            "Train epoch: 217 [653600/25046 (82%)]\tLoss: 0.171289\n",
            "Make prediction for 5010 samples...\n",
            "0.30463794 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 218 [0/25046 (0%)]\tLoss: 0.175562\n",
            "Train epoch: 218 [327520/25046 (41%)]\tLoss: 0.123322\n",
            "Train epoch: 218 [661160/25046 (82%)]\tLoss: 0.169231\n",
            "Make prediction for 5010 samples...\n",
            "0.27215916 No improvement since epoch  206 ; best_mse,best_ci: 0.2672569 0.8752676534088029 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 219 [0/25046 (0%)]\tLoss: 0.143186\n",
            "Train epoch: 219 [327220/25046 (41%)]\tLoss: 0.151532\n",
            "Train epoch: 219 [660040/25046 (82%)]\tLoss: 0.135518\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 220 [0/25046 (0%)]\tLoss: 0.143226\n",
            "Train epoch: 220 [328400/25046 (41%)]\tLoss: 0.148212\n",
            "Train epoch: 220 [646080/25046 (82%)]\tLoss: 0.185102\n",
            "Make prediction for 5010 samples...\n",
            "0.2759499 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 221 [0/25046 (0%)]\tLoss: 0.166045\n",
            "Train epoch: 221 [323720/25046 (41%)]\tLoss: 0.169449\n",
            "Train epoch: 221 [656200/25046 (82%)]\tLoss: 0.164234\n",
            "Make prediction for 5010 samples...\n",
            "0.32478404 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 222 [0/25046 (0%)]\tLoss: 0.194043\n",
            "Train epoch: 222 [325160/25046 (41%)]\tLoss: 0.156755\n",
            "Train epoch: 222 [662800/25046 (82%)]\tLoss: 0.219016\n",
            "Make prediction for 5010 samples...\n",
            "0.26907042 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 223 [0/25046 (0%)]\tLoss: 0.164654\n",
            "Train epoch: 223 [328160/25046 (41%)]\tLoss: 0.125832\n",
            "Train epoch: 223 [659280/25046 (82%)]\tLoss: 0.203376\n",
            "Make prediction for 5010 samples...\n",
            "0.34126928 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 224 [0/25046 (0%)]\tLoss: 0.277442\n",
            "Train epoch: 224 [330620/25046 (41%)]\tLoss: 0.170228\n",
            "Train epoch: 224 [652280/25046 (82%)]\tLoss: 0.162927\n",
            "Make prediction for 5010 samples...\n",
            "0.28065118 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 225 [0/25046 (0%)]\tLoss: 0.169762\n",
            "Train epoch: 225 [327600/25046 (41%)]\tLoss: 0.104553\n",
            "Train epoch: 225 [655880/25046 (82%)]\tLoss: 0.163107\n",
            "Make prediction for 5010 samples...\n",
            "0.31122229 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 226 [0/25046 (0%)]\tLoss: 0.143115\n",
            "Train epoch: 226 [325300/25046 (41%)]\tLoss: 0.180554\n",
            "Train epoch: 226 [653880/25046 (82%)]\tLoss: 0.211718\n",
            "Make prediction for 5010 samples...\n",
            "0.2703472 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 227 [0/25046 (0%)]\tLoss: 0.147480\n",
            "Train epoch: 227 [326980/25046 (41%)]\tLoss: 0.173089\n",
            "Train epoch: 227 [652400/25046 (82%)]\tLoss: 0.177771\n",
            "Make prediction for 5010 samples...\n",
            "0.344055 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 228 [0/25046 (0%)]\tLoss: 0.170759\n",
            "Train epoch: 228 [324820/25046 (41%)]\tLoss: 0.143727\n",
            "Train epoch: 228 [656240/25046 (82%)]\tLoss: 0.166324\n",
            "Make prediction for 5010 samples...\n",
            "0.2710441 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 229 [0/25046 (0%)]\tLoss: 0.133436\n",
            "Train epoch: 229 [330300/25046 (41%)]\tLoss: 0.162326\n",
            "Train epoch: 229 [667280/25046 (82%)]\tLoss: 0.158863\n",
            "Make prediction for 5010 samples...\n",
            "0.2755414 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 230 [0/25046 (0%)]\tLoss: 0.119435\n",
            "Train epoch: 230 [330820/25046 (41%)]\tLoss: 0.126257\n",
            "Train epoch: 230 [658000/25046 (82%)]\tLoss: 0.141759\n",
            "Make prediction for 5010 samples...\n",
            "0.26748353 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 231 [0/25046 (0%)]\tLoss: 0.124391\n",
            "Train epoch: 231 [333640/25046 (41%)]\tLoss: 0.139496\n",
            "Train epoch: 231 [649800/25046 (82%)]\tLoss: 0.187285\n",
            "Make prediction for 5010 samples...\n",
            "0.3073919 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 232 [0/25046 (0%)]\tLoss: 0.130768\n",
            "Train epoch: 232 [331660/25046 (41%)]\tLoss: 0.201774\n",
            "Train epoch: 232 [666720/25046 (82%)]\tLoss: 0.153643\n",
            "Make prediction for 5010 samples...\n",
            "0.27494523 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 233 [0/25046 (0%)]\tLoss: 0.128057\n",
            "Train epoch: 233 [331540/25046 (41%)]\tLoss: 0.202474\n",
            "Train epoch: 233 [662600/25046 (82%)]\tLoss: 0.201351\n",
            "Make prediction for 5010 samples...\n",
            "0.2719822 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 234 [0/25046 (0%)]\tLoss: 0.170614\n",
            "Train epoch: 234 [326920/25046 (41%)]\tLoss: 0.145174\n",
            "Train epoch: 234 [658840/25046 (82%)]\tLoss: 0.155624\n",
            "Make prediction for 5010 samples...\n",
            "0.32385406 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 235 [0/25046 (0%)]\tLoss: 0.162142\n",
            "Train epoch: 235 [319720/25046 (41%)]\tLoss: 0.186270\n",
            "Train epoch: 235 [649040/25046 (82%)]\tLoss: 0.154659\n",
            "Make prediction for 5010 samples...\n",
            "0.27540067 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 236 [0/25046 (0%)]\tLoss: 0.157916\n",
            "Train epoch: 236 [330000/25046 (41%)]\tLoss: 0.165618\n",
            "Train epoch: 236 [647320/25046 (82%)]\tLoss: 0.146798\n",
            "Make prediction for 5010 samples...\n",
            "0.2718407 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 237 [0/25046 (0%)]\tLoss: 0.111282\n",
            "Train epoch: 237 [328240/25046 (41%)]\tLoss: 0.140249\n",
            "Train epoch: 237 [659280/25046 (82%)]\tLoss: 0.159331\n",
            "Make prediction for 5010 samples...\n",
            "0.2894087 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 238 [0/25046 (0%)]\tLoss: 0.149111\n",
            "Train epoch: 238 [323920/25046 (41%)]\tLoss: 0.153971\n",
            "Train epoch: 238 [659080/25046 (82%)]\tLoss: 0.125587\n",
            "Make prediction for 5010 samples...\n",
            "0.27100506 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 239 [0/25046 (0%)]\tLoss: 0.139206\n",
            "Train epoch: 239 [329280/25046 (41%)]\tLoss: 0.185260\n",
            "Train epoch: 239 [659760/25046 (82%)]\tLoss: 0.120226\n",
            "Make prediction for 5010 samples...\n",
            "0.27426243 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 240 [0/25046 (0%)]\tLoss: 0.146399\n",
            "Train epoch: 240 [327180/25046 (41%)]\tLoss: 0.114343\n",
            "Train epoch: 240 [656560/25046 (82%)]\tLoss: 0.150851\n",
            "Make prediction for 5010 samples...\n",
            "0.2707053 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 241 [0/25046 (0%)]\tLoss: 0.127451\n",
            "Train epoch: 241 [327940/25046 (41%)]\tLoss: 0.135568\n",
            "Train epoch: 241 [661040/25046 (82%)]\tLoss: 0.133762\n",
            "Make prediction for 5010 samples...\n",
            "0.37148398 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 242 [0/25046 (0%)]\tLoss: 0.223255\n",
            "Train epoch: 242 [330880/25046 (41%)]\tLoss: 0.162599\n",
            "Train epoch: 242 [666320/25046 (82%)]\tLoss: 0.136120\n",
            "Make prediction for 5010 samples...\n",
            "0.30406064 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 243 [0/25046 (0%)]\tLoss: 0.169880\n",
            "Train epoch: 243 [328840/25046 (41%)]\tLoss: 0.129764\n",
            "Train epoch: 243 [657040/25046 (82%)]\tLoss: 0.158535\n",
            "Make prediction for 5010 samples...\n",
            "0.28154102 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 244 [0/25046 (0%)]\tLoss: 0.176184\n",
            "Train epoch: 244 [325800/25046 (41%)]\tLoss: 0.121126\n",
            "Train epoch: 244 [663120/25046 (82%)]\tLoss: 0.163172\n",
            "Make prediction for 5010 samples...\n",
            "0.2897247 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 245 [0/25046 (0%)]\tLoss: 0.156384\n",
            "Train epoch: 245 [332200/25046 (41%)]\tLoss: 0.172373\n",
            "Train epoch: 245 [653560/25046 (82%)]\tLoss: 0.183300\n",
            "Make prediction for 5010 samples...\n",
            "0.2702284 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 246 [0/25046 (0%)]\tLoss: 0.097574\n",
            "Train epoch: 246 [324940/25046 (41%)]\tLoss: 0.130048\n",
            "Train epoch: 246 [668840/25046 (82%)]\tLoss: 0.169861\n",
            "Make prediction for 5010 samples...\n",
            "0.27202535 No improvement since epoch  219 ; best_mse,best_ci: 0.2668725 0.8706233757203726 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 247 [0/25046 (0%)]\tLoss: 0.123186\n",
            "Train epoch: 247 [331300/25046 (41%)]\tLoss: 0.116153\n",
            "Train epoch: 247 [655960/25046 (82%)]\tLoss: 0.150548\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 248 [0/25046 (0%)]\tLoss: 0.163760\n",
            "Train epoch: 248 [327660/25046 (41%)]\tLoss: 0.147059\n",
            "Train epoch: 248 [645200/25046 (82%)]\tLoss: 0.147592\n",
            "Make prediction for 5010 samples...\n",
            "0.29268342 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 249 [0/25046 (0%)]\tLoss: 0.154765\n",
            "Train epoch: 249 [327780/25046 (41%)]\tLoss: 0.199032\n",
            "Train epoch: 249 [658360/25046 (82%)]\tLoss: 0.197003\n",
            "Make prediction for 5010 samples...\n",
            "0.29346162 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 250 [0/25046 (0%)]\tLoss: 0.123572\n",
            "Train epoch: 250 [328600/25046 (41%)]\tLoss: 0.147479\n",
            "Train epoch: 250 [655040/25046 (82%)]\tLoss: 0.177769\n",
            "Make prediction for 5010 samples...\n",
            "0.29073954 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 251 [0/25046 (0%)]\tLoss: 0.159096\n",
            "Train epoch: 251 [330420/25046 (41%)]\tLoss: 0.143219\n",
            "Train epoch: 251 [649760/25046 (82%)]\tLoss: 0.175291\n",
            "Make prediction for 5010 samples...\n",
            "0.27585873 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 252 [0/25046 (0%)]\tLoss: 0.124388\n",
            "Train epoch: 252 [330900/25046 (41%)]\tLoss: 0.159390\n",
            "Train epoch: 252 [665800/25046 (82%)]\tLoss: 0.132747\n",
            "Make prediction for 5010 samples...\n",
            "0.3034865 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 253 [0/25046 (0%)]\tLoss: 0.150665\n",
            "Train epoch: 253 [331340/25046 (41%)]\tLoss: 0.147565\n",
            "Train epoch: 253 [658000/25046 (82%)]\tLoss: 0.162387\n",
            "Make prediction for 5010 samples...\n",
            "0.29148346 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 254 [0/25046 (0%)]\tLoss: 0.160860\n",
            "Train epoch: 254 [324040/25046 (41%)]\tLoss: 0.149582\n",
            "Train epoch: 254 [655440/25046 (82%)]\tLoss: 0.161591\n",
            "Make prediction for 5010 samples...\n",
            "0.26748356 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 255 [0/25046 (0%)]\tLoss: 0.134830\n",
            "Train epoch: 255 [326560/25046 (41%)]\tLoss: 0.126926\n",
            "Train epoch: 255 [654800/25046 (82%)]\tLoss: 0.170045\n",
            "Make prediction for 5010 samples...\n",
            "0.29015434 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 256 [0/25046 (0%)]\tLoss: 0.178128\n",
            "Train epoch: 256 [334460/25046 (41%)]\tLoss: 0.211787\n",
            "Train epoch: 256 [657240/25046 (82%)]\tLoss: 0.150192\n",
            "Make prediction for 5010 samples...\n",
            "0.27328557 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 257 [0/25046 (0%)]\tLoss: 0.163638\n",
            "Train epoch: 257 [327340/25046 (41%)]\tLoss: 0.144634\n",
            "Train epoch: 257 [656040/25046 (82%)]\tLoss: 0.167897\n",
            "Make prediction for 5010 samples...\n",
            "0.28762767 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 258 [0/25046 (0%)]\tLoss: 0.139068\n",
            "Train epoch: 258 [331040/25046 (41%)]\tLoss: 0.131011\n",
            "Train epoch: 258 [648240/25046 (82%)]\tLoss: 0.122076\n",
            "Make prediction for 5010 samples...\n",
            "0.28619236 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 259 [0/25046 (0%)]\tLoss: 0.126934\n",
            "Train epoch: 259 [327520/25046 (41%)]\tLoss: 0.182313\n",
            "Train epoch: 259 [666360/25046 (82%)]\tLoss: 0.165061\n",
            "Make prediction for 5010 samples...\n",
            "0.2895337 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 260 [0/25046 (0%)]\tLoss: 0.177724\n",
            "Train epoch: 260 [326620/25046 (41%)]\tLoss: 0.202084\n",
            "Train epoch: 260 [648880/25046 (82%)]\tLoss: 0.141754\n",
            "Make prediction for 5010 samples...\n",
            "0.26613975 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 261 [0/25046 (0%)]\tLoss: 0.164197\n",
            "Train epoch: 261 [324420/25046 (41%)]\tLoss: 0.123633\n",
            "Train epoch: 261 [660320/25046 (82%)]\tLoss: 0.155626\n",
            "Make prediction for 5010 samples...\n",
            "0.29067048 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 262 [0/25046 (0%)]\tLoss: 0.127012\n",
            "Train epoch: 262 [324720/25046 (41%)]\tLoss: 0.122585\n",
            "Train epoch: 262 [657400/25046 (82%)]\tLoss: 0.139272\n",
            "Make prediction for 5010 samples...\n",
            "0.30073413 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 263 [0/25046 (0%)]\tLoss: 0.137378\n",
            "Train epoch: 263 [331600/25046 (41%)]\tLoss: 0.118472\n",
            "Train epoch: 263 [655440/25046 (82%)]\tLoss: 0.130414\n",
            "Make prediction for 5010 samples...\n",
            "0.2656596 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 264 [0/25046 (0%)]\tLoss: 0.119316\n",
            "Train epoch: 264 [326220/25046 (41%)]\tLoss: 0.184389\n",
            "Train epoch: 264 [661800/25046 (82%)]\tLoss: 0.126509\n",
            "Make prediction for 5010 samples...\n",
            "0.26560068 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 265 [0/25046 (0%)]\tLoss: 0.142579\n",
            "Train epoch: 265 [327140/25046 (41%)]\tLoss: 0.147855\n",
            "Train epoch: 265 [652600/25046 (82%)]\tLoss: 0.148030\n",
            "Make prediction for 5010 samples...\n",
            "0.27214956 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 266 [0/25046 (0%)]\tLoss: 0.117858\n",
            "Train epoch: 266 [327840/25046 (41%)]\tLoss: 0.100904\n",
            "Train epoch: 266 [662520/25046 (82%)]\tLoss: 0.141697\n",
            "Make prediction for 5010 samples...\n",
            "0.26377788 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 267 [0/25046 (0%)]\tLoss: 0.138472\n",
            "Train epoch: 267 [331160/25046 (41%)]\tLoss: 0.127906\n",
            "Train epoch: 267 [658480/25046 (82%)]\tLoss: 0.150226\n",
            "Make prediction for 5010 samples...\n",
            "0.29207093 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 268 [0/25046 (0%)]\tLoss: 0.165189\n",
            "Train epoch: 268 [328640/25046 (41%)]\tLoss: 0.161932\n",
            "Train epoch: 268 [657160/25046 (82%)]\tLoss: 0.136760\n",
            "Make prediction for 5010 samples...\n",
            "0.26995453 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 269 [0/25046 (0%)]\tLoss: 0.097708\n",
            "Train epoch: 269 [323240/25046 (41%)]\tLoss: 0.112314\n",
            "Train epoch: 269 [658000/25046 (82%)]\tLoss: 0.171398\n",
            "Make prediction for 5010 samples...\n",
            "0.28001451 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 270 [0/25046 (0%)]\tLoss: 0.131681\n",
            "Train epoch: 270 [326840/25046 (41%)]\tLoss: 0.120844\n",
            "Train epoch: 270 [658680/25046 (82%)]\tLoss: 0.143321\n",
            "Make prediction for 5010 samples...\n",
            "0.2841341 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 271 [0/25046 (0%)]\tLoss: 0.145667\n",
            "Train epoch: 271 [326460/25046 (41%)]\tLoss: 0.164279\n",
            "Train epoch: 271 [655200/25046 (82%)]\tLoss: 0.179650\n",
            "Make prediction for 5010 samples...\n",
            "0.2672535 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 272 [0/25046 (0%)]\tLoss: 0.133317\n",
            "Train epoch: 272 [330740/25046 (41%)]\tLoss: 0.152021\n",
            "Train epoch: 272 [675120/25046 (82%)]\tLoss: 0.134366\n",
            "Make prediction for 5010 samples...\n",
            "0.26208878 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 273 [0/25046 (0%)]\tLoss: 0.107935\n",
            "Train epoch: 273 [334300/25046 (41%)]\tLoss: 0.147735\n",
            "Train epoch: 273 [650880/25046 (82%)]\tLoss: 0.141673\n",
            "Make prediction for 5010 samples...\n",
            "0.26893684 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 274 [0/25046 (0%)]\tLoss: 0.131921\n",
            "Train epoch: 274 [334260/25046 (41%)]\tLoss: 0.127392\n",
            "Train epoch: 274 [654880/25046 (82%)]\tLoss: 0.124914\n",
            "Make prediction for 5010 samples...\n",
            "0.26245058 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 275 [0/25046 (0%)]\tLoss: 0.115220\n",
            "Train epoch: 275 [327600/25046 (41%)]\tLoss: 0.170652\n",
            "Train epoch: 275 [659640/25046 (82%)]\tLoss: 0.107336\n",
            "Make prediction for 5010 samples...\n",
            "0.26986 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 276 [0/25046 (0%)]\tLoss: 0.115677\n",
            "Train epoch: 276 [337080/25046 (41%)]\tLoss: 0.111519\n",
            "Train epoch: 276 [653840/25046 (82%)]\tLoss: 0.116574\n",
            "Make prediction for 5010 samples...\n",
            "0.27503756 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 277 [0/25046 (0%)]\tLoss: 0.133565\n",
            "Train epoch: 277 [330860/25046 (41%)]\tLoss: 0.161016\n",
            "Train epoch: 277 [657120/25046 (82%)]\tLoss: 0.115918\n",
            "Make prediction for 5010 samples...\n",
            "0.26493612 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 278 [0/25046 (0%)]\tLoss: 0.109234\n",
            "Train epoch: 278 [326500/25046 (41%)]\tLoss: 0.130582\n",
            "Train epoch: 278 [653800/25046 (82%)]\tLoss: 0.111670\n",
            "Make prediction for 5010 samples...\n",
            "0.26079366 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 279 [0/25046 (0%)]\tLoss: 0.127212\n",
            "Train epoch: 279 [328740/25046 (41%)]\tLoss: 0.125450\n",
            "Train epoch: 279 [651320/25046 (82%)]\tLoss: 0.162890\n",
            "Make prediction for 5010 samples...\n",
            "0.27879617 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 280 [0/25046 (0%)]\tLoss: 0.127684\n",
            "Train epoch: 280 [324760/25046 (41%)]\tLoss: 0.131067\n",
            "Train epoch: 280 [656520/25046 (82%)]\tLoss: 0.140181\n",
            "Make prediction for 5010 samples...\n",
            "0.2871132 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 281 [0/25046 (0%)]\tLoss: 0.130856\n",
            "Train epoch: 281 [328840/25046 (41%)]\tLoss: 0.136875\n",
            "Train epoch: 281 [650440/25046 (82%)]\tLoss: 0.162712\n",
            "Make prediction for 5010 samples...\n",
            "0.26875514 No improvement since epoch  247 ; best_mse,best_ci: 0.25930452 0.8762992896933011 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 282 [0/25046 (0%)]\tLoss: 0.151321\n",
            "Train epoch: 282 [330940/25046 (41%)]\tLoss: 0.201270\n",
            "Train epoch: 282 [666280/25046 (82%)]\tLoss: 0.138909\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  282 ; best_mse,best_ci: 0.25791258 0.8779237799055446 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 283 [0/25046 (0%)]\tLoss: 0.119621\n",
            "Train epoch: 283 [322360/25046 (41%)]\tLoss: 0.198655\n",
            "Train epoch: 283 [646680/25046 (82%)]\tLoss: 0.127009\n",
            "Make prediction for 5010 samples...\n",
            "0.27063543 No improvement since epoch  282 ; best_mse,best_ci: 0.25791258 0.8779237799055446 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 284 [0/25046 (0%)]\tLoss: 0.117472\n",
            "Train epoch: 284 [330060/25046 (41%)]\tLoss: 0.133862\n",
            "Train epoch: 284 [657480/25046 (82%)]\tLoss: 0.131711\n",
            "Make prediction for 5010 samples...\n",
            "0.26984435 No improvement since epoch  282 ; best_mse,best_ci: 0.25791258 0.8779237799055446 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 285 [0/25046 (0%)]\tLoss: 0.148994\n",
            "Train epoch: 285 [327060/25046 (41%)]\tLoss: 0.169155\n",
            "Train epoch: 285 [645000/25046 (82%)]\tLoss: 0.196114\n",
            "Make prediction for 5010 samples...\n",
            "0.26505074 No improvement since epoch  282 ; best_mse,best_ci: 0.25791258 0.8779237799055446 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 286 [0/25046 (0%)]\tLoss: 0.129695\n",
            "Train epoch: 286 [321960/25046 (41%)]\tLoss: 0.112951\n",
            "Train epoch: 286 [662960/25046 (82%)]\tLoss: 0.110779\n",
            "Make prediction for 5010 samples...\n",
            "0.27169698 No improvement since epoch  282 ; best_mse,best_ci: 0.25791258 0.8779237799055446 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 287 [0/25046 (0%)]\tLoss: 0.140524\n",
            "Train epoch: 287 [331440/25046 (41%)]\tLoss: 0.163676\n",
            "Train epoch: 287 [665360/25046 (82%)]\tLoss: 0.140527\n",
            "Make prediction for 5010 samples...\n",
            "0.2734413 No improvement since epoch  282 ; best_mse,best_ci: 0.25791258 0.8779237799055446 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 288 [0/25046 (0%)]\tLoss: 0.135998\n",
            "Train epoch: 288 [326540/25046 (41%)]\tLoss: 0.130908\n",
            "Train epoch: 288 [649880/25046 (82%)]\tLoss: 0.120769\n",
            "Make prediction for 5010 samples...\n",
            "0.29241922 No improvement since epoch  282 ; best_mse,best_ci: 0.25791258 0.8779237799055446 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 289 [0/25046 (0%)]\tLoss: 0.125425\n",
            "Train epoch: 289 [326340/25046 (41%)]\tLoss: 0.136039\n",
            "Train epoch: 289 [657760/25046 (82%)]\tLoss: 0.158990\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 290 [0/25046 (0%)]\tLoss: 0.137684\n",
            "Train epoch: 290 [328400/25046 (41%)]\tLoss: 0.126537\n",
            "Train epoch: 290 [651240/25046 (82%)]\tLoss: 0.142197\n",
            "Make prediction for 5010 samples...\n",
            "0.27352104 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 291 [0/25046 (0%)]\tLoss: 0.128562\n",
            "Train epoch: 291 [327600/25046 (41%)]\tLoss: 0.124561\n",
            "Train epoch: 291 [654640/25046 (82%)]\tLoss: 0.150172\n",
            "Make prediction for 5010 samples...\n",
            "0.27690032 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 292 [0/25046 (0%)]\tLoss: 0.144456\n",
            "Train epoch: 292 [332920/25046 (41%)]\tLoss: 0.159229\n",
            "Train epoch: 292 [654680/25046 (82%)]\tLoss: 0.189470\n",
            "Make prediction for 5010 samples...\n",
            "0.32750735 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 293 [0/25046 (0%)]\tLoss: 0.181165\n",
            "Train epoch: 293 [328160/25046 (41%)]\tLoss: 0.137268\n",
            "Train epoch: 293 [653000/25046 (82%)]\tLoss: 0.128395\n",
            "Make prediction for 5010 samples...\n",
            "0.29380596 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 294 [0/25046 (0%)]\tLoss: 0.139611\n",
            "Train epoch: 294 [329300/25046 (41%)]\tLoss: 0.123031\n",
            "Train epoch: 294 [656760/25046 (82%)]\tLoss: 0.119167\n",
            "Make prediction for 5010 samples...\n",
            "0.27829862 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 295 [0/25046 (0%)]\tLoss: 0.162478\n",
            "Train epoch: 295 [327560/25046 (41%)]\tLoss: 0.136445\n",
            "Train epoch: 295 [664200/25046 (82%)]\tLoss: 0.147508\n",
            "Make prediction for 5010 samples...\n",
            "0.2597574 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 296 [0/25046 (0%)]\tLoss: 0.111514\n",
            "Train epoch: 296 [328120/25046 (41%)]\tLoss: 0.137094\n",
            "Train epoch: 296 [651080/25046 (82%)]\tLoss: 0.125321\n",
            "Make prediction for 5010 samples...\n",
            "0.2636735 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 297 [0/25046 (0%)]\tLoss: 0.135279\n",
            "Train epoch: 297 [333660/25046 (41%)]\tLoss: 0.125936\n",
            "Train epoch: 297 [657920/25046 (82%)]\tLoss: 0.132352\n",
            "Make prediction for 5010 samples...\n",
            "0.27738106 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 298 [0/25046 (0%)]\tLoss: 0.117329\n",
            "Train epoch: 298 [327980/25046 (41%)]\tLoss: 0.128269\n",
            "Train epoch: 298 [655320/25046 (82%)]\tLoss: 0.125109\n",
            "Make prediction for 5010 samples...\n",
            "0.25726658 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 299 [0/25046 (0%)]\tLoss: 0.105180\n",
            "Train epoch: 299 [326160/25046 (41%)]\tLoss: 0.159717\n",
            "Train epoch: 299 [660440/25046 (82%)]\tLoss: 0.166881\n",
            "Make prediction for 5010 samples...\n",
            "0.2652308 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 300 [0/25046 (0%)]\tLoss: 0.153821\n",
            "Train epoch: 300 [330780/25046 (41%)]\tLoss: 0.115090\n",
            "Train epoch: 300 [657480/25046 (82%)]\tLoss: 0.129657\n",
            "Make prediction for 5010 samples...\n",
            "0.2575098 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 301 [0/25046 (0%)]\tLoss: 0.116625\n",
            "Train epoch: 301 [325840/25046 (41%)]\tLoss: 0.118766\n",
            "Train epoch: 301 [657560/25046 (82%)]\tLoss: 0.117118\n",
            "Make prediction for 5010 samples...\n",
            "0.2667749 No improvement since epoch  289 ; best_mse,best_ci: 0.25424215 0.8723640322214808 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 302 [0/25046 (0%)]\tLoss: 0.122800\n",
            "Train epoch: 302 [326520/25046 (41%)]\tLoss: 0.113786\n",
            "Train epoch: 302 [657760/25046 (82%)]\tLoss: 0.169746\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  302 ; best_mse,best_ci: 0.25347835 0.8798401790783366 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 303 [0/25046 (0%)]\tLoss: 0.126451\n",
            "Train epoch: 303 [327680/25046 (41%)]\tLoss: 0.131113\n",
            "Train epoch: 303 [659960/25046 (82%)]\tLoss: 0.119586\n",
            "Make prediction for 5010 samples...\n",
            "0.26354596 No improvement since epoch  302 ; best_mse,best_ci: 0.25347835 0.8798401790783366 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 304 [0/25046 (0%)]\tLoss: 0.124647\n",
            "Train epoch: 304 [324700/25046 (41%)]\tLoss: 0.127521\n",
            "Train epoch: 304 [654760/25046 (82%)]\tLoss: 0.136578\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 305 [0/25046 (0%)]\tLoss: 0.133152\n",
            "Train epoch: 305 [330180/25046 (41%)]\tLoss: 0.120770\n",
            "Train epoch: 305 [656360/25046 (82%)]\tLoss: 0.140801\n",
            "Make prediction for 5010 samples...\n",
            "0.25448444 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 306 [0/25046 (0%)]\tLoss: 0.096424\n",
            "Train epoch: 306 [328560/25046 (41%)]\tLoss: 0.132957\n",
            "Train epoch: 306 [660920/25046 (82%)]\tLoss: 0.167237\n",
            "Make prediction for 5010 samples...\n",
            "0.2834408 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 307 [0/25046 (0%)]\tLoss: 0.133955\n",
            "Train epoch: 307 [326680/25046 (41%)]\tLoss: 0.130497\n",
            "Train epoch: 307 [652160/25046 (82%)]\tLoss: 0.152057\n",
            "Make prediction for 5010 samples...\n",
            "0.26981917 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 308 [0/25046 (0%)]\tLoss: 0.131308\n",
            "Train epoch: 308 [330860/25046 (41%)]\tLoss: 0.094555\n",
            "Train epoch: 308 [667640/25046 (82%)]\tLoss: 0.103467\n",
            "Make prediction for 5010 samples...\n",
            "0.26155344 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 309 [0/25046 (0%)]\tLoss: 0.126921\n",
            "Train epoch: 309 [330680/25046 (41%)]\tLoss: 0.130026\n",
            "Train epoch: 309 [657840/25046 (82%)]\tLoss: 0.123746\n",
            "Make prediction for 5010 samples...\n",
            "0.26701748 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 310 [0/25046 (0%)]\tLoss: 0.120543\n",
            "Train epoch: 310 [329780/25046 (41%)]\tLoss: 0.118971\n",
            "Train epoch: 310 [653760/25046 (82%)]\tLoss: 0.133892\n",
            "Make prediction for 5010 samples...\n",
            "0.30250582 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 311 [0/25046 (0%)]\tLoss: 0.195186\n",
            "Train epoch: 311 [329300/25046 (41%)]\tLoss: 0.147818\n",
            "Train epoch: 311 [654000/25046 (82%)]\tLoss: 0.155419\n",
            "Make prediction for 5010 samples...\n",
            "0.27409706 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 312 [0/25046 (0%)]\tLoss: 0.125123\n",
            "Train epoch: 312 [326720/25046 (41%)]\tLoss: 0.119822\n",
            "Train epoch: 312 [651520/25046 (82%)]\tLoss: 0.121060\n",
            "Make prediction for 5010 samples...\n",
            "0.2712201 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 313 [0/25046 (0%)]\tLoss: 0.105879\n",
            "Train epoch: 313 [328580/25046 (41%)]\tLoss: 0.096298\n",
            "Train epoch: 313 [655880/25046 (82%)]\tLoss: 0.125119\n",
            "Make prediction for 5010 samples...\n",
            "0.2632968 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 314 [0/25046 (0%)]\tLoss: 0.142611\n",
            "Train epoch: 314 [331920/25046 (41%)]\tLoss: 0.136469\n",
            "Train epoch: 314 [651600/25046 (82%)]\tLoss: 0.139072\n",
            "Make prediction for 5010 samples...\n",
            "0.2652257 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 315 [0/25046 (0%)]\tLoss: 0.126710\n",
            "Train epoch: 315 [322440/25046 (41%)]\tLoss: 0.116820\n",
            "Train epoch: 315 [662840/25046 (82%)]\tLoss: 0.127680\n",
            "Make prediction for 5010 samples...\n",
            "0.26615903 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 316 [0/25046 (0%)]\tLoss: 0.140428\n",
            "Train epoch: 316 [329900/25046 (41%)]\tLoss: 0.133221\n",
            "Train epoch: 316 [656560/25046 (82%)]\tLoss: 0.148334\n",
            "Make prediction for 5010 samples...\n",
            "0.27506632 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 317 [0/25046 (0%)]\tLoss: 0.129146\n",
            "Train epoch: 317 [324300/25046 (41%)]\tLoss: 0.122877\n",
            "Train epoch: 317 [654120/25046 (82%)]\tLoss: 0.163358\n",
            "Make prediction for 5010 samples...\n",
            "0.27242234 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 318 [0/25046 (0%)]\tLoss: 0.119941\n",
            "Train epoch: 318 [330920/25046 (41%)]\tLoss: 0.124687\n",
            "Train epoch: 318 [660560/25046 (82%)]\tLoss: 0.114515\n",
            "Make prediction for 5010 samples...\n",
            "0.27576745 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 319 [0/25046 (0%)]\tLoss: 0.171038\n",
            "Train epoch: 319 [335640/25046 (41%)]\tLoss: 0.115423\n",
            "Train epoch: 319 [657040/25046 (82%)]\tLoss: 0.144808\n",
            "Make prediction for 5010 samples...\n",
            "0.26270083 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 320 [0/25046 (0%)]\tLoss: 0.157530\n",
            "Train epoch: 320 [333560/25046 (41%)]\tLoss: 0.116451\n",
            "Train epoch: 320 [653080/25046 (82%)]\tLoss: 0.168529\n",
            "Make prediction for 5010 samples...\n",
            "0.257383 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 321 [0/25046 (0%)]\tLoss: 0.104562\n",
            "Train epoch: 321 [326040/25046 (41%)]\tLoss: 0.134296\n",
            "Train epoch: 321 [659840/25046 (82%)]\tLoss: 0.142646\n",
            "Make prediction for 5010 samples...\n",
            "0.35967177 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 322 [0/25046 (0%)]\tLoss: 0.160257\n",
            "Train epoch: 322 [324960/25046 (41%)]\tLoss: 0.140372\n",
            "Train epoch: 322 [653280/25046 (82%)]\tLoss: 0.111728\n",
            "Make prediction for 5010 samples...\n",
            "0.270471 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 323 [0/25046 (0%)]\tLoss: 0.151260\n",
            "Train epoch: 323 [327040/25046 (41%)]\tLoss: 0.162918\n",
            "Train epoch: 323 [662920/25046 (82%)]\tLoss: 0.157737\n",
            "Make prediction for 5010 samples...\n",
            "0.28550488 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 324 [0/25046 (0%)]\tLoss: 0.138579\n",
            "Train epoch: 324 [323720/25046 (41%)]\tLoss: 0.133270\n",
            "Train epoch: 324 [653720/25046 (82%)]\tLoss: 0.146993\n",
            "Make prediction for 5010 samples...\n",
            "0.3161314 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 325 [0/25046 (0%)]\tLoss: 0.132997\n",
            "Train epoch: 325 [332840/25046 (41%)]\tLoss: 0.135541\n",
            "Train epoch: 325 [662160/25046 (82%)]\tLoss: 0.114018\n",
            "Make prediction for 5010 samples...\n",
            "0.25887367 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 326 [0/25046 (0%)]\tLoss: 0.141544\n",
            "Train epoch: 326 [326380/25046 (41%)]\tLoss: 0.134253\n",
            "Train epoch: 326 [659880/25046 (82%)]\tLoss: 0.134522\n",
            "Make prediction for 5010 samples...\n",
            "0.27084073 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 327 [0/25046 (0%)]\tLoss: 0.110327\n",
            "Train epoch: 327 [332720/25046 (41%)]\tLoss: 0.140300\n",
            "Train epoch: 327 [658680/25046 (82%)]\tLoss: 0.122603\n",
            "Make prediction for 5010 samples...\n",
            "0.27255562 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 328 [0/25046 (0%)]\tLoss: 0.137063\n",
            "Train epoch: 328 [326240/25046 (41%)]\tLoss: 0.157485\n",
            "Train epoch: 328 [655600/25046 (82%)]\tLoss: 0.121000\n",
            "Make prediction for 5010 samples...\n",
            "0.29460916 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 329 [0/25046 (0%)]\tLoss: 0.133628\n",
            "Train epoch: 329 [328100/25046 (41%)]\tLoss: 0.139058\n",
            "Train epoch: 329 [656520/25046 (82%)]\tLoss: 0.120617\n",
            "Make prediction for 5010 samples...\n",
            "0.27184048 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 330 [0/25046 (0%)]\tLoss: 0.140818\n",
            "Train epoch: 330 [328640/25046 (41%)]\tLoss: 0.184391\n",
            "Train epoch: 330 [651720/25046 (82%)]\tLoss: 0.127100\n",
            "Make prediction for 5010 samples...\n",
            "0.29017043 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 331 [0/25046 (0%)]\tLoss: 0.113869\n",
            "Train epoch: 331 [324000/25046 (41%)]\tLoss: 0.111640\n",
            "Train epoch: 331 [664280/25046 (82%)]\tLoss: 0.117287\n",
            "Make prediction for 5010 samples...\n",
            "0.26985726 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 332 [0/25046 (0%)]\tLoss: 0.113291\n",
            "Train epoch: 332 [330400/25046 (41%)]\tLoss: 0.119969\n",
            "Train epoch: 332 [659200/25046 (82%)]\tLoss: 0.143814\n",
            "Make prediction for 5010 samples...\n",
            "0.26597205 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 333 [0/25046 (0%)]\tLoss: 0.130862\n",
            "Train epoch: 333 [324100/25046 (41%)]\tLoss: 0.146047\n",
            "Train epoch: 333 [657840/25046 (82%)]\tLoss: 0.141777\n",
            "Make prediction for 5010 samples...\n",
            "0.28194308 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 334 [0/25046 (0%)]\tLoss: 0.107076\n",
            "Train epoch: 334 [331560/25046 (41%)]\tLoss: 0.164681\n",
            "Train epoch: 334 [661000/25046 (82%)]\tLoss: 0.139894\n",
            "Make prediction for 5010 samples...\n",
            "0.32285535 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 335 [0/25046 (0%)]\tLoss: 0.163440\n",
            "Train epoch: 335 [328440/25046 (41%)]\tLoss: 0.130738\n",
            "Train epoch: 335 [659000/25046 (82%)]\tLoss: 0.131882\n",
            "Make prediction for 5010 samples...\n",
            "0.2638891 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 336 [0/25046 (0%)]\tLoss: 0.116195\n",
            "Train epoch: 336 [332780/25046 (41%)]\tLoss: 0.092348\n",
            "Train epoch: 336 [660600/25046 (82%)]\tLoss: 0.170473\n",
            "Make prediction for 5010 samples...\n",
            "0.25669822 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 337 [0/25046 (0%)]\tLoss: 0.118628\n",
            "Train epoch: 337 [328100/25046 (41%)]\tLoss: 0.110425\n",
            "Train epoch: 337 [658440/25046 (82%)]\tLoss: 0.108861\n",
            "Make prediction for 5010 samples...\n",
            "0.2828243 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 338 [0/25046 (0%)]\tLoss: 0.090814\n",
            "Train epoch: 338 [329940/25046 (41%)]\tLoss: 0.155419\n",
            "Train epoch: 338 [665320/25046 (82%)]\tLoss: 0.127118\n",
            "Make prediction for 5010 samples...\n",
            "0.2635978 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 339 [0/25046 (0%)]\tLoss: 0.097930\n",
            "Train epoch: 339 [323460/25046 (41%)]\tLoss: 0.119053\n",
            "Train epoch: 339 [658160/25046 (82%)]\tLoss: 0.137561\n",
            "Make prediction for 5010 samples...\n",
            "0.31263214 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 340 [0/25046 (0%)]\tLoss: 0.131179\n",
            "Train epoch: 340 [325920/25046 (41%)]\tLoss: 0.116741\n",
            "Train epoch: 340 [649120/25046 (82%)]\tLoss: 0.132774\n",
            "Make prediction for 5010 samples...\n",
            "0.2531036 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 341 [0/25046 (0%)]\tLoss: 0.130999\n",
            "Train epoch: 341 [325700/25046 (41%)]\tLoss: 0.099697\n",
            "Train epoch: 341 [645480/25046 (82%)]\tLoss: 0.119337\n",
            "Make prediction for 5010 samples...\n",
            "0.27966967 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 342 [0/25046 (0%)]\tLoss: 0.152280\n",
            "Train epoch: 342 [328620/25046 (41%)]\tLoss: 0.135850\n",
            "Train epoch: 342 [663640/25046 (82%)]\tLoss: 0.151795\n",
            "Make prediction for 5010 samples...\n",
            "0.2636918 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 343 [0/25046 (0%)]\tLoss: 0.126209\n",
            "Train epoch: 343 [327940/25046 (41%)]\tLoss: 0.121819\n",
            "Train epoch: 343 [654720/25046 (82%)]\tLoss: 0.142021\n",
            "Make prediction for 5010 samples...\n",
            "0.27109423 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 344 [0/25046 (0%)]\tLoss: 0.101923\n",
            "Train epoch: 344 [329800/25046 (41%)]\tLoss: 0.138271\n",
            "Train epoch: 344 [660320/25046 (82%)]\tLoss: 0.112946\n",
            "Make prediction for 5010 samples...\n",
            "0.2688882 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 345 [0/25046 (0%)]\tLoss: 0.094197\n",
            "Train epoch: 345 [331640/25046 (41%)]\tLoss: 0.128713\n",
            "Train epoch: 345 [655440/25046 (82%)]\tLoss: 0.120967\n",
            "Make prediction for 5010 samples...\n",
            "0.28652027 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 346 [0/25046 (0%)]\tLoss: 0.142535\n",
            "Train epoch: 346 [327360/25046 (41%)]\tLoss: 0.105410\n",
            "Train epoch: 346 [653480/25046 (82%)]\tLoss: 0.115500\n",
            "Make prediction for 5010 samples...\n",
            "0.27319783 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 347 [0/25046 (0%)]\tLoss: 0.099463\n",
            "Train epoch: 347 [333340/25046 (41%)]\tLoss: 0.097558\n",
            "Train epoch: 347 [650960/25046 (82%)]\tLoss: 0.127823\n",
            "Make prediction for 5010 samples...\n",
            "0.26252148 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 348 [0/25046 (0%)]\tLoss: 0.133608\n",
            "Train epoch: 348 [333020/25046 (41%)]\tLoss: 0.098629\n",
            "Train epoch: 348 [650880/25046 (82%)]\tLoss: 0.106194\n",
            "Make prediction for 5010 samples...\n",
            "0.32302302 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 349 [0/25046 (0%)]\tLoss: 0.146587\n",
            "Train epoch: 349 [325580/25046 (41%)]\tLoss: 0.095503\n",
            "Train epoch: 349 [659120/25046 (82%)]\tLoss: 0.124290\n",
            "Make prediction for 5010 samples...\n",
            "0.3348491 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 350 [0/25046 (0%)]\tLoss: 0.151502\n",
            "Train epoch: 350 [325660/25046 (41%)]\tLoss: 0.102212\n",
            "Train epoch: 350 [666680/25046 (82%)]\tLoss: 0.150763\n",
            "Make prediction for 5010 samples...\n",
            "0.26169288 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 351 [0/25046 (0%)]\tLoss: 0.129924\n",
            "Train epoch: 351 [332140/25046 (41%)]\tLoss: 0.147999\n",
            "Train epoch: 351 [665680/25046 (82%)]\tLoss: 0.129729\n",
            "Make prediction for 5010 samples...\n",
            "0.27132052 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 352 [0/25046 (0%)]\tLoss: 0.132915\n",
            "Train epoch: 352 [327260/25046 (41%)]\tLoss: 0.126152\n",
            "Train epoch: 352 [652360/25046 (82%)]\tLoss: 0.137143\n",
            "Make prediction for 5010 samples...\n",
            "0.26170632 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 353 [0/25046 (0%)]\tLoss: 0.102238\n",
            "Train epoch: 353 [328480/25046 (41%)]\tLoss: 0.116293\n",
            "Train epoch: 353 [653960/25046 (82%)]\tLoss: 0.159211\n",
            "Make prediction for 5010 samples...\n",
            "0.27235284 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 354 [0/25046 (0%)]\tLoss: 0.124367\n",
            "Train epoch: 354 [329300/25046 (41%)]\tLoss: 0.121016\n",
            "Train epoch: 354 [666560/25046 (82%)]\tLoss: 0.117943\n",
            "Make prediction for 5010 samples...\n",
            "0.25673357 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 355 [0/25046 (0%)]\tLoss: 0.109717\n",
            "Train epoch: 355 [331800/25046 (41%)]\tLoss: 0.134785\n",
            "Train epoch: 355 [658280/25046 (82%)]\tLoss: 0.123670\n",
            "Make prediction for 5010 samples...\n",
            "0.2816127 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 356 [0/25046 (0%)]\tLoss: 0.115724\n",
            "Train epoch: 356 [326300/25046 (41%)]\tLoss: 0.120693\n",
            "Train epoch: 356 [657400/25046 (82%)]\tLoss: 0.118105\n",
            "Make prediction for 5010 samples...\n",
            "0.27572286 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 357 [0/25046 (0%)]\tLoss: 0.100869\n",
            "Train epoch: 357 [326860/25046 (41%)]\tLoss: 0.125666\n",
            "Train epoch: 357 [654840/25046 (82%)]\tLoss: 0.081409\n",
            "Make prediction for 5010 samples...\n",
            "0.35649443 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 358 [0/25046 (0%)]\tLoss: 0.175175\n",
            "Train epoch: 358 [332340/25046 (41%)]\tLoss: 0.132399\n",
            "Train epoch: 358 [647440/25046 (82%)]\tLoss: 0.113848\n",
            "Make prediction for 5010 samples...\n",
            "0.25906077 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 359 [0/25046 (0%)]\tLoss: 0.126831\n",
            "Train epoch: 359 [332280/25046 (41%)]\tLoss: 0.129319\n",
            "Train epoch: 359 [658960/25046 (82%)]\tLoss: 0.108974\n",
            "Make prediction for 5010 samples...\n",
            "0.27105325 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 360 [0/25046 (0%)]\tLoss: 0.121545\n",
            "Train epoch: 360 [330880/25046 (41%)]\tLoss: 0.149039\n",
            "Train epoch: 360 [656200/25046 (82%)]\tLoss: 0.136617\n",
            "Make prediction for 5010 samples...\n",
            "0.26844704 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 361 [0/25046 (0%)]\tLoss: 0.143510\n",
            "Train epoch: 361 [332200/25046 (41%)]\tLoss: 0.191564\n",
            "Train epoch: 361 [670040/25046 (82%)]\tLoss: 0.094379\n",
            "Make prediction for 5010 samples...\n",
            "0.29495683 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 362 [0/25046 (0%)]\tLoss: 0.109210\n",
            "Train epoch: 362 [329060/25046 (41%)]\tLoss: 0.129309\n",
            "Train epoch: 362 [652840/25046 (82%)]\tLoss: 0.144579\n",
            "Make prediction for 5010 samples...\n",
            "0.30771115 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 363 [0/25046 (0%)]\tLoss: 0.160455\n",
            "Train epoch: 363 [330820/25046 (41%)]\tLoss: 0.124508\n",
            "Train epoch: 363 [658200/25046 (82%)]\tLoss: 0.151924\n",
            "Make prediction for 5010 samples...\n",
            "0.27704537 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 364 [0/25046 (0%)]\tLoss: 0.109804\n",
            "Train epoch: 364 [325540/25046 (41%)]\tLoss: 0.135629\n",
            "Train epoch: 364 [656760/25046 (82%)]\tLoss: 0.149976\n",
            "Make prediction for 5010 samples...\n",
            "0.26252064 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 365 [0/25046 (0%)]\tLoss: 0.130913\n",
            "Train epoch: 365 [329080/25046 (41%)]\tLoss: 0.120856\n",
            "Train epoch: 365 [651720/25046 (82%)]\tLoss: 0.085335\n",
            "Make prediction for 5010 samples...\n",
            "0.26538467 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 366 [0/25046 (0%)]\tLoss: 0.107459\n",
            "Train epoch: 366 [327240/25046 (41%)]\tLoss: 0.104020\n",
            "Train epoch: 366 [652120/25046 (82%)]\tLoss: 0.156874\n",
            "Make prediction for 5010 samples...\n",
            "0.27288634 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 367 [0/25046 (0%)]\tLoss: 0.109143\n",
            "Train epoch: 367 [330380/25046 (41%)]\tLoss: 0.148056\n",
            "Train epoch: 367 [654320/25046 (82%)]\tLoss: 0.141322\n",
            "Make prediction for 5010 samples...\n",
            "0.2895912 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 368 [0/25046 (0%)]\tLoss: 0.105799\n",
            "Train epoch: 368 [328440/25046 (41%)]\tLoss: 0.140657\n",
            "Train epoch: 368 [659800/25046 (82%)]\tLoss: 0.138220\n",
            "Make prediction for 5010 samples...\n",
            "0.2716205 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 369 [0/25046 (0%)]\tLoss: 0.119302\n",
            "Train epoch: 369 [328400/25046 (41%)]\tLoss: 0.123031\n",
            "Train epoch: 369 [671160/25046 (82%)]\tLoss: 0.154165\n",
            "Make prediction for 5010 samples...\n",
            "0.26523748 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 370 [0/25046 (0%)]\tLoss: 0.130906\n",
            "Train epoch: 370 [326820/25046 (41%)]\tLoss: 0.103667\n",
            "Train epoch: 370 [657040/25046 (82%)]\tLoss: 0.180793\n",
            "Make prediction for 5010 samples...\n",
            "0.29690397 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 371 [0/25046 (0%)]\tLoss: 0.110473\n",
            "Train epoch: 371 [332940/25046 (41%)]\tLoss: 0.113256\n",
            "Train epoch: 371 [652960/25046 (82%)]\tLoss: 0.157544\n",
            "Make prediction for 5010 samples...\n",
            "0.27694795 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 372 [0/25046 (0%)]\tLoss: 0.114786\n",
            "Train epoch: 372 [334740/25046 (41%)]\tLoss: 0.103357\n",
            "Train epoch: 372 [659560/25046 (82%)]\tLoss: 0.170476\n",
            "Make prediction for 5010 samples...\n",
            "0.25875053 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 373 [0/25046 (0%)]\tLoss: 0.118952\n",
            "Train epoch: 373 [330580/25046 (41%)]\tLoss: 0.146721\n",
            "Train epoch: 373 [647440/25046 (82%)]\tLoss: 0.097275\n",
            "Make prediction for 5010 samples...\n",
            "0.25797564 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 374 [0/25046 (0%)]\tLoss: 0.089164\n",
            "Train epoch: 374 [331180/25046 (41%)]\tLoss: 0.141151\n",
            "Train epoch: 374 [660040/25046 (82%)]\tLoss: 0.108024\n",
            "Make prediction for 5010 samples...\n",
            "0.27964035 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 375 [0/25046 (0%)]\tLoss: 0.112567\n",
            "Train epoch: 375 [334520/25046 (41%)]\tLoss: 0.127123\n",
            "Train epoch: 375 [656600/25046 (82%)]\tLoss: 0.109861\n",
            "Make prediction for 5010 samples...\n",
            "0.26615447 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 376 [0/25046 (0%)]\tLoss: 0.147419\n",
            "Train epoch: 376 [326960/25046 (41%)]\tLoss: 0.146779\n",
            "Train epoch: 376 [652920/25046 (82%)]\tLoss: 0.107224\n",
            "Make prediction for 5010 samples...\n",
            "0.26592 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 377 [0/25046 (0%)]\tLoss: 0.103538\n",
            "Train epoch: 377 [329980/25046 (41%)]\tLoss: 0.133850\n",
            "Train epoch: 377 [646840/25046 (82%)]\tLoss: 0.113652\n",
            "Make prediction for 5010 samples...\n",
            "0.31341413 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 378 [0/25046 (0%)]\tLoss: 0.157404\n",
            "Train epoch: 378 [332640/25046 (41%)]\tLoss: 0.145708\n",
            "Train epoch: 378 [659400/25046 (82%)]\tLoss: 0.082172\n",
            "Make prediction for 5010 samples...\n",
            "0.25720996 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 379 [0/25046 (0%)]\tLoss: 0.109271\n",
            "Train epoch: 379 [326920/25046 (41%)]\tLoss: 0.120229\n",
            "Train epoch: 379 [646240/25046 (82%)]\tLoss: 0.105712\n",
            "Make prediction for 5010 samples...\n",
            "0.2951531 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 380 [0/25046 (0%)]\tLoss: 0.193788\n",
            "Train epoch: 380 [322640/25046 (41%)]\tLoss: 0.107056\n",
            "Train epoch: 380 [660600/25046 (82%)]\tLoss: 0.112809\n",
            "Make prediction for 5010 samples...\n",
            "0.27517012 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 381 [0/25046 (0%)]\tLoss: 0.120463\n",
            "Train epoch: 381 [333360/25046 (41%)]\tLoss: 0.178093\n",
            "Train epoch: 381 [650480/25046 (82%)]\tLoss: 0.111803\n",
            "Make prediction for 5010 samples...\n",
            "0.26062778 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 382 [0/25046 (0%)]\tLoss: 0.148559\n",
            "Train epoch: 382 [330860/25046 (41%)]\tLoss: 0.123884\n",
            "Train epoch: 382 [654560/25046 (82%)]\tLoss: 0.151699\n",
            "Make prediction for 5010 samples...\n",
            "0.25559732 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 383 [0/25046 (0%)]\tLoss: 0.118434\n",
            "Train epoch: 383 [335060/25046 (41%)]\tLoss: 0.103296\n",
            "Train epoch: 383 [654880/25046 (82%)]\tLoss: 0.107741\n",
            "Make prediction for 5010 samples...\n",
            "0.2590543 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 384 [0/25046 (0%)]\tLoss: 0.161640\n",
            "Train epoch: 384 [332960/25046 (41%)]\tLoss: 0.104178\n",
            "Train epoch: 384 [661960/25046 (82%)]\tLoss: 0.148134\n",
            "Make prediction for 5010 samples...\n",
            "0.26799503 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 385 [0/25046 (0%)]\tLoss: 0.124570\n",
            "Train epoch: 385 [326240/25046 (41%)]\tLoss: 0.111139\n",
            "Train epoch: 385 [650520/25046 (82%)]\tLoss: 0.136502\n",
            "Make prediction for 5010 samples...\n",
            "0.26224798 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 386 [0/25046 (0%)]\tLoss: 0.152620\n",
            "Train epoch: 386 [327660/25046 (41%)]\tLoss: 0.117213\n",
            "Train epoch: 386 [661600/25046 (82%)]\tLoss: 0.128182\n",
            "Make prediction for 5010 samples...\n",
            "0.2671495 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 387 [0/25046 (0%)]\tLoss: 0.106111\n",
            "Train epoch: 387 [329540/25046 (41%)]\tLoss: 0.102744\n",
            "Train epoch: 387 [657200/25046 (82%)]\tLoss: 0.132319\n",
            "Make prediction for 5010 samples...\n",
            "0.25942567 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 388 [0/25046 (0%)]\tLoss: 0.127973\n",
            "Train epoch: 388 [326760/25046 (41%)]\tLoss: 0.111263\n",
            "Train epoch: 388 [664960/25046 (82%)]\tLoss: 0.111091\n",
            "Make prediction for 5010 samples...\n",
            "0.25847825 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 389 [0/25046 (0%)]\tLoss: 0.125075\n",
            "Train epoch: 389 [330620/25046 (41%)]\tLoss: 0.102773\n",
            "Train epoch: 389 [640200/25046 (82%)]\tLoss: 0.122195\n",
            "Make prediction for 5010 samples...\n",
            "0.27844512 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 390 [0/25046 (0%)]\tLoss: 0.161330\n",
            "Train epoch: 390 [324800/25046 (41%)]\tLoss: 0.107099\n",
            "Train epoch: 390 [654080/25046 (82%)]\tLoss: 0.122832\n",
            "Make prediction for 5010 samples...\n",
            "0.26514763 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 391 [0/25046 (0%)]\tLoss: 0.117215\n",
            "Train epoch: 391 [331140/25046 (41%)]\tLoss: 0.129862\n",
            "Train epoch: 391 [665320/25046 (82%)]\tLoss: 0.109948\n",
            "Make prediction for 5010 samples...\n",
            "0.29389077 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 392 [0/25046 (0%)]\tLoss: 0.114599\n",
            "Train epoch: 392 [326120/25046 (41%)]\tLoss: 0.084053\n",
            "Train epoch: 392 [652720/25046 (82%)]\tLoss: 0.144719\n",
            "Make prediction for 5010 samples...\n",
            "0.25430116 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 393 [0/25046 (0%)]\tLoss: 0.109113\n",
            "Train epoch: 393 [331960/25046 (41%)]\tLoss: 0.102162\n",
            "Train epoch: 393 [655960/25046 (82%)]\tLoss: 0.105463\n",
            "Make prediction for 5010 samples...\n",
            "0.26318344 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 394 [0/25046 (0%)]\tLoss: 0.121221\n",
            "Train epoch: 394 [329700/25046 (41%)]\tLoss: 0.108235\n",
            "Train epoch: 394 [661480/25046 (82%)]\tLoss: 0.117015\n",
            "Make prediction for 5010 samples...\n",
            "0.25920758 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 395 [0/25046 (0%)]\tLoss: 0.096144\n",
            "Train epoch: 395 [329160/25046 (41%)]\tLoss: 0.126437\n",
            "Train epoch: 395 [663720/25046 (82%)]\tLoss: 0.121346\n",
            "Make prediction for 5010 samples...\n",
            "0.25460222 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 396 [0/25046 (0%)]\tLoss: 0.085659\n",
            "Train epoch: 396 [327500/25046 (41%)]\tLoss: 0.165887\n",
            "Train epoch: 396 [655360/25046 (82%)]\tLoss: 0.091046\n",
            "Make prediction for 5010 samples...\n",
            "0.31921005 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 397 [0/25046 (0%)]\tLoss: 0.142160\n",
            "Train epoch: 397 [325200/25046 (41%)]\tLoss: 0.165416\n",
            "Train epoch: 397 [653880/25046 (82%)]\tLoss: 0.150614\n",
            "Make prediction for 5010 samples...\n",
            "0.2667651 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 398 [0/25046 (0%)]\tLoss: 0.086780\n",
            "Train epoch: 398 [329940/25046 (41%)]\tLoss: 0.105672\n",
            "Train epoch: 398 [654920/25046 (82%)]\tLoss: 0.115213\n",
            "Make prediction for 5010 samples...\n",
            "0.257375 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 399 [0/25046 (0%)]\tLoss: 0.109243\n",
            "Train epoch: 399 [327800/25046 (41%)]\tLoss: 0.115665\n",
            "Train epoch: 399 [653400/25046 (82%)]\tLoss: 0.129484\n",
            "Make prediction for 5010 samples...\n",
            "0.3181195 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 400 [0/25046 (0%)]\tLoss: 0.115658\n",
            "Train epoch: 400 [327940/25046 (41%)]\tLoss: 0.100321\n",
            "Train epoch: 400 [658640/25046 (82%)]\tLoss: 0.161602\n",
            "Make prediction for 5010 samples...\n",
            "0.31706923 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 401 [0/25046 (0%)]\tLoss: 0.169795\n",
            "Train epoch: 401 [325920/25046 (41%)]\tLoss: 0.143288\n",
            "Train epoch: 401 [659640/25046 (82%)]\tLoss: 0.114780\n",
            "Make prediction for 5010 samples...\n",
            "0.25827911 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 402 [0/25046 (0%)]\tLoss: 0.129206\n",
            "Train epoch: 402 [324360/25046 (41%)]\tLoss: 0.112668\n",
            "Train epoch: 402 [659400/25046 (82%)]\tLoss: 0.102088\n",
            "Make prediction for 5010 samples...\n",
            "0.26977104 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 403 [0/25046 (0%)]\tLoss: 0.156390\n",
            "Train epoch: 403 [332020/25046 (41%)]\tLoss: 0.120106\n",
            "Train epoch: 403 [663520/25046 (82%)]\tLoss: 0.147254\n",
            "Make prediction for 5010 samples...\n",
            "0.2839083 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 404 [0/25046 (0%)]\tLoss: 0.128648\n",
            "Train epoch: 404 [328840/25046 (41%)]\tLoss: 0.114992\n",
            "Train epoch: 404 [653440/25046 (82%)]\tLoss: 0.140718\n",
            "Make prediction for 5010 samples...\n",
            "0.25155845 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 405 [0/25046 (0%)]\tLoss: 0.087257\n",
            "Train epoch: 405 [328380/25046 (41%)]\tLoss: 0.105983\n",
            "Train epoch: 405 [654400/25046 (82%)]\tLoss: 0.104330\n",
            "Make prediction for 5010 samples...\n",
            "0.26737493 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 406 [0/25046 (0%)]\tLoss: 0.107710\n",
            "Train epoch: 406 [326340/25046 (41%)]\tLoss: 0.151047\n",
            "Train epoch: 406 [654880/25046 (82%)]\tLoss: 0.107255\n",
            "Make prediction for 5010 samples...\n",
            "0.2553887 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 407 [0/25046 (0%)]\tLoss: 0.130493\n",
            "Train epoch: 407 [330660/25046 (41%)]\tLoss: 0.117124\n",
            "Train epoch: 407 [663240/25046 (82%)]\tLoss: 0.121139\n",
            "Make prediction for 5010 samples...\n",
            "0.25625843 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 408 [0/25046 (0%)]\tLoss: 0.116273\n",
            "Train epoch: 408 [327400/25046 (41%)]\tLoss: 0.105372\n",
            "Train epoch: 408 [663560/25046 (82%)]\tLoss: 0.139597\n",
            "Make prediction for 5010 samples...\n",
            "0.27892157 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 409 [0/25046 (0%)]\tLoss: 0.109159\n",
            "Train epoch: 409 [323580/25046 (41%)]\tLoss: 0.126998\n",
            "Train epoch: 409 [659640/25046 (82%)]\tLoss: 0.147925\n",
            "Make prediction for 5010 samples...\n",
            "0.26034012 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 410 [0/25046 (0%)]\tLoss: 0.121563\n",
            "Train epoch: 410 [331840/25046 (41%)]\tLoss: 0.101651\n",
            "Train epoch: 410 [655640/25046 (82%)]\tLoss: 0.084692\n",
            "Make prediction for 5010 samples...\n",
            "0.2714618 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 411 [0/25046 (0%)]\tLoss: 0.113664\n",
            "Train epoch: 411 [323640/25046 (41%)]\tLoss: 0.108299\n",
            "Train epoch: 411 [653480/25046 (82%)]\tLoss: 0.099424\n",
            "Make prediction for 5010 samples...\n",
            "0.2830386 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 412 [0/25046 (0%)]\tLoss: 0.107310\n",
            "Train epoch: 412 [330620/25046 (41%)]\tLoss: 0.110080\n",
            "Train epoch: 412 [646400/25046 (82%)]\tLoss: 0.141552\n",
            "Make prediction for 5010 samples...\n",
            "0.25109842 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 413 [0/25046 (0%)]\tLoss: 0.150677\n",
            "Train epoch: 413 [332660/25046 (41%)]\tLoss: 0.145307\n",
            "Train epoch: 413 [663040/25046 (82%)]\tLoss: 0.115089\n",
            "Make prediction for 5010 samples...\n",
            "0.2576421 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 414 [0/25046 (0%)]\tLoss: 0.110558\n",
            "Train epoch: 414 [325940/25046 (41%)]\tLoss: 0.122427\n",
            "Train epoch: 414 [666840/25046 (82%)]\tLoss: 0.139450\n",
            "Make prediction for 5010 samples...\n",
            "0.28229025 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 415 [0/25046 (0%)]\tLoss: 0.119304\n",
            "Train epoch: 415 [331740/25046 (41%)]\tLoss: 0.111411\n",
            "Train epoch: 415 [650360/25046 (82%)]\tLoss: 0.104359\n",
            "Make prediction for 5010 samples...\n",
            "0.27643356 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 416 [0/25046 (0%)]\tLoss: 0.106959\n",
            "Train epoch: 416 [331100/25046 (41%)]\tLoss: 0.163659\n",
            "Train epoch: 416 [651400/25046 (82%)]\tLoss: 0.123518\n",
            "Make prediction for 5010 samples...\n",
            "0.26219746 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 417 [0/25046 (0%)]\tLoss: 0.117116\n",
            "Train epoch: 417 [335740/25046 (41%)]\tLoss: 0.105995\n",
            "Train epoch: 417 [668560/25046 (82%)]\tLoss: 0.135360\n",
            "Make prediction for 5010 samples...\n",
            "0.2935523 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 418 [0/25046 (0%)]\tLoss: 0.113284\n",
            "Train epoch: 418 [330440/25046 (41%)]\tLoss: 0.122071\n",
            "Train epoch: 418 [665040/25046 (82%)]\tLoss: 0.137706\n",
            "Make prediction for 5010 samples...\n",
            "0.31290004 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 419 [0/25046 (0%)]\tLoss: 0.209721\n",
            "Train epoch: 419 [331740/25046 (41%)]\tLoss: 0.125721\n",
            "Train epoch: 419 [656200/25046 (82%)]\tLoss: 0.108231\n",
            "Make prediction for 5010 samples...\n",
            "0.25460976 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 420 [0/25046 (0%)]\tLoss: 0.101054\n",
            "Train epoch: 420 [330140/25046 (41%)]\tLoss: 0.111725\n",
            "Train epoch: 420 [650040/25046 (82%)]\tLoss: 0.147619\n",
            "Make prediction for 5010 samples...\n",
            "0.2610266 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 421 [0/25046 (0%)]\tLoss: 0.120517\n",
            "Train epoch: 421 [331320/25046 (41%)]\tLoss: 0.117096\n",
            "Train epoch: 421 [653600/25046 (82%)]\tLoss: 0.113766\n",
            "Make prediction for 5010 samples...\n",
            "0.25555474 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 422 [0/25046 (0%)]\tLoss: 0.141076\n",
            "Train epoch: 422 [328520/25046 (41%)]\tLoss: 0.126060\n",
            "Train epoch: 422 [661360/25046 (82%)]\tLoss: 0.128137\n",
            "Make prediction for 5010 samples...\n",
            "0.27407032 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 423 [0/25046 (0%)]\tLoss: 0.090067\n",
            "Train epoch: 423 [325980/25046 (41%)]\tLoss: 0.108761\n",
            "Train epoch: 423 [648760/25046 (82%)]\tLoss: 0.123295\n",
            "Make prediction for 5010 samples...\n",
            "0.28489846 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 424 [0/25046 (0%)]\tLoss: 0.126436\n",
            "Train epoch: 424 [332440/25046 (41%)]\tLoss: 0.101111\n",
            "Train epoch: 424 [658800/25046 (82%)]\tLoss: 0.128979\n",
            "Make prediction for 5010 samples...\n",
            "0.2551835 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 425 [0/25046 (0%)]\tLoss: 0.112818\n",
            "Train epoch: 425 [329280/25046 (41%)]\tLoss: 0.112085\n",
            "Train epoch: 425 [658320/25046 (82%)]\tLoss: 0.095754\n",
            "Make prediction for 5010 samples...\n",
            "0.2604104 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 426 [0/25046 (0%)]\tLoss: 0.104574\n",
            "Train epoch: 426 [325940/25046 (41%)]\tLoss: 0.101884\n",
            "Train epoch: 426 [658320/25046 (82%)]\tLoss: 0.113985\n",
            "Make prediction for 5010 samples...\n",
            "0.25758278 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 427 [0/25046 (0%)]\tLoss: 0.089641\n",
            "Train epoch: 427 [326200/25046 (41%)]\tLoss: 0.096535\n",
            "Train epoch: 427 [654960/25046 (82%)]\tLoss: 0.093773\n",
            "Make prediction for 5010 samples...\n",
            "0.26730928 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 428 [0/25046 (0%)]\tLoss: 0.083714\n",
            "Train epoch: 428 [329420/25046 (41%)]\tLoss: 0.122515\n",
            "Train epoch: 428 [658720/25046 (82%)]\tLoss: 0.113132\n",
            "Make prediction for 5010 samples...\n",
            "0.25847688 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 429 [0/25046 (0%)]\tLoss: 0.106451\n",
            "Train epoch: 429 [327740/25046 (41%)]\tLoss: 0.131266\n",
            "Train epoch: 429 [655760/25046 (82%)]\tLoss: 0.106330\n",
            "Make prediction for 5010 samples...\n",
            "0.2655676 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 430 [0/25046 (0%)]\tLoss: 0.096004\n",
            "Train epoch: 430 [328060/25046 (41%)]\tLoss: 0.103878\n",
            "Train epoch: 430 [650360/25046 (82%)]\tLoss: 0.111558\n",
            "Make prediction for 5010 samples...\n",
            "0.28419825 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 431 [0/25046 (0%)]\tLoss: 0.116705\n",
            "Train epoch: 431 [332160/25046 (41%)]\tLoss: 0.137796\n",
            "Train epoch: 431 [661280/25046 (82%)]\tLoss: 0.115553\n",
            "Make prediction for 5010 samples...\n",
            "0.26201168 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 432 [0/25046 (0%)]\tLoss: 0.115871\n",
            "Train epoch: 432 [327500/25046 (41%)]\tLoss: 0.107399\n",
            "Train epoch: 432 [651720/25046 (82%)]\tLoss: 0.103552\n",
            "Make prediction for 5010 samples...\n",
            "0.2642756 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 433 [0/25046 (0%)]\tLoss: 0.094045\n",
            "Train epoch: 433 [327700/25046 (41%)]\tLoss: 0.110437\n",
            "Train epoch: 433 [652760/25046 (82%)]\tLoss: 0.136730\n",
            "Make prediction for 5010 samples...\n",
            "0.27329603 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 434 [0/25046 (0%)]\tLoss: 0.112224\n",
            "Train epoch: 434 [333640/25046 (41%)]\tLoss: 0.143237\n",
            "Train epoch: 434 [663960/25046 (82%)]\tLoss: 0.118119\n",
            "Make prediction for 5010 samples...\n",
            "0.25678366 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 435 [0/25046 (0%)]\tLoss: 0.126007\n",
            "Train epoch: 435 [328620/25046 (41%)]\tLoss: 0.108624\n",
            "Train epoch: 435 [672400/25046 (82%)]\tLoss: 0.089542\n",
            "Make prediction for 5010 samples...\n",
            "0.26881585 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 436 [0/25046 (0%)]\tLoss: 0.108561\n",
            "Train epoch: 436 [328120/25046 (41%)]\tLoss: 0.135935\n",
            "Train epoch: 436 [660080/25046 (82%)]\tLoss: 0.106650\n",
            "Make prediction for 5010 samples...\n",
            "0.25770456 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 437 [0/25046 (0%)]\tLoss: 0.130346\n",
            "Train epoch: 437 [327260/25046 (41%)]\tLoss: 0.106545\n",
            "Train epoch: 437 [660200/25046 (82%)]\tLoss: 0.119367\n",
            "Make prediction for 5010 samples...\n",
            "0.260421 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 438 [0/25046 (0%)]\tLoss: 0.081576\n",
            "Train epoch: 438 [329460/25046 (41%)]\tLoss: 0.125661\n",
            "Train epoch: 438 [661520/25046 (82%)]\tLoss: 0.124518\n",
            "Make prediction for 5010 samples...\n",
            "0.26689065 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 439 [0/25046 (0%)]\tLoss: 0.100498\n",
            "Train epoch: 439 [327340/25046 (41%)]\tLoss: 0.115088\n",
            "Train epoch: 439 [665880/25046 (82%)]\tLoss: 0.138773\n",
            "Make prediction for 5010 samples...\n",
            "0.26426157 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 440 [0/25046 (0%)]\tLoss: 0.090303\n",
            "Train epoch: 440 [324320/25046 (41%)]\tLoss: 0.105961\n",
            "Train epoch: 440 [658240/25046 (82%)]\tLoss: 0.155114\n",
            "Make prediction for 5010 samples...\n",
            "0.31945238 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 441 [0/25046 (0%)]\tLoss: 0.169411\n",
            "Train epoch: 441 [330260/25046 (41%)]\tLoss: 0.143229\n",
            "Train epoch: 441 [655760/25046 (82%)]\tLoss: 0.119929\n",
            "Make prediction for 5010 samples...\n",
            "0.26874307 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 442 [0/25046 (0%)]\tLoss: 0.064948\n",
            "Train epoch: 442 [319700/25046 (41%)]\tLoss: 0.127783\n",
            "Train epoch: 442 [654520/25046 (82%)]\tLoss: 0.135920\n",
            "Make prediction for 5010 samples...\n",
            "0.27241793 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 443 [0/25046 (0%)]\tLoss: 0.159015\n",
            "Train epoch: 443 [325940/25046 (41%)]\tLoss: 0.166980\n",
            "Train epoch: 443 [650960/25046 (82%)]\tLoss: 0.087554\n",
            "Make prediction for 5010 samples...\n",
            "0.26871938 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 444 [0/25046 (0%)]\tLoss: 0.108514\n",
            "Train epoch: 444 [327240/25046 (41%)]\tLoss: 0.089191\n",
            "Train epoch: 444 [672200/25046 (82%)]\tLoss: 0.099914\n",
            "Make prediction for 5010 samples...\n",
            "0.304056 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 445 [0/25046 (0%)]\tLoss: 0.147910\n",
            "Train epoch: 445 [331540/25046 (41%)]\tLoss: 0.135782\n",
            "Train epoch: 445 [659280/25046 (82%)]\tLoss: 0.112623\n",
            "Make prediction for 5010 samples...\n",
            "0.2682383 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 446 [0/25046 (0%)]\tLoss: 0.113400\n",
            "Train epoch: 446 [327720/25046 (41%)]\tLoss: 0.082554\n",
            "Train epoch: 446 [650920/25046 (82%)]\tLoss: 0.109631\n",
            "Make prediction for 5010 samples...\n",
            "0.29482675 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 447 [0/25046 (0%)]\tLoss: 0.116328\n",
            "Train epoch: 447 [328580/25046 (41%)]\tLoss: 0.086788\n",
            "Train epoch: 447 [645440/25046 (82%)]\tLoss: 0.097946\n",
            "Make prediction for 5010 samples...\n",
            "0.25692126 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 448 [0/25046 (0%)]\tLoss: 0.109965\n",
            "Train epoch: 448 [328380/25046 (41%)]\tLoss: 0.093901\n",
            "Train epoch: 448 [646360/25046 (82%)]\tLoss: 0.105853\n",
            "Make prediction for 5010 samples...\n",
            "0.26378047 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 449 [0/25046 (0%)]\tLoss: 0.098199\n",
            "Train epoch: 449 [326800/25046 (41%)]\tLoss: 0.119301\n",
            "Train epoch: 449 [654200/25046 (82%)]\tLoss: 0.134916\n",
            "Make prediction for 5010 samples...\n",
            "0.32807812 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 450 [0/25046 (0%)]\tLoss: 0.137507\n",
            "Train epoch: 450 [329200/25046 (41%)]\tLoss: 0.154900\n",
            "Train epoch: 450 [651160/25046 (82%)]\tLoss: 0.180815\n",
            "Make prediction for 5010 samples...\n",
            "0.27563784 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 451 [0/25046 (0%)]\tLoss: 0.136724\n",
            "Train epoch: 451 [324940/25046 (41%)]\tLoss: 0.119922\n",
            "Train epoch: 451 [657040/25046 (82%)]\tLoss: 0.121068\n",
            "Make prediction for 5010 samples...\n",
            "0.26589027 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 452 [0/25046 (0%)]\tLoss: 0.106815\n",
            "Train epoch: 452 [330660/25046 (41%)]\tLoss: 0.095357\n",
            "Train epoch: 452 [653480/25046 (82%)]\tLoss: 0.101268\n",
            "Make prediction for 5010 samples...\n",
            "0.26893145 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 453 [0/25046 (0%)]\tLoss: 0.118217\n",
            "Train epoch: 453 [328780/25046 (41%)]\tLoss: 0.127029\n",
            "Train epoch: 453 [650720/25046 (82%)]\tLoss: 0.136005\n",
            "Make prediction for 5010 samples...\n",
            "0.265672 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 454 [0/25046 (0%)]\tLoss: 0.128166\n",
            "Train epoch: 454 [331620/25046 (41%)]\tLoss: 0.120396\n",
            "Train epoch: 454 [662640/25046 (82%)]\tLoss: 0.109524\n",
            "Make prediction for 5010 samples...\n",
            "0.26572537 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 455 [0/25046 (0%)]\tLoss: 0.094716\n",
            "Train epoch: 455 [330640/25046 (41%)]\tLoss: 0.121453\n",
            "Train epoch: 455 [656480/25046 (82%)]\tLoss: 0.118782\n",
            "Make prediction for 5010 samples...\n",
            "0.26242223 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 456 [0/25046 (0%)]\tLoss: 0.094136\n",
            "Train epoch: 456 [326440/25046 (41%)]\tLoss: 0.111924\n",
            "Train epoch: 456 [661400/25046 (82%)]\tLoss: 0.103660\n",
            "Make prediction for 5010 samples...\n",
            "0.25739813 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 457 [0/25046 (0%)]\tLoss: 0.112648\n",
            "Train epoch: 457 [327040/25046 (41%)]\tLoss: 0.137240\n",
            "Train epoch: 457 [648560/25046 (82%)]\tLoss: 0.146452\n",
            "Make prediction for 5010 samples...\n",
            "0.2660543 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 458 [0/25046 (0%)]\tLoss: 0.090834\n",
            "Train epoch: 458 [329480/25046 (41%)]\tLoss: 0.102674\n",
            "Train epoch: 458 [656560/25046 (82%)]\tLoss: 0.093275\n",
            "Make prediction for 5010 samples...\n",
            "0.2678258 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 459 [0/25046 (0%)]\tLoss: 0.089753\n",
            "Train epoch: 459 [325560/25046 (41%)]\tLoss: 0.110913\n",
            "Train epoch: 459 [650920/25046 (82%)]\tLoss: 0.118997\n",
            "Make prediction for 5010 samples...\n",
            "0.25531268 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 460 [0/25046 (0%)]\tLoss: 0.089727\n",
            "Train epoch: 460 [323460/25046 (41%)]\tLoss: 0.102293\n",
            "Train epoch: 460 [661080/25046 (82%)]\tLoss: 0.086815\n",
            "Make prediction for 5010 samples...\n",
            "0.27347228 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 461 [0/25046 (0%)]\tLoss: 0.121408\n",
            "Train epoch: 461 [326800/25046 (41%)]\tLoss: 0.100544\n",
            "Train epoch: 461 [660240/25046 (82%)]\tLoss: 0.109523\n",
            "Make prediction for 5010 samples...\n",
            "0.2559238 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 462 [0/25046 (0%)]\tLoss: 0.093863\n",
            "Train epoch: 462 [326720/25046 (41%)]\tLoss: 0.102674\n",
            "Train epoch: 462 [651720/25046 (82%)]\tLoss: 0.098699\n",
            "Make prediction for 5010 samples...\n",
            "0.2856519 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 463 [0/25046 (0%)]\tLoss: 0.099369\n",
            "Train epoch: 463 [327960/25046 (41%)]\tLoss: 0.112030\n",
            "Train epoch: 463 [666000/25046 (82%)]\tLoss: 0.142709\n",
            "Make prediction for 5010 samples...\n",
            "0.25397667 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 464 [0/25046 (0%)]\tLoss: 0.113200\n",
            "Train epoch: 464 [330840/25046 (41%)]\tLoss: 0.095880\n",
            "Train epoch: 464 [650080/25046 (82%)]\tLoss: 0.106218\n",
            "Make prediction for 5010 samples...\n",
            "0.26141644 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 465 [0/25046 (0%)]\tLoss: 0.125896\n",
            "Train epoch: 465 [331840/25046 (41%)]\tLoss: 0.109219\n",
            "Train epoch: 465 [650520/25046 (82%)]\tLoss: 0.100576\n",
            "Make prediction for 5010 samples...\n",
            "0.27047536 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 466 [0/25046 (0%)]\tLoss: 0.098985\n",
            "Train epoch: 466 [330440/25046 (41%)]\tLoss: 0.157386\n",
            "Train epoch: 466 [659760/25046 (82%)]\tLoss: 0.136606\n",
            "Make prediction for 5010 samples...\n",
            "0.25344542 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 467 [0/25046 (0%)]\tLoss: 0.103928\n",
            "Train epoch: 467 [328340/25046 (41%)]\tLoss: 0.108212\n",
            "Train epoch: 467 [665480/25046 (82%)]\tLoss: 0.114451\n",
            "Make prediction for 5010 samples...\n",
            "0.25914636 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 468 [0/25046 (0%)]\tLoss: 0.121010\n",
            "Train epoch: 468 [332840/25046 (41%)]\tLoss: 0.120854\n",
            "Train epoch: 468 [658040/25046 (82%)]\tLoss: 0.125354\n",
            "Make prediction for 5010 samples...\n",
            "0.2572119 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 469 [0/25046 (0%)]\tLoss: 0.108206\n",
            "Train epoch: 469 [327660/25046 (41%)]\tLoss: 0.094479\n",
            "Train epoch: 469 [653480/25046 (82%)]\tLoss: 0.091796\n",
            "Make prediction for 5010 samples...\n",
            "0.26588205 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 470 [0/25046 (0%)]\tLoss: 0.074891\n",
            "Train epoch: 470 [328440/25046 (41%)]\tLoss: 0.106825\n",
            "Train epoch: 470 [661200/25046 (82%)]\tLoss: 0.144247\n",
            "Make prediction for 5010 samples...\n",
            "0.25672153 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 471 [0/25046 (0%)]\tLoss: 0.149681\n",
            "Train epoch: 471 [324800/25046 (41%)]\tLoss: 0.085565\n",
            "Train epoch: 471 [646600/25046 (82%)]\tLoss: 0.136226\n",
            "Make prediction for 5010 samples...\n",
            "0.25057787 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 472 [0/25046 (0%)]\tLoss: 0.099785\n",
            "Train epoch: 472 [329040/25046 (41%)]\tLoss: 0.088231\n",
            "Train epoch: 472 [657120/25046 (82%)]\tLoss: 0.150572\n",
            "Make prediction for 5010 samples...\n",
            "0.25921372 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 473 [0/25046 (0%)]\tLoss: 0.094863\n",
            "Train epoch: 473 [332820/25046 (41%)]\tLoss: 0.105851\n",
            "Train epoch: 473 [656480/25046 (82%)]\tLoss: 0.112987\n",
            "Make prediction for 5010 samples...\n",
            "0.25915134 No improvement since epoch  304 ; best_mse,best_ci: 0.24986151 0.8786355568699457 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 474 [0/25046 (0%)]\tLoss: 0.097195\n",
            "Train epoch: 474 [332180/25046 (41%)]\tLoss: 0.091407\n",
            "Train epoch: 474 [655440/25046 (82%)]\tLoss: 0.111683\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 475 [0/25046 (0%)]\tLoss: 0.095279\n",
            "Train epoch: 475 [327080/25046 (41%)]\tLoss: 0.111197\n",
            "Train epoch: 475 [652440/25046 (82%)]\tLoss: 0.111937\n",
            "Make prediction for 5010 samples...\n",
            "0.26522675 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 476 [0/25046 (0%)]\tLoss: 0.080809\n",
            "Train epoch: 476 [325280/25046 (41%)]\tLoss: 0.103450\n",
            "Train epoch: 476 [645840/25046 (82%)]\tLoss: 0.120897\n",
            "Make prediction for 5010 samples...\n",
            "0.26981708 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 477 [0/25046 (0%)]\tLoss: 0.098467\n",
            "Train epoch: 477 [328220/25046 (41%)]\tLoss: 0.074330\n",
            "Train epoch: 477 [658320/25046 (82%)]\tLoss: 0.143450\n",
            "Make prediction for 5010 samples...\n",
            "0.26531205 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 478 [0/25046 (0%)]\tLoss: 0.134985\n",
            "Train epoch: 478 [325220/25046 (41%)]\tLoss: 0.106983\n",
            "Train epoch: 478 [658200/25046 (82%)]\tLoss: 0.165739\n",
            "Make prediction for 5010 samples...\n",
            "0.2553093 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 479 [0/25046 (0%)]\tLoss: 0.091812\n",
            "Train epoch: 479 [328740/25046 (41%)]\tLoss: 0.091426\n",
            "Train epoch: 479 [673560/25046 (82%)]\tLoss: 0.099442\n",
            "Make prediction for 5010 samples...\n",
            "0.26186398 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 480 [0/25046 (0%)]\tLoss: 0.106225\n",
            "Train epoch: 480 [324740/25046 (41%)]\tLoss: 0.150211\n",
            "Train epoch: 480 [660680/25046 (82%)]\tLoss: 0.108674\n",
            "Make prediction for 5010 samples...\n",
            "0.26172253 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 481 [0/25046 (0%)]\tLoss: 0.101225\n",
            "Train epoch: 481 [324400/25046 (41%)]\tLoss: 0.109884\n",
            "Train epoch: 481 [652520/25046 (82%)]\tLoss: 0.099861\n",
            "Make prediction for 5010 samples...\n",
            "0.28498507 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 482 [0/25046 (0%)]\tLoss: 0.100611\n",
            "Train epoch: 482 [332260/25046 (41%)]\tLoss: 0.090002\n",
            "Train epoch: 482 [661560/25046 (82%)]\tLoss: 0.115872\n",
            "Make prediction for 5010 samples...\n",
            "0.27795702 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 483 [0/25046 (0%)]\tLoss: 0.136846\n",
            "Train epoch: 483 [329500/25046 (41%)]\tLoss: 0.114607\n",
            "Train epoch: 483 [663560/25046 (82%)]\tLoss: 0.085472\n",
            "Make prediction for 5010 samples...\n",
            "0.26768252 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 484 [0/25046 (0%)]\tLoss: 0.105867\n",
            "Train epoch: 484 [331680/25046 (41%)]\tLoss: 0.140292\n",
            "Train epoch: 484 [655480/25046 (82%)]\tLoss: 0.130969\n",
            "Make prediction for 5010 samples...\n",
            "0.27087393 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 485 [0/25046 (0%)]\tLoss: 0.108719\n",
            "Train epoch: 485 [328180/25046 (41%)]\tLoss: 0.097367\n",
            "Train epoch: 485 [665680/25046 (82%)]\tLoss: 0.102597\n",
            "Make prediction for 5010 samples...\n",
            "0.26828724 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 486 [0/25046 (0%)]\tLoss: 0.113344\n",
            "Train epoch: 486 [324660/25046 (41%)]\tLoss: 0.097063\n",
            "Train epoch: 486 [657280/25046 (82%)]\tLoss: 0.090259\n",
            "Make prediction for 5010 samples...\n",
            "0.253925 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 487 [0/25046 (0%)]\tLoss: 0.086269\n",
            "Train epoch: 487 [333560/25046 (41%)]\tLoss: 0.092732\n",
            "Train epoch: 487 [652680/25046 (82%)]\tLoss: 0.111127\n",
            "Make prediction for 5010 samples...\n",
            "0.25254506 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 488 [0/25046 (0%)]\tLoss: 0.102463\n",
            "Train epoch: 488 [330980/25046 (41%)]\tLoss: 0.097576\n",
            "Train epoch: 488 [658360/25046 (82%)]\tLoss: 0.090583\n",
            "Make prediction for 5010 samples...\n",
            "0.26377806 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 489 [0/25046 (0%)]\tLoss: 0.103022\n",
            "Train epoch: 489 [324180/25046 (41%)]\tLoss: 0.116862\n",
            "Train epoch: 489 [670360/25046 (82%)]\tLoss: 0.099325\n",
            "Make prediction for 5010 samples...\n",
            "0.28194198 No improvement since epoch  474 ; best_mse,best_ci: 0.24953513 0.8796214770869079 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 490 [0/25046 (0%)]\tLoss: 0.115804\n",
            "Train epoch: 490 [329240/25046 (41%)]\tLoss: 0.107018\n",
            "Train epoch: 490 [664640/25046 (82%)]\tLoss: 0.105316\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 491 [0/25046 (0%)]\tLoss: 0.112865\n",
            "Train epoch: 491 [330160/25046 (41%)]\tLoss: 0.107157\n",
            "Train epoch: 491 [661680/25046 (82%)]\tLoss: 0.087698\n",
            "Make prediction for 5010 samples...\n",
            "0.25194347 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 492 [0/25046 (0%)]\tLoss: 0.109094\n",
            "Train epoch: 492 [330300/25046 (41%)]\tLoss: 0.105494\n",
            "Train epoch: 492 [660040/25046 (82%)]\tLoss: 0.097891\n",
            "Make prediction for 5010 samples...\n",
            "0.26451108 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 493 [0/25046 (0%)]\tLoss: 0.127015\n",
            "Train epoch: 493 [325840/25046 (41%)]\tLoss: 0.122552\n",
            "Train epoch: 493 [657240/25046 (82%)]\tLoss: 0.094729\n",
            "Make prediction for 5010 samples...\n",
            "0.26482636 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 494 [0/25046 (0%)]\tLoss: 0.093011\n",
            "Train epoch: 494 [327800/25046 (41%)]\tLoss: 0.086955\n",
            "Train epoch: 494 [662400/25046 (82%)]\tLoss: 0.107474\n",
            "Make prediction for 5010 samples...\n",
            "0.26719257 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 495 [0/25046 (0%)]\tLoss: 0.103708\n",
            "Train epoch: 495 [329380/25046 (41%)]\tLoss: 0.098474\n",
            "Train epoch: 495 [656560/25046 (82%)]\tLoss: 0.102433\n",
            "Make prediction for 5010 samples...\n",
            "0.26212877 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 496 [0/25046 (0%)]\tLoss: 0.097102\n",
            "Train epoch: 496 [326000/25046 (41%)]\tLoss: 0.110015\n",
            "Train epoch: 496 [655640/25046 (82%)]\tLoss: 0.123505\n",
            "Make prediction for 5010 samples...\n",
            "0.3027801 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 497 [0/25046 (0%)]\tLoss: 0.120091\n",
            "Train epoch: 497 [325260/25046 (41%)]\tLoss: 0.129047\n",
            "Train epoch: 497 [654560/25046 (82%)]\tLoss: 0.107930\n",
            "Make prediction for 5010 samples...\n",
            "0.2558254 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 498 [0/25046 (0%)]\tLoss: 0.118168\n",
            "Train epoch: 498 [327880/25046 (41%)]\tLoss: 0.108191\n",
            "Train epoch: 498 [660160/25046 (82%)]\tLoss: 0.125294\n",
            "Make prediction for 5010 samples...\n",
            "0.2539269 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 499 [0/25046 (0%)]\tLoss: 0.106327\n",
            "Train epoch: 499 [326560/25046 (41%)]\tLoss: 0.113532\n",
            "Train epoch: 499 [658000/25046 (82%)]\tLoss: 0.113760\n",
            "Make prediction for 5010 samples...\n",
            "0.2618584 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 500 [0/25046 (0%)]\tLoss: 0.107446\n",
            "Train epoch: 500 [327160/25046 (41%)]\tLoss: 0.125680\n",
            "Train epoch: 500 [662040/25046 (82%)]\tLoss: 0.121549\n",
            "Make prediction for 5010 samples...\n",
            "0.2567129 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 501 [0/25046 (0%)]\tLoss: 0.122330\n",
            "Train epoch: 501 [327820/25046 (41%)]\tLoss: 0.087442\n",
            "Train epoch: 501 [648600/25046 (82%)]\tLoss: 0.075256\n",
            "Make prediction for 5010 samples...\n",
            "0.27059966 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 502 [0/25046 (0%)]\tLoss: 0.103019\n",
            "Train epoch: 502 [330220/25046 (41%)]\tLoss: 0.094993\n",
            "Train epoch: 502 [657880/25046 (82%)]\tLoss: 0.096631\n",
            "Make prediction for 5010 samples...\n",
            "0.29804853 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 503 [0/25046 (0%)]\tLoss: 0.134552\n",
            "Train epoch: 503 [331660/25046 (41%)]\tLoss: 0.108114\n",
            "Train epoch: 503 [658480/25046 (82%)]\tLoss: 0.090252\n",
            "Make prediction for 5010 samples...\n",
            "0.30385685 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 504 [0/25046 (0%)]\tLoss: 0.132733\n",
            "Train epoch: 504 [327420/25046 (41%)]\tLoss: 0.108485\n",
            "Train epoch: 504 [662360/25046 (82%)]\tLoss: 0.103800\n",
            "Make prediction for 5010 samples...\n",
            "0.26655376 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 505 [0/25046 (0%)]\tLoss: 0.085618\n",
            "Train epoch: 505 [328500/25046 (41%)]\tLoss: 0.099415\n",
            "Train epoch: 505 [661680/25046 (82%)]\tLoss: 0.129228\n",
            "Make prediction for 5010 samples...\n",
            "0.26531267 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 506 [0/25046 (0%)]\tLoss: 0.113287\n",
            "Train epoch: 506 [327920/25046 (41%)]\tLoss: 0.127266\n",
            "Train epoch: 506 [657280/25046 (82%)]\tLoss: 0.115697\n",
            "Make prediction for 5010 samples...\n",
            "0.25703692 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 507 [0/25046 (0%)]\tLoss: 0.098991\n",
            "Train epoch: 507 [332300/25046 (41%)]\tLoss: 0.087229\n",
            "Train epoch: 507 [644200/25046 (82%)]\tLoss: 0.133972\n",
            "Make prediction for 5010 samples...\n",
            "0.2667006 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 508 [0/25046 (0%)]\tLoss: 0.086560\n",
            "Train epoch: 508 [326660/25046 (41%)]\tLoss: 0.084114\n",
            "Train epoch: 508 [655920/25046 (82%)]\tLoss: 0.102234\n",
            "Make prediction for 5010 samples...\n",
            "0.25930336 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 509 [0/25046 (0%)]\tLoss: 0.099046\n",
            "Train epoch: 509 [325140/25046 (41%)]\tLoss: 0.110420\n",
            "Train epoch: 509 [659760/25046 (82%)]\tLoss: 0.114110\n",
            "Make prediction for 5010 samples...\n",
            "0.26929867 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 510 [0/25046 (0%)]\tLoss: 0.127609\n",
            "Train epoch: 510 [327280/25046 (41%)]\tLoss: 0.107707\n",
            "Train epoch: 510 [660160/25046 (82%)]\tLoss: 0.107225\n",
            "Make prediction for 5010 samples...\n",
            "0.27198103 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 511 [0/25046 (0%)]\tLoss: 0.097153\n",
            "Train epoch: 511 [333160/25046 (41%)]\tLoss: 0.108337\n",
            "Train epoch: 511 [656120/25046 (82%)]\tLoss: 0.120775\n",
            "Make prediction for 5010 samples...\n",
            "0.24924852 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 512 [0/25046 (0%)]\tLoss: 0.104779\n",
            "Train epoch: 512 [332440/25046 (41%)]\tLoss: 0.103506\n",
            "Train epoch: 512 [667720/25046 (82%)]\tLoss: 0.097680\n",
            "Make prediction for 5010 samples...\n",
            "0.27324823 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 513 [0/25046 (0%)]\tLoss: 0.108752\n",
            "Train epoch: 513 [326000/25046 (41%)]\tLoss: 0.092974\n",
            "Train epoch: 513 [652680/25046 (82%)]\tLoss: 0.128692\n",
            "Make prediction for 5010 samples...\n",
            "0.30110052 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 514 [0/25046 (0%)]\tLoss: 0.197412\n",
            "Train epoch: 514 [330620/25046 (41%)]\tLoss: 0.125783\n",
            "Train epoch: 514 [660520/25046 (82%)]\tLoss: 0.142500\n",
            "Make prediction for 5010 samples...\n",
            "0.3137411 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 515 [0/25046 (0%)]\tLoss: 0.125317\n",
            "Train epoch: 515 [328460/25046 (41%)]\tLoss: 0.111395\n",
            "Train epoch: 515 [656400/25046 (82%)]\tLoss: 0.088549\n",
            "Make prediction for 5010 samples...\n",
            "0.27826148 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 516 [0/25046 (0%)]\tLoss: 0.099846\n",
            "Train epoch: 516 [330620/25046 (41%)]\tLoss: 0.104322\n",
            "Train epoch: 516 [653160/25046 (82%)]\tLoss: 0.121180\n",
            "Make prediction for 5010 samples...\n",
            "0.254981 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 517 [0/25046 (0%)]\tLoss: 0.090418\n",
            "Train epoch: 517 [328400/25046 (41%)]\tLoss: 0.107131\n",
            "Train epoch: 517 [651560/25046 (82%)]\tLoss: 0.100880\n",
            "Make prediction for 5010 samples...\n",
            "0.2590903 No improvement since epoch  490 ; best_mse,best_ci: 0.24909726 0.8766682344393456 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 518 [0/25046 (0%)]\tLoss: 0.087363\n",
            "Train epoch: 518 [332220/25046 (41%)]\tLoss: 0.108971\n",
            "Train epoch: 518 [658200/25046 (82%)]\tLoss: 0.106062\n",
            "Make prediction for 5010 samples...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphDTA-master/training.py\", line 94, in <module>\n",
            "    torch.save(model.state_dict(), model_file_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 440, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 315, in _open_zipfile_writer\n",
            "    return container(name_or_buffer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 288, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileWriter(str(name)))\n",
            "RuntimeError: File model_GAT_GATNet_davis.model cannot be opened.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA-TTZ19BeV3",
        "outputId": "0891d02a-7ff7-4a7f-9704-4df6489845f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate:  0.0005\n",
            "Epochs:  2\n",
            "\n",
            "running on  GAT_GATNet_davis\n",
            "Pre-processed data found: data/processed/davis_train.pt, loading ...\n",
            "Pre-processed data found: data/processed/davis_test.pt, loading ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on 25046 samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/scatter.py:93: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train epoch: 1 [0/25046 (0%)]\tLoss: 0.107014\n",
            "Train epoch: 1 [329680/25046 (41%)]\tLoss: 0.135768\n",
            "Train epoch: 1 [657720/25046 (82%)]\tLoss: 0.093029\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  1 ; best_mse,best_ci: 0.24873847 0.8773788627588337 GAT_GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 2 [0/25046 (0%)]\tLoss: 0.072308\n",
            "Train epoch: 2 [331360/25046 (41%)]\tLoss: 0.098862\n",
            "Train epoch: 2 [659080/25046 (82%)]\tLoss: 0.069238\n",
            "Make prediction for 5010 samples...\n",
            "0.2679761 No improvement since epoch  1 ; best_mse,best_ci: 0.24873847 0.8773788627588337 GAT_GATNet davis\n"
          ]
        }
      ],
      "source": [
        "dataset = 'davis'\n",
        "#kiba\n",
        "modeling = [GAT_GATNet]\n",
        "model_st = modeling[0].__name__\n",
        "\n",
        "cuda_name = \"cuda:0\"\n",
        "# if len(sys.argv)>3:\n",
        "#     cuda_name = \"cuda:\" + str(int(sys.argv[3]))\n",
        "# print('cuda_name:', cuda_name)\n",
        "\n",
        "TRAIN_BATCH_SIZE = 512\n",
        "TEST_BATCH_SIZE = 512\n",
        "LR = 0.0005\n",
        "LOG_INTERVAL = 20\n",
        "NUM_EPOCHS = 2\n",
        "\n",
        "print('Learning rate: ', LR)\n",
        "print('Epochs: ', NUM_EPOCHS)\n",
        "\n",
        "# Main program: iterate over different datasets\n",
        "# for dataset in dataset:\n",
        "print('\\nrunning on ', model_st + '_' + dataset )\n",
        "processed_data_file_train = 'data/processed/' + dataset + '_train.pt'\n",
        "processed_data_file_test = 'data/processed/' + dataset + '_test.pt'\n",
        "if ((not os.path.isfile(processed_data_file_train)) or \\\n",
        " (not os.path.isfile(processed_data_file_test))):\n",
        "    print('please run create_data.py to prepare data in pytorch format!')\n",
        "else:\n",
        "    train_data = TestbedDataset(root='data', dataset=dataset+'_train')\n",
        "    test_data = TestbedDataset(root='data', dataset=dataset+'_test')\n",
        "\n",
        "    # make data PyTorch mini-batch processing ready\n",
        "    train_loader = DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# training the model\n",
        "    device = torch.device(cuda_name if torch.cuda.is_available() else \"cpu\")\n",
        "    #model = modeling\n",
        "    for modeling in [GAT_GATNet]:\n",
        "      model = modeling().to(device)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    best_mse = 0.24929152\n",
        "    best_ci =  0.8811023101087032\n",
        "    best_epoch = 853\n",
        "    model_file_name = 'model_' + model_st + '_' + dataset +  '.model'\n",
        "    result_file_name = 'result_' + model_st + '_' + dataset +  '.csv'\n",
        "    model.load_state_dict(torch.\\\n",
        "    load('/content/drive/MyDrive/GraphDTA-master/model_GAT_GATNet_davis.model',\\\n",
        "         map_location=torch.device('cpu'))\n",
        "    )\n",
        "     #map_location=torch.device('cpu'))) # load the state_dict on CPU\n",
        "    # model.train()\n",
        "\n",
        "    mse_list = []\n",
        "    ci_list = []\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "      torch.cuda.empty_cache()\n",
        "      train(model, device, train_loader, optimizer, epoch+1)\n",
        "      G,P = predicting(model, device, test_loader)\n",
        "      ret = [rmse(G,P),mse(G,P),pearson(G,P),spearman(G,P),ci(G,P)]\n",
        "\n",
        "\n",
        "      mse_list.append(ret[1])\n",
        "      ci_list.append(ret[-1])\n",
        "      if ret[1]<best_mse:\n",
        "          torch.save(model.state_dict(), \\\n",
        "                '/content/drive/MyDrive/GraphDTA-master/model_GAT_GATNet_davis.model')\n",
        "          with open(result_file_name,'w') as f:\n",
        "              f.write(','.join(map(str,ret)))\n",
        "          best_epoch = epoch+1\n",
        "          best_mse = ret[1]\n",
        "          best_ci = ret[-1]\n",
        "\n",
        "\n",
        "          print('rmse improved at epoch ', best_epoch, '; best_mse,best_ci:',\\\n",
        "                best_mse,best_ci,model_st,dataset)\n",
        "\n",
        "      else:\n",
        "          print(ret[1],'No improvement since epoch ', best_epoch,\\\n",
        "                '; best_mse,best_ci:', best_mse,best_ci,model_st,dataset)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJN2dLKR8CGF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Nf4J2xrJ61o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}