{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rgo8cLB7Ayqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3c396b-f48f-4b11-b848-9bed5bd3aba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_Et0csGA4of",
        "outputId": "1c3ea176-305f-427f-fc4a-75f6c651d064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCJG-aZCA4lg",
        "outputId": "a6903033-5ec3-4385-a743-9e9e271737e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive  Othercomputers\n"
          ]
        }
      ],
      "source": [
        "!ls drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqBB0ST7A4i_",
        "outputId": "4e85e970-eb99-4683-f48f-1f5f053e2bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GraphDTA-new\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/GraphDTA-new'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xsOYH5eqLNn"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3b_OMfravpyX"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jYc3W8E4A4fw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab525486-82b0-402d-def4-4db1fa60ed32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/661.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/661.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=31ca22171ceac1ed2709d384d4f7049d6e87cac55c59bd68eb0e3c718c3eadc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I6H3tkEBMmf",
        "outputId": "7ae1bc61-c64a-4593-c4fb-7ad1b994b00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision numpy pandas scikit-learn tqdm matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SqX64FABMhW",
        "outputId": "7ac7001f-8392-4dc0-ef5b-d34a548af25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QwFW6ZtGBMdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea731822-a966-4194-da88-03de3018c152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/drive/MyDrive/GraphDTA-new/create_data.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q90AnsOn2XoA",
        "outputId": "c8d26223-d65c-4208-ff06-64ae713978ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Converting SMILES to graph: 14712/19709\n",
            "Converting SMILES to graph: 14713/19709\n",
            "Converting SMILES to graph: 14714/19709\n",
            "Converting SMILES to graph: 14715/19709\n",
            "Converting SMILES to graph: 14716/19709\n",
            "Converting SMILES to graph: 14717/19709\n",
            "Converting SMILES to graph: 14718/19709\n",
            "Converting SMILES to graph: 14719/19709\n",
            "Converting SMILES to graph: 14720/19709\n",
            "Converting SMILES to graph: 14721/19709\n",
            "Converting SMILES to graph: 14722/19709\n",
            "Converting SMILES to graph: 14723/19709\n",
            "Converting SMILES to graph: 14724/19709\n",
            "Converting SMILES to graph: 14725/19709\n",
            "Converting SMILES to graph: 14726/19709\n",
            "Converting SMILES to graph: 14727/19709\n",
            "Converting SMILES to graph: 14728/19709\n",
            "Converting SMILES to graph: 14729/19709\n",
            "Converting SMILES to graph: 14730/19709\n",
            "Converting SMILES to graph: 14731/19709\n",
            "Converting SMILES to graph: 14732/19709\n",
            "Converting SMILES to graph: 14733/19709\n",
            "Converting SMILES to graph: 14734/19709\n",
            "Converting SMILES to graph: 14735/19709\n",
            "Converting SMILES to graph: 14736/19709\n",
            "Converting SMILES to graph: 14737/19709\n",
            "Converting SMILES to graph: 14738/19709\n",
            "Converting SMILES to graph: 14739/19709\n",
            "Converting SMILES to graph: 14740/19709\n",
            "Converting SMILES to graph: 14741/19709\n",
            "Converting SMILES to graph: 14742/19709\n",
            "Converting SMILES to graph: 14743/19709\n",
            "Converting SMILES to graph: 14744/19709\n",
            "Converting SMILES to graph: 14745/19709\n",
            "Converting SMILES to graph: 14746/19709\n",
            "Converting SMILES to graph: 14747/19709\n",
            "Converting SMILES to graph: 14748/19709\n",
            "Converting SMILES to graph: 14749/19709\n",
            "Converting SMILES to graph: 14750/19709\n",
            "Converting SMILES to graph: 14751/19709\n",
            "Converting SMILES to graph: 14752/19709\n",
            "Converting SMILES to graph: 14753/19709\n",
            "Converting SMILES to graph: 14754/19709\n",
            "Converting SMILES to graph: 14755/19709\n",
            "Converting SMILES to graph: 14756/19709\n",
            "Converting SMILES to graph: 14757/19709\n",
            "Converting SMILES to graph: 14758/19709\n",
            "Converting SMILES to graph: 14759/19709\n",
            "Converting SMILES to graph: 14760/19709\n",
            "Converting SMILES to graph: 14761/19709\n",
            "Converting SMILES to graph: 14762/19709\n",
            "Converting SMILES to graph: 14763/19709\n",
            "Converting SMILES to graph: 14764/19709\n",
            "Converting SMILES to graph: 14765/19709\n",
            "Converting SMILES to graph: 14766/19709\n",
            "Converting SMILES to graph: 14767/19709\n",
            "Converting SMILES to graph: 14768/19709\n",
            "Converting SMILES to graph: 14769/19709\n",
            "Converting SMILES to graph: 14770/19709\n",
            "Converting SMILES to graph: 14771/19709\n",
            "Converting SMILES to graph: 14772/19709\n",
            "Converting SMILES to graph: 14773/19709\n",
            "Converting SMILES to graph: 14774/19709\n",
            "Converting SMILES to graph: 14775/19709\n",
            "Converting SMILES to graph: 14776/19709\n",
            "Converting SMILES to graph: 14777/19709\n",
            "Converting SMILES to graph: 14778/19709\n",
            "Converting SMILES to graph: 14779/19709\n",
            "Converting SMILES to graph: 14780/19709\n",
            "Converting SMILES to graph: 14781/19709\n",
            "Converting SMILES to graph: 14782/19709\n",
            "Converting SMILES to graph: 14783/19709\n",
            "Converting SMILES to graph: 14784/19709\n",
            "Converting SMILES to graph: 14785/19709\n",
            "Converting SMILES to graph: 14786/19709\n",
            "Converting SMILES to graph: 14787/19709\n",
            "Converting SMILES to graph: 14788/19709\n",
            "Converting SMILES to graph: 14789/19709\n",
            "Converting SMILES to graph: 14790/19709\n",
            "Converting SMILES to graph: 14791/19709\n",
            "Converting SMILES to graph: 14792/19709\n",
            "Converting SMILES to graph: 14793/19709\n",
            "Converting SMILES to graph: 14794/19709\n",
            "Converting SMILES to graph: 14795/19709\n",
            "Converting SMILES to graph: 14796/19709\n",
            "Converting SMILES to graph: 14797/19709\n",
            "Converting SMILES to graph: 14798/19709\n",
            "Converting SMILES to graph: 14799/19709\n",
            "Converting SMILES to graph: 14800/19709\n",
            "Converting SMILES to graph: 14801/19709\n",
            "Converting SMILES to graph: 14802/19709\n",
            "Converting SMILES to graph: 14803/19709\n",
            "Converting SMILES to graph: 14804/19709\n",
            "Converting SMILES to graph: 14805/19709\n",
            "Converting SMILES to graph: 14806/19709\n",
            "Converting SMILES to graph: 14807/19709\n",
            "Converting SMILES to graph: 14808/19709\n",
            "Converting SMILES to graph: 14809/19709\n",
            "Converting SMILES to graph: 14810/19709\n",
            "Converting SMILES to graph: 14811/19709\n",
            "Converting SMILES to graph: 14812/19709\n",
            "Converting SMILES to graph: 14813/19709\n",
            "Converting SMILES to graph: 14814/19709\n",
            "Converting SMILES to graph: 14815/19709\n",
            "Converting SMILES to graph: 14816/19709\n",
            "Converting SMILES to graph: 14817/19709\n",
            "Converting SMILES to graph: 14818/19709\n",
            "Converting SMILES to graph: 14819/19709\n",
            "Converting SMILES to graph: 14820/19709\n",
            "Converting SMILES to graph: 14821/19709\n",
            "Converting SMILES to graph: 14822/19709\n",
            "Converting SMILES to graph: 14823/19709\n",
            "Converting SMILES to graph: 14824/19709\n",
            "Converting SMILES to graph: 14825/19709\n",
            "Converting SMILES to graph: 14826/19709\n",
            "Converting SMILES to graph: 14827/19709\n",
            "Converting SMILES to graph: 14828/19709\n",
            "Converting SMILES to graph: 14829/19709\n",
            "Converting SMILES to graph: 14830/19709\n",
            "Converting SMILES to graph: 14831/19709\n",
            "Converting SMILES to graph: 14832/19709\n",
            "Converting SMILES to graph: 14833/19709\n",
            "Converting SMILES to graph: 14834/19709\n",
            "Converting SMILES to graph: 14835/19709\n",
            "Converting SMILES to graph: 14836/19709\n",
            "Converting SMILES to graph: 14837/19709\n",
            "Converting SMILES to graph: 14838/19709\n",
            "Converting SMILES to graph: 14839/19709\n",
            "Converting SMILES to graph: 14840/19709\n",
            "Converting SMILES to graph: 14841/19709\n",
            "Converting SMILES to graph: 14842/19709\n",
            "Converting SMILES to graph: 14843/19709\n",
            "Converting SMILES to graph: 14844/19709\n",
            "Converting SMILES to graph: 14845/19709\n",
            "Converting SMILES to graph: 14846/19709\n",
            "Converting SMILES to graph: 14847/19709\n",
            "Converting SMILES to graph: 14848/19709\n",
            "Converting SMILES to graph: 14849/19709\n",
            "Converting SMILES to graph: 14850/19709\n",
            "Converting SMILES to graph: 14851/19709\n",
            "Converting SMILES to graph: 14852/19709\n",
            "Converting SMILES to graph: 14853/19709\n",
            "Converting SMILES to graph: 14854/19709\n",
            "Converting SMILES to graph: 14855/19709\n",
            "Converting SMILES to graph: 14856/19709\n",
            "Converting SMILES to graph: 14857/19709\n",
            "Converting SMILES to graph: 14858/19709\n",
            "Converting SMILES to graph: 14859/19709\n",
            "Converting SMILES to graph: 14860/19709\n",
            "Converting SMILES to graph: 14861/19709\n",
            "Converting SMILES to graph: 14862/19709\n",
            "Converting SMILES to graph: 14863/19709\n",
            "Converting SMILES to graph: 14864/19709\n",
            "Converting SMILES to graph: 14865/19709\n",
            "Converting SMILES to graph: 14866/19709\n",
            "Converting SMILES to graph: 14867/19709\n",
            "Converting SMILES to graph: 14868/19709\n",
            "Converting SMILES to graph: 14869/19709\n",
            "Converting SMILES to graph: 14870/19709\n",
            "Converting SMILES to graph: 14871/19709\n",
            "Converting SMILES to graph: 14872/19709\n",
            "Converting SMILES to graph: 14873/19709\n",
            "Converting SMILES to graph: 14874/19709\n",
            "Converting SMILES to graph: 14875/19709\n",
            "Converting SMILES to graph: 14876/19709\n",
            "Converting SMILES to graph: 14877/19709\n",
            "Converting SMILES to graph: 14878/19709\n",
            "Converting SMILES to graph: 14879/19709\n",
            "Converting SMILES to graph: 14880/19709\n",
            "Converting SMILES to graph: 14881/19709\n",
            "Converting SMILES to graph: 14882/19709\n",
            "Converting SMILES to graph: 14883/19709\n",
            "Converting SMILES to graph: 14884/19709\n",
            "Converting SMILES to graph: 14885/19709\n",
            "Converting SMILES to graph: 14886/19709\n",
            "Converting SMILES to graph: 14887/19709\n",
            "Converting SMILES to graph: 14888/19709\n",
            "Converting SMILES to graph: 14889/19709\n",
            "Converting SMILES to graph: 14890/19709\n",
            "Converting SMILES to graph: 14891/19709\n",
            "Converting SMILES to graph: 14892/19709\n",
            "Converting SMILES to graph: 14893/19709\n",
            "Converting SMILES to graph: 14894/19709\n",
            "Converting SMILES to graph: 14895/19709\n",
            "Converting SMILES to graph: 14896/19709\n",
            "Converting SMILES to graph: 14897/19709\n",
            "Converting SMILES to graph: 14898/19709\n",
            "Converting SMILES to graph: 14899/19709\n",
            "Converting SMILES to graph: 14900/19709\n",
            "Converting SMILES to graph: 14901/19709\n",
            "Converting SMILES to graph: 14902/19709\n",
            "Converting SMILES to graph: 14903/19709\n",
            "Converting SMILES to graph: 14904/19709\n",
            "Converting SMILES to graph: 14905/19709\n",
            "Converting SMILES to graph: 14906/19709\n",
            "Converting SMILES to graph: 14907/19709\n",
            "Converting SMILES to graph: 14908/19709\n",
            "Converting SMILES to graph: 14909/19709\n",
            "Converting SMILES to graph: 14910/19709\n",
            "Converting SMILES to graph: 14911/19709\n",
            "Converting SMILES to graph: 14912/19709\n",
            "Converting SMILES to graph: 14913/19709\n",
            "Converting SMILES to graph: 14914/19709\n",
            "Converting SMILES to graph: 14915/19709\n",
            "Converting SMILES to graph: 14916/19709\n",
            "Converting SMILES to graph: 14917/19709\n",
            "Converting SMILES to graph: 14918/19709\n",
            "Converting SMILES to graph: 14919/19709\n",
            "Converting SMILES to graph: 14920/19709\n",
            "Converting SMILES to graph: 14921/19709\n",
            "Converting SMILES to graph: 14922/19709\n",
            "Converting SMILES to graph: 14923/19709\n",
            "Converting SMILES to graph: 14924/19709\n",
            "Converting SMILES to graph: 14925/19709\n",
            "Converting SMILES to graph: 14926/19709\n",
            "Converting SMILES to graph: 14927/19709\n",
            "Converting SMILES to graph: 14928/19709\n",
            "Converting SMILES to graph: 14929/19709\n",
            "Converting SMILES to graph: 14930/19709\n",
            "Converting SMILES to graph: 14931/19709\n",
            "Converting SMILES to graph: 14932/19709\n",
            "Converting SMILES to graph: 14933/19709\n",
            "Converting SMILES to graph: 14934/19709\n",
            "Converting SMILES to graph: 14935/19709\n",
            "Converting SMILES to graph: 14936/19709\n",
            "Converting SMILES to graph: 14937/19709\n",
            "Converting SMILES to graph: 14938/19709\n",
            "Converting SMILES to graph: 14939/19709\n",
            "Converting SMILES to graph: 14940/19709\n",
            "Converting SMILES to graph: 14941/19709\n",
            "Converting SMILES to graph: 14942/19709\n",
            "Converting SMILES to graph: 14943/19709\n",
            "Converting SMILES to graph: 14944/19709\n",
            "Converting SMILES to graph: 14945/19709\n",
            "Converting SMILES to graph: 14946/19709\n",
            "Converting SMILES to graph: 14947/19709\n",
            "Converting SMILES to graph: 14948/19709\n",
            "Converting SMILES to graph: 14949/19709\n",
            "Converting SMILES to graph: 14950/19709\n",
            "Converting SMILES to graph: 14951/19709\n",
            "Converting SMILES to graph: 14952/19709\n",
            "Converting SMILES to graph: 14953/19709\n",
            "Converting SMILES to graph: 14954/19709\n",
            "Converting SMILES to graph: 14955/19709\n",
            "Converting SMILES to graph: 14956/19709\n",
            "Converting SMILES to graph: 14957/19709\n",
            "Converting SMILES to graph: 14958/19709\n",
            "Converting SMILES to graph: 14959/19709\n",
            "Converting SMILES to graph: 14960/19709\n",
            "Converting SMILES to graph: 14961/19709\n",
            "Converting SMILES to graph: 14962/19709\n",
            "Converting SMILES to graph: 14963/19709\n",
            "Converting SMILES to graph: 14964/19709\n",
            "Converting SMILES to graph: 14965/19709\n",
            "Converting SMILES to graph: 14966/19709\n",
            "Converting SMILES to graph: 14967/19709\n",
            "Converting SMILES to graph: 14968/19709\n",
            "Converting SMILES to graph: 14969/19709\n",
            "Converting SMILES to graph: 14970/19709\n",
            "Converting SMILES to graph: 14971/19709\n",
            "Converting SMILES to graph: 14972/19709\n",
            "Converting SMILES to graph: 14973/19709\n",
            "Converting SMILES to graph: 14974/19709\n",
            "Converting SMILES to graph: 14975/19709\n",
            "Converting SMILES to graph: 14976/19709\n",
            "Converting SMILES to graph: 14977/19709\n",
            "Converting SMILES to graph: 14978/19709\n",
            "Converting SMILES to graph: 14979/19709\n",
            "Converting SMILES to graph: 14980/19709\n",
            "Converting SMILES to graph: 14981/19709\n",
            "Converting SMILES to graph: 14982/19709\n",
            "Converting SMILES to graph: 14983/19709\n",
            "Converting SMILES to graph: 14984/19709\n",
            "Converting SMILES to graph: 14985/19709\n",
            "Converting SMILES to graph: 14986/19709\n",
            "Converting SMILES to graph: 14987/19709\n",
            "Converting SMILES to graph: 14988/19709\n",
            "Converting SMILES to graph: 14989/19709\n",
            "Converting SMILES to graph: 14990/19709\n",
            "Converting SMILES to graph: 14991/19709\n",
            "Converting SMILES to graph: 14992/19709\n",
            "Converting SMILES to graph: 14993/19709\n",
            "Converting SMILES to graph: 14994/19709\n",
            "Converting SMILES to graph: 14995/19709\n",
            "Converting SMILES to graph: 14996/19709\n",
            "Converting SMILES to graph: 14997/19709\n",
            "Converting SMILES to graph: 14998/19709\n",
            "Converting SMILES to graph: 14999/19709\n",
            "Converting SMILES to graph: 15000/19709\n",
            "Converting SMILES to graph: 15001/19709\n",
            "Converting SMILES to graph: 15002/19709\n",
            "Converting SMILES to graph: 15003/19709\n",
            "Converting SMILES to graph: 15004/19709\n",
            "Converting SMILES to graph: 15005/19709\n",
            "Converting SMILES to graph: 15006/19709\n",
            "Converting SMILES to graph: 15007/19709\n",
            "Converting SMILES to graph: 15008/19709\n",
            "Converting SMILES to graph: 15009/19709\n",
            "Converting SMILES to graph: 15010/19709\n",
            "Converting SMILES to graph: 15011/19709\n",
            "Converting SMILES to graph: 15012/19709\n",
            "Converting SMILES to graph: 15013/19709\n",
            "Converting SMILES to graph: 15014/19709\n",
            "Converting SMILES to graph: 15015/19709\n",
            "Converting SMILES to graph: 15016/19709\n",
            "Converting SMILES to graph: 15017/19709\n",
            "Converting SMILES to graph: 15018/19709\n",
            "Converting SMILES to graph: 15019/19709\n",
            "Converting SMILES to graph: 15020/19709\n",
            "Converting SMILES to graph: 15021/19709\n",
            "Converting SMILES to graph: 15022/19709\n",
            "Converting SMILES to graph: 15023/19709\n",
            "Converting SMILES to graph: 15024/19709\n",
            "Converting SMILES to graph: 15025/19709\n",
            "Converting SMILES to graph: 15026/19709\n",
            "Converting SMILES to graph: 15027/19709\n",
            "Converting SMILES to graph: 15028/19709\n",
            "Converting SMILES to graph: 15029/19709\n",
            "Converting SMILES to graph: 15030/19709\n",
            "Converting SMILES to graph: 15031/19709\n",
            "Converting SMILES to graph: 15032/19709\n",
            "Converting SMILES to graph: 15033/19709\n",
            "Converting SMILES to graph: 15034/19709\n",
            "Converting SMILES to graph: 15035/19709\n",
            "Converting SMILES to graph: 15036/19709\n",
            "Converting SMILES to graph: 15037/19709\n",
            "Converting SMILES to graph: 15038/19709\n",
            "Converting SMILES to graph: 15039/19709\n",
            "Converting SMILES to graph: 15040/19709\n",
            "Converting SMILES to graph: 15041/19709\n",
            "Converting SMILES to graph: 15042/19709\n",
            "Converting SMILES to graph: 15043/19709\n",
            "Converting SMILES to graph: 15044/19709\n",
            "Converting SMILES to graph: 15045/19709\n",
            "Converting SMILES to graph: 15046/19709\n",
            "Converting SMILES to graph: 15047/19709\n",
            "Converting SMILES to graph: 15048/19709\n",
            "Converting SMILES to graph: 15049/19709\n",
            "Converting SMILES to graph: 15050/19709\n",
            "Converting SMILES to graph: 15051/19709\n",
            "Converting SMILES to graph: 15052/19709\n",
            "Converting SMILES to graph: 15053/19709\n",
            "Converting SMILES to graph: 15054/19709\n",
            "Converting SMILES to graph: 15055/19709\n",
            "Converting SMILES to graph: 15056/19709\n",
            "Converting SMILES to graph: 15057/19709\n",
            "Converting SMILES to graph: 15058/19709\n",
            "Converting SMILES to graph: 15059/19709\n",
            "Converting SMILES to graph: 15060/19709\n",
            "Converting SMILES to graph: 15061/19709\n",
            "Converting SMILES to graph: 15062/19709\n",
            "Converting SMILES to graph: 15063/19709\n",
            "Converting SMILES to graph: 15064/19709\n",
            "Converting SMILES to graph: 15065/19709\n",
            "Converting SMILES to graph: 15066/19709\n",
            "Converting SMILES to graph: 15067/19709\n",
            "Converting SMILES to graph: 15068/19709\n",
            "Converting SMILES to graph: 15069/19709\n",
            "Converting SMILES to graph: 15070/19709\n",
            "Converting SMILES to graph: 15071/19709\n",
            "Converting SMILES to graph: 15072/19709\n",
            "Converting SMILES to graph: 15073/19709\n",
            "Converting SMILES to graph: 15074/19709\n",
            "Converting SMILES to graph: 15075/19709\n",
            "Converting SMILES to graph: 15076/19709\n",
            "Converting SMILES to graph: 15077/19709\n",
            "Converting SMILES to graph: 15078/19709\n",
            "Converting SMILES to graph: 15079/19709\n",
            "Converting SMILES to graph: 15080/19709\n",
            "Converting SMILES to graph: 15081/19709\n",
            "Converting SMILES to graph: 15082/19709\n",
            "Converting SMILES to graph: 15083/19709\n",
            "Converting SMILES to graph: 15084/19709\n",
            "Converting SMILES to graph: 15085/19709\n",
            "Converting SMILES to graph: 15086/19709\n",
            "Converting SMILES to graph: 15087/19709\n",
            "Converting SMILES to graph: 15088/19709\n",
            "Converting SMILES to graph: 15089/19709\n",
            "Converting SMILES to graph: 15090/19709\n",
            "Converting SMILES to graph: 15091/19709\n",
            "Converting SMILES to graph: 15092/19709\n",
            "Converting SMILES to graph: 15093/19709\n",
            "Converting SMILES to graph: 15094/19709\n",
            "Converting SMILES to graph: 15095/19709\n",
            "Converting SMILES to graph: 15096/19709\n",
            "Converting SMILES to graph: 15097/19709\n",
            "Converting SMILES to graph: 15098/19709\n",
            "Converting SMILES to graph: 15099/19709\n",
            "Converting SMILES to graph: 15100/19709\n",
            "Converting SMILES to graph: 15101/19709\n",
            "Converting SMILES to graph: 15102/19709\n",
            "Converting SMILES to graph: 15103/19709\n",
            "Converting SMILES to graph: 15104/19709\n",
            "Converting SMILES to graph: 15105/19709\n",
            "Converting SMILES to graph: 15106/19709\n",
            "Converting SMILES to graph: 15107/19709\n",
            "Converting SMILES to graph: 15108/19709\n",
            "Converting SMILES to graph: 15109/19709\n",
            "Converting SMILES to graph: 15110/19709\n",
            "Converting SMILES to graph: 15111/19709\n",
            "Converting SMILES to graph: 15112/19709\n",
            "Converting SMILES to graph: 15113/19709\n",
            "Converting SMILES to graph: 15114/19709\n",
            "Converting SMILES to graph: 15115/19709\n",
            "Converting SMILES to graph: 15116/19709\n",
            "Converting SMILES to graph: 15117/19709\n",
            "Converting SMILES to graph: 15118/19709\n",
            "Converting SMILES to graph: 15119/19709\n",
            "Converting SMILES to graph: 15120/19709\n",
            "Converting SMILES to graph: 15121/19709\n",
            "Converting SMILES to graph: 15122/19709\n",
            "Converting SMILES to graph: 15123/19709\n",
            "Converting SMILES to graph: 15124/19709\n",
            "Converting SMILES to graph: 15125/19709\n",
            "Converting SMILES to graph: 15126/19709\n",
            "Converting SMILES to graph: 15127/19709\n",
            "Converting SMILES to graph: 15128/19709\n",
            "Converting SMILES to graph: 15129/19709\n",
            "Converting SMILES to graph: 15130/19709\n",
            "Converting SMILES to graph: 15131/19709\n",
            "Converting SMILES to graph: 15132/19709\n",
            "Converting SMILES to graph: 15133/19709\n",
            "Converting SMILES to graph: 15134/19709\n",
            "Converting SMILES to graph: 15135/19709\n",
            "Converting SMILES to graph: 15136/19709\n",
            "Converting SMILES to graph: 15137/19709\n",
            "Converting SMILES to graph: 15138/19709\n",
            "Converting SMILES to graph: 15139/19709\n",
            "Converting SMILES to graph: 15140/19709\n",
            "Converting SMILES to graph: 15141/19709\n",
            "Converting SMILES to graph: 15142/19709\n",
            "Converting SMILES to graph: 15143/19709\n",
            "Converting SMILES to graph: 15144/19709\n",
            "Converting SMILES to graph: 15145/19709\n",
            "Converting SMILES to graph: 15146/19709\n",
            "Converting SMILES to graph: 15147/19709\n",
            "Converting SMILES to graph: 15148/19709\n",
            "Converting SMILES to graph: 15149/19709\n",
            "Converting SMILES to graph: 15150/19709\n",
            "Converting SMILES to graph: 15151/19709\n",
            "Converting SMILES to graph: 15152/19709\n",
            "Converting SMILES to graph: 15153/19709\n",
            "Converting SMILES to graph: 15154/19709\n",
            "Converting SMILES to graph: 15155/19709\n",
            "Converting SMILES to graph: 15156/19709\n",
            "Converting SMILES to graph: 15157/19709\n",
            "Converting SMILES to graph: 15158/19709\n",
            "Converting SMILES to graph: 15159/19709\n",
            "Converting SMILES to graph: 15160/19709\n",
            "Converting SMILES to graph: 15161/19709\n",
            "Converting SMILES to graph: 15162/19709\n",
            "Converting SMILES to graph: 15163/19709\n",
            "Converting SMILES to graph: 15164/19709\n",
            "Converting SMILES to graph: 15165/19709\n",
            "Converting SMILES to graph: 15166/19709\n",
            "Converting SMILES to graph: 15167/19709\n",
            "Converting SMILES to graph: 15168/19709\n",
            "Converting SMILES to graph: 15169/19709\n",
            "Converting SMILES to graph: 15170/19709\n",
            "Converting SMILES to graph: 15171/19709\n",
            "Converting SMILES to graph: 15172/19709\n",
            "Converting SMILES to graph: 15173/19709\n",
            "Converting SMILES to graph: 15174/19709\n",
            "Converting SMILES to graph: 15175/19709\n",
            "Converting SMILES to graph: 15176/19709\n",
            "Converting SMILES to graph: 15177/19709\n",
            "Converting SMILES to graph: 15178/19709\n",
            "Converting SMILES to graph: 15179/19709\n",
            "Converting SMILES to graph: 15180/19709\n",
            "Converting SMILES to graph: 15181/19709\n",
            "Converting SMILES to graph: 15182/19709\n",
            "Converting SMILES to graph: 15183/19709\n",
            "Converting SMILES to graph: 15184/19709\n",
            "Converting SMILES to graph: 15185/19709\n",
            "Converting SMILES to graph: 15186/19709\n",
            "Converting SMILES to graph: 15187/19709\n",
            "Converting SMILES to graph: 15188/19709\n",
            "Converting SMILES to graph: 15189/19709\n",
            "Converting SMILES to graph: 15190/19709\n",
            "Converting SMILES to graph: 15191/19709\n",
            "Converting SMILES to graph: 15192/19709\n",
            "Converting SMILES to graph: 15193/19709\n",
            "Converting SMILES to graph: 15194/19709\n",
            "Converting SMILES to graph: 15195/19709\n",
            "Converting SMILES to graph: 15196/19709\n",
            "Converting SMILES to graph: 15197/19709\n",
            "Converting SMILES to graph: 15198/19709\n",
            "Converting SMILES to graph: 15199/19709\n",
            "Converting SMILES to graph: 15200/19709\n",
            "Converting SMILES to graph: 15201/19709\n",
            "Converting SMILES to graph: 15202/19709\n",
            "Converting SMILES to graph: 15203/19709\n",
            "Converting SMILES to graph: 15204/19709\n",
            "Converting SMILES to graph: 15205/19709\n",
            "Converting SMILES to graph: 15206/19709\n",
            "Converting SMILES to graph: 15207/19709\n",
            "Converting SMILES to graph: 15208/19709\n",
            "Converting SMILES to graph: 15209/19709\n",
            "Converting SMILES to graph: 15210/19709\n",
            "Converting SMILES to graph: 15211/19709\n",
            "Converting SMILES to graph: 15212/19709\n",
            "Converting SMILES to graph: 15213/19709\n",
            "Converting SMILES to graph: 15214/19709\n",
            "Converting SMILES to graph: 15215/19709\n",
            "Converting SMILES to graph: 15216/19709\n",
            "Converting SMILES to graph: 15217/19709\n",
            "Converting SMILES to graph: 15218/19709\n",
            "Converting SMILES to graph: 15219/19709\n",
            "Converting SMILES to graph: 15220/19709\n",
            "Converting SMILES to graph: 15221/19709\n",
            "Converting SMILES to graph: 15222/19709\n",
            "Converting SMILES to graph: 15223/19709\n",
            "Converting SMILES to graph: 15224/19709\n",
            "Converting SMILES to graph: 15225/19709\n",
            "Converting SMILES to graph: 15226/19709\n",
            "Converting SMILES to graph: 15227/19709\n",
            "Converting SMILES to graph: 15228/19709\n",
            "Converting SMILES to graph: 15229/19709\n",
            "Converting SMILES to graph: 15230/19709\n",
            "Converting SMILES to graph: 15231/19709\n",
            "Converting SMILES to graph: 15232/19709\n",
            "Converting SMILES to graph: 15233/19709\n",
            "Converting SMILES to graph: 15234/19709\n",
            "Converting SMILES to graph: 15235/19709\n",
            "Converting SMILES to graph: 15236/19709\n",
            "Converting SMILES to graph: 15237/19709\n",
            "Converting SMILES to graph: 15238/19709\n",
            "Converting SMILES to graph: 15239/19709\n",
            "Converting SMILES to graph: 15240/19709\n",
            "Converting SMILES to graph: 15241/19709\n",
            "Converting SMILES to graph: 15242/19709\n",
            "Converting SMILES to graph: 15243/19709\n",
            "Converting SMILES to graph: 15244/19709\n",
            "Converting SMILES to graph: 15245/19709\n",
            "Converting SMILES to graph: 15246/19709\n",
            "Converting SMILES to graph: 15247/19709\n",
            "Converting SMILES to graph: 15248/19709\n",
            "Converting SMILES to graph: 15249/19709\n",
            "Converting SMILES to graph: 15250/19709\n",
            "Converting SMILES to graph: 15251/19709\n",
            "Converting SMILES to graph: 15252/19709\n",
            "Converting SMILES to graph: 15253/19709\n",
            "Converting SMILES to graph: 15254/19709\n",
            "Converting SMILES to graph: 15255/19709\n",
            "Converting SMILES to graph: 15256/19709\n",
            "Converting SMILES to graph: 15257/19709\n",
            "Converting SMILES to graph: 15258/19709\n",
            "Converting SMILES to graph: 15259/19709\n",
            "Converting SMILES to graph: 15260/19709\n",
            "Converting SMILES to graph: 15261/19709\n",
            "Converting SMILES to graph: 15262/19709\n",
            "Converting SMILES to graph: 15263/19709\n",
            "Converting SMILES to graph: 15264/19709\n",
            "Converting SMILES to graph: 15265/19709\n",
            "Converting SMILES to graph: 15266/19709\n",
            "Converting SMILES to graph: 15267/19709\n",
            "Converting SMILES to graph: 15268/19709\n",
            "Converting SMILES to graph: 15269/19709\n",
            "Converting SMILES to graph: 15270/19709\n",
            "Converting SMILES to graph: 15271/19709\n",
            "Converting SMILES to graph: 15272/19709\n",
            "Converting SMILES to graph: 15273/19709\n",
            "Converting SMILES to graph: 15274/19709\n",
            "Converting SMILES to graph: 15275/19709\n",
            "Converting SMILES to graph: 15276/19709\n",
            "Converting SMILES to graph: 15277/19709\n",
            "Converting SMILES to graph: 15278/19709\n",
            "Converting SMILES to graph: 15279/19709\n",
            "Converting SMILES to graph: 15280/19709\n",
            "Converting SMILES to graph: 15281/19709\n",
            "Converting SMILES to graph: 15282/19709\n",
            "Converting SMILES to graph: 15283/19709\n",
            "Converting SMILES to graph: 15284/19709\n",
            "Converting SMILES to graph: 15285/19709\n",
            "Converting SMILES to graph: 15286/19709\n",
            "Converting SMILES to graph: 15287/19709\n",
            "Converting SMILES to graph: 15288/19709\n",
            "Converting SMILES to graph: 15289/19709\n",
            "Converting SMILES to graph: 15290/19709\n",
            "Converting SMILES to graph: 15291/19709\n",
            "Converting SMILES to graph: 15292/19709\n",
            "Converting SMILES to graph: 15293/19709\n",
            "Converting SMILES to graph: 15294/19709\n",
            "Converting SMILES to graph: 15295/19709\n",
            "Converting SMILES to graph: 15296/19709\n",
            "Converting SMILES to graph: 15297/19709\n",
            "Converting SMILES to graph: 15298/19709\n",
            "Converting SMILES to graph: 15299/19709\n",
            "Converting SMILES to graph: 15300/19709\n",
            "Converting SMILES to graph: 15301/19709\n",
            "Converting SMILES to graph: 15302/19709\n",
            "Converting SMILES to graph: 15303/19709\n",
            "Converting SMILES to graph: 15304/19709\n",
            "Converting SMILES to graph: 15305/19709\n",
            "Converting SMILES to graph: 15306/19709\n",
            "Converting SMILES to graph: 15307/19709\n",
            "Converting SMILES to graph: 15308/19709\n",
            "Converting SMILES to graph: 15309/19709\n",
            "Converting SMILES to graph: 15310/19709\n",
            "Converting SMILES to graph: 15311/19709\n",
            "Converting SMILES to graph: 15312/19709\n",
            "Converting SMILES to graph: 15313/19709\n",
            "Converting SMILES to graph: 15314/19709\n",
            "Converting SMILES to graph: 15315/19709\n",
            "Converting SMILES to graph: 15316/19709\n",
            "Converting SMILES to graph: 15317/19709\n",
            "Converting SMILES to graph: 15318/19709\n",
            "Converting SMILES to graph: 15319/19709\n",
            "Converting SMILES to graph: 15320/19709\n",
            "Converting SMILES to graph: 15321/19709\n",
            "Converting SMILES to graph: 15322/19709\n",
            "Converting SMILES to graph: 15323/19709\n",
            "Converting SMILES to graph: 15324/19709\n",
            "Converting SMILES to graph: 15325/19709\n",
            "Converting SMILES to graph: 15326/19709\n",
            "Converting SMILES to graph: 15327/19709\n",
            "Converting SMILES to graph: 15328/19709\n",
            "Converting SMILES to graph: 15329/19709\n",
            "Converting SMILES to graph: 15330/19709\n",
            "Converting SMILES to graph: 15331/19709\n",
            "Converting SMILES to graph: 15332/19709\n",
            "Converting SMILES to graph: 15333/19709\n",
            "Converting SMILES to graph: 15334/19709\n",
            "Converting SMILES to graph: 15335/19709\n",
            "Converting SMILES to graph: 15336/19709\n",
            "Converting SMILES to graph: 15337/19709\n",
            "Converting SMILES to graph: 15338/19709\n",
            "Converting SMILES to graph: 15339/19709\n",
            "Converting SMILES to graph: 15340/19709\n",
            "Converting SMILES to graph: 15341/19709\n",
            "Converting SMILES to graph: 15342/19709\n",
            "Converting SMILES to graph: 15343/19709\n",
            "Converting SMILES to graph: 15344/19709\n",
            "Converting SMILES to graph: 15345/19709\n",
            "Converting SMILES to graph: 15346/19709\n",
            "Converting SMILES to graph: 15347/19709\n",
            "Converting SMILES to graph: 15348/19709\n",
            "Converting SMILES to graph: 15349/19709\n",
            "Converting SMILES to graph: 15350/19709\n",
            "Converting SMILES to graph: 15351/19709\n",
            "Converting SMILES to graph: 15352/19709\n",
            "Converting SMILES to graph: 15353/19709\n",
            "Converting SMILES to graph: 15354/19709\n",
            "Converting SMILES to graph: 15355/19709\n",
            "Converting SMILES to graph: 15356/19709\n",
            "Converting SMILES to graph: 15357/19709\n",
            "Converting SMILES to graph: 15358/19709\n",
            "Converting SMILES to graph: 15359/19709\n",
            "Converting SMILES to graph: 15360/19709\n",
            "Converting SMILES to graph: 15361/19709\n",
            "Converting SMILES to graph: 15362/19709\n",
            "Converting SMILES to graph: 15363/19709\n",
            "Converting SMILES to graph: 15364/19709\n",
            "Converting SMILES to graph: 15365/19709\n",
            "Converting SMILES to graph: 15366/19709\n",
            "Converting SMILES to graph: 15367/19709\n",
            "Converting SMILES to graph: 15368/19709\n",
            "Converting SMILES to graph: 15369/19709\n",
            "Converting SMILES to graph: 15370/19709\n",
            "Converting SMILES to graph: 15371/19709\n",
            "Converting SMILES to graph: 15372/19709\n",
            "Converting SMILES to graph: 15373/19709\n",
            "Converting SMILES to graph: 15374/19709\n",
            "Converting SMILES to graph: 15375/19709\n",
            "Converting SMILES to graph: 15376/19709\n",
            "Converting SMILES to graph: 15377/19709\n",
            "Converting SMILES to graph: 15378/19709\n",
            "Converting SMILES to graph: 15379/19709\n",
            "Converting SMILES to graph: 15380/19709\n",
            "Converting SMILES to graph: 15381/19709\n",
            "Converting SMILES to graph: 15382/19709\n",
            "Converting SMILES to graph: 15383/19709\n",
            "Converting SMILES to graph: 15384/19709\n",
            "Converting SMILES to graph: 15385/19709\n",
            "Converting SMILES to graph: 15386/19709\n",
            "Converting SMILES to graph: 15387/19709\n",
            "Converting SMILES to graph: 15388/19709\n",
            "Converting SMILES to graph: 15389/19709\n",
            "Converting SMILES to graph: 15390/19709\n",
            "Converting SMILES to graph: 15391/19709\n",
            "Converting SMILES to graph: 15392/19709\n",
            "Converting SMILES to graph: 15393/19709\n",
            "Converting SMILES to graph: 15394/19709\n",
            "Converting SMILES to graph: 15395/19709\n",
            "Converting SMILES to graph: 15396/19709\n",
            "Converting SMILES to graph: 15397/19709\n",
            "Converting SMILES to graph: 15398/19709\n",
            "Converting SMILES to graph: 15399/19709\n",
            "Converting SMILES to graph: 15400/19709\n",
            "Converting SMILES to graph: 15401/19709\n",
            "Converting SMILES to graph: 15402/19709\n",
            "Converting SMILES to graph: 15403/19709\n",
            "Converting SMILES to graph: 15404/19709\n",
            "Converting SMILES to graph: 15405/19709\n",
            "Converting SMILES to graph: 15406/19709\n",
            "Converting SMILES to graph: 15407/19709\n",
            "Converting SMILES to graph: 15408/19709\n",
            "Converting SMILES to graph: 15409/19709\n",
            "Converting SMILES to graph: 15410/19709\n",
            "Converting SMILES to graph: 15411/19709\n",
            "Converting SMILES to graph: 15412/19709\n",
            "Converting SMILES to graph: 15413/19709\n",
            "Converting SMILES to graph: 15414/19709\n",
            "Converting SMILES to graph: 15415/19709\n",
            "Converting SMILES to graph: 15416/19709\n",
            "Converting SMILES to graph: 15417/19709\n",
            "Converting SMILES to graph: 15418/19709\n",
            "Converting SMILES to graph: 15419/19709\n",
            "Converting SMILES to graph: 15420/19709\n",
            "Converting SMILES to graph: 15421/19709\n",
            "Converting SMILES to graph: 15422/19709\n",
            "Converting SMILES to graph: 15423/19709\n",
            "Converting SMILES to graph: 15424/19709\n",
            "Converting SMILES to graph: 15425/19709\n",
            "Converting SMILES to graph: 15426/19709\n",
            "Converting SMILES to graph: 15427/19709\n",
            "Converting SMILES to graph: 15428/19709\n",
            "Converting SMILES to graph: 15429/19709\n",
            "Converting SMILES to graph: 15430/19709\n",
            "Converting SMILES to graph: 15431/19709\n",
            "Converting SMILES to graph: 15432/19709\n",
            "Converting SMILES to graph: 15433/19709\n",
            "Converting SMILES to graph: 15434/19709\n",
            "Converting SMILES to graph: 15435/19709\n",
            "Converting SMILES to graph: 15436/19709\n",
            "Converting SMILES to graph: 15437/19709\n",
            "Converting SMILES to graph: 15438/19709\n",
            "Converting SMILES to graph: 15439/19709\n",
            "Converting SMILES to graph: 15440/19709\n",
            "Converting SMILES to graph: 15441/19709\n",
            "Converting SMILES to graph: 15442/19709\n",
            "Converting SMILES to graph: 15443/19709\n",
            "Converting SMILES to graph: 15444/19709\n",
            "Converting SMILES to graph: 15445/19709\n",
            "Converting SMILES to graph: 15446/19709\n",
            "Converting SMILES to graph: 15447/19709\n",
            "Converting SMILES to graph: 15448/19709\n",
            "Converting SMILES to graph: 15449/19709\n",
            "Converting SMILES to graph: 15450/19709\n",
            "Converting SMILES to graph: 15451/19709\n",
            "Converting SMILES to graph: 15452/19709\n",
            "Converting SMILES to graph: 15453/19709\n",
            "Converting SMILES to graph: 15454/19709\n",
            "Converting SMILES to graph: 15455/19709\n",
            "Converting SMILES to graph: 15456/19709\n",
            "Converting SMILES to graph: 15457/19709\n",
            "Converting SMILES to graph: 15458/19709\n",
            "Converting SMILES to graph: 15459/19709\n",
            "Converting SMILES to graph: 15460/19709\n",
            "Converting SMILES to graph: 15461/19709\n",
            "Converting SMILES to graph: 15462/19709\n",
            "Converting SMILES to graph: 15463/19709\n",
            "Converting SMILES to graph: 15464/19709\n",
            "Converting SMILES to graph: 15465/19709\n",
            "Converting SMILES to graph: 15466/19709\n",
            "Converting SMILES to graph: 15467/19709\n",
            "Converting SMILES to graph: 15468/19709\n",
            "Converting SMILES to graph: 15469/19709\n",
            "Converting SMILES to graph: 15470/19709\n",
            "Converting SMILES to graph: 15471/19709\n",
            "Converting SMILES to graph: 15472/19709\n",
            "Converting SMILES to graph: 15473/19709\n",
            "Converting SMILES to graph: 15474/19709\n",
            "Converting SMILES to graph: 15475/19709\n",
            "Converting SMILES to graph: 15476/19709\n",
            "Converting SMILES to graph: 15477/19709\n",
            "Converting SMILES to graph: 15478/19709\n",
            "Converting SMILES to graph: 15479/19709\n",
            "Converting SMILES to graph: 15480/19709\n",
            "Converting SMILES to graph: 15481/19709\n",
            "Converting SMILES to graph: 15482/19709\n",
            "Converting SMILES to graph: 15483/19709\n",
            "Converting SMILES to graph: 15484/19709\n",
            "Converting SMILES to graph: 15485/19709\n",
            "Converting SMILES to graph: 15486/19709\n",
            "Converting SMILES to graph: 15487/19709\n",
            "Converting SMILES to graph: 15488/19709\n",
            "Converting SMILES to graph: 15489/19709\n",
            "Converting SMILES to graph: 15490/19709\n",
            "Converting SMILES to graph: 15491/19709\n",
            "Converting SMILES to graph: 15492/19709\n",
            "Converting SMILES to graph: 15493/19709\n",
            "Converting SMILES to graph: 15494/19709\n",
            "Converting SMILES to graph: 15495/19709\n",
            "Converting SMILES to graph: 15496/19709\n",
            "Converting SMILES to graph: 15497/19709\n",
            "Converting SMILES to graph: 15498/19709\n",
            "Converting SMILES to graph: 15499/19709\n",
            "Converting SMILES to graph: 15500/19709\n",
            "Converting SMILES to graph: 15501/19709\n",
            "Converting SMILES to graph: 15502/19709\n",
            "Converting SMILES to graph: 15503/19709\n",
            "Converting SMILES to graph: 15504/19709\n",
            "Converting SMILES to graph: 15505/19709\n",
            "Converting SMILES to graph: 15506/19709\n",
            "Converting SMILES to graph: 15507/19709\n",
            "Converting SMILES to graph: 15508/19709\n",
            "Converting SMILES to graph: 15509/19709\n",
            "Converting SMILES to graph: 15510/19709\n",
            "Converting SMILES to graph: 15511/19709\n",
            "Converting SMILES to graph: 15512/19709\n",
            "Converting SMILES to graph: 15513/19709\n",
            "Converting SMILES to graph: 15514/19709\n",
            "Converting SMILES to graph: 15515/19709\n",
            "Converting SMILES to graph: 15516/19709\n",
            "Converting SMILES to graph: 15517/19709\n",
            "Converting SMILES to graph: 15518/19709\n",
            "Converting SMILES to graph: 15519/19709\n",
            "Converting SMILES to graph: 15520/19709\n",
            "Converting SMILES to graph: 15521/19709\n",
            "Converting SMILES to graph: 15522/19709\n",
            "Converting SMILES to graph: 15523/19709\n",
            "Converting SMILES to graph: 15524/19709\n",
            "Converting SMILES to graph: 15525/19709\n",
            "Converting SMILES to graph: 15526/19709\n",
            "Converting SMILES to graph: 15527/19709\n",
            "Converting SMILES to graph: 15528/19709\n",
            "Converting SMILES to graph: 15529/19709\n",
            "Converting SMILES to graph: 15530/19709\n",
            "Converting SMILES to graph: 15531/19709\n",
            "Converting SMILES to graph: 15532/19709\n",
            "Converting SMILES to graph: 15533/19709\n",
            "Converting SMILES to graph: 15534/19709\n",
            "Converting SMILES to graph: 15535/19709\n",
            "Converting SMILES to graph: 15536/19709\n",
            "Converting SMILES to graph: 15537/19709\n",
            "Converting SMILES to graph: 15538/19709\n",
            "Converting SMILES to graph: 15539/19709\n",
            "Converting SMILES to graph: 15540/19709\n",
            "Converting SMILES to graph: 15541/19709\n",
            "Converting SMILES to graph: 15542/19709\n",
            "Converting SMILES to graph: 15543/19709\n",
            "Converting SMILES to graph: 15544/19709\n",
            "Converting SMILES to graph: 15545/19709\n",
            "Converting SMILES to graph: 15546/19709\n",
            "Converting SMILES to graph: 15547/19709\n",
            "Converting SMILES to graph: 15548/19709\n",
            "Converting SMILES to graph: 15549/19709\n",
            "Converting SMILES to graph: 15550/19709\n",
            "Converting SMILES to graph: 15551/19709\n",
            "Converting SMILES to graph: 15552/19709\n",
            "Converting SMILES to graph: 15553/19709\n",
            "Converting SMILES to graph: 15554/19709\n",
            "Converting SMILES to graph: 15555/19709\n",
            "Converting SMILES to graph: 15556/19709\n",
            "Converting SMILES to graph: 15557/19709\n",
            "Converting SMILES to graph: 15558/19709\n",
            "Converting SMILES to graph: 15559/19709\n",
            "Converting SMILES to graph: 15560/19709\n",
            "Converting SMILES to graph: 15561/19709\n",
            "Converting SMILES to graph: 15562/19709\n",
            "Converting SMILES to graph: 15563/19709\n",
            "Converting SMILES to graph: 15564/19709\n",
            "Converting SMILES to graph: 15565/19709\n",
            "Converting SMILES to graph: 15566/19709\n",
            "Converting SMILES to graph: 15567/19709\n",
            "Converting SMILES to graph: 15568/19709\n",
            "Converting SMILES to graph: 15569/19709\n",
            "Converting SMILES to graph: 15570/19709\n",
            "Converting SMILES to graph: 15571/19709\n",
            "Converting SMILES to graph: 15572/19709\n",
            "Converting SMILES to graph: 15573/19709\n",
            "Converting SMILES to graph: 15574/19709\n",
            "Converting SMILES to graph: 15575/19709\n",
            "Converting SMILES to graph: 15576/19709\n",
            "Converting SMILES to graph: 15577/19709\n",
            "Converting SMILES to graph: 15578/19709\n",
            "Converting SMILES to graph: 15579/19709\n",
            "Converting SMILES to graph: 15580/19709\n",
            "Converting SMILES to graph: 15581/19709\n",
            "Converting SMILES to graph: 15582/19709\n",
            "Converting SMILES to graph: 15583/19709\n",
            "Converting SMILES to graph: 15584/19709\n",
            "Converting SMILES to graph: 15585/19709\n",
            "Converting SMILES to graph: 15586/19709\n",
            "Converting SMILES to graph: 15587/19709\n",
            "Converting SMILES to graph: 15588/19709\n",
            "Converting SMILES to graph: 15589/19709\n",
            "Converting SMILES to graph: 15590/19709\n",
            "Converting SMILES to graph: 15591/19709\n",
            "Converting SMILES to graph: 15592/19709\n",
            "Converting SMILES to graph: 15593/19709\n",
            "Converting SMILES to graph: 15594/19709\n",
            "Converting SMILES to graph: 15595/19709\n",
            "Converting SMILES to graph: 15596/19709\n",
            "Converting SMILES to graph: 15597/19709\n",
            "Converting SMILES to graph: 15598/19709\n",
            "Converting SMILES to graph: 15599/19709\n",
            "Converting SMILES to graph: 15600/19709\n",
            "Converting SMILES to graph: 15601/19709\n",
            "Converting SMILES to graph: 15602/19709\n",
            "Converting SMILES to graph: 15603/19709\n",
            "Converting SMILES to graph: 15604/19709\n",
            "Converting SMILES to graph: 15605/19709\n",
            "Converting SMILES to graph: 15606/19709\n",
            "Converting SMILES to graph: 15607/19709\n",
            "Converting SMILES to graph: 15608/19709\n",
            "Converting SMILES to graph: 15609/19709\n",
            "Converting SMILES to graph: 15610/19709\n",
            "Converting SMILES to graph: 15611/19709\n",
            "Converting SMILES to graph: 15612/19709\n",
            "Converting SMILES to graph: 15613/19709\n",
            "Converting SMILES to graph: 15614/19709\n",
            "Converting SMILES to graph: 15615/19709\n",
            "Converting SMILES to graph: 15616/19709\n",
            "Converting SMILES to graph: 15617/19709\n",
            "Converting SMILES to graph: 15618/19709\n",
            "Converting SMILES to graph: 15619/19709\n",
            "Converting SMILES to graph: 15620/19709\n",
            "Converting SMILES to graph: 15621/19709\n",
            "Converting SMILES to graph: 15622/19709\n",
            "Converting SMILES to graph: 15623/19709\n",
            "Converting SMILES to graph: 15624/19709\n",
            "Converting SMILES to graph: 15625/19709\n",
            "Converting SMILES to graph: 15626/19709\n",
            "Converting SMILES to graph: 15627/19709\n",
            "Converting SMILES to graph: 15628/19709\n",
            "Converting SMILES to graph: 15629/19709\n",
            "Converting SMILES to graph: 15630/19709\n",
            "Converting SMILES to graph: 15631/19709\n",
            "Converting SMILES to graph: 15632/19709\n",
            "Converting SMILES to graph: 15633/19709\n",
            "Converting SMILES to graph: 15634/19709\n",
            "Converting SMILES to graph: 15635/19709\n",
            "Converting SMILES to graph: 15636/19709\n",
            "Converting SMILES to graph: 15637/19709\n",
            "Converting SMILES to graph: 15638/19709\n",
            "Converting SMILES to graph: 15639/19709\n",
            "Converting SMILES to graph: 15640/19709\n",
            "Converting SMILES to graph: 15641/19709\n",
            "Converting SMILES to graph: 15642/19709\n",
            "Converting SMILES to graph: 15643/19709\n",
            "Converting SMILES to graph: 15644/19709\n",
            "Converting SMILES to graph: 15645/19709\n",
            "Converting SMILES to graph: 15646/19709\n",
            "Converting SMILES to graph: 15647/19709\n",
            "Converting SMILES to graph: 15648/19709\n",
            "Converting SMILES to graph: 15649/19709\n",
            "Converting SMILES to graph: 15650/19709\n",
            "Converting SMILES to graph: 15651/19709\n",
            "Converting SMILES to graph: 15652/19709\n",
            "Converting SMILES to graph: 15653/19709\n",
            "Converting SMILES to graph: 15654/19709\n",
            "Converting SMILES to graph: 15655/19709\n",
            "Converting SMILES to graph: 15656/19709\n",
            "Converting SMILES to graph: 15657/19709\n",
            "Converting SMILES to graph: 15658/19709\n",
            "Converting SMILES to graph: 15659/19709\n",
            "Converting SMILES to graph: 15660/19709\n",
            "Converting SMILES to graph: 15661/19709\n",
            "Converting SMILES to graph: 15662/19709\n",
            "Converting SMILES to graph: 15663/19709\n",
            "Converting SMILES to graph: 15664/19709\n",
            "Converting SMILES to graph: 15665/19709\n",
            "Converting SMILES to graph: 15666/19709\n",
            "Converting SMILES to graph: 15667/19709\n",
            "Converting SMILES to graph: 15668/19709\n",
            "Converting SMILES to graph: 15669/19709\n",
            "Converting SMILES to graph: 15670/19709\n",
            "Converting SMILES to graph: 15671/19709\n",
            "Converting SMILES to graph: 15672/19709\n",
            "Converting SMILES to graph: 15673/19709\n",
            "Converting SMILES to graph: 15674/19709\n",
            "Converting SMILES to graph: 15675/19709\n",
            "Converting SMILES to graph: 15676/19709\n",
            "Converting SMILES to graph: 15677/19709\n",
            "Converting SMILES to graph: 15678/19709\n",
            "Converting SMILES to graph: 15679/19709\n",
            "Converting SMILES to graph: 15680/19709\n",
            "Converting SMILES to graph: 15681/19709\n",
            "Converting SMILES to graph: 15682/19709\n",
            "Converting SMILES to graph: 15683/19709\n",
            "Converting SMILES to graph: 15684/19709\n",
            "Converting SMILES to graph: 15685/19709\n",
            "Converting SMILES to graph: 15686/19709\n",
            "Converting SMILES to graph: 15687/19709\n",
            "Converting SMILES to graph: 15688/19709\n",
            "Converting SMILES to graph: 15689/19709\n",
            "Converting SMILES to graph: 15690/19709\n",
            "Converting SMILES to graph: 15691/19709\n",
            "Converting SMILES to graph: 15692/19709\n",
            "Converting SMILES to graph: 15693/19709\n",
            "Converting SMILES to graph: 15694/19709\n",
            "Converting SMILES to graph: 15695/19709\n",
            "Converting SMILES to graph: 15696/19709\n",
            "Converting SMILES to graph: 15697/19709\n",
            "Converting SMILES to graph: 15698/19709\n",
            "Converting SMILES to graph: 15699/19709\n",
            "Converting SMILES to graph: 15700/19709\n",
            "Converting SMILES to graph: 15701/19709\n",
            "Converting SMILES to graph: 15702/19709\n",
            "Converting SMILES to graph: 15703/19709\n",
            "Converting SMILES to graph: 15704/19709\n",
            "Converting SMILES to graph: 15705/19709\n",
            "Converting SMILES to graph: 15706/19709\n",
            "Converting SMILES to graph: 15707/19709\n",
            "Converting SMILES to graph: 15708/19709\n",
            "Converting SMILES to graph: 15709/19709\n",
            "Converting SMILES to graph: 15710/19709\n",
            "Converting SMILES to graph: 15711/19709\n",
            "Converting SMILES to graph: 15712/19709\n",
            "Converting SMILES to graph: 15713/19709\n",
            "Converting SMILES to graph: 15714/19709\n",
            "Converting SMILES to graph: 15715/19709\n",
            "Converting SMILES to graph: 15716/19709\n",
            "Converting SMILES to graph: 15717/19709\n",
            "Converting SMILES to graph: 15718/19709\n",
            "Converting SMILES to graph: 15719/19709\n",
            "Converting SMILES to graph: 15720/19709\n",
            "Converting SMILES to graph: 15721/19709\n",
            "Converting SMILES to graph: 15722/19709\n",
            "Converting SMILES to graph: 15723/19709\n",
            "Converting SMILES to graph: 15724/19709\n",
            "Converting SMILES to graph: 15725/19709\n",
            "Converting SMILES to graph: 15726/19709\n",
            "Converting SMILES to graph: 15727/19709\n",
            "Converting SMILES to graph: 15728/19709\n",
            "Converting SMILES to graph: 15729/19709\n",
            "Converting SMILES to graph: 15730/19709\n",
            "Converting SMILES to graph: 15731/19709\n",
            "Converting SMILES to graph: 15732/19709\n",
            "Converting SMILES to graph: 15733/19709\n",
            "Converting SMILES to graph: 15734/19709\n",
            "Converting SMILES to graph: 15735/19709\n",
            "Converting SMILES to graph: 15736/19709\n",
            "Converting SMILES to graph: 15737/19709\n",
            "Converting SMILES to graph: 15738/19709\n",
            "Converting SMILES to graph: 15739/19709\n",
            "Converting SMILES to graph: 15740/19709\n",
            "Converting SMILES to graph: 15741/19709\n",
            "Converting SMILES to graph: 15742/19709\n",
            "Converting SMILES to graph: 15743/19709\n",
            "Converting SMILES to graph: 15744/19709\n",
            "Converting SMILES to graph: 15745/19709\n",
            "Converting SMILES to graph: 15746/19709\n",
            "Converting SMILES to graph: 15747/19709\n",
            "Converting SMILES to graph: 15748/19709\n",
            "Converting SMILES to graph: 15749/19709\n",
            "Converting SMILES to graph: 15750/19709\n",
            "Converting SMILES to graph: 15751/19709\n",
            "Converting SMILES to graph: 15752/19709\n",
            "Converting SMILES to graph: 15753/19709\n",
            "Converting SMILES to graph: 15754/19709\n",
            "Converting SMILES to graph: 15755/19709\n",
            "Converting SMILES to graph: 15756/19709\n",
            "Converting SMILES to graph: 15757/19709\n",
            "Converting SMILES to graph: 15758/19709\n",
            "Converting SMILES to graph: 15759/19709\n",
            "Converting SMILES to graph: 15760/19709\n",
            "Converting SMILES to graph: 15761/19709\n",
            "Converting SMILES to graph: 15762/19709\n",
            "Converting SMILES to graph: 15763/19709\n",
            "Converting SMILES to graph: 15764/19709\n",
            "Converting SMILES to graph: 15765/19709\n",
            "Converting SMILES to graph: 15766/19709\n",
            "Converting SMILES to graph: 15767/19709\n",
            "Converting SMILES to graph: 15768/19709\n",
            "Converting SMILES to graph: 15769/19709\n",
            "Converting SMILES to graph: 15770/19709\n",
            "Converting SMILES to graph: 15771/19709\n",
            "Converting SMILES to graph: 15772/19709\n",
            "Converting SMILES to graph: 15773/19709\n",
            "Converting SMILES to graph: 15774/19709\n",
            "Converting SMILES to graph: 15775/19709\n",
            "Converting SMILES to graph: 15776/19709\n",
            "Converting SMILES to graph: 15777/19709\n",
            "Converting SMILES to graph: 15778/19709\n",
            "Converting SMILES to graph: 15779/19709\n",
            "Converting SMILES to graph: 15780/19709\n",
            "Converting SMILES to graph: 15781/19709\n",
            "Converting SMILES to graph: 15782/19709\n",
            "Converting SMILES to graph: 15783/19709\n",
            "Converting SMILES to graph: 15784/19709\n",
            "Converting SMILES to graph: 15785/19709\n",
            "Converting SMILES to graph: 15786/19709\n",
            "Converting SMILES to graph: 15787/19709\n",
            "Converting SMILES to graph: 15788/19709\n",
            "Converting SMILES to graph: 15789/19709\n",
            "Converting SMILES to graph: 15790/19709\n",
            "Converting SMILES to graph: 15791/19709\n",
            "Converting SMILES to graph: 15792/19709\n",
            "Converting SMILES to graph: 15793/19709\n",
            "Converting SMILES to graph: 15794/19709\n",
            "Converting SMILES to graph: 15795/19709\n",
            "Converting SMILES to graph: 15796/19709\n",
            "Converting SMILES to graph: 15797/19709\n",
            "Converting SMILES to graph: 15798/19709\n",
            "Converting SMILES to graph: 15799/19709\n",
            "Converting SMILES to graph: 15800/19709\n",
            "Converting SMILES to graph: 15801/19709\n",
            "Converting SMILES to graph: 15802/19709\n",
            "Converting SMILES to graph: 15803/19709\n",
            "Converting SMILES to graph: 15804/19709\n",
            "Converting SMILES to graph: 15805/19709\n",
            "Converting SMILES to graph: 15806/19709\n",
            "Converting SMILES to graph: 15807/19709\n",
            "Converting SMILES to graph: 15808/19709\n",
            "Converting SMILES to graph: 15809/19709\n",
            "Converting SMILES to graph: 15810/19709\n",
            "Converting SMILES to graph: 15811/19709\n",
            "Converting SMILES to graph: 15812/19709\n",
            "Converting SMILES to graph: 15813/19709\n",
            "Converting SMILES to graph: 15814/19709\n",
            "Converting SMILES to graph: 15815/19709\n",
            "Converting SMILES to graph: 15816/19709\n",
            "Converting SMILES to graph: 15817/19709\n",
            "Converting SMILES to graph: 15818/19709\n",
            "Converting SMILES to graph: 15819/19709\n",
            "Converting SMILES to graph: 15820/19709\n",
            "Converting SMILES to graph: 15821/19709\n",
            "Converting SMILES to graph: 15822/19709\n",
            "Converting SMILES to graph: 15823/19709\n",
            "Converting SMILES to graph: 15824/19709\n",
            "Converting SMILES to graph: 15825/19709\n",
            "Converting SMILES to graph: 15826/19709\n",
            "Converting SMILES to graph: 15827/19709\n",
            "Converting SMILES to graph: 15828/19709\n",
            "Converting SMILES to graph: 15829/19709\n",
            "Converting SMILES to graph: 15830/19709\n",
            "Converting SMILES to graph: 15831/19709\n",
            "Converting SMILES to graph: 15832/19709\n",
            "Converting SMILES to graph: 15833/19709\n",
            "Converting SMILES to graph: 15834/19709\n",
            "Converting SMILES to graph: 15835/19709\n",
            "Converting SMILES to graph: 15836/19709\n",
            "Converting SMILES to graph: 15837/19709\n",
            "Converting SMILES to graph: 15838/19709\n",
            "Converting SMILES to graph: 15839/19709\n",
            "Converting SMILES to graph: 15840/19709\n",
            "Converting SMILES to graph: 15841/19709\n",
            "Converting SMILES to graph: 15842/19709\n",
            "Converting SMILES to graph: 15843/19709\n",
            "Converting SMILES to graph: 15844/19709\n",
            "Converting SMILES to graph: 15845/19709\n",
            "Converting SMILES to graph: 15846/19709\n",
            "Converting SMILES to graph: 15847/19709\n",
            "Converting SMILES to graph: 15848/19709\n",
            "Converting SMILES to graph: 15849/19709\n",
            "Converting SMILES to graph: 15850/19709\n",
            "Converting SMILES to graph: 15851/19709\n",
            "Converting SMILES to graph: 15852/19709\n",
            "Converting SMILES to graph: 15853/19709\n",
            "Converting SMILES to graph: 15854/19709\n",
            "Converting SMILES to graph: 15855/19709\n",
            "Converting SMILES to graph: 15856/19709\n",
            "Converting SMILES to graph: 15857/19709\n",
            "Converting SMILES to graph: 15858/19709\n",
            "Converting SMILES to graph: 15859/19709\n",
            "Converting SMILES to graph: 15860/19709\n",
            "Converting SMILES to graph: 15861/19709\n",
            "Converting SMILES to graph: 15862/19709\n",
            "Converting SMILES to graph: 15863/19709\n",
            "Converting SMILES to graph: 15864/19709\n",
            "Converting SMILES to graph: 15865/19709\n",
            "Converting SMILES to graph: 15866/19709\n",
            "Converting SMILES to graph: 15867/19709\n",
            "Converting SMILES to graph: 15868/19709\n",
            "Converting SMILES to graph: 15869/19709\n",
            "Converting SMILES to graph: 15870/19709\n",
            "Converting SMILES to graph: 15871/19709\n",
            "Converting SMILES to graph: 15872/19709\n",
            "Converting SMILES to graph: 15873/19709\n",
            "Converting SMILES to graph: 15874/19709\n",
            "Converting SMILES to graph: 15875/19709\n",
            "Converting SMILES to graph: 15876/19709\n",
            "Converting SMILES to graph: 15877/19709\n",
            "Converting SMILES to graph: 15878/19709\n",
            "Converting SMILES to graph: 15879/19709\n",
            "Converting SMILES to graph: 15880/19709\n",
            "Converting SMILES to graph: 15881/19709\n",
            "Converting SMILES to graph: 15882/19709\n",
            "Converting SMILES to graph: 15883/19709\n",
            "Converting SMILES to graph: 15884/19709\n",
            "Converting SMILES to graph: 15885/19709\n",
            "Converting SMILES to graph: 15886/19709\n",
            "Converting SMILES to graph: 15887/19709\n",
            "Converting SMILES to graph: 15888/19709\n",
            "Converting SMILES to graph: 15889/19709\n",
            "Converting SMILES to graph: 15890/19709\n",
            "Converting SMILES to graph: 15891/19709\n",
            "Converting SMILES to graph: 15892/19709\n",
            "Converting SMILES to graph: 15893/19709\n",
            "Converting SMILES to graph: 15894/19709\n",
            "Converting SMILES to graph: 15895/19709\n",
            "Converting SMILES to graph: 15896/19709\n",
            "Converting SMILES to graph: 15897/19709\n",
            "Converting SMILES to graph: 15898/19709\n",
            "Converting SMILES to graph: 15899/19709\n",
            "Converting SMILES to graph: 15900/19709\n",
            "Converting SMILES to graph: 15901/19709\n",
            "Converting SMILES to graph: 15902/19709\n",
            "Converting SMILES to graph: 15903/19709\n",
            "Converting SMILES to graph: 15904/19709\n",
            "Converting SMILES to graph: 15905/19709\n",
            "Converting SMILES to graph: 15906/19709\n",
            "Converting SMILES to graph: 15907/19709\n",
            "Converting SMILES to graph: 15908/19709\n",
            "Converting SMILES to graph: 15909/19709\n",
            "Converting SMILES to graph: 15910/19709\n",
            "Converting SMILES to graph: 15911/19709\n",
            "Converting SMILES to graph: 15912/19709\n",
            "Converting SMILES to graph: 15913/19709\n",
            "Converting SMILES to graph: 15914/19709\n",
            "Converting SMILES to graph: 15915/19709\n",
            "Converting SMILES to graph: 15916/19709\n",
            "Converting SMILES to graph: 15917/19709\n",
            "Converting SMILES to graph: 15918/19709\n",
            "Converting SMILES to graph: 15919/19709\n",
            "Converting SMILES to graph: 15920/19709\n",
            "Converting SMILES to graph: 15921/19709\n",
            "Converting SMILES to graph: 15922/19709\n",
            "Converting SMILES to graph: 15923/19709\n",
            "Converting SMILES to graph: 15924/19709\n",
            "Converting SMILES to graph: 15925/19709\n",
            "Converting SMILES to graph: 15926/19709\n",
            "Converting SMILES to graph: 15927/19709\n",
            "Converting SMILES to graph: 15928/19709\n",
            "Converting SMILES to graph: 15929/19709\n",
            "Converting SMILES to graph: 15930/19709\n",
            "Converting SMILES to graph: 15931/19709\n",
            "Converting SMILES to graph: 15932/19709\n",
            "Converting SMILES to graph: 15933/19709\n",
            "Converting SMILES to graph: 15934/19709\n",
            "Converting SMILES to graph: 15935/19709\n",
            "Converting SMILES to graph: 15936/19709\n",
            "Converting SMILES to graph: 15937/19709\n",
            "Converting SMILES to graph: 15938/19709\n",
            "Converting SMILES to graph: 15939/19709\n",
            "Converting SMILES to graph: 15940/19709\n",
            "Converting SMILES to graph: 15941/19709\n",
            "Converting SMILES to graph: 15942/19709\n",
            "Converting SMILES to graph: 15943/19709\n",
            "Converting SMILES to graph: 15944/19709\n",
            "Converting SMILES to graph: 15945/19709\n",
            "Converting SMILES to graph: 15946/19709\n",
            "Converting SMILES to graph: 15947/19709\n",
            "Converting SMILES to graph: 15948/19709\n",
            "Converting SMILES to graph: 15949/19709\n",
            "Converting SMILES to graph: 15950/19709\n",
            "Converting SMILES to graph: 15951/19709\n",
            "Converting SMILES to graph: 15952/19709\n",
            "Converting SMILES to graph: 15953/19709\n",
            "Converting SMILES to graph: 15954/19709\n",
            "Converting SMILES to graph: 15955/19709\n",
            "Converting SMILES to graph: 15956/19709\n",
            "Converting SMILES to graph: 15957/19709\n",
            "Converting SMILES to graph: 15958/19709\n",
            "Converting SMILES to graph: 15959/19709\n",
            "Converting SMILES to graph: 15960/19709\n",
            "Converting SMILES to graph: 15961/19709\n",
            "Converting SMILES to graph: 15962/19709\n",
            "Converting SMILES to graph: 15963/19709\n",
            "Converting SMILES to graph: 15964/19709\n",
            "Converting SMILES to graph: 15965/19709\n",
            "Converting SMILES to graph: 15966/19709\n",
            "Converting SMILES to graph: 15967/19709\n",
            "Converting SMILES to graph: 15968/19709\n",
            "Converting SMILES to graph: 15969/19709\n",
            "Converting SMILES to graph: 15970/19709\n",
            "Converting SMILES to graph: 15971/19709\n",
            "Converting SMILES to graph: 15972/19709\n",
            "Converting SMILES to graph: 15973/19709\n",
            "Converting SMILES to graph: 15974/19709\n",
            "Converting SMILES to graph: 15975/19709\n",
            "Converting SMILES to graph: 15976/19709\n",
            "Converting SMILES to graph: 15977/19709\n",
            "Converting SMILES to graph: 15978/19709\n",
            "Converting SMILES to graph: 15979/19709\n",
            "Converting SMILES to graph: 15980/19709\n",
            "Converting SMILES to graph: 15981/19709\n",
            "Converting SMILES to graph: 15982/19709\n",
            "Converting SMILES to graph: 15983/19709\n",
            "Converting SMILES to graph: 15984/19709\n",
            "Converting SMILES to graph: 15985/19709\n",
            "Converting SMILES to graph: 15986/19709\n",
            "Converting SMILES to graph: 15987/19709\n",
            "Converting SMILES to graph: 15988/19709\n",
            "Converting SMILES to graph: 15989/19709\n",
            "Converting SMILES to graph: 15990/19709\n",
            "Converting SMILES to graph: 15991/19709\n",
            "Converting SMILES to graph: 15992/19709\n",
            "Converting SMILES to graph: 15993/19709\n",
            "Converting SMILES to graph: 15994/19709\n",
            "Converting SMILES to graph: 15995/19709\n",
            "Converting SMILES to graph: 15996/19709\n",
            "Converting SMILES to graph: 15997/19709\n",
            "Converting SMILES to graph: 15998/19709\n",
            "Converting SMILES to graph: 15999/19709\n",
            "Converting SMILES to graph: 16000/19709\n",
            "Converting SMILES to graph: 16001/19709\n",
            "Converting SMILES to graph: 16002/19709\n",
            "Converting SMILES to graph: 16003/19709\n",
            "Converting SMILES to graph: 16004/19709\n",
            "Converting SMILES to graph: 16005/19709\n",
            "Converting SMILES to graph: 16006/19709\n",
            "Converting SMILES to graph: 16007/19709\n",
            "Converting SMILES to graph: 16008/19709\n",
            "Converting SMILES to graph: 16009/19709\n",
            "Converting SMILES to graph: 16010/19709\n",
            "Converting SMILES to graph: 16011/19709\n",
            "Converting SMILES to graph: 16012/19709\n",
            "Converting SMILES to graph: 16013/19709\n",
            "Converting SMILES to graph: 16014/19709\n",
            "Converting SMILES to graph: 16015/19709\n",
            "Converting SMILES to graph: 16016/19709\n",
            "Converting SMILES to graph: 16017/19709\n",
            "Converting SMILES to graph: 16018/19709\n",
            "Converting SMILES to graph: 16019/19709\n",
            "Converting SMILES to graph: 16020/19709\n",
            "Converting SMILES to graph: 16021/19709\n",
            "Converting SMILES to graph: 16022/19709\n",
            "Converting SMILES to graph: 16023/19709\n",
            "Converting SMILES to graph: 16024/19709\n",
            "Converting SMILES to graph: 16025/19709\n",
            "Converting SMILES to graph: 16026/19709\n",
            "Converting SMILES to graph: 16027/19709\n",
            "Converting SMILES to graph: 16028/19709\n",
            "Converting SMILES to graph: 16029/19709\n",
            "Converting SMILES to graph: 16030/19709\n",
            "Converting SMILES to graph: 16031/19709\n",
            "Converting SMILES to graph: 16032/19709\n",
            "Converting SMILES to graph: 16033/19709\n",
            "Converting SMILES to graph: 16034/19709\n",
            "Converting SMILES to graph: 16035/19709\n",
            "Converting SMILES to graph: 16036/19709\n",
            "Converting SMILES to graph: 16037/19709\n",
            "Converting SMILES to graph: 16038/19709\n",
            "Converting SMILES to graph: 16039/19709\n",
            "Converting SMILES to graph: 16040/19709\n",
            "Converting SMILES to graph: 16041/19709\n",
            "Converting SMILES to graph: 16042/19709\n",
            "Converting SMILES to graph: 16043/19709\n",
            "Converting SMILES to graph: 16044/19709\n",
            "Converting SMILES to graph: 16045/19709\n",
            "Converting SMILES to graph: 16046/19709\n",
            "Converting SMILES to graph: 16047/19709\n",
            "Converting SMILES to graph: 16048/19709\n",
            "Converting SMILES to graph: 16049/19709\n",
            "Converting SMILES to graph: 16050/19709\n",
            "Converting SMILES to graph: 16051/19709\n",
            "Converting SMILES to graph: 16052/19709\n",
            "Converting SMILES to graph: 16053/19709\n",
            "Converting SMILES to graph: 16054/19709\n",
            "Converting SMILES to graph: 16055/19709\n",
            "Converting SMILES to graph: 16056/19709\n",
            "Converting SMILES to graph: 16057/19709\n",
            "Converting SMILES to graph: 16058/19709\n",
            "Converting SMILES to graph: 16059/19709\n",
            "Converting SMILES to graph: 16060/19709\n",
            "Converting SMILES to graph: 16061/19709\n",
            "Converting SMILES to graph: 16062/19709\n",
            "Converting SMILES to graph: 16063/19709\n",
            "Converting SMILES to graph: 16064/19709\n",
            "Converting SMILES to graph: 16065/19709\n",
            "Converting SMILES to graph: 16066/19709\n",
            "Converting SMILES to graph: 16067/19709\n",
            "Converting SMILES to graph: 16068/19709\n",
            "Converting SMILES to graph: 16069/19709\n",
            "Converting SMILES to graph: 16070/19709\n",
            "Converting SMILES to graph: 16071/19709\n",
            "Converting SMILES to graph: 16072/19709\n",
            "Converting SMILES to graph: 16073/19709\n",
            "Converting SMILES to graph: 16074/19709\n",
            "Converting SMILES to graph: 16075/19709\n",
            "Converting SMILES to graph: 16076/19709\n",
            "Converting SMILES to graph: 16077/19709\n",
            "Converting SMILES to graph: 16078/19709\n",
            "Converting SMILES to graph: 16079/19709\n",
            "Converting SMILES to graph: 16080/19709\n",
            "Converting SMILES to graph: 16081/19709\n",
            "Converting SMILES to graph: 16082/19709\n",
            "Converting SMILES to graph: 16083/19709\n",
            "Converting SMILES to graph: 16084/19709\n",
            "Converting SMILES to graph: 16085/19709\n",
            "Converting SMILES to graph: 16086/19709\n",
            "Converting SMILES to graph: 16087/19709\n",
            "Converting SMILES to graph: 16088/19709\n",
            "Converting SMILES to graph: 16089/19709\n",
            "Converting SMILES to graph: 16090/19709\n",
            "Converting SMILES to graph: 16091/19709\n",
            "Converting SMILES to graph: 16092/19709\n",
            "Converting SMILES to graph: 16093/19709\n",
            "Converting SMILES to graph: 16094/19709\n",
            "Converting SMILES to graph: 16095/19709\n",
            "Converting SMILES to graph: 16096/19709\n",
            "Converting SMILES to graph: 16097/19709\n",
            "Converting SMILES to graph: 16098/19709\n",
            "Converting SMILES to graph: 16099/19709\n",
            "Converting SMILES to graph: 16100/19709\n",
            "Converting SMILES to graph: 16101/19709\n",
            "Converting SMILES to graph: 16102/19709\n",
            "Converting SMILES to graph: 16103/19709\n",
            "Converting SMILES to graph: 16104/19709\n",
            "Converting SMILES to graph: 16105/19709\n",
            "Converting SMILES to graph: 16106/19709\n",
            "Converting SMILES to graph: 16107/19709\n",
            "Converting SMILES to graph: 16108/19709\n",
            "Converting SMILES to graph: 16109/19709\n",
            "Converting SMILES to graph: 16110/19709\n",
            "Converting SMILES to graph: 16111/19709\n",
            "Converting SMILES to graph: 16112/19709\n",
            "Converting SMILES to graph: 16113/19709\n",
            "Converting SMILES to graph: 16114/19709\n",
            "Converting SMILES to graph: 16115/19709\n",
            "Converting SMILES to graph: 16116/19709\n",
            "Converting SMILES to graph: 16117/19709\n",
            "Converting SMILES to graph: 16118/19709\n",
            "Converting SMILES to graph: 16119/19709\n",
            "Converting SMILES to graph: 16120/19709\n",
            "Converting SMILES to graph: 16121/19709\n",
            "Converting SMILES to graph: 16122/19709\n",
            "Converting SMILES to graph: 16123/19709\n",
            "Converting SMILES to graph: 16124/19709\n",
            "Converting SMILES to graph: 16125/19709\n",
            "Converting SMILES to graph: 16126/19709\n",
            "Converting SMILES to graph: 16127/19709\n",
            "Converting SMILES to graph: 16128/19709\n",
            "Converting SMILES to graph: 16129/19709\n",
            "Converting SMILES to graph: 16130/19709\n",
            "Converting SMILES to graph: 16131/19709\n",
            "Converting SMILES to graph: 16132/19709\n",
            "Converting SMILES to graph: 16133/19709\n",
            "Converting SMILES to graph: 16134/19709\n",
            "Converting SMILES to graph: 16135/19709\n",
            "Converting SMILES to graph: 16136/19709\n",
            "Converting SMILES to graph: 16137/19709\n",
            "Converting SMILES to graph: 16138/19709\n",
            "Converting SMILES to graph: 16139/19709\n",
            "Converting SMILES to graph: 16140/19709\n",
            "Converting SMILES to graph: 16141/19709\n",
            "Converting SMILES to graph: 16142/19709\n",
            "Converting SMILES to graph: 16143/19709\n",
            "Converting SMILES to graph: 16144/19709\n",
            "Converting SMILES to graph: 16145/19709\n",
            "Converting SMILES to graph: 16146/19709\n",
            "Converting SMILES to graph: 16147/19709\n",
            "Converting SMILES to graph: 16148/19709\n",
            "Converting SMILES to graph: 16149/19709\n",
            "Converting SMILES to graph: 16150/19709\n",
            "Converting SMILES to graph: 16151/19709\n",
            "Converting SMILES to graph: 16152/19709\n",
            "Converting SMILES to graph: 16153/19709\n",
            "Converting SMILES to graph: 16154/19709\n",
            "Converting SMILES to graph: 16155/19709\n",
            "Converting SMILES to graph: 16156/19709\n",
            "Converting SMILES to graph: 16157/19709\n",
            "Converting SMILES to graph: 16158/19709\n",
            "Converting SMILES to graph: 16159/19709\n",
            "Converting SMILES to graph: 16160/19709\n",
            "Converting SMILES to graph: 16161/19709\n",
            "Converting SMILES to graph: 16162/19709\n",
            "Converting SMILES to graph: 16163/19709\n",
            "Converting SMILES to graph: 16164/19709\n",
            "Converting SMILES to graph: 16165/19709\n",
            "Converting SMILES to graph: 16166/19709\n",
            "Converting SMILES to graph: 16167/19709\n",
            "Converting SMILES to graph: 16168/19709\n",
            "Converting SMILES to graph: 16169/19709\n",
            "Converting SMILES to graph: 16170/19709\n",
            "Converting SMILES to graph: 16171/19709\n",
            "Converting SMILES to graph: 16172/19709\n",
            "Converting SMILES to graph: 16173/19709\n",
            "Converting SMILES to graph: 16174/19709\n",
            "Converting SMILES to graph: 16175/19709\n",
            "Converting SMILES to graph: 16176/19709\n",
            "Converting SMILES to graph: 16177/19709\n",
            "Converting SMILES to graph: 16178/19709\n",
            "Converting SMILES to graph: 16179/19709\n",
            "Converting SMILES to graph: 16180/19709\n",
            "Converting SMILES to graph: 16181/19709\n",
            "Converting SMILES to graph: 16182/19709\n",
            "Converting SMILES to graph: 16183/19709\n",
            "Converting SMILES to graph: 16184/19709\n",
            "Converting SMILES to graph: 16185/19709\n",
            "Converting SMILES to graph: 16186/19709\n",
            "Converting SMILES to graph: 16187/19709\n",
            "Converting SMILES to graph: 16188/19709\n",
            "Converting SMILES to graph: 16189/19709\n",
            "Converting SMILES to graph: 16190/19709\n",
            "Converting SMILES to graph: 16191/19709\n",
            "Converting SMILES to graph: 16192/19709\n",
            "Converting SMILES to graph: 16193/19709\n",
            "Converting SMILES to graph: 16194/19709\n",
            "Converting SMILES to graph: 16195/19709\n",
            "Converting SMILES to graph: 16196/19709\n",
            "Converting SMILES to graph: 16197/19709\n",
            "Converting SMILES to graph: 16198/19709\n",
            "Converting SMILES to graph: 16199/19709\n",
            "Converting SMILES to graph: 16200/19709\n",
            "Converting SMILES to graph: 16201/19709\n",
            "Converting SMILES to graph: 16202/19709\n",
            "Converting SMILES to graph: 16203/19709\n",
            "Converting SMILES to graph: 16204/19709\n",
            "Converting SMILES to graph: 16205/19709\n",
            "Converting SMILES to graph: 16206/19709\n",
            "Converting SMILES to graph: 16207/19709\n",
            "Converting SMILES to graph: 16208/19709\n",
            "Converting SMILES to graph: 16209/19709\n",
            "Converting SMILES to graph: 16210/19709\n",
            "Converting SMILES to graph: 16211/19709\n",
            "Converting SMILES to graph: 16212/19709\n",
            "Converting SMILES to graph: 16213/19709\n",
            "Converting SMILES to graph: 16214/19709\n",
            "Converting SMILES to graph: 16215/19709\n",
            "Converting SMILES to graph: 16216/19709\n",
            "Converting SMILES to graph: 16217/19709\n",
            "Converting SMILES to graph: 16218/19709\n",
            "Converting SMILES to graph: 16219/19709\n",
            "Converting SMILES to graph: 16220/19709\n",
            "Converting SMILES to graph: 16221/19709\n",
            "Converting SMILES to graph: 16222/19709\n",
            "Converting SMILES to graph: 16223/19709\n",
            "Converting SMILES to graph: 16224/19709\n",
            "Converting SMILES to graph: 16225/19709\n",
            "Converting SMILES to graph: 16226/19709\n",
            "Converting SMILES to graph: 16227/19709\n",
            "Converting SMILES to graph: 16228/19709\n",
            "Converting SMILES to graph: 16229/19709\n",
            "Converting SMILES to graph: 16230/19709\n",
            "Converting SMILES to graph: 16231/19709\n",
            "Converting SMILES to graph: 16232/19709\n",
            "Converting SMILES to graph: 16233/19709\n",
            "Converting SMILES to graph: 16234/19709\n",
            "Converting SMILES to graph: 16235/19709\n",
            "Converting SMILES to graph: 16236/19709\n",
            "Converting SMILES to graph: 16237/19709\n",
            "Converting SMILES to graph: 16238/19709\n",
            "Converting SMILES to graph: 16239/19709\n",
            "Converting SMILES to graph: 16240/19709\n",
            "Converting SMILES to graph: 16241/19709\n",
            "Converting SMILES to graph: 16242/19709\n",
            "Converting SMILES to graph: 16243/19709\n",
            "Converting SMILES to graph: 16244/19709\n",
            "Converting SMILES to graph: 16245/19709\n",
            "Converting SMILES to graph: 16246/19709\n",
            "Converting SMILES to graph: 16247/19709\n",
            "Converting SMILES to graph: 16248/19709\n",
            "Converting SMILES to graph: 16249/19709\n",
            "Converting SMILES to graph: 16250/19709\n",
            "Converting SMILES to graph: 16251/19709\n",
            "Converting SMILES to graph: 16252/19709\n",
            "Converting SMILES to graph: 16253/19709\n",
            "Converting SMILES to graph: 16254/19709\n",
            "Converting SMILES to graph: 16255/19709\n",
            "Converting SMILES to graph: 16256/19709\n",
            "Converting SMILES to graph: 16257/19709\n",
            "Converting SMILES to graph: 16258/19709\n",
            "Converting SMILES to graph: 16259/19709\n",
            "Converting SMILES to graph: 16260/19709\n",
            "Converting SMILES to graph: 16261/19709\n",
            "Converting SMILES to graph: 16262/19709\n",
            "Converting SMILES to graph: 16263/19709\n",
            "Converting SMILES to graph: 16264/19709\n",
            "Converting SMILES to graph: 16265/19709\n",
            "Converting SMILES to graph: 16266/19709\n",
            "Converting SMILES to graph: 16267/19709\n",
            "Converting SMILES to graph: 16268/19709\n",
            "Converting SMILES to graph: 16269/19709\n",
            "Converting SMILES to graph: 16270/19709\n",
            "Converting SMILES to graph: 16271/19709\n",
            "Converting SMILES to graph: 16272/19709\n",
            "Converting SMILES to graph: 16273/19709\n",
            "Converting SMILES to graph: 16274/19709\n",
            "Converting SMILES to graph: 16275/19709\n",
            "Converting SMILES to graph: 16276/19709\n",
            "Converting SMILES to graph: 16277/19709\n",
            "Converting SMILES to graph: 16278/19709\n",
            "Converting SMILES to graph: 16279/19709\n",
            "Converting SMILES to graph: 16280/19709\n",
            "Converting SMILES to graph: 16281/19709\n",
            "Converting SMILES to graph: 16282/19709\n",
            "Converting SMILES to graph: 16283/19709\n",
            "Converting SMILES to graph: 16284/19709\n",
            "Converting SMILES to graph: 16285/19709\n",
            "Converting SMILES to graph: 16286/19709\n",
            "Converting SMILES to graph: 16287/19709\n",
            "Converting SMILES to graph: 16288/19709\n",
            "Converting SMILES to graph: 16289/19709\n",
            "Converting SMILES to graph: 16290/19709\n",
            "Converting SMILES to graph: 16291/19709\n",
            "Converting SMILES to graph: 16292/19709\n",
            "Converting SMILES to graph: 16293/19709\n",
            "Converting SMILES to graph: 16294/19709\n",
            "Converting SMILES to graph: 16295/19709\n",
            "Converting SMILES to graph: 16296/19709\n",
            "Converting SMILES to graph: 16297/19709\n",
            "Converting SMILES to graph: 16298/19709\n",
            "Converting SMILES to graph: 16299/19709\n",
            "Converting SMILES to graph: 16300/19709\n",
            "Converting SMILES to graph: 16301/19709\n",
            "Converting SMILES to graph: 16302/19709\n",
            "Converting SMILES to graph: 16303/19709\n",
            "Converting SMILES to graph: 16304/19709\n",
            "Converting SMILES to graph: 16305/19709\n",
            "Converting SMILES to graph: 16306/19709\n",
            "Converting SMILES to graph: 16307/19709\n",
            "Converting SMILES to graph: 16308/19709\n",
            "Converting SMILES to graph: 16309/19709\n",
            "Converting SMILES to graph: 16310/19709\n",
            "Converting SMILES to graph: 16311/19709\n",
            "Converting SMILES to graph: 16312/19709\n",
            "Converting SMILES to graph: 16313/19709\n",
            "Converting SMILES to graph: 16314/19709\n",
            "Converting SMILES to graph: 16315/19709\n",
            "Converting SMILES to graph: 16316/19709\n",
            "Converting SMILES to graph: 16317/19709\n",
            "Converting SMILES to graph: 16318/19709\n",
            "Converting SMILES to graph: 16319/19709\n",
            "Converting SMILES to graph: 16320/19709\n",
            "Converting SMILES to graph: 16321/19709\n",
            "Converting SMILES to graph: 16322/19709\n",
            "Converting SMILES to graph: 16323/19709\n",
            "Converting SMILES to graph: 16324/19709\n",
            "Converting SMILES to graph: 16325/19709\n",
            "Converting SMILES to graph: 16326/19709\n",
            "Converting SMILES to graph: 16327/19709\n",
            "Converting SMILES to graph: 16328/19709\n",
            "Converting SMILES to graph: 16329/19709\n",
            "Converting SMILES to graph: 16330/19709\n",
            "Converting SMILES to graph: 16331/19709\n",
            "Converting SMILES to graph: 16332/19709\n",
            "Converting SMILES to graph: 16333/19709\n",
            "Converting SMILES to graph: 16334/19709\n",
            "Converting SMILES to graph: 16335/19709\n",
            "Converting SMILES to graph: 16336/19709\n",
            "Converting SMILES to graph: 16337/19709\n",
            "Converting SMILES to graph: 16338/19709\n",
            "Converting SMILES to graph: 16339/19709\n",
            "Converting SMILES to graph: 16340/19709\n",
            "Converting SMILES to graph: 16341/19709\n",
            "Converting SMILES to graph: 16342/19709\n",
            "Converting SMILES to graph: 16343/19709\n",
            "Converting SMILES to graph: 16344/19709\n",
            "Converting SMILES to graph: 16345/19709\n",
            "Converting SMILES to graph: 16346/19709\n",
            "Converting SMILES to graph: 16347/19709\n",
            "Converting SMILES to graph: 16348/19709\n",
            "Converting SMILES to graph: 16349/19709\n",
            "Converting SMILES to graph: 16350/19709\n",
            "Converting SMILES to graph: 16351/19709\n",
            "Converting SMILES to graph: 16352/19709\n",
            "Converting SMILES to graph: 16353/19709\n",
            "Converting SMILES to graph: 16354/19709\n",
            "Converting SMILES to graph: 16355/19709\n",
            "Converting SMILES to graph: 16356/19709\n",
            "Converting SMILES to graph: 16357/19709\n",
            "Converting SMILES to graph: 16358/19709\n",
            "Converting SMILES to graph: 16359/19709\n",
            "Converting SMILES to graph: 16360/19709\n",
            "Converting SMILES to graph: 16361/19709\n",
            "Converting SMILES to graph: 16362/19709\n",
            "Converting SMILES to graph: 16363/19709\n",
            "Converting SMILES to graph: 16364/19709\n",
            "Converting SMILES to graph: 16365/19709\n",
            "Converting SMILES to graph: 16366/19709\n",
            "Converting SMILES to graph: 16367/19709\n",
            "Converting SMILES to graph: 16368/19709\n",
            "Converting SMILES to graph: 16369/19709\n",
            "Converting SMILES to graph: 16370/19709\n",
            "Converting SMILES to graph: 16371/19709\n",
            "Converting SMILES to graph: 16372/19709\n",
            "Converting SMILES to graph: 16373/19709\n",
            "Converting SMILES to graph: 16374/19709\n",
            "Converting SMILES to graph: 16375/19709\n",
            "Converting SMILES to graph: 16376/19709\n",
            "Converting SMILES to graph: 16377/19709\n",
            "Converting SMILES to graph: 16378/19709\n",
            "Converting SMILES to graph: 16379/19709\n",
            "Converting SMILES to graph: 16380/19709\n",
            "Converting SMILES to graph: 16381/19709\n",
            "Converting SMILES to graph: 16382/19709\n",
            "Converting SMILES to graph: 16383/19709\n",
            "Converting SMILES to graph: 16384/19709\n",
            "Converting SMILES to graph: 16385/19709\n",
            "Converting SMILES to graph: 16386/19709\n",
            "Converting SMILES to graph: 16387/19709\n",
            "Converting SMILES to graph: 16388/19709\n",
            "Converting SMILES to graph: 16389/19709\n",
            "Converting SMILES to graph: 16390/19709\n",
            "Converting SMILES to graph: 16391/19709\n",
            "Converting SMILES to graph: 16392/19709\n",
            "Converting SMILES to graph: 16393/19709\n",
            "Converting SMILES to graph: 16394/19709\n",
            "Converting SMILES to graph: 16395/19709\n",
            "Converting SMILES to graph: 16396/19709\n",
            "Converting SMILES to graph: 16397/19709\n",
            "Converting SMILES to graph: 16398/19709\n",
            "Converting SMILES to graph: 16399/19709\n",
            "Converting SMILES to graph: 16400/19709\n",
            "Converting SMILES to graph: 16401/19709\n",
            "Converting SMILES to graph: 16402/19709\n",
            "Converting SMILES to graph: 16403/19709\n",
            "Converting SMILES to graph: 16404/19709\n",
            "Converting SMILES to graph: 16405/19709\n",
            "Converting SMILES to graph: 16406/19709\n",
            "Converting SMILES to graph: 16407/19709\n",
            "Converting SMILES to graph: 16408/19709\n",
            "Converting SMILES to graph: 16409/19709\n",
            "Converting SMILES to graph: 16410/19709\n",
            "Converting SMILES to graph: 16411/19709\n",
            "Converting SMILES to graph: 16412/19709\n",
            "Converting SMILES to graph: 16413/19709\n",
            "Converting SMILES to graph: 16414/19709\n",
            "Converting SMILES to graph: 16415/19709\n",
            "Converting SMILES to graph: 16416/19709\n",
            "Converting SMILES to graph: 16417/19709\n",
            "Converting SMILES to graph: 16418/19709\n",
            "Converting SMILES to graph: 16419/19709\n",
            "Converting SMILES to graph: 16420/19709\n",
            "Converting SMILES to graph: 16421/19709\n",
            "Converting SMILES to graph: 16422/19709\n",
            "Converting SMILES to graph: 16423/19709\n",
            "Converting SMILES to graph: 16424/19709\n",
            "Converting SMILES to graph: 16425/19709\n",
            "Converting SMILES to graph: 16426/19709\n",
            "Converting SMILES to graph: 16427/19709\n",
            "Converting SMILES to graph: 16428/19709\n",
            "Converting SMILES to graph: 16429/19709\n",
            "Converting SMILES to graph: 16430/19709\n",
            "Converting SMILES to graph: 16431/19709\n",
            "Converting SMILES to graph: 16432/19709\n",
            "Converting SMILES to graph: 16433/19709\n",
            "Converting SMILES to graph: 16434/19709\n",
            "Converting SMILES to graph: 16435/19709\n",
            "Converting SMILES to graph: 16436/19709\n",
            "Converting SMILES to graph: 16437/19709\n",
            "Converting SMILES to graph: 16438/19709\n",
            "Converting SMILES to graph: 16439/19709\n",
            "Converting SMILES to graph: 16440/19709\n",
            "Converting SMILES to graph: 16441/19709\n",
            "Converting SMILES to graph: 16442/19709\n",
            "Converting SMILES to graph: 16443/19709\n",
            "Converting SMILES to graph: 16444/19709\n",
            "Converting SMILES to graph: 16445/19709\n",
            "Converting SMILES to graph: 16446/19709\n",
            "Converting SMILES to graph: 16447/19709\n",
            "Converting SMILES to graph: 16448/19709\n",
            "Converting SMILES to graph: 16449/19709\n",
            "Converting SMILES to graph: 16450/19709\n",
            "Converting SMILES to graph: 16451/19709\n",
            "Converting SMILES to graph: 16452/19709\n",
            "Converting SMILES to graph: 16453/19709\n",
            "Converting SMILES to graph: 16454/19709\n",
            "Converting SMILES to graph: 16455/19709\n",
            "Converting SMILES to graph: 16456/19709\n",
            "Converting SMILES to graph: 16457/19709\n",
            "Converting SMILES to graph: 16458/19709\n",
            "Converting SMILES to graph: 16459/19709\n",
            "Converting SMILES to graph: 16460/19709\n",
            "Converting SMILES to graph: 16461/19709\n",
            "Converting SMILES to graph: 16462/19709\n",
            "Converting SMILES to graph: 16463/19709\n",
            "Converting SMILES to graph: 16464/19709\n",
            "Converting SMILES to graph: 16465/19709\n",
            "Converting SMILES to graph: 16466/19709\n",
            "Converting SMILES to graph: 16467/19709\n",
            "Converting SMILES to graph: 16468/19709\n",
            "Converting SMILES to graph: 16469/19709\n",
            "Converting SMILES to graph: 16470/19709\n",
            "Converting SMILES to graph: 16471/19709\n",
            "Converting SMILES to graph: 16472/19709\n",
            "Converting SMILES to graph: 16473/19709\n",
            "Converting SMILES to graph: 16474/19709\n",
            "Converting SMILES to graph: 16475/19709\n",
            "Converting SMILES to graph: 16476/19709\n",
            "Converting SMILES to graph: 16477/19709\n",
            "Converting SMILES to graph: 16478/19709\n",
            "Converting SMILES to graph: 16479/19709\n",
            "Converting SMILES to graph: 16480/19709\n",
            "Converting SMILES to graph: 16481/19709\n",
            "Converting SMILES to graph: 16482/19709\n",
            "Converting SMILES to graph: 16483/19709\n",
            "Converting SMILES to graph: 16484/19709\n",
            "Converting SMILES to graph: 16485/19709\n",
            "Converting SMILES to graph: 16486/19709\n",
            "Converting SMILES to graph: 16487/19709\n",
            "Converting SMILES to graph: 16488/19709\n",
            "Converting SMILES to graph: 16489/19709\n",
            "Converting SMILES to graph: 16490/19709\n",
            "Converting SMILES to graph: 16491/19709\n",
            "Converting SMILES to graph: 16492/19709\n",
            "Converting SMILES to graph: 16493/19709\n",
            "Converting SMILES to graph: 16494/19709\n",
            "Converting SMILES to graph: 16495/19709\n",
            "Converting SMILES to graph: 16496/19709\n",
            "Converting SMILES to graph: 16497/19709\n",
            "Converting SMILES to graph: 16498/19709\n",
            "Converting SMILES to graph: 16499/19709\n",
            "Converting SMILES to graph: 16500/19709\n",
            "Converting SMILES to graph: 16501/19709\n",
            "Converting SMILES to graph: 16502/19709\n",
            "Converting SMILES to graph: 16503/19709\n",
            "Converting SMILES to graph: 16504/19709\n",
            "Converting SMILES to graph: 16505/19709\n",
            "Converting SMILES to graph: 16506/19709\n",
            "Converting SMILES to graph: 16507/19709\n",
            "Converting SMILES to graph: 16508/19709\n",
            "Converting SMILES to graph: 16509/19709\n",
            "Converting SMILES to graph: 16510/19709\n",
            "Converting SMILES to graph: 16511/19709\n",
            "Converting SMILES to graph: 16512/19709\n",
            "Converting SMILES to graph: 16513/19709\n",
            "Converting SMILES to graph: 16514/19709\n",
            "Converting SMILES to graph: 16515/19709\n",
            "Converting SMILES to graph: 16516/19709\n",
            "Converting SMILES to graph: 16517/19709\n",
            "Converting SMILES to graph: 16518/19709\n",
            "Converting SMILES to graph: 16519/19709\n",
            "Converting SMILES to graph: 16520/19709\n",
            "Converting SMILES to graph: 16521/19709\n",
            "Converting SMILES to graph: 16522/19709\n",
            "Converting SMILES to graph: 16523/19709\n",
            "Converting SMILES to graph: 16524/19709\n",
            "Converting SMILES to graph: 16525/19709\n",
            "Converting SMILES to graph: 16526/19709\n",
            "Converting SMILES to graph: 16527/19709\n",
            "Converting SMILES to graph: 16528/19709\n",
            "Converting SMILES to graph: 16529/19709\n",
            "Converting SMILES to graph: 16530/19709\n",
            "Converting SMILES to graph: 16531/19709\n",
            "Converting SMILES to graph: 16532/19709\n",
            "Converting SMILES to graph: 16533/19709\n",
            "Converting SMILES to graph: 16534/19709\n",
            "Converting SMILES to graph: 16535/19709\n",
            "Converting SMILES to graph: 16536/19709\n",
            "Converting SMILES to graph: 16537/19709\n",
            "Converting SMILES to graph: 16538/19709\n",
            "Converting SMILES to graph: 16539/19709\n",
            "Converting SMILES to graph: 16540/19709\n",
            "Converting SMILES to graph: 16541/19709\n",
            "Converting SMILES to graph: 16542/19709\n",
            "Converting SMILES to graph: 16543/19709\n",
            "Converting SMILES to graph: 16544/19709\n",
            "Converting SMILES to graph: 16545/19709\n",
            "Converting SMILES to graph: 16546/19709\n",
            "Converting SMILES to graph: 16547/19709\n",
            "Converting SMILES to graph: 16548/19709\n",
            "Converting SMILES to graph: 16549/19709\n",
            "Converting SMILES to graph: 16550/19709\n",
            "Converting SMILES to graph: 16551/19709\n",
            "Converting SMILES to graph: 16552/19709\n",
            "Converting SMILES to graph: 16553/19709\n",
            "Converting SMILES to graph: 16554/19709\n",
            "Converting SMILES to graph: 16555/19709\n",
            "Converting SMILES to graph: 16556/19709\n",
            "Converting SMILES to graph: 16557/19709\n",
            "Converting SMILES to graph: 16558/19709\n",
            "Converting SMILES to graph: 16559/19709\n",
            "Converting SMILES to graph: 16560/19709\n",
            "Converting SMILES to graph: 16561/19709\n",
            "Converting SMILES to graph: 16562/19709\n",
            "Converting SMILES to graph: 16563/19709\n",
            "Converting SMILES to graph: 16564/19709\n",
            "Converting SMILES to graph: 16565/19709\n",
            "Converting SMILES to graph: 16566/19709\n",
            "Converting SMILES to graph: 16567/19709\n",
            "Converting SMILES to graph: 16568/19709\n",
            "Converting SMILES to graph: 16569/19709\n",
            "Converting SMILES to graph: 16570/19709\n",
            "Converting SMILES to graph: 16571/19709\n",
            "Converting SMILES to graph: 16572/19709\n",
            "Converting SMILES to graph: 16573/19709\n",
            "Converting SMILES to graph: 16574/19709\n",
            "Converting SMILES to graph: 16575/19709\n",
            "Converting SMILES to graph: 16576/19709\n",
            "Converting SMILES to graph: 16577/19709\n",
            "Converting SMILES to graph: 16578/19709\n",
            "Converting SMILES to graph: 16579/19709\n",
            "Converting SMILES to graph: 16580/19709\n",
            "Converting SMILES to graph: 16581/19709\n",
            "Converting SMILES to graph: 16582/19709\n",
            "Converting SMILES to graph: 16583/19709\n",
            "Converting SMILES to graph: 16584/19709\n",
            "Converting SMILES to graph: 16585/19709\n",
            "Converting SMILES to graph: 16586/19709\n",
            "Converting SMILES to graph: 16587/19709\n",
            "Converting SMILES to graph: 16588/19709\n",
            "Converting SMILES to graph: 16589/19709\n",
            "Converting SMILES to graph: 16590/19709\n",
            "Converting SMILES to graph: 16591/19709\n",
            "Converting SMILES to graph: 16592/19709\n",
            "Converting SMILES to graph: 16593/19709\n",
            "Converting SMILES to graph: 16594/19709\n",
            "Converting SMILES to graph: 16595/19709\n",
            "Converting SMILES to graph: 16596/19709\n",
            "Converting SMILES to graph: 16597/19709\n",
            "Converting SMILES to graph: 16598/19709\n",
            "Converting SMILES to graph: 16599/19709\n",
            "Converting SMILES to graph: 16600/19709\n",
            "Converting SMILES to graph: 16601/19709\n",
            "Converting SMILES to graph: 16602/19709\n",
            "Converting SMILES to graph: 16603/19709\n",
            "Converting SMILES to graph: 16604/19709\n",
            "Converting SMILES to graph: 16605/19709\n",
            "Converting SMILES to graph: 16606/19709\n",
            "Converting SMILES to graph: 16607/19709\n",
            "Converting SMILES to graph: 16608/19709\n",
            "Converting SMILES to graph: 16609/19709\n",
            "Converting SMILES to graph: 16610/19709\n",
            "Converting SMILES to graph: 16611/19709\n",
            "Converting SMILES to graph: 16612/19709\n",
            "Converting SMILES to graph: 16613/19709\n",
            "Converting SMILES to graph: 16614/19709\n",
            "Converting SMILES to graph: 16615/19709\n",
            "Converting SMILES to graph: 16616/19709\n",
            "Converting SMILES to graph: 16617/19709\n",
            "Converting SMILES to graph: 16618/19709\n",
            "Converting SMILES to graph: 16619/19709\n",
            "Converting SMILES to graph: 16620/19709\n",
            "Converting SMILES to graph: 16621/19709\n",
            "Converting SMILES to graph: 16622/19709\n",
            "Converting SMILES to graph: 16623/19709\n",
            "Converting SMILES to graph: 16624/19709\n",
            "Converting SMILES to graph: 16625/19709\n",
            "Converting SMILES to graph: 16626/19709\n",
            "Converting SMILES to graph: 16627/19709\n",
            "Converting SMILES to graph: 16628/19709\n",
            "Converting SMILES to graph: 16629/19709\n",
            "Converting SMILES to graph: 16630/19709\n",
            "Converting SMILES to graph: 16631/19709\n",
            "Converting SMILES to graph: 16632/19709\n",
            "Converting SMILES to graph: 16633/19709\n",
            "Converting SMILES to graph: 16634/19709\n",
            "Converting SMILES to graph: 16635/19709\n",
            "Converting SMILES to graph: 16636/19709\n",
            "Converting SMILES to graph: 16637/19709\n",
            "Converting SMILES to graph: 16638/19709\n",
            "Converting SMILES to graph: 16639/19709\n",
            "Converting SMILES to graph: 16640/19709\n",
            "Converting SMILES to graph: 16641/19709\n",
            "Converting SMILES to graph: 16642/19709\n",
            "Converting SMILES to graph: 16643/19709\n",
            "Converting SMILES to graph: 16644/19709\n",
            "Converting SMILES to graph: 16645/19709\n",
            "Converting SMILES to graph: 16646/19709\n",
            "Converting SMILES to graph: 16647/19709\n",
            "Converting SMILES to graph: 16648/19709\n",
            "Converting SMILES to graph: 16649/19709\n",
            "Converting SMILES to graph: 16650/19709\n",
            "Converting SMILES to graph: 16651/19709\n",
            "Converting SMILES to graph: 16652/19709\n",
            "Converting SMILES to graph: 16653/19709\n",
            "Converting SMILES to graph: 16654/19709\n",
            "Converting SMILES to graph: 16655/19709\n",
            "Converting SMILES to graph: 16656/19709\n",
            "Converting SMILES to graph: 16657/19709\n",
            "Converting SMILES to graph: 16658/19709\n",
            "Converting SMILES to graph: 16659/19709\n",
            "Converting SMILES to graph: 16660/19709\n",
            "Converting SMILES to graph: 16661/19709\n",
            "Converting SMILES to graph: 16662/19709\n",
            "Converting SMILES to graph: 16663/19709\n",
            "Converting SMILES to graph: 16664/19709\n",
            "Converting SMILES to graph: 16665/19709\n",
            "Converting SMILES to graph: 16666/19709\n",
            "Converting SMILES to graph: 16667/19709\n",
            "Converting SMILES to graph: 16668/19709\n",
            "Converting SMILES to graph: 16669/19709\n",
            "Converting SMILES to graph: 16670/19709\n",
            "Converting SMILES to graph: 16671/19709\n",
            "Converting SMILES to graph: 16672/19709\n",
            "Converting SMILES to graph: 16673/19709\n",
            "Converting SMILES to graph: 16674/19709\n",
            "Converting SMILES to graph: 16675/19709\n",
            "Converting SMILES to graph: 16676/19709\n",
            "Converting SMILES to graph: 16677/19709\n",
            "Converting SMILES to graph: 16678/19709\n",
            "Converting SMILES to graph: 16679/19709\n",
            "Converting SMILES to graph: 16680/19709\n",
            "Converting SMILES to graph: 16681/19709\n",
            "Converting SMILES to graph: 16682/19709\n",
            "Converting SMILES to graph: 16683/19709\n",
            "Converting SMILES to graph: 16684/19709\n",
            "Converting SMILES to graph: 16685/19709\n",
            "Converting SMILES to graph: 16686/19709\n",
            "Converting SMILES to graph: 16687/19709\n",
            "Converting SMILES to graph: 16688/19709\n",
            "Converting SMILES to graph: 16689/19709\n",
            "Converting SMILES to graph: 16690/19709\n",
            "Converting SMILES to graph: 16691/19709\n",
            "Converting SMILES to graph: 16692/19709\n",
            "Converting SMILES to graph: 16693/19709\n",
            "Converting SMILES to graph: 16694/19709\n",
            "Converting SMILES to graph: 16695/19709\n",
            "Converting SMILES to graph: 16696/19709\n",
            "Converting SMILES to graph: 16697/19709\n",
            "Converting SMILES to graph: 16698/19709\n",
            "Converting SMILES to graph: 16699/19709\n",
            "Converting SMILES to graph: 16700/19709\n",
            "Converting SMILES to graph: 16701/19709\n",
            "Converting SMILES to graph: 16702/19709\n",
            "Converting SMILES to graph: 16703/19709\n",
            "Converting SMILES to graph: 16704/19709\n",
            "Converting SMILES to graph: 16705/19709\n",
            "Converting SMILES to graph: 16706/19709\n",
            "Converting SMILES to graph: 16707/19709\n",
            "Converting SMILES to graph: 16708/19709\n",
            "Converting SMILES to graph: 16709/19709\n",
            "Converting SMILES to graph: 16710/19709\n",
            "Converting SMILES to graph: 16711/19709\n",
            "Converting SMILES to graph: 16712/19709\n",
            "Converting SMILES to graph: 16713/19709\n",
            "Converting SMILES to graph: 16714/19709\n",
            "Converting SMILES to graph: 16715/19709\n",
            "Converting SMILES to graph: 16716/19709\n",
            "Converting SMILES to graph: 16717/19709\n",
            "Converting SMILES to graph: 16718/19709\n",
            "Converting SMILES to graph: 16719/19709\n",
            "Converting SMILES to graph: 16720/19709\n",
            "Converting SMILES to graph: 16721/19709\n",
            "Converting SMILES to graph: 16722/19709\n",
            "Converting SMILES to graph: 16723/19709\n",
            "Converting SMILES to graph: 16724/19709\n",
            "Converting SMILES to graph: 16725/19709\n",
            "Converting SMILES to graph: 16726/19709\n",
            "Converting SMILES to graph: 16727/19709\n",
            "Converting SMILES to graph: 16728/19709\n",
            "Converting SMILES to graph: 16729/19709\n",
            "Converting SMILES to graph: 16730/19709\n",
            "Converting SMILES to graph: 16731/19709\n",
            "Converting SMILES to graph: 16732/19709\n",
            "Converting SMILES to graph: 16733/19709\n",
            "Converting SMILES to graph: 16734/19709\n",
            "Converting SMILES to graph: 16735/19709\n",
            "Converting SMILES to graph: 16736/19709\n",
            "Converting SMILES to graph: 16737/19709\n",
            "Converting SMILES to graph: 16738/19709\n",
            "Converting SMILES to graph: 16739/19709\n",
            "Converting SMILES to graph: 16740/19709\n",
            "Converting SMILES to graph: 16741/19709\n",
            "Converting SMILES to graph: 16742/19709\n",
            "Converting SMILES to graph: 16743/19709\n",
            "Converting SMILES to graph: 16744/19709\n",
            "Converting SMILES to graph: 16745/19709\n",
            "Converting SMILES to graph: 16746/19709\n",
            "Converting SMILES to graph: 16747/19709\n",
            "Converting SMILES to graph: 16748/19709\n",
            "Converting SMILES to graph: 16749/19709\n",
            "Converting SMILES to graph: 16750/19709\n",
            "Converting SMILES to graph: 16751/19709\n",
            "Converting SMILES to graph: 16752/19709\n",
            "Converting SMILES to graph: 16753/19709\n",
            "Converting SMILES to graph: 16754/19709\n",
            "Converting SMILES to graph: 16755/19709\n",
            "Converting SMILES to graph: 16756/19709\n",
            "Converting SMILES to graph: 16757/19709\n",
            "Converting SMILES to graph: 16758/19709\n",
            "Converting SMILES to graph: 16759/19709\n",
            "Converting SMILES to graph: 16760/19709\n",
            "Converting SMILES to graph: 16761/19709\n",
            "Converting SMILES to graph: 16762/19709\n",
            "Converting SMILES to graph: 16763/19709\n",
            "Converting SMILES to graph: 16764/19709\n",
            "Converting SMILES to graph: 16765/19709\n",
            "Converting SMILES to graph: 16766/19709\n",
            "Converting SMILES to graph: 16767/19709\n",
            "Converting SMILES to graph: 16768/19709\n",
            "Converting SMILES to graph: 16769/19709\n",
            "Converting SMILES to graph: 16770/19709\n",
            "Converting SMILES to graph: 16771/19709\n",
            "Converting SMILES to graph: 16772/19709\n",
            "Converting SMILES to graph: 16773/19709\n",
            "Converting SMILES to graph: 16774/19709\n",
            "Converting SMILES to graph: 16775/19709\n",
            "Converting SMILES to graph: 16776/19709\n",
            "Converting SMILES to graph: 16777/19709\n",
            "Converting SMILES to graph: 16778/19709\n",
            "Converting SMILES to graph: 16779/19709\n",
            "Converting SMILES to graph: 16780/19709\n",
            "Converting SMILES to graph: 16781/19709\n",
            "Converting SMILES to graph: 16782/19709\n",
            "Converting SMILES to graph: 16783/19709\n",
            "Converting SMILES to graph: 16784/19709\n",
            "Converting SMILES to graph: 16785/19709\n",
            "Converting SMILES to graph: 16786/19709\n",
            "Converting SMILES to graph: 16787/19709\n",
            "Converting SMILES to graph: 16788/19709\n",
            "Converting SMILES to graph: 16789/19709\n",
            "Converting SMILES to graph: 16790/19709\n",
            "Converting SMILES to graph: 16791/19709\n",
            "Converting SMILES to graph: 16792/19709\n",
            "Converting SMILES to graph: 16793/19709\n",
            "Converting SMILES to graph: 16794/19709\n",
            "Converting SMILES to graph: 16795/19709\n",
            "Converting SMILES to graph: 16796/19709\n",
            "Converting SMILES to graph: 16797/19709\n",
            "Converting SMILES to graph: 16798/19709\n",
            "Converting SMILES to graph: 16799/19709\n",
            "Converting SMILES to graph: 16800/19709\n",
            "Converting SMILES to graph: 16801/19709\n",
            "Converting SMILES to graph: 16802/19709\n",
            "Converting SMILES to graph: 16803/19709\n",
            "Converting SMILES to graph: 16804/19709\n",
            "Converting SMILES to graph: 16805/19709\n",
            "Converting SMILES to graph: 16806/19709\n",
            "Converting SMILES to graph: 16807/19709\n",
            "Converting SMILES to graph: 16808/19709\n",
            "Converting SMILES to graph: 16809/19709\n",
            "Converting SMILES to graph: 16810/19709\n",
            "Converting SMILES to graph: 16811/19709\n",
            "Converting SMILES to graph: 16812/19709\n",
            "Converting SMILES to graph: 16813/19709\n",
            "Converting SMILES to graph: 16814/19709\n",
            "Converting SMILES to graph: 16815/19709\n",
            "Converting SMILES to graph: 16816/19709\n",
            "Converting SMILES to graph: 16817/19709\n",
            "Converting SMILES to graph: 16818/19709\n",
            "Converting SMILES to graph: 16819/19709\n",
            "Converting SMILES to graph: 16820/19709\n",
            "Converting SMILES to graph: 16821/19709\n",
            "Converting SMILES to graph: 16822/19709\n",
            "Converting SMILES to graph: 16823/19709\n",
            "Converting SMILES to graph: 16824/19709\n",
            "Converting SMILES to graph: 16825/19709\n",
            "Converting SMILES to graph: 16826/19709\n",
            "Converting SMILES to graph: 16827/19709\n",
            "Converting SMILES to graph: 16828/19709\n",
            "Converting SMILES to graph: 16829/19709\n",
            "Converting SMILES to graph: 16830/19709\n",
            "Converting SMILES to graph: 16831/19709\n",
            "Converting SMILES to graph: 16832/19709\n",
            "Converting SMILES to graph: 16833/19709\n",
            "Converting SMILES to graph: 16834/19709\n",
            "Converting SMILES to graph: 16835/19709\n",
            "Converting SMILES to graph: 16836/19709\n",
            "Converting SMILES to graph: 16837/19709\n",
            "Converting SMILES to graph: 16838/19709\n",
            "Converting SMILES to graph: 16839/19709\n",
            "Converting SMILES to graph: 16840/19709\n",
            "Converting SMILES to graph: 16841/19709\n",
            "Converting SMILES to graph: 16842/19709\n",
            "Converting SMILES to graph: 16843/19709\n",
            "Converting SMILES to graph: 16844/19709\n",
            "Converting SMILES to graph: 16845/19709\n",
            "Converting SMILES to graph: 16846/19709\n",
            "Converting SMILES to graph: 16847/19709\n",
            "Converting SMILES to graph: 16848/19709\n",
            "Converting SMILES to graph: 16849/19709\n",
            "Converting SMILES to graph: 16850/19709\n",
            "Converting SMILES to graph: 16851/19709\n",
            "Converting SMILES to graph: 16852/19709\n",
            "Converting SMILES to graph: 16853/19709\n",
            "Converting SMILES to graph: 16854/19709\n",
            "Converting SMILES to graph: 16855/19709\n",
            "Converting SMILES to graph: 16856/19709\n",
            "Converting SMILES to graph: 16857/19709\n",
            "Converting SMILES to graph: 16858/19709\n",
            "Converting SMILES to graph: 16859/19709\n",
            "Converting SMILES to graph: 16860/19709\n",
            "Converting SMILES to graph: 16861/19709\n",
            "Converting SMILES to graph: 16862/19709\n",
            "Converting SMILES to graph: 16863/19709\n",
            "Converting SMILES to graph: 16864/19709\n",
            "Converting SMILES to graph: 16865/19709\n",
            "Converting SMILES to graph: 16866/19709\n",
            "Converting SMILES to graph: 16867/19709\n",
            "Converting SMILES to graph: 16868/19709\n",
            "Converting SMILES to graph: 16869/19709\n",
            "Converting SMILES to graph: 16870/19709\n",
            "Converting SMILES to graph: 16871/19709\n",
            "Converting SMILES to graph: 16872/19709\n",
            "Converting SMILES to graph: 16873/19709\n",
            "Converting SMILES to graph: 16874/19709\n",
            "Converting SMILES to graph: 16875/19709\n",
            "Converting SMILES to graph: 16876/19709\n",
            "Converting SMILES to graph: 16877/19709\n",
            "Converting SMILES to graph: 16878/19709\n",
            "Converting SMILES to graph: 16879/19709\n",
            "Converting SMILES to graph: 16880/19709\n",
            "Converting SMILES to graph: 16881/19709\n",
            "Converting SMILES to graph: 16882/19709\n",
            "Converting SMILES to graph: 16883/19709\n",
            "Converting SMILES to graph: 16884/19709\n",
            "Converting SMILES to graph: 16885/19709\n",
            "Converting SMILES to graph: 16886/19709\n",
            "Converting SMILES to graph: 16887/19709\n",
            "Converting SMILES to graph: 16888/19709\n",
            "Converting SMILES to graph: 16889/19709\n",
            "Converting SMILES to graph: 16890/19709\n",
            "Converting SMILES to graph: 16891/19709\n",
            "Converting SMILES to graph: 16892/19709\n",
            "Converting SMILES to graph: 16893/19709\n",
            "Converting SMILES to graph: 16894/19709\n",
            "Converting SMILES to graph: 16895/19709\n",
            "Converting SMILES to graph: 16896/19709\n",
            "Converting SMILES to graph: 16897/19709\n",
            "Converting SMILES to graph: 16898/19709\n",
            "Converting SMILES to graph: 16899/19709\n",
            "Converting SMILES to graph: 16900/19709\n",
            "Converting SMILES to graph: 16901/19709\n",
            "Converting SMILES to graph: 16902/19709\n",
            "Converting SMILES to graph: 16903/19709\n",
            "Converting SMILES to graph: 16904/19709\n",
            "Converting SMILES to graph: 16905/19709\n",
            "Converting SMILES to graph: 16906/19709\n",
            "Converting SMILES to graph: 16907/19709\n",
            "Converting SMILES to graph: 16908/19709\n",
            "Converting SMILES to graph: 16909/19709\n",
            "Converting SMILES to graph: 16910/19709\n",
            "Converting SMILES to graph: 16911/19709\n",
            "Converting SMILES to graph: 16912/19709\n",
            "Converting SMILES to graph: 16913/19709\n",
            "Converting SMILES to graph: 16914/19709\n",
            "Converting SMILES to graph: 16915/19709\n",
            "Converting SMILES to graph: 16916/19709\n",
            "Converting SMILES to graph: 16917/19709\n",
            "Converting SMILES to graph: 16918/19709\n",
            "Converting SMILES to graph: 16919/19709\n",
            "Converting SMILES to graph: 16920/19709\n",
            "Converting SMILES to graph: 16921/19709\n",
            "Converting SMILES to graph: 16922/19709\n",
            "Converting SMILES to graph: 16923/19709\n",
            "Converting SMILES to graph: 16924/19709\n",
            "Converting SMILES to graph: 16925/19709\n",
            "Converting SMILES to graph: 16926/19709\n",
            "Converting SMILES to graph: 16927/19709\n",
            "Converting SMILES to graph: 16928/19709\n",
            "Converting SMILES to graph: 16929/19709\n",
            "Converting SMILES to graph: 16930/19709\n",
            "Converting SMILES to graph: 16931/19709\n",
            "Converting SMILES to graph: 16932/19709\n",
            "Converting SMILES to graph: 16933/19709\n",
            "Converting SMILES to graph: 16934/19709\n",
            "Converting SMILES to graph: 16935/19709\n",
            "Converting SMILES to graph: 16936/19709\n",
            "Converting SMILES to graph: 16937/19709\n",
            "Converting SMILES to graph: 16938/19709\n",
            "Converting SMILES to graph: 16939/19709\n",
            "Converting SMILES to graph: 16940/19709\n",
            "Converting SMILES to graph: 16941/19709\n",
            "Converting SMILES to graph: 16942/19709\n",
            "Converting SMILES to graph: 16943/19709\n",
            "Converting SMILES to graph: 16944/19709\n",
            "Converting SMILES to graph: 16945/19709\n",
            "Converting SMILES to graph: 16946/19709\n",
            "Converting SMILES to graph: 16947/19709\n",
            "Converting SMILES to graph: 16948/19709\n",
            "Converting SMILES to graph: 16949/19709\n",
            "Converting SMILES to graph: 16950/19709\n",
            "Converting SMILES to graph: 16951/19709\n",
            "Converting SMILES to graph: 16952/19709\n",
            "Converting SMILES to graph: 16953/19709\n",
            "Converting SMILES to graph: 16954/19709\n",
            "Converting SMILES to graph: 16955/19709\n",
            "Converting SMILES to graph: 16956/19709\n",
            "Converting SMILES to graph: 16957/19709\n",
            "Converting SMILES to graph: 16958/19709\n",
            "Converting SMILES to graph: 16959/19709\n",
            "Converting SMILES to graph: 16960/19709\n",
            "Converting SMILES to graph: 16961/19709\n",
            "Converting SMILES to graph: 16962/19709\n",
            "Converting SMILES to graph: 16963/19709\n",
            "Converting SMILES to graph: 16964/19709\n",
            "Converting SMILES to graph: 16965/19709\n",
            "Converting SMILES to graph: 16966/19709\n",
            "Converting SMILES to graph: 16967/19709\n",
            "Converting SMILES to graph: 16968/19709\n",
            "Converting SMILES to graph: 16969/19709\n",
            "Converting SMILES to graph: 16970/19709\n",
            "Converting SMILES to graph: 16971/19709\n",
            "Converting SMILES to graph: 16972/19709\n",
            "Converting SMILES to graph: 16973/19709\n",
            "Converting SMILES to graph: 16974/19709\n",
            "Converting SMILES to graph: 16975/19709\n",
            "Converting SMILES to graph: 16976/19709\n",
            "Converting SMILES to graph: 16977/19709\n",
            "Converting SMILES to graph: 16978/19709\n",
            "Converting SMILES to graph: 16979/19709\n",
            "Converting SMILES to graph: 16980/19709\n",
            "Converting SMILES to graph: 16981/19709\n",
            "Converting SMILES to graph: 16982/19709\n",
            "Converting SMILES to graph: 16983/19709\n",
            "Converting SMILES to graph: 16984/19709\n",
            "Converting SMILES to graph: 16985/19709\n",
            "Converting SMILES to graph: 16986/19709\n",
            "Converting SMILES to graph: 16987/19709\n",
            "Converting SMILES to graph: 16988/19709\n",
            "Converting SMILES to graph: 16989/19709\n",
            "Converting SMILES to graph: 16990/19709\n",
            "Converting SMILES to graph: 16991/19709\n",
            "Converting SMILES to graph: 16992/19709\n",
            "Converting SMILES to graph: 16993/19709\n",
            "Converting SMILES to graph: 16994/19709\n",
            "Converting SMILES to graph: 16995/19709\n",
            "Converting SMILES to graph: 16996/19709\n",
            "Converting SMILES to graph: 16997/19709\n",
            "Converting SMILES to graph: 16998/19709\n",
            "Converting SMILES to graph: 16999/19709\n",
            "Converting SMILES to graph: 17000/19709\n",
            "Converting SMILES to graph: 17001/19709\n",
            "Converting SMILES to graph: 17002/19709\n",
            "Converting SMILES to graph: 17003/19709\n",
            "Converting SMILES to graph: 17004/19709\n",
            "Converting SMILES to graph: 17005/19709\n",
            "Converting SMILES to graph: 17006/19709\n",
            "Converting SMILES to graph: 17007/19709\n",
            "Converting SMILES to graph: 17008/19709\n",
            "Converting SMILES to graph: 17009/19709\n",
            "Converting SMILES to graph: 17010/19709\n",
            "Converting SMILES to graph: 17011/19709\n",
            "Converting SMILES to graph: 17012/19709\n",
            "Converting SMILES to graph: 17013/19709\n",
            "Converting SMILES to graph: 17014/19709\n",
            "Converting SMILES to graph: 17015/19709\n",
            "Converting SMILES to graph: 17016/19709\n",
            "Converting SMILES to graph: 17017/19709\n",
            "Converting SMILES to graph: 17018/19709\n",
            "Converting SMILES to graph: 17019/19709\n",
            "Converting SMILES to graph: 17020/19709\n",
            "Converting SMILES to graph: 17021/19709\n",
            "Converting SMILES to graph: 17022/19709\n",
            "Converting SMILES to graph: 17023/19709\n",
            "Converting SMILES to graph: 17024/19709\n",
            "Converting SMILES to graph: 17025/19709\n",
            "Converting SMILES to graph: 17026/19709\n",
            "Converting SMILES to graph: 17027/19709\n",
            "Converting SMILES to graph: 17028/19709\n",
            "Converting SMILES to graph: 17029/19709\n",
            "Converting SMILES to graph: 17030/19709\n",
            "Converting SMILES to graph: 17031/19709\n",
            "Converting SMILES to graph: 17032/19709\n",
            "Converting SMILES to graph: 17033/19709\n",
            "Converting SMILES to graph: 17034/19709\n",
            "Converting SMILES to graph: 17035/19709\n",
            "Converting SMILES to graph: 17036/19709\n",
            "Converting SMILES to graph: 17037/19709\n",
            "Converting SMILES to graph: 17038/19709\n",
            "Converting SMILES to graph: 17039/19709\n",
            "Converting SMILES to graph: 17040/19709\n",
            "Converting SMILES to graph: 17041/19709\n",
            "Converting SMILES to graph: 17042/19709\n",
            "Converting SMILES to graph: 17043/19709\n",
            "Converting SMILES to graph: 17044/19709\n",
            "Converting SMILES to graph: 17045/19709\n",
            "Converting SMILES to graph: 17046/19709\n",
            "Converting SMILES to graph: 17047/19709\n",
            "Converting SMILES to graph: 17048/19709\n",
            "Converting SMILES to graph: 17049/19709\n",
            "Converting SMILES to graph: 17050/19709\n",
            "Converting SMILES to graph: 17051/19709\n",
            "Converting SMILES to graph: 17052/19709\n",
            "Converting SMILES to graph: 17053/19709\n",
            "Converting SMILES to graph: 17054/19709\n",
            "Converting SMILES to graph: 17055/19709\n",
            "Converting SMILES to graph: 17056/19709\n",
            "Converting SMILES to graph: 17057/19709\n",
            "Converting SMILES to graph: 17058/19709\n",
            "Converting SMILES to graph: 17059/19709\n",
            "Converting SMILES to graph: 17060/19709\n",
            "Converting SMILES to graph: 17061/19709\n",
            "Converting SMILES to graph: 17062/19709\n",
            "Converting SMILES to graph: 17063/19709\n",
            "Converting SMILES to graph: 17064/19709\n",
            "Converting SMILES to graph: 17065/19709\n",
            "Converting SMILES to graph: 17066/19709\n",
            "Converting SMILES to graph: 17067/19709\n",
            "Converting SMILES to graph: 17068/19709\n",
            "Converting SMILES to graph: 17069/19709\n",
            "Converting SMILES to graph: 17070/19709\n",
            "Converting SMILES to graph: 17071/19709\n",
            "Converting SMILES to graph: 17072/19709\n",
            "Converting SMILES to graph: 17073/19709\n",
            "Converting SMILES to graph: 17074/19709\n",
            "Converting SMILES to graph: 17075/19709\n",
            "Converting SMILES to graph: 17076/19709\n",
            "Converting SMILES to graph: 17077/19709\n",
            "Converting SMILES to graph: 17078/19709\n",
            "Converting SMILES to graph: 17079/19709\n",
            "Converting SMILES to graph: 17080/19709\n",
            "Converting SMILES to graph: 17081/19709\n",
            "Converting SMILES to graph: 17082/19709\n",
            "Converting SMILES to graph: 17083/19709\n",
            "Converting SMILES to graph: 17084/19709\n",
            "Converting SMILES to graph: 17085/19709\n",
            "Converting SMILES to graph: 17086/19709\n",
            "Converting SMILES to graph: 17087/19709\n",
            "Converting SMILES to graph: 17088/19709\n",
            "Converting SMILES to graph: 17089/19709\n",
            "Converting SMILES to graph: 17090/19709\n",
            "Converting SMILES to graph: 17091/19709\n",
            "Converting SMILES to graph: 17092/19709\n",
            "Converting SMILES to graph: 17093/19709\n",
            "Converting SMILES to graph: 17094/19709\n",
            "Converting SMILES to graph: 17095/19709\n",
            "Converting SMILES to graph: 17096/19709\n",
            "Converting SMILES to graph: 17097/19709\n",
            "Converting SMILES to graph: 17098/19709\n",
            "Converting SMILES to graph: 17099/19709\n",
            "Converting SMILES to graph: 17100/19709\n",
            "Converting SMILES to graph: 17101/19709\n",
            "Converting SMILES to graph: 17102/19709\n",
            "Converting SMILES to graph: 17103/19709\n",
            "Converting SMILES to graph: 17104/19709\n",
            "Converting SMILES to graph: 17105/19709\n",
            "Converting SMILES to graph: 17106/19709\n",
            "Converting SMILES to graph: 17107/19709\n",
            "Converting SMILES to graph: 17108/19709\n",
            "Converting SMILES to graph: 17109/19709\n",
            "Converting SMILES to graph: 17110/19709\n",
            "Converting SMILES to graph: 17111/19709\n",
            "Converting SMILES to graph: 17112/19709\n",
            "Converting SMILES to graph: 17113/19709\n",
            "Converting SMILES to graph: 17114/19709\n",
            "Converting SMILES to graph: 17115/19709\n",
            "Converting SMILES to graph: 17116/19709\n",
            "Converting SMILES to graph: 17117/19709\n",
            "Converting SMILES to graph: 17118/19709\n",
            "Converting SMILES to graph: 17119/19709\n",
            "Converting SMILES to graph: 17120/19709\n",
            "Converting SMILES to graph: 17121/19709\n",
            "Converting SMILES to graph: 17122/19709\n",
            "Converting SMILES to graph: 17123/19709\n",
            "Converting SMILES to graph: 17124/19709\n",
            "Converting SMILES to graph: 17125/19709\n",
            "Converting SMILES to graph: 17126/19709\n",
            "Converting SMILES to graph: 17127/19709\n",
            "Converting SMILES to graph: 17128/19709\n",
            "Converting SMILES to graph: 17129/19709\n",
            "Converting SMILES to graph: 17130/19709\n",
            "Converting SMILES to graph: 17131/19709\n",
            "Converting SMILES to graph: 17132/19709\n",
            "Converting SMILES to graph: 17133/19709\n",
            "Converting SMILES to graph: 17134/19709\n",
            "Converting SMILES to graph: 17135/19709\n",
            "Converting SMILES to graph: 17136/19709\n",
            "Converting SMILES to graph: 17137/19709\n",
            "Converting SMILES to graph: 17138/19709\n",
            "Converting SMILES to graph: 17139/19709\n",
            "Converting SMILES to graph: 17140/19709\n",
            "Converting SMILES to graph: 17141/19709\n",
            "Converting SMILES to graph: 17142/19709\n",
            "Converting SMILES to graph: 17143/19709\n",
            "Converting SMILES to graph: 17144/19709\n",
            "Converting SMILES to graph: 17145/19709\n",
            "Converting SMILES to graph: 17146/19709\n",
            "Converting SMILES to graph: 17147/19709\n",
            "Converting SMILES to graph: 17148/19709\n",
            "Converting SMILES to graph: 17149/19709\n",
            "Converting SMILES to graph: 17150/19709\n",
            "Converting SMILES to graph: 17151/19709\n",
            "Converting SMILES to graph: 17152/19709\n",
            "Converting SMILES to graph: 17153/19709\n",
            "Converting SMILES to graph: 17154/19709\n",
            "Converting SMILES to graph: 17155/19709\n",
            "Converting SMILES to graph: 17156/19709\n",
            "Converting SMILES to graph: 17157/19709\n",
            "Converting SMILES to graph: 17158/19709\n",
            "Converting SMILES to graph: 17159/19709\n",
            "Converting SMILES to graph: 17160/19709\n",
            "Converting SMILES to graph: 17161/19709\n",
            "Converting SMILES to graph: 17162/19709\n",
            "Converting SMILES to graph: 17163/19709\n",
            "Converting SMILES to graph: 17164/19709\n",
            "Converting SMILES to graph: 17165/19709\n",
            "Converting SMILES to graph: 17166/19709\n",
            "Converting SMILES to graph: 17167/19709\n",
            "Converting SMILES to graph: 17168/19709\n",
            "Converting SMILES to graph: 17169/19709\n",
            "Converting SMILES to graph: 17170/19709\n",
            "Converting SMILES to graph: 17171/19709\n",
            "Converting SMILES to graph: 17172/19709\n",
            "Converting SMILES to graph: 17173/19709\n",
            "Converting SMILES to graph: 17174/19709\n",
            "Converting SMILES to graph: 17175/19709\n",
            "Converting SMILES to graph: 17176/19709\n",
            "Converting SMILES to graph: 17177/19709\n",
            "Converting SMILES to graph: 17178/19709\n",
            "Converting SMILES to graph: 17179/19709\n",
            "Converting SMILES to graph: 17180/19709\n",
            "Converting SMILES to graph: 17181/19709\n",
            "Converting SMILES to graph: 17182/19709\n",
            "Converting SMILES to graph: 17183/19709\n",
            "Converting SMILES to graph: 17184/19709\n",
            "Converting SMILES to graph: 17185/19709\n",
            "Converting SMILES to graph: 17186/19709\n",
            "Converting SMILES to graph: 17187/19709\n",
            "Converting SMILES to graph: 17188/19709\n",
            "Converting SMILES to graph: 17189/19709\n",
            "Converting SMILES to graph: 17190/19709\n",
            "Converting SMILES to graph: 17191/19709\n",
            "Converting SMILES to graph: 17192/19709\n",
            "Converting SMILES to graph: 17193/19709\n",
            "Converting SMILES to graph: 17194/19709\n",
            "Converting SMILES to graph: 17195/19709\n",
            "Converting SMILES to graph: 17196/19709\n",
            "Converting SMILES to graph: 17197/19709\n",
            "Converting SMILES to graph: 17198/19709\n",
            "Converting SMILES to graph: 17199/19709\n",
            "Converting SMILES to graph: 17200/19709\n",
            "Converting SMILES to graph: 17201/19709\n",
            "Converting SMILES to graph: 17202/19709\n",
            "Converting SMILES to graph: 17203/19709\n",
            "Converting SMILES to graph: 17204/19709\n",
            "Converting SMILES to graph: 17205/19709\n",
            "Converting SMILES to graph: 17206/19709\n",
            "Converting SMILES to graph: 17207/19709\n",
            "Converting SMILES to graph: 17208/19709\n",
            "Converting SMILES to graph: 17209/19709\n",
            "Converting SMILES to graph: 17210/19709\n",
            "Converting SMILES to graph: 17211/19709\n",
            "Converting SMILES to graph: 17212/19709\n",
            "Converting SMILES to graph: 17213/19709\n",
            "Converting SMILES to graph: 17214/19709\n",
            "Converting SMILES to graph: 17215/19709\n",
            "Converting SMILES to graph: 17216/19709\n",
            "Converting SMILES to graph: 17217/19709\n",
            "Converting SMILES to graph: 17218/19709\n",
            "Converting SMILES to graph: 17219/19709\n",
            "Converting SMILES to graph: 17220/19709\n",
            "Converting SMILES to graph: 17221/19709\n",
            "Converting SMILES to graph: 17222/19709\n",
            "Converting SMILES to graph: 17223/19709\n",
            "Converting SMILES to graph: 17224/19709\n",
            "Converting SMILES to graph: 17225/19709\n",
            "Converting SMILES to graph: 17226/19709\n",
            "Converting SMILES to graph: 17227/19709\n",
            "Converting SMILES to graph: 17228/19709\n",
            "Converting SMILES to graph: 17229/19709\n",
            "Converting SMILES to graph: 17230/19709\n",
            "Converting SMILES to graph: 17231/19709\n",
            "Converting SMILES to graph: 17232/19709\n",
            "Converting SMILES to graph: 17233/19709\n",
            "Converting SMILES to graph: 17234/19709\n",
            "Converting SMILES to graph: 17235/19709\n",
            "Converting SMILES to graph: 17236/19709\n",
            "Converting SMILES to graph: 17237/19709\n",
            "Converting SMILES to graph: 17238/19709\n",
            "Converting SMILES to graph: 17239/19709\n",
            "Converting SMILES to graph: 17240/19709\n",
            "Converting SMILES to graph: 17241/19709\n",
            "Converting SMILES to graph: 17242/19709\n",
            "Converting SMILES to graph: 17243/19709\n",
            "Converting SMILES to graph: 17244/19709\n",
            "Converting SMILES to graph: 17245/19709\n",
            "Converting SMILES to graph: 17246/19709\n",
            "Converting SMILES to graph: 17247/19709\n",
            "Converting SMILES to graph: 17248/19709\n",
            "Converting SMILES to graph: 17249/19709\n",
            "Converting SMILES to graph: 17250/19709\n",
            "Converting SMILES to graph: 17251/19709\n",
            "Converting SMILES to graph: 17252/19709\n",
            "Converting SMILES to graph: 17253/19709\n",
            "Converting SMILES to graph: 17254/19709\n",
            "Converting SMILES to graph: 17255/19709\n",
            "Converting SMILES to graph: 17256/19709\n",
            "Converting SMILES to graph: 17257/19709\n",
            "Converting SMILES to graph: 17258/19709\n",
            "Converting SMILES to graph: 17259/19709\n",
            "Converting SMILES to graph: 17260/19709\n",
            "Converting SMILES to graph: 17261/19709\n",
            "Converting SMILES to graph: 17262/19709\n",
            "Converting SMILES to graph: 17263/19709\n",
            "Converting SMILES to graph: 17264/19709\n",
            "Converting SMILES to graph: 17265/19709\n",
            "Converting SMILES to graph: 17266/19709\n",
            "Converting SMILES to graph: 17267/19709\n",
            "Converting SMILES to graph: 17268/19709\n",
            "Converting SMILES to graph: 17269/19709\n",
            "Converting SMILES to graph: 17270/19709\n",
            "Converting SMILES to graph: 17271/19709\n",
            "Converting SMILES to graph: 17272/19709\n",
            "Converting SMILES to graph: 17273/19709\n",
            "Converting SMILES to graph: 17274/19709\n",
            "Converting SMILES to graph: 17275/19709\n",
            "Converting SMILES to graph: 17276/19709\n",
            "Converting SMILES to graph: 17277/19709\n",
            "Converting SMILES to graph: 17278/19709\n",
            "Converting SMILES to graph: 17279/19709\n",
            "Converting SMILES to graph: 17280/19709\n",
            "Converting SMILES to graph: 17281/19709\n",
            "Converting SMILES to graph: 17282/19709\n",
            "Converting SMILES to graph: 17283/19709\n",
            "Converting SMILES to graph: 17284/19709\n",
            "Converting SMILES to graph: 17285/19709\n",
            "Converting SMILES to graph: 17286/19709\n",
            "Converting SMILES to graph: 17287/19709\n",
            "Converting SMILES to graph: 17288/19709\n",
            "Converting SMILES to graph: 17289/19709\n",
            "Converting SMILES to graph: 17290/19709\n",
            "Converting SMILES to graph: 17291/19709\n",
            "Converting SMILES to graph: 17292/19709\n",
            "Converting SMILES to graph: 17293/19709\n",
            "Converting SMILES to graph: 17294/19709\n",
            "Converting SMILES to graph: 17295/19709\n",
            "Converting SMILES to graph: 17296/19709\n",
            "Converting SMILES to graph: 17297/19709\n",
            "Converting SMILES to graph: 17298/19709\n",
            "Converting SMILES to graph: 17299/19709\n",
            "Converting SMILES to graph: 17300/19709\n",
            "Converting SMILES to graph: 17301/19709\n",
            "Converting SMILES to graph: 17302/19709\n",
            "Converting SMILES to graph: 17303/19709\n",
            "Converting SMILES to graph: 17304/19709\n",
            "Converting SMILES to graph: 17305/19709\n",
            "Converting SMILES to graph: 17306/19709\n",
            "Converting SMILES to graph: 17307/19709\n",
            "Converting SMILES to graph: 17308/19709\n",
            "Converting SMILES to graph: 17309/19709\n",
            "Converting SMILES to graph: 17310/19709\n",
            "Converting SMILES to graph: 17311/19709\n",
            "Converting SMILES to graph: 17312/19709\n",
            "Converting SMILES to graph: 17313/19709\n",
            "Converting SMILES to graph: 17314/19709\n",
            "Converting SMILES to graph: 17315/19709\n",
            "Converting SMILES to graph: 17316/19709\n",
            "Converting SMILES to graph: 17317/19709\n",
            "Converting SMILES to graph: 17318/19709\n",
            "Converting SMILES to graph: 17319/19709\n",
            "Converting SMILES to graph: 17320/19709\n",
            "Converting SMILES to graph: 17321/19709\n",
            "Converting SMILES to graph: 17322/19709\n",
            "Converting SMILES to graph: 17323/19709\n",
            "Converting SMILES to graph: 17324/19709\n",
            "Converting SMILES to graph: 17325/19709\n",
            "Converting SMILES to graph: 17326/19709\n",
            "Converting SMILES to graph: 17327/19709\n",
            "Converting SMILES to graph: 17328/19709\n",
            "Converting SMILES to graph: 17329/19709\n",
            "Converting SMILES to graph: 17330/19709\n",
            "Converting SMILES to graph: 17331/19709\n",
            "Converting SMILES to graph: 17332/19709\n",
            "Converting SMILES to graph: 17333/19709\n",
            "Converting SMILES to graph: 17334/19709\n",
            "Converting SMILES to graph: 17335/19709\n",
            "Converting SMILES to graph: 17336/19709\n",
            "Converting SMILES to graph: 17337/19709\n",
            "Converting SMILES to graph: 17338/19709\n",
            "Converting SMILES to graph: 17339/19709\n",
            "Converting SMILES to graph: 17340/19709\n",
            "Converting SMILES to graph: 17341/19709\n",
            "Converting SMILES to graph: 17342/19709\n",
            "Converting SMILES to graph: 17343/19709\n",
            "Converting SMILES to graph: 17344/19709\n",
            "Converting SMILES to graph: 17345/19709\n",
            "Converting SMILES to graph: 17346/19709\n",
            "Converting SMILES to graph: 17347/19709\n",
            "Converting SMILES to graph: 17348/19709\n",
            "Converting SMILES to graph: 17349/19709\n",
            "Converting SMILES to graph: 17350/19709\n",
            "Converting SMILES to graph: 17351/19709\n",
            "Converting SMILES to graph: 17352/19709\n",
            "Converting SMILES to graph: 17353/19709\n",
            "Converting SMILES to graph: 17354/19709\n",
            "Converting SMILES to graph: 17355/19709\n",
            "Converting SMILES to graph: 17356/19709\n",
            "Converting SMILES to graph: 17357/19709\n",
            "Converting SMILES to graph: 17358/19709\n",
            "Converting SMILES to graph: 17359/19709\n",
            "Converting SMILES to graph: 17360/19709\n",
            "Converting SMILES to graph: 17361/19709\n",
            "Converting SMILES to graph: 17362/19709\n",
            "Converting SMILES to graph: 17363/19709\n",
            "Converting SMILES to graph: 17364/19709\n",
            "Converting SMILES to graph: 17365/19709\n",
            "Converting SMILES to graph: 17366/19709\n",
            "Converting SMILES to graph: 17367/19709\n",
            "Converting SMILES to graph: 17368/19709\n",
            "Converting SMILES to graph: 17369/19709\n",
            "Converting SMILES to graph: 17370/19709\n",
            "Converting SMILES to graph: 17371/19709\n",
            "Converting SMILES to graph: 17372/19709\n",
            "Converting SMILES to graph: 17373/19709\n",
            "Converting SMILES to graph: 17374/19709\n",
            "Converting SMILES to graph: 17375/19709\n",
            "Converting SMILES to graph: 17376/19709\n",
            "Converting SMILES to graph: 17377/19709\n",
            "Converting SMILES to graph: 17378/19709\n",
            "Converting SMILES to graph: 17379/19709\n",
            "Converting SMILES to graph: 17380/19709\n",
            "Converting SMILES to graph: 17381/19709\n",
            "Converting SMILES to graph: 17382/19709\n",
            "Converting SMILES to graph: 17383/19709\n",
            "Converting SMILES to graph: 17384/19709\n",
            "Converting SMILES to graph: 17385/19709\n",
            "Converting SMILES to graph: 17386/19709\n",
            "Converting SMILES to graph: 17387/19709\n",
            "Converting SMILES to graph: 17388/19709\n",
            "Converting SMILES to graph: 17389/19709\n",
            "Converting SMILES to graph: 17390/19709\n",
            "Converting SMILES to graph: 17391/19709\n",
            "Converting SMILES to graph: 17392/19709\n",
            "Converting SMILES to graph: 17393/19709\n",
            "Converting SMILES to graph: 17394/19709\n",
            "Converting SMILES to graph: 17395/19709\n",
            "Converting SMILES to graph: 17396/19709\n",
            "Converting SMILES to graph: 17397/19709\n",
            "Converting SMILES to graph: 17398/19709\n",
            "Converting SMILES to graph: 17399/19709\n",
            "Converting SMILES to graph: 17400/19709\n",
            "Converting SMILES to graph: 17401/19709\n",
            "Converting SMILES to graph: 17402/19709\n",
            "Converting SMILES to graph: 17403/19709\n",
            "Converting SMILES to graph: 17404/19709\n",
            "Converting SMILES to graph: 17405/19709\n",
            "Converting SMILES to graph: 17406/19709\n",
            "Converting SMILES to graph: 17407/19709\n",
            "Converting SMILES to graph: 17408/19709\n",
            "Converting SMILES to graph: 17409/19709\n",
            "Converting SMILES to graph: 17410/19709\n",
            "Converting SMILES to graph: 17411/19709\n",
            "Converting SMILES to graph: 17412/19709\n",
            "Converting SMILES to graph: 17413/19709\n",
            "Converting SMILES to graph: 17414/19709\n",
            "Converting SMILES to graph: 17415/19709\n",
            "Converting SMILES to graph: 17416/19709\n",
            "Converting SMILES to graph: 17417/19709\n",
            "Converting SMILES to graph: 17418/19709\n",
            "Converting SMILES to graph: 17419/19709\n",
            "Converting SMILES to graph: 17420/19709\n",
            "Converting SMILES to graph: 17421/19709\n",
            "Converting SMILES to graph: 17422/19709\n",
            "Converting SMILES to graph: 17423/19709\n",
            "Converting SMILES to graph: 17424/19709\n",
            "Converting SMILES to graph: 17425/19709\n",
            "Converting SMILES to graph: 17426/19709\n",
            "Converting SMILES to graph: 17427/19709\n",
            "Converting SMILES to graph: 17428/19709\n",
            "Converting SMILES to graph: 17429/19709\n",
            "Converting SMILES to graph: 17430/19709\n",
            "Converting SMILES to graph: 17431/19709\n",
            "Converting SMILES to graph: 17432/19709\n",
            "Converting SMILES to graph: 17433/19709\n",
            "Converting SMILES to graph: 17434/19709\n",
            "Converting SMILES to graph: 17435/19709\n",
            "Converting SMILES to graph: 17436/19709\n",
            "Converting SMILES to graph: 17437/19709\n",
            "Converting SMILES to graph: 17438/19709\n",
            "Converting SMILES to graph: 17439/19709\n",
            "Converting SMILES to graph: 17440/19709\n",
            "Converting SMILES to graph: 17441/19709\n",
            "Converting SMILES to graph: 17442/19709\n",
            "Converting SMILES to graph: 17443/19709\n",
            "Converting SMILES to graph: 17444/19709\n",
            "Converting SMILES to graph: 17445/19709\n",
            "Converting SMILES to graph: 17446/19709\n",
            "Converting SMILES to graph: 17447/19709\n",
            "Converting SMILES to graph: 17448/19709\n",
            "Converting SMILES to graph: 17449/19709\n",
            "Converting SMILES to graph: 17450/19709\n",
            "Converting SMILES to graph: 17451/19709\n",
            "Converting SMILES to graph: 17452/19709\n",
            "Converting SMILES to graph: 17453/19709\n",
            "Converting SMILES to graph: 17454/19709\n",
            "Converting SMILES to graph: 17455/19709\n",
            "Converting SMILES to graph: 17456/19709\n",
            "Converting SMILES to graph: 17457/19709\n",
            "Converting SMILES to graph: 17458/19709\n",
            "Converting SMILES to graph: 17459/19709\n",
            "Converting SMILES to graph: 17460/19709\n",
            "Converting SMILES to graph: 17461/19709\n",
            "Converting SMILES to graph: 17462/19709\n",
            "Converting SMILES to graph: 17463/19709\n",
            "Converting SMILES to graph: 17464/19709\n",
            "Converting SMILES to graph: 17465/19709\n",
            "Converting SMILES to graph: 17466/19709\n",
            "Converting SMILES to graph: 17467/19709\n",
            "Converting SMILES to graph: 17468/19709\n",
            "Converting SMILES to graph: 17469/19709\n",
            "Converting SMILES to graph: 17470/19709\n",
            "Converting SMILES to graph: 17471/19709\n",
            "Converting SMILES to graph: 17472/19709\n",
            "Converting SMILES to graph: 17473/19709\n",
            "Converting SMILES to graph: 17474/19709\n",
            "Converting SMILES to graph: 17475/19709\n",
            "Converting SMILES to graph: 17476/19709\n",
            "Converting SMILES to graph: 17477/19709\n",
            "Converting SMILES to graph: 17478/19709\n",
            "Converting SMILES to graph: 17479/19709\n",
            "Converting SMILES to graph: 17480/19709\n",
            "Converting SMILES to graph: 17481/19709\n",
            "Converting SMILES to graph: 17482/19709\n",
            "Converting SMILES to graph: 17483/19709\n",
            "Converting SMILES to graph: 17484/19709\n",
            "Converting SMILES to graph: 17485/19709\n",
            "Converting SMILES to graph: 17486/19709\n",
            "Converting SMILES to graph: 17487/19709\n",
            "Converting SMILES to graph: 17488/19709\n",
            "Converting SMILES to graph: 17489/19709\n",
            "Converting SMILES to graph: 17490/19709\n",
            "Converting SMILES to graph: 17491/19709\n",
            "Converting SMILES to graph: 17492/19709\n",
            "Converting SMILES to graph: 17493/19709\n",
            "Converting SMILES to graph: 17494/19709\n",
            "Converting SMILES to graph: 17495/19709\n",
            "Converting SMILES to graph: 17496/19709\n",
            "Converting SMILES to graph: 17497/19709\n",
            "Converting SMILES to graph: 17498/19709\n",
            "Converting SMILES to graph: 17499/19709\n",
            "Converting SMILES to graph: 17500/19709\n",
            "Converting SMILES to graph: 17501/19709\n",
            "Converting SMILES to graph: 17502/19709\n",
            "Converting SMILES to graph: 17503/19709\n",
            "Converting SMILES to graph: 17504/19709\n",
            "Converting SMILES to graph: 17505/19709\n",
            "Converting SMILES to graph: 17506/19709\n",
            "Converting SMILES to graph: 17507/19709\n",
            "Converting SMILES to graph: 17508/19709\n",
            "Converting SMILES to graph: 17509/19709\n",
            "Converting SMILES to graph: 17510/19709\n",
            "Converting SMILES to graph: 17511/19709\n",
            "Converting SMILES to graph: 17512/19709\n",
            "Converting SMILES to graph: 17513/19709\n",
            "Converting SMILES to graph: 17514/19709\n",
            "Converting SMILES to graph: 17515/19709\n",
            "Converting SMILES to graph: 17516/19709\n",
            "Converting SMILES to graph: 17517/19709\n",
            "Converting SMILES to graph: 17518/19709\n",
            "Converting SMILES to graph: 17519/19709\n",
            "Converting SMILES to graph: 17520/19709\n",
            "Converting SMILES to graph: 17521/19709\n",
            "Converting SMILES to graph: 17522/19709\n",
            "Converting SMILES to graph: 17523/19709\n",
            "Converting SMILES to graph: 17524/19709\n",
            "Converting SMILES to graph: 17525/19709\n",
            "Converting SMILES to graph: 17526/19709\n",
            "Converting SMILES to graph: 17527/19709\n",
            "Converting SMILES to graph: 17528/19709\n",
            "Converting SMILES to graph: 17529/19709\n",
            "Converting SMILES to graph: 17530/19709\n",
            "Converting SMILES to graph: 17531/19709\n",
            "Converting SMILES to graph: 17532/19709\n",
            "Converting SMILES to graph: 17533/19709\n",
            "Converting SMILES to graph: 17534/19709\n",
            "Converting SMILES to graph: 17535/19709\n",
            "Converting SMILES to graph: 17536/19709\n",
            "Converting SMILES to graph: 17537/19709\n",
            "Converting SMILES to graph: 17538/19709\n",
            "Converting SMILES to graph: 17539/19709\n",
            "Converting SMILES to graph: 17540/19709\n",
            "Converting SMILES to graph: 17541/19709\n",
            "Converting SMILES to graph: 17542/19709\n",
            "Converting SMILES to graph: 17543/19709\n",
            "Converting SMILES to graph: 17544/19709\n",
            "Converting SMILES to graph: 17545/19709\n",
            "Converting SMILES to graph: 17546/19709\n",
            "Converting SMILES to graph: 17547/19709\n",
            "Converting SMILES to graph: 17548/19709\n",
            "Converting SMILES to graph: 17549/19709\n",
            "Converting SMILES to graph: 17550/19709\n",
            "Converting SMILES to graph: 17551/19709\n",
            "Converting SMILES to graph: 17552/19709\n",
            "Converting SMILES to graph: 17553/19709\n",
            "Converting SMILES to graph: 17554/19709\n",
            "Converting SMILES to graph: 17555/19709\n",
            "Converting SMILES to graph: 17556/19709\n",
            "Converting SMILES to graph: 17557/19709\n",
            "Converting SMILES to graph: 17558/19709\n",
            "Converting SMILES to graph: 17559/19709\n",
            "Converting SMILES to graph: 17560/19709\n",
            "Converting SMILES to graph: 17561/19709\n",
            "Converting SMILES to graph: 17562/19709\n",
            "Converting SMILES to graph: 17563/19709\n",
            "Converting SMILES to graph: 17564/19709\n",
            "Converting SMILES to graph: 17565/19709\n",
            "Converting SMILES to graph: 17566/19709\n",
            "Converting SMILES to graph: 17567/19709\n",
            "Converting SMILES to graph: 17568/19709\n",
            "Converting SMILES to graph: 17569/19709\n",
            "Converting SMILES to graph: 17570/19709\n",
            "Converting SMILES to graph: 17571/19709\n",
            "Converting SMILES to graph: 17572/19709\n",
            "Converting SMILES to graph: 17573/19709\n",
            "Converting SMILES to graph: 17574/19709\n",
            "Converting SMILES to graph: 17575/19709\n",
            "Converting SMILES to graph: 17576/19709\n",
            "Converting SMILES to graph: 17577/19709\n",
            "Converting SMILES to graph: 17578/19709\n",
            "Converting SMILES to graph: 17579/19709\n",
            "Converting SMILES to graph: 17580/19709\n",
            "Converting SMILES to graph: 17581/19709\n",
            "Converting SMILES to graph: 17582/19709\n",
            "Converting SMILES to graph: 17583/19709\n",
            "Converting SMILES to graph: 17584/19709\n",
            "Converting SMILES to graph: 17585/19709\n",
            "Converting SMILES to graph: 17586/19709\n",
            "Converting SMILES to graph: 17587/19709\n",
            "Converting SMILES to graph: 17588/19709\n",
            "Converting SMILES to graph: 17589/19709\n",
            "Converting SMILES to graph: 17590/19709\n",
            "Converting SMILES to graph: 17591/19709\n",
            "Converting SMILES to graph: 17592/19709\n",
            "Converting SMILES to graph: 17593/19709\n",
            "Converting SMILES to graph: 17594/19709\n",
            "Converting SMILES to graph: 17595/19709\n",
            "Converting SMILES to graph: 17596/19709\n",
            "Converting SMILES to graph: 17597/19709\n",
            "Converting SMILES to graph: 17598/19709\n",
            "Converting SMILES to graph: 17599/19709\n",
            "Converting SMILES to graph: 17600/19709\n",
            "Converting SMILES to graph: 17601/19709\n",
            "Converting SMILES to graph: 17602/19709\n",
            "Converting SMILES to graph: 17603/19709\n",
            "Converting SMILES to graph: 17604/19709\n",
            "Converting SMILES to graph: 17605/19709\n",
            "Converting SMILES to graph: 17606/19709\n",
            "Converting SMILES to graph: 17607/19709\n",
            "Converting SMILES to graph: 17608/19709\n",
            "Converting SMILES to graph: 17609/19709\n",
            "Converting SMILES to graph: 17610/19709\n",
            "Converting SMILES to graph: 17611/19709\n",
            "Converting SMILES to graph: 17612/19709\n",
            "Converting SMILES to graph: 17613/19709\n",
            "Converting SMILES to graph: 17614/19709\n",
            "Converting SMILES to graph: 17615/19709\n",
            "Converting SMILES to graph: 17616/19709\n",
            "Converting SMILES to graph: 17617/19709\n",
            "Converting SMILES to graph: 17618/19709\n",
            "Converting SMILES to graph: 17619/19709\n",
            "Converting SMILES to graph: 17620/19709\n",
            "Converting SMILES to graph: 17621/19709\n",
            "Converting SMILES to graph: 17622/19709\n",
            "Converting SMILES to graph: 17623/19709\n",
            "Converting SMILES to graph: 17624/19709\n",
            "Converting SMILES to graph: 17625/19709\n",
            "Converting SMILES to graph: 17626/19709\n",
            "Converting SMILES to graph: 17627/19709\n",
            "Converting SMILES to graph: 17628/19709\n",
            "Converting SMILES to graph: 17629/19709\n",
            "Converting SMILES to graph: 17630/19709\n",
            "Converting SMILES to graph: 17631/19709\n",
            "Converting SMILES to graph: 17632/19709\n",
            "Converting SMILES to graph: 17633/19709\n",
            "Converting SMILES to graph: 17634/19709\n",
            "Converting SMILES to graph: 17635/19709\n",
            "Converting SMILES to graph: 17636/19709\n",
            "Converting SMILES to graph: 17637/19709\n",
            "Converting SMILES to graph: 17638/19709\n",
            "Converting SMILES to graph: 17639/19709\n",
            "Converting SMILES to graph: 17640/19709\n",
            "Converting SMILES to graph: 17641/19709\n",
            "Converting SMILES to graph: 17642/19709\n",
            "Converting SMILES to graph: 17643/19709\n",
            "Converting SMILES to graph: 17644/19709\n",
            "Converting SMILES to graph: 17645/19709\n",
            "Converting SMILES to graph: 17646/19709\n",
            "Converting SMILES to graph: 17647/19709\n",
            "Converting SMILES to graph: 17648/19709\n",
            "Converting SMILES to graph: 17649/19709\n",
            "Converting SMILES to graph: 17650/19709\n",
            "Converting SMILES to graph: 17651/19709\n",
            "Converting SMILES to graph: 17652/19709\n",
            "Converting SMILES to graph: 17653/19709\n",
            "Converting SMILES to graph: 17654/19709\n",
            "Converting SMILES to graph: 17655/19709\n",
            "Converting SMILES to graph: 17656/19709\n",
            "Converting SMILES to graph: 17657/19709\n",
            "Converting SMILES to graph: 17658/19709\n",
            "Converting SMILES to graph: 17659/19709\n",
            "Converting SMILES to graph: 17660/19709\n",
            "Converting SMILES to graph: 17661/19709\n",
            "Converting SMILES to graph: 17662/19709\n",
            "Converting SMILES to graph: 17663/19709\n",
            "Converting SMILES to graph: 17664/19709\n",
            "Converting SMILES to graph: 17665/19709\n",
            "Converting SMILES to graph: 17666/19709\n",
            "Converting SMILES to graph: 17667/19709\n",
            "Converting SMILES to graph: 17668/19709\n",
            "Converting SMILES to graph: 17669/19709\n",
            "Converting SMILES to graph: 17670/19709\n",
            "Converting SMILES to graph: 17671/19709\n",
            "Converting SMILES to graph: 17672/19709\n",
            "Converting SMILES to graph: 17673/19709\n",
            "Converting SMILES to graph: 17674/19709\n",
            "Converting SMILES to graph: 17675/19709\n",
            "Converting SMILES to graph: 17676/19709\n",
            "Converting SMILES to graph: 17677/19709\n",
            "Converting SMILES to graph: 17678/19709\n",
            "Converting SMILES to graph: 17679/19709\n",
            "Converting SMILES to graph: 17680/19709\n",
            "Converting SMILES to graph: 17681/19709\n",
            "Converting SMILES to graph: 17682/19709\n",
            "Converting SMILES to graph: 17683/19709\n",
            "Converting SMILES to graph: 17684/19709\n",
            "Converting SMILES to graph: 17685/19709\n",
            "Converting SMILES to graph: 17686/19709\n",
            "Converting SMILES to graph: 17687/19709\n",
            "Converting SMILES to graph: 17688/19709\n",
            "Converting SMILES to graph: 17689/19709\n",
            "Converting SMILES to graph: 17690/19709\n",
            "Converting SMILES to graph: 17691/19709\n",
            "Converting SMILES to graph: 17692/19709\n",
            "Converting SMILES to graph: 17693/19709\n",
            "Converting SMILES to graph: 17694/19709\n",
            "Converting SMILES to graph: 17695/19709\n",
            "Converting SMILES to graph: 17696/19709\n",
            "Converting SMILES to graph: 17697/19709\n",
            "Converting SMILES to graph: 17698/19709\n",
            "Converting SMILES to graph: 17699/19709\n",
            "Converting SMILES to graph: 17700/19709\n",
            "Converting SMILES to graph: 17701/19709\n",
            "Converting SMILES to graph: 17702/19709\n",
            "Converting SMILES to graph: 17703/19709\n",
            "Converting SMILES to graph: 17704/19709\n",
            "Converting SMILES to graph: 17705/19709\n",
            "Converting SMILES to graph: 17706/19709\n",
            "Converting SMILES to graph: 17707/19709\n",
            "Converting SMILES to graph: 17708/19709\n",
            "Converting SMILES to graph: 17709/19709\n",
            "Converting SMILES to graph: 17710/19709\n",
            "Converting SMILES to graph: 17711/19709\n",
            "Converting SMILES to graph: 17712/19709\n",
            "Converting SMILES to graph: 17713/19709\n",
            "Converting SMILES to graph: 17714/19709\n",
            "Converting SMILES to graph: 17715/19709\n",
            "Converting SMILES to graph: 17716/19709\n",
            "Converting SMILES to graph: 17717/19709\n",
            "Converting SMILES to graph: 17718/19709\n",
            "Converting SMILES to graph: 17719/19709\n",
            "Converting SMILES to graph: 17720/19709\n",
            "Converting SMILES to graph: 17721/19709\n",
            "Converting SMILES to graph: 17722/19709\n",
            "Converting SMILES to graph: 17723/19709\n",
            "Converting SMILES to graph: 17724/19709\n",
            "Converting SMILES to graph: 17725/19709\n",
            "Converting SMILES to graph: 17726/19709\n",
            "Converting SMILES to graph: 17727/19709\n",
            "Converting SMILES to graph: 17728/19709\n",
            "Converting SMILES to graph: 17729/19709\n",
            "Converting SMILES to graph: 17730/19709\n",
            "Converting SMILES to graph: 17731/19709\n",
            "Converting SMILES to graph: 17732/19709\n",
            "Converting SMILES to graph: 17733/19709\n",
            "Converting SMILES to graph: 17734/19709\n",
            "Converting SMILES to graph: 17735/19709\n",
            "Converting SMILES to graph: 17736/19709\n",
            "Converting SMILES to graph: 17737/19709\n",
            "Converting SMILES to graph: 17738/19709\n",
            "Converting SMILES to graph: 17739/19709\n",
            "Converting SMILES to graph: 17740/19709\n",
            "Converting SMILES to graph: 17741/19709\n",
            "Converting SMILES to graph: 17742/19709\n",
            "Converting SMILES to graph: 17743/19709\n",
            "Converting SMILES to graph: 17744/19709\n",
            "Converting SMILES to graph: 17745/19709\n",
            "Converting SMILES to graph: 17746/19709\n",
            "Converting SMILES to graph: 17747/19709\n",
            "Converting SMILES to graph: 17748/19709\n",
            "Converting SMILES to graph: 17749/19709\n",
            "Converting SMILES to graph: 17750/19709\n",
            "Converting SMILES to graph: 17751/19709\n",
            "Converting SMILES to graph: 17752/19709\n",
            "Converting SMILES to graph: 17753/19709\n",
            "Converting SMILES to graph: 17754/19709\n",
            "Converting SMILES to graph: 17755/19709\n",
            "Converting SMILES to graph: 17756/19709\n",
            "Converting SMILES to graph: 17757/19709\n",
            "Converting SMILES to graph: 17758/19709\n",
            "Converting SMILES to graph: 17759/19709\n",
            "Converting SMILES to graph: 17760/19709\n",
            "Converting SMILES to graph: 17761/19709\n",
            "Converting SMILES to graph: 17762/19709\n",
            "Converting SMILES to graph: 17763/19709\n",
            "Converting SMILES to graph: 17764/19709\n",
            "Converting SMILES to graph: 17765/19709\n",
            "Converting SMILES to graph: 17766/19709\n",
            "Converting SMILES to graph: 17767/19709\n",
            "Converting SMILES to graph: 17768/19709\n",
            "Converting SMILES to graph: 17769/19709\n",
            "Converting SMILES to graph: 17770/19709\n",
            "Converting SMILES to graph: 17771/19709\n",
            "Converting SMILES to graph: 17772/19709\n",
            "Converting SMILES to graph: 17773/19709\n",
            "Converting SMILES to graph: 17774/19709\n",
            "Converting SMILES to graph: 17775/19709\n",
            "Converting SMILES to graph: 17776/19709\n",
            "Converting SMILES to graph: 17777/19709\n",
            "Converting SMILES to graph: 17778/19709\n",
            "Converting SMILES to graph: 17779/19709\n",
            "Converting SMILES to graph: 17780/19709\n",
            "Converting SMILES to graph: 17781/19709\n",
            "Converting SMILES to graph: 17782/19709\n",
            "Converting SMILES to graph: 17783/19709\n",
            "Converting SMILES to graph: 17784/19709\n",
            "Converting SMILES to graph: 17785/19709\n",
            "Converting SMILES to graph: 17786/19709\n",
            "Converting SMILES to graph: 17787/19709\n",
            "Converting SMILES to graph: 17788/19709\n",
            "Converting SMILES to graph: 17789/19709\n",
            "Converting SMILES to graph: 17790/19709\n",
            "Converting SMILES to graph: 17791/19709\n",
            "Converting SMILES to graph: 17792/19709\n",
            "Converting SMILES to graph: 17793/19709\n",
            "Converting SMILES to graph: 17794/19709\n",
            "Converting SMILES to graph: 17795/19709\n",
            "Converting SMILES to graph: 17796/19709\n",
            "Converting SMILES to graph: 17797/19709\n",
            "Converting SMILES to graph: 17798/19709\n",
            "Converting SMILES to graph: 17799/19709\n",
            "Converting SMILES to graph: 17800/19709\n",
            "Converting SMILES to graph: 17801/19709\n",
            "Converting SMILES to graph: 17802/19709\n",
            "Converting SMILES to graph: 17803/19709\n",
            "Converting SMILES to graph: 17804/19709\n",
            "Converting SMILES to graph: 17805/19709\n",
            "Converting SMILES to graph: 17806/19709\n",
            "Converting SMILES to graph: 17807/19709\n",
            "Converting SMILES to graph: 17808/19709\n",
            "Converting SMILES to graph: 17809/19709\n",
            "Converting SMILES to graph: 17810/19709\n",
            "Converting SMILES to graph: 17811/19709\n",
            "Converting SMILES to graph: 17812/19709\n",
            "Converting SMILES to graph: 17813/19709\n",
            "Converting SMILES to graph: 17814/19709\n",
            "Converting SMILES to graph: 17815/19709\n",
            "Converting SMILES to graph: 17816/19709\n",
            "Converting SMILES to graph: 17817/19709\n",
            "Converting SMILES to graph: 17818/19709\n",
            "Converting SMILES to graph: 17819/19709\n",
            "Converting SMILES to graph: 17820/19709\n",
            "Converting SMILES to graph: 17821/19709\n",
            "Converting SMILES to graph: 17822/19709\n",
            "Converting SMILES to graph: 17823/19709\n",
            "Converting SMILES to graph: 17824/19709\n",
            "Converting SMILES to graph: 17825/19709\n",
            "Converting SMILES to graph: 17826/19709\n",
            "Converting SMILES to graph: 17827/19709\n",
            "Converting SMILES to graph: 17828/19709\n",
            "Converting SMILES to graph: 17829/19709\n",
            "Converting SMILES to graph: 17830/19709\n",
            "Converting SMILES to graph: 17831/19709\n",
            "Converting SMILES to graph: 17832/19709\n",
            "Converting SMILES to graph: 17833/19709\n",
            "Converting SMILES to graph: 17834/19709\n",
            "Converting SMILES to graph: 17835/19709\n",
            "Converting SMILES to graph: 17836/19709\n",
            "Converting SMILES to graph: 17837/19709\n",
            "Converting SMILES to graph: 17838/19709\n",
            "Converting SMILES to graph: 17839/19709\n",
            "Converting SMILES to graph: 17840/19709\n",
            "Converting SMILES to graph: 17841/19709\n",
            "Converting SMILES to graph: 17842/19709\n",
            "Converting SMILES to graph: 17843/19709\n",
            "Converting SMILES to graph: 17844/19709\n",
            "Converting SMILES to graph: 17845/19709\n",
            "Converting SMILES to graph: 17846/19709\n",
            "Converting SMILES to graph: 17847/19709\n",
            "Converting SMILES to graph: 17848/19709\n",
            "Converting SMILES to graph: 17849/19709\n",
            "Converting SMILES to graph: 17850/19709\n",
            "Converting SMILES to graph: 17851/19709\n",
            "Converting SMILES to graph: 17852/19709\n",
            "Converting SMILES to graph: 17853/19709\n",
            "Converting SMILES to graph: 17854/19709\n",
            "Converting SMILES to graph: 17855/19709\n",
            "Converting SMILES to graph: 17856/19709\n",
            "Converting SMILES to graph: 17857/19709\n",
            "Converting SMILES to graph: 17858/19709\n",
            "Converting SMILES to graph: 17859/19709\n",
            "Converting SMILES to graph: 17860/19709\n",
            "Converting SMILES to graph: 17861/19709\n",
            "Converting SMILES to graph: 17862/19709\n",
            "Converting SMILES to graph: 17863/19709\n",
            "Converting SMILES to graph: 17864/19709\n",
            "Converting SMILES to graph: 17865/19709\n",
            "Converting SMILES to graph: 17866/19709\n",
            "Converting SMILES to graph: 17867/19709\n",
            "Converting SMILES to graph: 17868/19709\n",
            "Converting SMILES to graph: 17869/19709\n",
            "Converting SMILES to graph: 17870/19709\n",
            "Converting SMILES to graph: 17871/19709\n",
            "Converting SMILES to graph: 17872/19709\n",
            "Converting SMILES to graph: 17873/19709\n",
            "Converting SMILES to graph: 17874/19709\n",
            "Converting SMILES to graph: 17875/19709\n",
            "Converting SMILES to graph: 17876/19709\n",
            "Converting SMILES to graph: 17877/19709\n",
            "Converting SMILES to graph: 17878/19709\n",
            "Converting SMILES to graph: 17879/19709\n",
            "Converting SMILES to graph: 17880/19709\n",
            "Converting SMILES to graph: 17881/19709\n",
            "Converting SMILES to graph: 17882/19709\n",
            "Converting SMILES to graph: 17883/19709\n",
            "Converting SMILES to graph: 17884/19709\n",
            "Converting SMILES to graph: 17885/19709\n",
            "Converting SMILES to graph: 17886/19709\n",
            "Converting SMILES to graph: 17887/19709\n",
            "Converting SMILES to graph: 17888/19709\n",
            "Converting SMILES to graph: 17889/19709\n",
            "Converting SMILES to graph: 17890/19709\n",
            "Converting SMILES to graph: 17891/19709\n",
            "Converting SMILES to graph: 17892/19709\n",
            "Converting SMILES to graph: 17893/19709\n",
            "Converting SMILES to graph: 17894/19709\n",
            "Converting SMILES to graph: 17895/19709\n",
            "Converting SMILES to graph: 17896/19709\n",
            "Converting SMILES to graph: 17897/19709\n",
            "Converting SMILES to graph: 17898/19709\n",
            "Converting SMILES to graph: 17899/19709\n",
            "Converting SMILES to graph: 17900/19709\n",
            "Converting SMILES to graph: 17901/19709\n",
            "Converting SMILES to graph: 17902/19709\n",
            "Converting SMILES to graph: 17903/19709\n",
            "Converting SMILES to graph: 17904/19709\n",
            "Converting SMILES to graph: 17905/19709\n",
            "Converting SMILES to graph: 17906/19709\n",
            "Converting SMILES to graph: 17907/19709\n",
            "Converting SMILES to graph: 17908/19709\n",
            "Converting SMILES to graph: 17909/19709\n",
            "Converting SMILES to graph: 17910/19709\n",
            "Converting SMILES to graph: 17911/19709\n",
            "Converting SMILES to graph: 17912/19709\n",
            "Converting SMILES to graph: 17913/19709\n",
            "Converting SMILES to graph: 17914/19709\n",
            "Converting SMILES to graph: 17915/19709\n",
            "Converting SMILES to graph: 17916/19709\n",
            "Converting SMILES to graph: 17917/19709\n",
            "Converting SMILES to graph: 17918/19709\n",
            "Converting SMILES to graph: 17919/19709\n",
            "Converting SMILES to graph: 17920/19709\n",
            "Converting SMILES to graph: 17921/19709\n",
            "Converting SMILES to graph: 17922/19709\n",
            "Converting SMILES to graph: 17923/19709\n",
            "Converting SMILES to graph: 17924/19709\n",
            "Converting SMILES to graph: 17925/19709\n",
            "Converting SMILES to graph: 17926/19709\n",
            "Converting SMILES to graph: 17927/19709\n",
            "Converting SMILES to graph: 17928/19709\n",
            "Converting SMILES to graph: 17929/19709\n",
            "Converting SMILES to graph: 17930/19709\n",
            "Converting SMILES to graph: 17931/19709\n",
            "Converting SMILES to graph: 17932/19709\n",
            "Converting SMILES to graph: 17933/19709\n",
            "Converting SMILES to graph: 17934/19709\n",
            "Converting SMILES to graph: 17935/19709\n",
            "Converting SMILES to graph: 17936/19709\n",
            "Converting SMILES to graph: 17937/19709\n",
            "Converting SMILES to graph: 17938/19709\n",
            "Converting SMILES to graph: 17939/19709\n",
            "Converting SMILES to graph: 17940/19709\n",
            "Converting SMILES to graph: 17941/19709\n",
            "Converting SMILES to graph: 17942/19709\n",
            "Converting SMILES to graph: 17943/19709\n",
            "Converting SMILES to graph: 17944/19709\n",
            "Converting SMILES to graph: 17945/19709\n",
            "Converting SMILES to graph: 17946/19709\n",
            "Converting SMILES to graph: 17947/19709\n",
            "Converting SMILES to graph: 17948/19709\n",
            "Converting SMILES to graph: 17949/19709\n",
            "Converting SMILES to graph: 17950/19709\n",
            "Converting SMILES to graph: 17951/19709\n",
            "Converting SMILES to graph: 17952/19709\n",
            "Converting SMILES to graph: 17953/19709\n",
            "Converting SMILES to graph: 17954/19709\n",
            "Converting SMILES to graph: 17955/19709\n",
            "Converting SMILES to graph: 17956/19709\n",
            "Converting SMILES to graph: 17957/19709\n",
            "Converting SMILES to graph: 17958/19709\n",
            "Converting SMILES to graph: 17959/19709\n",
            "Converting SMILES to graph: 17960/19709\n",
            "Converting SMILES to graph: 17961/19709\n",
            "Converting SMILES to graph: 17962/19709\n",
            "Converting SMILES to graph: 17963/19709\n",
            "Converting SMILES to graph: 17964/19709\n",
            "Converting SMILES to graph: 17965/19709\n",
            "Converting SMILES to graph: 17966/19709\n",
            "Converting SMILES to graph: 17967/19709\n",
            "Converting SMILES to graph: 17968/19709\n",
            "Converting SMILES to graph: 17969/19709\n",
            "Converting SMILES to graph: 17970/19709\n",
            "Converting SMILES to graph: 17971/19709\n",
            "Converting SMILES to graph: 17972/19709\n",
            "Converting SMILES to graph: 17973/19709\n",
            "Converting SMILES to graph: 17974/19709\n",
            "Converting SMILES to graph: 17975/19709\n",
            "Converting SMILES to graph: 17976/19709\n",
            "Converting SMILES to graph: 17977/19709\n",
            "Converting SMILES to graph: 17978/19709\n",
            "Converting SMILES to graph: 17979/19709\n",
            "Converting SMILES to graph: 17980/19709\n",
            "Converting SMILES to graph: 17981/19709\n",
            "Converting SMILES to graph: 17982/19709\n",
            "Converting SMILES to graph: 17983/19709\n",
            "Converting SMILES to graph: 17984/19709\n",
            "Converting SMILES to graph: 17985/19709\n",
            "Converting SMILES to graph: 17986/19709\n",
            "Converting SMILES to graph: 17987/19709\n",
            "Converting SMILES to graph: 17988/19709\n",
            "Converting SMILES to graph: 17989/19709\n",
            "Converting SMILES to graph: 17990/19709\n",
            "Converting SMILES to graph: 17991/19709\n",
            "Converting SMILES to graph: 17992/19709\n",
            "Converting SMILES to graph: 17993/19709\n",
            "Converting SMILES to graph: 17994/19709\n",
            "Converting SMILES to graph: 17995/19709\n",
            "Converting SMILES to graph: 17996/19709\n",
            "Converting SMILES to graph: 17997/19709\n",
            "Converting SMILES to graph: 17998/19709\n",
            "Converting SMILES to graph: 17999/19709\n",
            "Converting SMILES to graph: 18000/19709\n",
            "Converting SMILES to graph: 18001/19709\n",
            "Converting SMILES to graph: 18002/19709\n",
            "Converting SMILES to graph: 18003/19709\n",
            "Converting SMILES to graph: 18004/19709\n",
            "Converting SMILES to graph: 18005/19709\n",
            "Converting SMILES to graph: 18006/19709\n",
            "Converting SMILES to graph: 18007/19709\n",
            "Converting SMILES to graph: 18008/19709\n",
            "Converting SMILES to graph: 18009/19709\n",
            "Converting SMILES to graph: 18010/19709\n",
            "Converting SMILES to graph: 18011/19709\n",
            "Converting SMILES to graph: 18012/19709\n",
            "Converting SMILES to graph: 18013/19709\n",
            "Converting SMILES to graph: 18014/19709\n",
            "Converting SMILES to graph: 18015/19709\n",
            "Converting SMILES to graph: 18016/19709\n",
            "Converting SMILES to graph: 18017/19709\n",
            "Converting SMILES to graph: 18018/19709\n",
            "Converting SMILES to graph: 18019/19709\n",
            "Converting SMILES to graph: 18020/19709\n",
            "Converting SMILES to graph: 18021/19709\n",
            "Converting SMILES to graph: 18022/19709\n",
            "Converting SMILES to graph: 18023/19709\n",
            "Converting SMILES to graph: 18024/19709\n",
            "Converting SMILES to graph: 18025/19709\n",
            "Converting SMILES to graph: 18026/19709\n",
            "Converting SMILES to graph: 18027/19709\n",
            "Converting SMILES to graph: 18028/19709\n",
            "Converting SMILES to graph: 18029/19709\n",
            "Converting SMILES to graph: 18030/19709\n",
            "Converting SMILES to graph: 18031/19709\n",
            "Converting SMILES to graph: 18032/19709\n",
            "Converting SMILES to graph: 18033/19709\n",
            "Converting SMILES to graph: 18034/19709\n",
            "Converting SMILES to graph: 18035/19709\n",
            "Converting SMILES to graph: 18036/19709\n",
            "Converting SMILES to graph: 18037/19709\n",
            "Converting SMILES to graph: 18038/19709\n",
            "Converting SMILES to graph: 18039/19709\n",
            "Converting SMILES to graph: 18040/19709\n",
            "Converting SMILES to graph: 18041/19709\n",
            "Converting SMILES to graph: 18042/19709\n",
            "Converting SMILES to graph: 18043/19709\n",
            "Converting SMILES to graph: 18044/19709\n",
            "Converting SMILES to graph: 18045/19709\n",
            "Converting SMILES to graph: 18046/19709\n",
            "Converting SMILES to graph: 18047/19709\n",
            "Converting SMILES to graph: 18048/19709\n",
            "Converting SMILES to graph: 18049/19709\n",
            "Converting SMILES to graph: 18050/19709\n",
            "Converting SMILES to graph: 18051/19709\n",
            "Converting SMILES to graph: 18052/19709\n",
            "Converting SMILES to graph: 18053/19709\n",
            "Converting SMILES to graph: 18054/19709\n",
            "Converting SMILES to graph: 18055/19709\n",
            "Converting SMILES to graph: 18056/19709\n",
            "Converting SMILES to graph: 18057/19709\n",
            "Converting SMILES to graph: 18058/19709\n",
            "Converting SMILES to graph: 18059/19709\n",
            "Converting SMILES to graph: 18060/19709\n",
            "Converting SMILES to graph: 18061/19709\n",
            "Converting SMILES to graph: 18062/19709\n",
            "Converting SMILES to graph: 18063/19709\n",
            "Converting SMILES to graph: 18064/19709\n",
            "Converting SMILES to graph: 18065/19709\n",
            "Converting SMILES to graph: 18066/19709\n",
            "Converting SMILES to graph: 18067/19709\n",
            "Converting SMILES to graph: 18068/19709\n",
            "Converting SMILES to graph: 18069/19709\n",
            "Converting SMILES to graph: 18070/19709\n",
            "Converting SMILES to graph: 18071/19709\n",
            "Converting SMILES to graph: 18072/19709\n",
            "Converting SMILES to graph: 18073/19709\n",
            "Converting SMILES to graph: 18074/19709\n",
            "Converting SMILES to graph: 18075/19709\n",
            "Converting SMILES to graph: 18076/19709\n",
            "Converting SMILES to graph: 18077/19709\n",
            "Converting SMILES to graph: 18078/19709\n",
            "Converting SMILES to graph: 18079/19709\n",
            "Converting SMILES to graph: 18080/19709\n",
            "Converting SMILES to graph: 18081/19709\n",
            "Converting SMILES to graph: 18082/19709\n",
            "Converting SMILES to graph: 18083/19709\n",
            "Converting SMILES to graph: 18084/19709\n",
            "Converting SMILES to graph: 18085/19709\n",
            "Converting SMILES to graph: 18086/19709\n",
            "Converting SMILES to graph: 18087/19709\n",
            "Converting SMILES to graph: 18088/19709\n",
            "Converting SMILES to graph: 18089/19709\n",
            "Converting SMILES to graph: 18090/19709\n",
            "Converting SMILES to graph: 18091/19709\n",
            "Converting SMILES to graph: 18092/19709\n",
            "Converting SMILES to graph: 18093/19709\n",
            "Converting SMILES to graph: 18094/19709\n",
            "Converting SMILES to graph: 18095/19709\n",
            "Converting SMILES to graph: 18096/19709\n",
            "Converting SMILES to graph: 18097/19709\n",
            "Converting SMILES to graph: 18098/19709\n",
            "Converting SMILES to graph: 18099/19709\n",
            "Converting SMILES to graph: 18100/19709\n",
            "Converting SMILES to graph: 18101/19709\n",
            "Converting SMILES to graph: 18102/19709\n",
            "Converting SMILES to graph: 18103/19709\n",
            "Converting SMILES to graph: 18104/19709\n",
            "Converting SMILES to graph: 18105/19709\n",
            "Converting SMILES to graph: 18106/19709\n",
            "Converting SMILES to graph: 18107/19709\n",
            "Converting SMILES to graph: 18108/19709\n",
            "Converting SMILES to graph: 18109/19709\n",
            "Converting SMILES to graph: 18110/19709\n",
            "Converting SMILES to graph: 18111/19709\n",
            "Converting SMILES to graph: 18112/19709\n",
            "Converting SMILES to graph: 18113/19709\n",
            "Converting SMILES to graph: 18114/19709\n",
            "Converting SMILES to graph: 18115/19709\n",
            "Converting SMILES to graph: 18116/19709\n",
            "Converting SMILES to graph: 18117/19709\n",
            "Converting SMILES to graph: 18118/19709\n",
            "Converting SMILES to graph: 18119/19709\n",
            "Converting SMILES to graph: 18120/19709\n",
            "Converting SMILES to graph: 18121/19709\n",
            "Converting SMILES to graph: 18122/19709\n",
            "Converting SMILES to graph: 18123/19709\n",
            "Converting SMILES to graph: 18124/19709\n",
            "Converting SMILES to graph: 18125/19709\n",
            "Converting SMILES to graph: 18126/19709\n",
            "Converting SMILES to graph: 18127/19709\n",
            "Converting SMILES to graph: 18128/19709\n",
            "Converting SMILES to graph: 18129/19709\n",
            "Converting SMILES to graph: 18130/19709\n",
            "Converting SMILES to graph: 18131/19709\n",
            "Converting SMILES to graph: 18132/19709\n",
            "Converting SMILES to graph: 18133/19709\n",
            "Converting SMILES to graph: 18134/19709\n",
            "Converting SMILES to graph: 18135/19709\n",
            "Converting SMILES to graph: 18136/19709\n",
            "Converting SMILES to graph: 18137/19709\n",
            "Converting SMILES to graph: 18138/19709\n",
            "Converting SMILES to graph: 18139/19709\n",
            "Converting SMILES to graph: 18140/19709\n",
            "Converting SMILES to graph: 18141/19709\n",
            "Converting SMILES to graph: 18142/19709\n",
            "Converting SMILES to graph: 18143/19709\n",
            "Converting SMILES to graph: 18144/19709\n",
            "Converting SMILES to graph: 18145/19709\n",
            "Converting SMILES to graph: 18146/19709\n",
            "Converting SMILES to graph: 18147/19709\n",
            "Converting SMILES to graph: 18148/19709\n",
            "Converting SMILES to graph: 18149/19709\n",
            "Converting SMILES to graph: 18150/19709\n",
            "Converting SMILES to graph: 18151/19709\n",
            "Converting SMILES to graph: 18152/19709\n",
            "Converting SMILES to graph: 18153/19709\n",
            "Converting SMILES to graph: 18154/19709\n",
            "Converting SMILES to graph: 18155/19709\n",
            "Converting SMILES to graph: 18156/19709\n",
            "Converting SMILES to graph: 18157/19709\n",
            "Converting SMILES to graph: 18158/19709\n",
            "Converting SMILES to graph: 18159/19709\n",
            "Converting SMILES to graph: 18160/19709\n",
            "Converting SMILES to graph: 18161/19709\n",
            "Converting SMILES to graph: 18162/19709\n",
            "Converting SMILES to graph: 18163/19709\n",
            "Converting SMILES to graph: 18164/19709\n",
            "Converting SMILES to graph: 18165/19709\n",
            "Converting SMILES to graph: 18166/19709\n",
            "Converting SMILES to graph: 18167/19709\n",
            "Converting SMILES to graph: 18168/19709\n",
            "Converting SMILES to graph: 18169/19709\n",
            "Converting SMILES to graph: 18170/19709\n",
            "Converting SMILES to graph: 18171/19709\n",
            "Converting SMILES to graph: 18172/19709\n",
            "Converting SMILES to graph: 18173/19709\n",
            "Converting SMILES to graph: 18174/19709\n",
            "Converting SMILES to graph: 18175/19709\n",
            "Converting SMILES to graph: 18176/19709\n",
            "Converting SMILES to graph: 18177/19709\n",
            "Converting SMILES to graph: 18178/19709\n",
            "Converting SMILES to graph: 18179/19709\n",
            "Converting SMILES to graph: 18180/19709\n",
            "Converting SMILES to graph: 18181/19709\n",
            "Converting SMILES to graph: 18182/19709\n",
            "Converting SMILES to graph: 18183/19709\n",
            "Converting SMILES to graph: 18184/19709\n",
            "Converting SMILES to graph: 18185/19709\n",
            "Converting SMILES to graph: 18186/19709\n",
            "Converting SMILES to graph: 18187/19709\n",
            "Converting SMILES to graph: 18188/19709\n",
            "Converting SMILES to graph: 18189/19709\n",
            "Converting SMILES to graph: 18190/19709\n",
            "Converting SMILES to graph: 18191/19709\n",
            "Converting SMILES to graph: 18192/19709\n",
            "Converting SMILES to graph: 18193/19709\n",
            "Converting SMILES to graph: 18194/19709\n",
            "Converting SMILES to graph: 18195/19709\n",
            "Converting SMILES to graph: 18196/19709\n",
            "Converting SMILES to graph: 18197/19709\n",
            "Converting SMILES to graph: 18198/19709\n",
            "Converting SMILES to graph: 18199/19709\n",
            "Converting SMILES to graph: 18200/19709\n",
            "Converting SMILES to graph: 18201/19709\n",
            "Converting SMILES to graph: 18202/19709\n",
            "Converting SMILES to graph: 18203/19709\n",
            "Converting SMILES to graph: 18204/19709\n",
            "Converting SMILES to graph: 18205/19709\n",
            "Converting SMILES to graph: 18206/19709\n",
            "Converting SMILES to graph: 18207/19709\n",
            "Converting SMILES to graph: 18208/19709\n",
            "Converting SMILES to graph: 18209/19709\n",
            "Converting SMILES to graph: 18210/19709\n",
            "Converting SMILES to graph: 18211/19709\n",
            "Converting SMILES to graph: 18212/19709\n",
            "Converting SMILES to graph: 18213/19709\n",
            "Converting SMILES to graph: 18214/19709\n",
            "Converting SMILES to graph: 18215/19709\n",
            "Converting SMILES to graph: 18216/19709\n",
            "Converting SMILES to graph: 18217/19709\n",
            "Converting SMILES to graph: 18218/19709\n",
            "Converting SMILES to graph: 18219/19709\n",
            "Converting SMILES to graph: 18220/19709\n",
            "Converting SMILES to graph: 18221/19709\n",
            "Converting SMILES to graph: 18222/19709\n",
            "Converting SMILES to graph: 18223/19709\n",
            "Converting SMILES to graph: 18224/19709\n",
            "Converting SMILES to graph: 18225/19709\n",
            "Converting SMILES to graph: 18226/19709\n",
            "Converting SMILES to graph: 18227/19709\n",
            "Converting SMILES to graph: 18228/19709\n",
            "Converting SMILES to graph: 18229/19709\n",
            "Converting SMILES to graph: 18230/19709\n",
            "Converting SMILES to graph: 18231/19709\n",
            "Converting SMILES to graph: 18232/19709\n",
            "Converting SMILES to graph: 18233/19709\n",
            "Converting SMILES to graph: 18234/19709\n",
            "Converting SMILES to graph: 18235/19709\n",
            "Converting SMILES to graph: 18236/19709\n",
            "Converting SMILES to graph: 18237/19709\n",
            "Converting SMILES to graph: 18238/19709\n",
            "Converting SMILES to graph: 18239/19709\n",
            "Converting SMILES to graph: 18240/19709\n",
            "Converting SMILES to graph: 18241/19709\n",
            "Converting SMILES to graph: 18242/19709\n",
            "Converting SMILES to graph: 18243/19709\n",
            "Converting SMILES to graph: 18244/19709\n",
            "Converting SMILES to graph: 18245/19709\n",
            "Converting SMILES to graph: 18246/19709\n",
            "Converting SMILES to graph: 18247/19709\n",
            "Converting SMILES to graph: 18248/19709\n",
            "Converting SMILES to graph: 18249/19709\n",
            "Converting SMILES to graph: 18250/19709\n",
            "Converting SMILES to graph: 18251/19709\n",
            "Converting SMILES to graph: 18252/19709\n",
            "Converting SMILES to graph: 18253/19709\n",
            "Converting SMILES to graph: 18254/19709\n",
            "Converting SMILES to graph: 18255/19709\n",
            "Converting SMILES to graph: 18256/19709\n",
            "Converting SMILES to graph: 18257/19709\n",
            "Converting SMILES to graph: 18258/19709\n",
            "Converting SMILES to graph: 18259/19709\n",
            "Converting SMILES to graph: 18260/19709\n",
            "Converting SMILES to graph: 18261/19709\n",
            "Converting SMILES to graph: 18262/19709\n",
            "Converting SMILES to graph: 18263/19709\n",
            "Converting SMILES to graph: 18264/19709\n",
            "Converting SMILES to graph: 18265/19709\n",
            "Converting SMILES to graph: 18266/19709\n",
            "Converting SMILES to graph: 18267/19709\n",
            "Converting SMILES to graph: 18268/19709\n",
            "Converting SMILES to graph: 18269/19709\n",
            "Converting SMILES to graph: 18270/19709\n",
            "Converting SMILES to graph: 18271/19709\n",
            "Converting SMILES to graph: 18272/19709\n",
            "Converting SMILES to graph: 18273/19709\n",
            "Converting SMILES to graph: 18274/19709\n",
            "Converting SMILES to graph: 18275/19709\n",
            "Converting SMILES to graph: 18276/19709\n",
            "Converting SMILES to graph: 18277/19709\n",
            "Converting SMILES to graph: 18278/19709\n",
            "Converting SMILES to graph: 18279/19709\n",
            "Converting SMILES to graph: 18280/19709\n",
            "Converting SMILES to graph: 18281/19709\n",
            "Converting SMILES to graph: 18282/19709\n",
            "Converting SMILES to graph: 18283/19709\n",
            "Converting SMILES to graph: 18284/19709\n",
            "Converting SMILES to graph: 18285/19709\n",
            "Converting SMILES to graph: 18286/19709\n",
            "Converting SMILES to graph: 18287/19709\n",
            "Converting SMILES to graph: 18288/19709\n",
            "Converting SMILES to graph: 18289/19709\n",
            "Converting SMILES to graph: 18290/19709\n",
            "Converting SMILES to graph: 18291/19709\n",
            "Converting SMILES to graph: 18292/19709\n",
            "Converting SMILES to graph: 18293/19709\n",
            "Converting SMILES to graph: 18294/19709\n",
            "Converting SMILES to graph: 18295/19709\n",
            "Converting SMILES to graph: 18296/19709\n",
            "Converting SMILES to graph: 18297/19709\n",
            "Converting SMILES to graph: 18298/19709\n",
            "Converting SMILES to graph: 18299/19709\n",
            "Converting SMILES to graph: 18300/19709\n",
            "Converting SMILES to graph: 18301/19709\n",
            "Converting SMILES to graph: 18302/19709\n",
            "Converting SMILES to graph: 18303/19709\n",
            "Converting SMILES to graph: 18304/19709\n",
            "Converting SMILES to graph: 18305/19709\n",
            "Converting SMILES to graph: 18306/19709\n",
            "Converting SMILES to graph: 18307/19709\n",
            "Converting SMILES to graph: 18308/19709\n",
            "Converting SMILES to graph: 18309/19709\n",
            "Converting SMILES to graph: 18310/19709\n",
            "Converting SMILES to graph: 18311/19709\n",
            "Converting SMILES to graph: 18312/19709\n",
            "Converting SMILES to graph: 18313/19709\n",
            "Converting SMILES to graph: 18314/19709\n",
            "Converting SMILES to graph: 18315/19709\n",
            "Converting SMILES to graph: 18316/19709\n",
            "Converting SMILES to graph: 18317/19709\n",
            "Converting SMILES to graph: 18318/19709\n",
            "Converting SMILES to graph: 18319/19709\n",
            "Converting SMILES to graph: 18320/19709\n",
            "Converting SMILES to graph: 18321/19709\n",
            "Converting SMILES to graph: 18322/19709\n",
            "Converting SMILES to graph: 18323/19709\n",
            "Converting SMILES to graph: 18324/19709\n",
            "Converting SMILES to graph: 18325/19709\n",
            "Converting SMILES to graph: 18326/19709\n",
            "Converting SMILES to graph: 18327/19709\n",
            "Converting SMILES to graph: 18328/19709\n",
            "Converting SMILES to graph: 18329/19709\n",
            "Converting SMILES to graph: 18330/19709\n",
            "Converting SMILES to graph: 18331/19709\n",
            "Converting SMILES to graph: 18332/19709\n",
            "Converting SMILES to graph: 18333/19709\n",
            "Converting SMILES to graph: 18334/19709\n",
            "Converting SMILES to graph: 18335/19709\n",
            "Converting SMILES to graph: 18336/19709\n",
            "Converting SMILES to graph: 18337/19709\n",
            "Converting SMILES to graph: 18338/19709\n",
            "Converting SMILES to graph: 18339/19709\n",
            "Converting SMILES to graph: 18340/19709\n",
            "Converting SMILES to graph: 18341/19709\n",
            "Converting SMILES to graph: 18342/19709\n",
            "Converting SMILES to graph: 18343/19709\n",
            "Converting SMILES to graph: 18344/19709\n",
            "Converting SMILES to graph: 18345/19709\n",
            "Converting SMILES to graph: 18346/19709\n",
            "Converting SMILES to graph: 18347/19709\n",
            "Converting SMILES to graph: 18348/19709\n",
            "Converting SMILES to graph: 18349/19709\n",
            "Converting SMILES to graph: 18350/19709\n",
            "Converting SMILES to graph: 18351/19709\n",
            "Converting SMILES to graph: 18352/19709\n",
            "Converting SMILES to graph: 18353/19709\n",
            "Converting SMILES to graph: 18354/19709\n",
            "Converting SMILES to graph: 18355/19709\n",
            "Converting SMILES to graph: 18356/19709\n",
            "Converting SMILES to graph: 18357/19709\n",
            "Converting SMILES to graph: 18358/19709\n",
            "Converting SMILES to graph: 18359/19709\n",
            "Converting SMILES to graph: 18360/19709\n",
            "Converting SMILES to graph: 18361/19709\n",
            "Converting SMILES to graph: 18362/19709\n",
            "Converting SMILES to graph: 18363/19709\n",
            "Converting SMILES to graph: 18364/19709\n",
            "Converting SMILES to graph: 18365/19709\n",
            "Converting SMILES to graph: 18366/19709\n",
            "Converting SMILES to graph: 18367/19709\n",
            "Converting SMILES to graph: 18368/19709\n",
            "Converting SMILES to graph: 18369/19709\n",
            "Converting SMILES to graph: 18370/19709\n",
            "Converting SMILES to graph: 18371/19709\n",
            "Converting SMILES to graph: 18372/19709\n",
            "Converting SMILES to graph: 18373/19709\n",
            "Converting SMILES to graph: 18374/19709\n",
            "Converting SMILES to graph: 18375/19709\n",
            "Converting SMILES to graph: 18376/19709\n",
            "Converting SMILES to graph: 18377/19709\n",
            "Converting SMILES to graph: 18378/19709\n",
            "Converting SMILES to graph: 18379/19709\n",
            "Converting SMILES to graph: 18380/19709\n",
            "Converting SMILES to graph: 18381/19709\n",
            "Converting SMILES to graph: 18382/19709\n",
            "Converting SMILES to graph: 18383/19709\n",
            "Converting SMILES to graph: 18384/19709\n",
            "Converting SMILES to graph: 18385/19709\n",
            "Converting SMILES to graph: 18386/19709\n",
            "Converting SMILES to graph: 18387/19709\n",
            "Converting SMILES to graph: 18388/19709\n",
            "Converting SMILES to graph: 18389/19709\n",
            "Converting SMILES to graph: 18390/19709\n",
            "Converting SMILES to graph: 18391/19709\n",
            "Converting SMILES to graph: 18392/19709\n",
            "Converting SMILES to graph: 18393/19709\n",
            "Converting SMILES to graph: 18394/19709\n",
            "Converting SMILES to graph: 18395/19709\n",
            "Converting SMILES to graph: 18396/19709\n",
            "Converting SMILES to graph: 18397/19709\n",
            "Converting SMILES to graph: 18398/19709\n",
            "Converting SMILES to graph: 18399/19709\n",
            "Converting SMILES to graph: 18400/19709\n",
            "Converting SMILES to graph: 18401/19709\n",
            "Converting SMILES to graph: 18402/19709\n",
            "Converting SMILES to graph: 18403/19709\n",
            "Converting SMILES to graph: 18404/19709\n",
            "Converting SMILES to graph: 18405/19709\n",
            "Converting SMILES to graph: 18406/19709\n",
            "Converting SMILES to graph: 18407/19709\n",
            "Converting SMILES to graph: 18408/19709\n",
            "Converting SMILES to graph: 18409/19709\n",
            "Converting SMILES to graph: 18410/19709\n",
            "Converting SMILES to graph: 18411/19709\n",
            "Converting SMILES to graph: 18412/19709\n",
            "Converting SMILES to graph: 18413/19709\n",
            "Converting SMILES to graph: 18414/19709\n",
            "Converting SMILES to graph: 18415/19709\n",
            "Converting SMILES to graph: 18416/19709\n",
            "Converting SMILES to graph: 18417/19709\n",
            "Converting SMILES to graph: 18418/19709\n",
            "Converting SMILES to graph: 18419/19709\n",
            "Converting SMILES to graph: 18420/19709\n",
            "Converting SMILES to graph: 18421/19709\n",
            "Converting SMILES to graph: 18422/19709\n",
            "Converting SMILES to graph: 18423/19709\n",
            "Converting SMILES to graph: 18424/19709\n",
            "Converting SMILES to graph: 18425/19709\n",
            "Converting SMILES to graph: 18426/19709\n",
            "Converting SMILES to graph: 18427/19709\n",
            "Converting SMILES to graph: 18428/19709\n",
            "Converting SMILES to graph: 18429/19709\n",
            "Converting SMILES to graph: 18430/19709\n",
            "Converting SMILES to graph: 18431/19709\n",
            "Converting SMILES to graph: 18432/19709\n",
            "Converting SMILES to graph: 18433/19709\n",
            "Converting SMILES to graph: 18434/19709\n",
            "Converting SMILES to graph: 18435/19709\n",
            "Converting SMILES to graph: 18436/19709\n",
            "Converting SMILES to graph: 18437/19709\n",
            "Converting SMILES to graph: 18438/19709\n",
            "Converting SMILES to graph: 18439/19709\n",
            "Converting SMILES to graph: 18440/19709\n",
            "Converting SMILES to graph: 18441/19709\n",
            "Converting SMILES to graph: 18442/19709\n",
            "Converting SMILES to graph: 18443/19709\n",
            "Converting SMILES to graph: 18444/19709\n",
            "Converting SMILES to graph: 18445/19709\n",
            "Converting SMILES to graph: 18446/19709\n",
            "Converting SMILES to graph: 18447/19709\n",
            "Converting SMILES to graph: 18448/19709\n",
            "Converting SMILES to graph: 18449/19709\n",
            "Converting SMILES to graph: 18450/19709\n",
            "Converting SMILES to graph: 18451/19709\n",
            "Converting SMILES to graph: 18452/19709\n",
            "Converting SMILES to graph: 18453/19709\n",
            "Converting SMILES to graph: 18454/19709\n",
            "Converting SMILES to graph: 18455/19709\n",
            "Converting SMILES to graph: 18456/19709\n",
            "Converting SMILES to graph: 18457/19709\n",
            "Converting SMILES to graph: 18458/19709\n",
            "Converting SMILES to graph: 18459/19709\n",
            "Converting SMILES to graph: 18460/19709\n",
            "Converting SMILES to graph: 18461/19709\n",
            "Converting SMILES to graph: 18462/19709\n",
            "Converting SMILES to graph: 18463/19709\n",
            "Converting SMILES to graph: 18464/19709\n",
            "Converting SMILES to graph: 18465/19709\n",
            "Converting SMILES to graph: 18466/19709\n",
            "Converting SMILES to graph: 18467/19709\n",
            "Converting SMILES to graph: 18468/19709\n",
            "Converting SMILES to graph: 18469/19709\n",
            "Converting SMILES to graph: 18470/19709\n",
            "Converting SMILES to graph: 18471/19709\n",
            "Converting SMILES to graph: 18472/19709\n",
            "Converting SMILES to graph: 18473/19709\n",
            "Converting SMILES to graph: 18474/19709\n",
            "Converting SMILES to graph: 18475/19709\n",
            "Converting SMILES to graph: 18476/19709\n",
            "Converting SMILES to graph: 18477/19709\n",
            "Converting SMILES to graph: 18478/19709\n",
            "Converting SMILES to graph: 18479/19709\n",
            "Converting SMILES to graph: 18480/19709\n",
            "Converting SMILES to graph: 18481/19709\n",
            "Converting SMILES to graph: 18482/19709\n",
            "Converting SMILES to graph: 18483/19709\n",
            "Converting SMILES to graph: 18484/19709\n",
            "Converting SMILES to graph: 18485/19709\n",
            "Converting SMILES to graph: 18486/19709\n",
            "Converting SMILES to graph: 18487/19709\n",
            "Converting SMILES to graph: 18488/19709\n",
            "Converting SMILES to graph: 18489/19709\n",
            "Converting SMILES to graph: 18490/19709\n",
            "Converting SMILES to graph: 18491/19709\n",
            "Converting SMILES to graph: 18492/19709\n",
            "Converting SMILES to graph: 18493/19709\n",
            "Converting SMILES to graph: 18494/19709\n",
            "Converting SMILES to graph: 18495/19709\n",
            "Converting SMILES to graph: 18496/19709\n",
            "Converting SMILES to graph: 18497/19709\n",
            "Converting SMILES to graph: 18498/19709\n",
            "Converting SMILES to graph: 18499/19709\n",
            "Converting SMILES to graph: 18500/19709\n",
            "Converting SMILES to graph: 18501/19709\n",
            "Converting SMILES to graph: 18502/19709\n",
            "Converting SMILES to graph: 18503/19709\n",
            "Converting SMILES to graph: 18504/19709\n",
            "Converting SMILES to graph: 18505/19709\n",
            "Converting SMILES to graph: 18506/19709\n",
            "Converting SMILES to graph: 18507/19709\n",
            "Converting SMILES to graph: 18508/19709\n",
            "Converting SMILES to graph: 18509/19709\n",
            "Converting SMILES to graph: 18510/19709\n",
            "Converting SMILES to graph: 18511/19709\n",
            "Converting SMILES to graph: 18512/19709\n",
            "Converting SMILES to graph: 18513/19709\n",
            "Converting SMILES to graph: 18514/19709\n",
            "Converting SMILES to graph: 18515/19709\n",
            "Converting SMILES to graph: 18516/19709\n",
            "Converting SMILES to graph: 18517/19709\n",
            "Converting SMILES to graph: 18518/19709\n",
            "Converting SMILES to graph: 18519/19709\n",
            "Converting SMILES to graph: 18520/19709\n",
            "Converting SMILES to graph: 18521/19709\n",
            "Converting SMILES to graph: 18522/19709\n",
            "Converting SMILES to graph: 18523/19709\n",
            "Converting SMILES to graph: 18524/19709\n",
            "Converting SMILES to graph: 18525/19709\n",
            "Converting SMILES to graph: 18526/19709\n",
            "Converting SMILES to graph: 18527/19709\n",
            "Converting SMILES to graph: 18528/19709\n",
            "Converting SMILES to graph: 18529/19709\n",
            "Converting SMILES to graph: 18530/19709\n",
            "Converting SMILES to graph: 18531/19709\n",
            "Converting SMILES to graph: 18532/19709\n",
            "Converting SMILES to graph: 18533/19709\n",
            "Converting SMILES to graph: 18534/19709\n",
            "Converting SMILES to graph: 18535/19709\n",
            "Converting SMILES to graph: 18536/19709\n",
            "Converting SMILES to graph: 18537/19709\n",
            "Converting SMILES to graph: 18538/19709\n",
            "Converting SMILES to graph: 18539/19709\n",
            "Converting SMILES to graph: 18540/19709\n",
            "Converting SMILES to graph: 18541/19709\n",
            "Converting SMILES to graph: 18542/19709\n",
            "Converting SMILES to graph: 18543/19709\n",
            "Converting SMILES to graph: 18544/19709\n",
            "Converting SMILES to graph: 18545/19709\n",
            "Converting SMILES to graph: 18546/19709\n",
            "Converting SMILES to graph: 18547/19709\n",
            "Converting SMILES to graph: 18548/19709\n",
            "Converting SMILES to graph: 18549/19709\n",
            "Converting SMILES to graph: 18550/19709\n",
            "Converting SMILES to graph: 18551/19709\n",
            "Converting SMILES to graph: 18552/19709\n",
            "Converting SMILES to graph: 18553/19709\n",
            "Converting SMILES to graph: 18554/19709\n",
            "Converting SMILES to graph: 18555/19709\n",
            "Converting SMILES to graph: 18556/19709\n",
            "Converting SMILES to graph: 18557/19709\n",
            "Converting SMILES to graph: 18558/19709\n",
            "Converting SMILES to graph: 18559/19709\n",
            "Converting SMILES to graph: 18560/19709\n",
            "Converting SMILES to graph: 18561/19709\n",
            "Converting SMILES to graph: 18562/19709\n",
            "Converting SMILES to graph: 18563/19709\n",
            "Converting SMILES to graph: 18564/19709\n",
            "Converting SMILES to graph: 18565/19709\n",
            "Converting SMILES to graph: 18566/19709\n",
            "Converting SMILES to graph: 18567/19709\n",
            "Converting SMILES to graph: 18568/19709\n",
            "Converting SMILES to graph: 18569/19709\n",
            "Converting SMILES to graph: 18570/19709\n",
            "Converting SMILES to graph: 18571/19709\n",
            "Converting SMILES to graph: 18572/19709\n",
            "Converting SMILES to graph: 18573/19709\n",
            "Converting SMILES to graph: 18574/19709\n",
            "Converting SMILES to graph: 18575/19709\n",
            "Converting SMILES to graph: 18576/19709\n",
            "Converting SMILES to graph: 18577/19709\n",
            "Converting SMILES to graph: 18578/19709\n",
            "Converting SMILES to graph: 18579/19709\n",
            "Converting SMILES to graph: 18580/19709\n",
            "Converting SMILES to graph: 18581/19709\n",
            "Converting SMILES to graph: 18582/19709\n",
            "Converting SMILES to graph: 18583/19709\n",
            "Converting SMILES to graph: 18584/19709\n",
            "Converting SMILES to graph: 18585/19709\n",
            "Converting SMILES to graph: 18586/19709\n",
            "Converting SMILES to graph: 18587/19709\n",
            "Converting SMILES to graph: 18588/19709\n",
            "Converting SMILES to graph: 18589/19709\n",
            "Converting SMILES to graph: 18590/19709\n",
            "Converting SMILES to graph: 18591/19709\n",
            "Converting SMILES to graph: 18592/19709\n",
            "Converting SMILES to graph: 18593/19709\n",
            "Converting SMILES to graph: 18594/19709\n",
            "Converting SMILES to graph: 18595/19709\n",
            "Converting SMILES to graph: 18596/19709\n",
            "Converting SMILES to graph: 18597/19709\n",
            "Converting SMILES to graph: 18598/19709\n",
            "Converting SMILES to graph: 18599/19709\n",
            "Converting SMILES to graph: 18600/19709\n",
            "Converting SMILES to graph: 18601/19709\n",
            "Converting SMILES to graph: 18602/19709\n",
            "Converting SMILES to graph: 18603/19709\n",
            "Converting SMILES to graph: 18604/19709\n",
            "Converting SMILES to graph: 18605/19709\n",
            "Converting SMILES to graph: 18606/19709\n",
            "Converting SMILES to graph: 18607/19709\n",
            "Converting SMILES to graph: 18608/19709\n",
            "Converting SMILES to graph: 18609/19709\n",
            "Converting SMILES to graph: 18610/19709\n",
            "Converting SMILES to graph: 18611/19709\n",
            "Converting SMILES to graph: 18612/19709\n",
            "Converting SMILES to graph: 18613/19709\n",
            "Converting SMILES to graph: 18614/19709\n",
            "Converting SMILES to graph: 18615/19709\n",
            "Converting SMILES to graph: 18616/19709\n",
            "Converting SMILES to graph: 18617/19709\n",
            "Converting SMILES to graph: 18618/19709\n",
            "Converting SMILES to graph: 18619/19709\n",
            "Converting SMILES to graph: 18620/19709\n",
            "Converting SMILES to graph: 18621/19709\n",
            "Converting SMILES to graph: 18622/19709\n",
            "Converting SMILES to graph: 18623/19709\n",
            "Converting SMILES to graph: 18624/19709\n",
            "Converting SMILES to graph: 18625/19709\n",
            "Converting SMILES to graph: 18626/19709\n",
            "Converting SMILES to graph: 18627/19709\n",
            "Converting SMILES to graph: 18628/19709\n",
            "Converting SMILES to graph: 18629/19709\n",
            "Converting SMILES to graph: 18630/19709\n",
            "Converting SMILES to graph: 18631/19709\n",
            "Converting SMILES to graph: 18632/19709\n",
            "Converting SMILES to graph: 18633/19709\n",
            "Converting SMILES to graph: 18634/19709\n",
            "Converting SMILES to graph: 18635/19709\n",
            "Converting SMILES to graph: 18636/19709\n",
            "Converting SMILES to graph: 18637/19709\n",
            "Converting SMILES to graph: 18638/19709\n",
            "Converting SMILES to graph: 18639/19709\n",
            "Converting SMILES to graph: 18640/19709\n",
            "Converting SMILES to graph: 18641/19709\n",
            "Converting SMILES to graph: 18642/19709\n",
            "Converting SMILES to graph: 18643/19709\n",
            "Converting SMILES to graph: 18644/19709\n",
            "Converting SMILES to graph: 18645/19709\n",
            "Converting SMILES to graph: 18646/19709\n",
            "Converting SMILES to graph: 18647/19709\n",
            "Converting SMILES to graph: 18648/19709\n",
            "Converting SMILES to graph: 18649/19709\n",
            "Converting SMILES to graph: 18650/19709\n",
            "Converting SMILES to graph: 18651/19709\n",
            "Converting SMILES to graph: 18652/19709\n",
            "Converting SMILES to graph: 18653/19709\n",
            "Converting SMILES to graph: 18654/19709\n",
            "Converting SMILES to graph: 18655/19709\n",
            "Converting SMILES to graph: 18656/19709\n",
            "Converting SMILES to graph: 18657/19709\n",
            "Converting SMILES to graph: 18658/19709\n",
            "Converting SMILES to graph: 18659/19709\n",
            "Converting SMILES to graph: 18660/19709\n",
            "Converting SMILES to graph: 18661/19709\n",
            "Converting SMILES to graph: 18662/19709\n",
            "Converting SMILES to graph: 18663/19709\n",
            "Converting SMILES to graph: 18664/19709\n",
            "Converting SMILES to graph: 18665/19709\n",
            "Converting SMILES to graph: 18666/19709\n",
            "Converting SMILES to graph: 18667/19709\n",
            "Converting SMILES to graph: 18668/19709\n",
            "Converting SMILES to graph: 18669/19709\n",
            "Converting SMILES to graph: 18670/19709\n",
            "Converting SMILES to graph: 18671/19709\n",
            "Converting SMILES to graph: 18672/19709\n",
            "Converting SMILES to graph: 18673/19709\n",
            "Converting SMILES to graph: 18674/19709\n",
            "Converting SMILES to graph: 18675/19709\n",
            "Converting SMILES to graph: 18676/19709\n",
            "Converting SMILES to graph: 18677/19709\n",
            "Converting SMILES to graph: 18678/19709\n",
            "Converting SMILES to graph: 18679/19709\n",
            "Converting SMILES to graph: 18680/19709\n",
            "Converting SMILES to graph: 18681/19709\n",
            "Converting SMILES to graph: 18682/19709\n",
            "Converting SMILES to graph: 18683/19709\n",
            "Converting SMILES to graph: 18684/19709\n",
            "Converting SMILES to graph: 18685/19709\n",
            "Converting SMILES to graph: 18686/19709\n",
            "Converting SMILES to graph: 18687/19709\n",
            "Converting SMILES to graph: 18688/19709\n",
            "Converting SMILES to graph: 18689/19709\n",
            "Converting SMILES to graph: 18690/19709\n",
            "Converting SMILES to graph: 18691/19709\n",
            "Converting SMILES to graph: 18692/19709\n",
            "Converting SMILES to graph: 18693/19709\n",
            "Converting SMILES to graph: 18694/19709\n",
            "Converting SMILES to graph: 18695/19709\n",
            "Converting SMILES to graph: 18696/19709\n",
            "Converting SMILES to graph: 18697/19709\n",
            "Converting SMILES to graph: 18698/19709\n",
            "Converting SMILES to graph: 18699/19709\n",
            "Converting SMILES to graph: 18700/19709\n",
            "Converting SMILES to graph: 18701/19709\n",
            "Converting SMILES to graph: 18702/19709\n",
            "Converting SMILES to graph: 18703/19709\n",
            "Converting SMILES to graph: 18704/19709\n",
            "Converting SMILES to graph: 18705/19709\n",
            "Converting SMILES to graph: 18706/19709\n",
            "Converting SMILES to graph: 18707/19709\n",
            "Converting SMILES to graph: 18708/19709\n",
            "Converting SMILES to graph: 18709/19709\n",
            "Converting SMILES to graph: 18710/19709\n",
            "Converting SMILES to graph: 18711/19709\n",
            "Converting SMILES to graph: 18712/19709\n",
            "Converting SMILES to graph: 18713/19709\n",
            "Converting SMILES to graph: 18714/19709\n",
            "Converting SMILES to graph: 18715/19709\n",
            "Converting SMILES to graph: 18716/19709\n",
            "Converting SMILES to graph: 18717/19709\n",
            "Converting SMILES to graph: 18718/19709\n",
            "Converting SMILES to graph: 18719/19709\n",
            "Converting SMILES to graph: 18720/19709\n",
            "Converting SMILES to graph: 18721/19709\n",
            "Converting SMILES to graph: 18722/19709\n",
            "Converting SMILES to graph: 18723/19709\n",
            "Converting SMILES to graph: 18724/19709\n",
            "Converting SMILES to graph: 18725/19709\n",
            "Converting SMILES to graph: 18726/19709\n",
            "Converting SMILES to graph: 18727/19709\n",
            "Converting SMILES to graph: 18728/19709\n",
            "Converting SMILES to graph: 18729/19709\n",
            "Converting SMILES to graph: 18730/19709\n",
            "Converting SMILES to graph: 18731/19709\n",
            "Converting SMILES to graph: 18732/19709\n",
            "Converting SMILES to graph: 18733/19709\n",
            "Converting SMILES to graph: 18734/19709\n",
            "Converting SMILES to graph: 18735/19709\n",
            "Converting SMILES to graph: 18736/19709\n",
            "Converting SMILES to graph: 18737/19709\n",
            "Converting SMILES to graph: 18738/19709\n",
            "Converting SMILES to graph: 18739/19709\n",
            "Converting SMILES to graph: 18740/19709\n",
            "Converting SMILES to graph: 18741/19709\n",
            "Converting SMILES to graph: 18742/19709\n",
            "Converting SMILES to graph: 18743/19709\n",
            "Converting SMILES to graph: 18744/19709\n",
            "Converting SMILES to graph: 18745/19709\n",
            "Converting SMILES to graph: 18746/19709\n",
            "Converting SMILES to graph: 18747/19709\n",
            "Converting SMILES to graph: 18748/19709\n",
            "Converting SMILES to graph: 18749/19709\n",
            "Converting SMILES to graph: 18750/19709\n",
            "Converting SMILES to graph: 18751/19709\n",
            "Converting SMILES to graph: 18752/19709\n",
            "Converting SMILES to graph: 18753/19709\n",
            "Converting SMILES to graph: 18754/19709\n",
            "Converting SMILES to graph: 18755/19709\n",
            "Converting SMILES to graph: 18756/19709\n",
            "Converting SMILES to graph: 18757/19709\n",
            "Converting SMILES to graph: 18758/19709\n",
            "Converting SMILES to graph: 18759/19709\n",
            "Converting SMILES to graph: 18760/19709\n",
            "Converting SMILES to graph: 18761/19709\n",
            "Converting SMILES to graph: 18762/19709\n",
            "Converting SMILES to graph: 18763/19709\n",
            "Converting SMILES to graph: 18764/19709\n",
            "Converting SMILES to graph: 18765/19709\n",
            "Converting SMILES to graph: 18766/19709\n",
            "Converting SMILES to graph: 18767/19709\n",
            "Converting SMILES to graph: 18768/19709\n",
            "Converting SMILES to graph: 18769/19709\n",
            "Converting SMILES to graph: 18770/19709\n",
            "Converting SMILES to graph: 18771/19709\n",
            "Converting SMILES to graph: 18772/19709\n",
            "Converting SMILES to graph: 18773/19709\n",
            "Converting SMILES to graph: 18774/19709\n",
            "Converting SMILES to graph: 18775/19709\n",
            "Converting SMILES to graph: 18776/19709\n",
            "Converting SMILES to graph: 18777/19709\n",
            "Converting SMILES to graph: 18778/19709\n",
            "Converting SMILES to graph: 18779/19709\n",
            "Converting SMILES to graph: 18780/19709\n",
            "Converting SMILES to graph: 18781/19709\n",
            "Converting SMILES to graph: 18782/19709\n",
            "Converting SMILES to graph: 18783/19709\n",
            "Converting SMILES to graph: 18784/19709\n",
            "Converting SMILES to graph: 18785/19709\n",
            "Converting SMILES to graph: 18786/19709\n",
            "Converting SMILES to graph: 18787/19709\n",
            "Converting SMILES to graph: 18788/19709\n",
            "Converting SMILES to graph: 18789/19709\n",
            "Converting SMILES to graph: 18790/19709\n",
            "Converting SMILES to graph: 18791/19709\n",
            "Converting SMILES to graph: 18792/19709\n",
            "Converting SMILES to graph: 18793/19709\n",
            "Converting SMILES to graph: 18794/19709\n",
            "Converting SMILES to graph: 18795/19709\n",
            "Converting SMILES to graph: 18796/19709\n",
            "Converting SMILES to graph: 18797/19709\n",
            "Converting SMILES to graph: 18798/19709\n",
            "Converting SMILES to graph: 18799/19709\n",
            "Converting SMILES to graph: 18800/19709\n",
            "Converting SMILES to graph: 18801/19709\n",
            "Converting SMILES to graph: 18802/19709\n",
            "Converting SMILES to graph: 18803/19709\n",
            "Converting SMILES to graph: 18804/19709\n",
            "Converting SMILES to graph: 18805/19709\n",
            "Converting SMILES to graph: 18806/19709\n",
            "Converting SMILES to graph: 18807/19709\n",
            "Converting SMILES to graph: 18808/19709\n",
            "Converting SMILES to graph: 18809/19709\n",
            "Converting SMILES to graph: 18810/19709\n",
            "Converting SMILES to graph: 18811/19709\n",
            "Converting SMILES to graph: 18812/19709\n",
            "Converting SMILES to graph: 18813/19709\n",
            "Converting SMILES to graph: 18814/19709\n",
            "Converting SMILES to graph: 18815/19709\n",
            "Converting SMILES to graph: 18816/19709\n",
            "Converting SMILES to graph: 18817/19709\n",
            "Converting SMILES to graph: 18818/19709\n",
            "Converting SMILES to graph: 18819/19709\n",
            "Converting SMILES to graph: 18820/19709\n",
            "Converting SMILES to graph: 18821/19709\n",
            "Converting SMILES to graph: 18822/19709\n",
            "Converting SMILES to graph: 18823/19709\n",
            "Converting SMILES to graph: 18824/19709\n",
            "Converting SMILES to graph: 18825/19709\n",
            "Converting SMILES to graph: 18826/19709\n",
            "Converting SMILES to graph: 18827/19709\n",
            "Converting SMILES to graph: 18828/19709\n",
            "Converting SMILES to graph: 18829/19709\n",
            "Converting SMILES to graph: 18830/19709\n",
            "Converting SMILES to graph: 18831/19709\n",
            "Converting SMILES to graph: 18832/19709\n",
            "Converting SMILES to graph: 18833/19709\n",
            "Converting SMILES to graph: 18834/19709\n",
            "Converting SMILES to graph: 18835/19709\n",
            "Converting SMILES to graph: 18836/19709\n",
            "Converting SMILES to graph: 18837/19709\n",
            "Converting SMILES to graph: 18838/19709\n",
            "Converting SMILES to graph: 18839/19709\n",
            "Converting SMILES to graph: 18840/19709\n",
            "Converting SMILES to graph: 18841/19709\n",
            "Converting SMILES to graph: 18842/19709\n",
            "Converting SMILES to graph: 18843/19709\n",
            "Converting SMILES to graph: 18844/19709\n",
            "Converting SMILES to graph: 18845/19709\n",
            "Converting SMILES to graph: 18846/19709\n",
            "Converting SMILES to graph: 18847/19709\n",
            "Converting SMILES to graph: 18848/19709\n",
            "Converting SMILES to graph: 18849/19709\n",
            "Converting SMILES to graph: 18850/19709\n",
            "Converting SMILES to graph: 18851/19709\n",
            "Converting SMILES to graph: 18852/19709\n",
            "Converting SMILES to graph: 18853/19709\n",
            "Converting SMILES to graph: 18854/19709\n",
            "Converting SMILES to graph: 18855/19709\n",
            "Converting SMILES to graph: 18856/19709\n",
            "Converting SMILES to graph: 18857/19709\n",
            "Converting SMILES to graph: 18858/19709\n",
            "Converting SMILES to graph: 18859/19709\n",
            "Converting SMILES to graph: 18860/19709\n",
            "Converting SMILES to graph: 18861/19709\n",
            "Converting SMILES to graph: 18862/19709\n",
            "Converting SMILES to graph: 18863/19709\n",
            "Converting SMILES to graph: 18864/19709\n",
            "Converting SMILES to graph: 18865/19709\n",
            "Converting SMILES to graph: 18866/19709\n",
            "Converting SMILES to graph: 18867/19709\n",
            "Converting SMILES to graph: 18868/19709\n",
            "Converting SMILES to graph: 18869/19709\n",
            "Converting SMILES to graph: 18870/19709\n",
            "Converting SMILES to graph: 18871/19709\n",
            "Converting SMILES to graph: 18872/19709\n",
            "Converting SMILES to graph: 18873/19709\n",
            "Converting SMILES to graph: 18874/19709\n",
            "Converting SMILES to graph: 18875/19709\n",
            "Converting SMILES to graph: 18876/19709\n",
            "Converting SMILES to graph: 18877/19709\n",
            "Converting SMILES to graph: 18878/19709\n",
            "Converting SMILES to graph: 18879/19709\n",
            "Converting SMILES to graph: 18880/19709\n",
            "Converting SMILES to graph: 18881/19709\n",
            "Converting SMILES to graph: 18882/19709\n",
            "Converting SMILES to graph: 18883/19709\n",
            "Converting SMILES to graph: 18884/19709\n",
            "Converting SMILES to graph: 18885/19709\n",
            "Converting SMILES to graph: 18886/19709\n",
            "Converting SMILES to graph: 18887/19709\n",
            "Converting SMILES to graph: 18888/19709\n",
            "Converting SMILES to graph: 18889/19709\n",
            "Converting SMILES to graph: 18890/19709\n",
            "Converting SMILES to graph: 18891/19709\n",
            "Converting SMILES to graph: 18892/19709\n",
            "Converting SMILES to graph: 18893/19709\n",
            "Converting SMILES to graph: 18894/19709\n",
            "Converting SMILES to graph: 18895/19709\n",
            "Converting SMILES to graph: 18896/19709\n",
            "Converting SMILES to graph: 18897/19709\n",
            "Converting SMILES to graph: 18898/19709\n",
            "Converting SMILES to graph: 18899/19709\n",
            "Converting SMILES to graph: 18900/19709\n",
            "Converting SMILES to graph: 18901/19709\n",
            "Converting SMILES to graph: 18902/19709\n",
            "Converting SMILES to graph: 18903/19709\n",
            "Converting SMILES to graph: 18904/19709\n",
            "Converting SMILES to graph: 18905/19709\n",
            "Converting SMILES to graph: 18906/19709\n",
            "Converting SMILES to graph: 18907/19709\n",
            "Converting SMILES to graph: 18908/19709\n",
            "Converting SMILES to graph: 18909/19709\n",
            "Converting SMILES to graph: 18910/19709\n",
            "Converting SMILES to graph: 18911/19709\n",
            "Converting SMILES to graph: 18912/19709\n",
            "Converting SMILES to graph: 18913/19709\n",
            "Converting SMILES to graph: 18914/19709\n",
            "Converting SMILES to graph: 18915/19709\n",
            "Converting SMILES to graph: 18916/19709\n",
            "Converting SMILES to graph: 18917/19709\n",
            "Converting SMILES to graph: 18918/19709\n",
            "Converting SMILES to graph: 18919/19709\n",
            "Converting SMILES to graph: 18920/19709\n",
            "Converting SMILES to graph: 18921/19709\n",
            "Converting SMILES to graph: 18922/19709\n",
            "Converting SMILES to graph: 18923/19709\n",
            "Converting SMILES to graph: 18924/19709\n",
            "Converting SMILES to graph: 18925/19709\n",
            "Converting SMILES to graph: 18926/19709\n",
            "Converting SMILES to graph: 18927/19709\n",
            "Converting SMILES to graph: 18928/19709\n",
            "Converting SMILES to graph: 18929/19709\n",
            "Converting SMILES to graph: 18930/19709\n",
            "Converting SMILES to graph: 18931/19709\n",
            "Converting SMILES to graph: 18932/19709\n",
            "Converting SMILES to graph: 18933/19709\n",
            "Converting SMILES to graph: 18934/19709\n",
            "Converting SMILES to graph: 18935/19709\n",
            "Converting SMILES to graph: 18936/19709\n",
            "Converting SMILES to graph: 18937/19709\n",
            "Converting SMILES to graph: 18938/19709\n",
            "Converting SMILES to graph: 18939/19709\n",
            "Converting SMILES to graph: 18940/19709\n",
            "Converting SMILES to graph: 18941/19709\n",
            "Converting SMILES to graph: 18942/19709\n",
            "Converting SMILES to graph: 18943/19709\n",
            "Converting SMILES to graph: 18944/19709\n",
            "Converting SMILES to graph: 18945/19709\n",
            "Converting SMILES to graph: 18946/19709\n",
            "Converting SMILES to graph: 18947/19709\n",
            "Converting SMILES to graph: 18948/19709\n",
            "Converting SMILES to graph: 18949/19709\n",
            "Converting SMILES to graph: 18950/19709\n",
            "Converting SMILES to graph: 18951/19709\n",
            "Converting SMILES to graph: 18952/19709\n",
            "Converting SMILES to graph: 18953/19709\n",
            "Converting SMILES to graph: 18954/19709\n",
            "Converting SMILES to graph: 18955/19709\n",
            "Converting SMILES to graph: 18956/19709\n",
            "Converting SMILES to graph: 18957/19709\n",
            "Converting SMILES to graph: 18958/19709\n",
            "Converting SMILES to graph: 18959/19709\n",
            "Converting SMILES to graph: 18960/19709\n",
            "Converting SMILES to graph: 18961/19709\n",
            "Converting SMILES to graph: 18962/19709\n",
            "Converting SMILES to graph: 18963/19709\n",
            "Converting SMILES to graph: 18964/19709\n",
            "Converting SMILES to graph: 18965/19709\n",
            "Converting SMILES to graph: 18966/19709\n",
            "Converting SMILES to graph: 18967/19709\n",
            "Converting SMILES to graph: 18968/19709\n",
            "Converting SMILES to graph: 18969/19709\n",
            "Converting SMILES to graph: 18970/19709\n",
            "Converting SMILES to graph: 18971/19709\n",
            "Converting SMILES to graph: 18972/19709\n",
            "Converting SMILES to graph: 18973/19709\n",
            "Converting SMILES to graph: 18974/19709\n",
            "Converting SMILES to graph: 18975/19709\n",
            "Converting SMILES to graph: 18976/19709\n",
            "Converting SMILES to graph: 18977/19709\n",
            "Converting SMILES to graph: 18978/19709\n",
            "Converting SMILES to graph: 18979/19709\n",
            "Converting SMILES to graph: 18980/19709\n",
            "Converting SMILES to graph: 18981/19709\n",
            "Converting SMILES to graph: 18982/19709\n",
            "Converting SMILES to graph: 18983/19709\n",
            "Converting SMILES to graph: 18984/19709\n",
            "Converting SMILES to graph: 18985/19709\n",
            "Converting SMILES to graph: 18986/19709\n",
            "Converting SMILES to graph: 18987/19709\n",
            "Converting SMILES to graph: 18988/19709\n",
            "Converting SMILES to graph: 18989/19709\n",
            "Converting SMILES to graph: 18990/19709\n",
            "Converting SMILES to graph: 18991/19709\n",
            "Converting SMILES to graph: 18992/19709\n",
            "Converting SMILES to graph: 18993/19709\n",
            "Converting SMILES to graph: 18994/19709\n",
            "Converting SMILES to graph: 18995/19709\n",
            "Converting SMILES to graph: 18996/19709\n",
            "Converting SMILES to graph: 18997/19709\n",
            "Converting SMILES to graph: 18998/19709\n",
            "Converting SMILES to graph: 18999/19709\n",
            "Converting SMILES to graph: 19000/19709\n",
            "Converting SMILES to graph: 19001/19709\n",
            "Converting SMILES to graph: 19002/19709\n",
            "Converting SMILES to graph: 19003/19709\n",
            "Converting SMILES to graph: 19004/19709\n",
            "Converting SMILES to graph: 19005/19709\n",
            "Converting SMILES to graph: 19006/19709\n",
            "Converting SMILES to graph: 19007/19709\n",
            "Converting SMILES to graph: 19008/19709\n",
            "Converting SMILES to graph: 19009/19709\n",
            "Converting SMILES to graph: 19010/19709\n",
            "Converting SMILES to graph: 19011/19709\n",
            "Converting SMILES to graph: 19012/19709\n",
            "Converting SMILES to graph: 19013/19709\n",
            "Converting SMILES to graph: 19014/19709\n",
            "Converting SMILES to graph: 19015/19709\n",
            "Converting SMILES to graph: 19016/19709\n",
            "Converting SMILES to graph: 19017/19709\n",
            "Converting SMILES to graph: 19018/19709\n",
            "Converting SMILES to graph: 19019/19709\n",
            "Converting SMILES to graph: 19020/19709\n",
            "Converting SMILES to graph: 19021/19709\n",
            "Converting SMILES to graph: 19022/19709\n",
            "Converting SMILES to graph: 19023/19709\n",
            "Converting SMILES to graph: 19024/19709\n",
            "Converting SMILES to graph: 19025/19709\n",
            "Converting SMILES to graph: 19026/19709\n",
            "Converting SMILES to graph: 19027/19709\n",
            "Converting SMILES to graph: 19028/19709\n",
            "Converting SMILES to graph: 19029/19709\n",
            "Converting SMILES to graph: 19030/19709\n",
            "Converting SMILES to graph: 19031/19709\n",
            "Converting SMILES to graph: 19032/19709\n",
            "Converting SMILES to graph: 19033/19709\n",
            "Converting SMILES to graph: 19034/19709\n",
            "Converting SMILES to graph: 19035/19709\n",
            "Converting SMILES to graph: 19036/19709\n",
            "Converting SMILES to graph: 19037/19709\n",
            "Converting SMILES to graph: 19038/19709\n",
            "Converting SMILES to graph: 19039/19709\n",
            "Converting SMILES to graph: 19040/19709\n",
            "Converting SMILES to graph: 19041/19709\n",
            "Converting SMILES to graph: 19042/19709\n",
            "Converting SMILES to graph: 19043/19709\n",
            "Converting SMILES to graph: 19044/19709\n",
            "Converting SMILES to graph: 19045/19709\n",
            "Converting SMILES to graph: 19046/19709\n",
            "Converting SMILES to graph: 19047/19709\n",
            "Converting SMILES to graph: 19048/19709\n",
            "Converting SMILES to graph: 19049/19709\n",
            "Converting SMILES to graph: 19050/19709\n",
            "Converting SMILES to graph: 19051/19709\n",
            "Converting SMILES to graph: 19052/19709\n",
            "Converting SMILES to graph: 19053/19709\n",
            "Converting SMILES to graph: 19054/19709\n",
            "Converting SMILES to graph: 19055/19709\n",
            "Converting SMILES to graph: 19056/19709\n",
            "Converting SMILES to graph: 19057/19709\n",
            "Converting SMILES to graph: 19058/19709\n",
            "Converting SMILES to graph: 19059/19709\n",
            "Converting SMILES to graph: 19060/19709\n",
            "Converting SMILES to graph: 19061/19709\n",
            "Converting SMILES to graph: 19062/19709\n",
            "Converting SMILES to graph: 19063/19709\n",
            "Converting SMILES to graph: 19064/19709\n",
            "Converting SMILES to graph: 19065/19709\n",
            "Converting SMILES to graph: 19066/19709\n",
            "Converting SMILES to graph: 19067/19709\n",
            "Converting SMILES to graph: 19068/19709\n",
            "Converting SMILES to graph: 19069/19709\n",
            "Converting SMILES to graph: 19070/19709\n",
            "Converting SMILES to graph: 19071/19709\n",
            "Converting SMILES to graph: 19072/19709\n",
            "Converting SMILES to graph: 19073/19709\n",
            "Converting SMILES to graph: 19074/19709\n",
            "Converting SMILES to graph: 19075/19709\n",
            "Converting SMILES to graph: 19076/19709\n",
            "Converting SMILES to graph: 19077/19709\n",
            "Converting SMILES to graph: 19078/19709\n",
            "Converting SMILES to graph: 19079/19709\n",
            "Converting SMILES to graph: 19080/19709\n",
            "Converting SMILES to graph: 19081/19709\n",
            "Converting SMILES to graph: 19082/19709\n",
            "Converting SMILES to graph: 19083/19709\n",
            "Converting SMILES to graph: 19084/19709\n",
            "Converting SMILES to graph: 19085/19709\n",
            "Converting SMILES to graph: 19086/19709\n",
            "Converting SMILES to graph: 19087/19709\n",
            "Converting SMILES to graph: 19088/19709\n",
            "Converting SMILES to graph: 19089/19709\n",
            "Converting SMILES to graph: 19090/19709\n",
            "Converting SMILES to graph: 19091/19709\n",
            "Converting SMILES to graph: 19092/19709\n",
            "Converting SMILES to graph: 19093/19709\n",
            "Converting SMILES to graph: 19094/19709\n",
            "Converting SMILES to graph: 19095/19709\n",
            "Converting SMILES to graph: 19096/19709\n",
            "Converting SMILES to graph: 19097/19709\n",
            "Converting SMILES to graph: 19098/19709\n",
            "Converting SMILES to graph: 19099/19709\n",
            "Converting SMILES to graph: 19100/19709\n",
            "Converting SMILES to graph: 19101/19709\n",
            "Converting SMILES to graph: 19102/19709\n",
            "Converting SMILES to graph: 19103/19709\n",
            "Converting SMILES to graph: 19104/19709\n",
            "Converting SMILES to graph: 19105/19709\n",
            "Converting SMILES to graph: 19106/19709\n",
            "Converting SMILES to graph: 19107/19709\n",
            "Converting SMILES to graph: 19108/19709\n",
            "Converting SMILES to graph: 19109/19709\n",
            "Converting SMILES to graph: 19110/19709\n",
            "Converting SMILES to graph: 19111/19709\n",
            "Converting SMILES to graph: 19112/19709\n",
            "Converting SMILES to graph: 19113/19709\n",
            "Converting SMILES to graph: 19114/19709\n",
            "Converting SMILES to graph: 19115/19709\n",
            "Converting SMILES to graph: 19116/19709\n",
            "Converting SMILES to graph: 19117/19709\n",
            "Converting SMILES to graph: 19118/19709\n",
            "Converting SMILES to graph: 19119/19709\n",
            "Converting SMILES to graph: 19120/19709\n",
            "Converting SMILES to graph: 19121/19709\n",
            "Converting SMILES to graph: 19122/19709\n",
            "Converting SMILES to graph: 19123/19709\n",
            "Converting SMILES to graph: 19124/19709\n",
            "Converting SMILES to graph: 19125/19709\n",
            "Converting SMILES to graph: 19126/19709\n",
            "Converting SMILES to graph: 19127/19709\n",
            "Converting SMILES to graph: 19128/19709\n",
            "Converting SMILES to graph: 19129/19709\n",
            "Converting SMILES to graph: 19130/19709\n",
            "Converting SMILES to graph: 19131/19709\n",
            "Converting SMILES to graph: 19132/19709\n",
            "Converting SMILES to graph: 19133/19709\n",
            "Converting SMILES to graph: 19134/19709\n",
            "Converting SMILES to graph: 19135/19709\n",
            "Converting SMILES to graph: 19136/19709\n",
            "Converting SMILES to graph: 19137/19709\n",
            "Converting SMILES to graph: 19138/19709\n",
            "Converting SMILES to graph: 19139/19709\n",
            "Converting SMILES to graph: 19140/19709\n",
            "Converting SMILES to graph: 19141/19709\n",
            "Converting SMILES to graph: 19142/19709\n",
            "Converting SMILES to graph: 19143/19709\n",
            "Converting SMILES to graph: 19144/19709\n",
            "Converting SMILES to graph: 19145/19709\n",
            "Converting SMILES to graph: 19146/19709\n",
            "Converting SMILES to graph: 19147/19709\n",
            "Converting SMILES to graph: 19148/19709\n",
            "Converting SMILES to graph: 19149/19709\n",
            "Converting SMILES to graph: 19150/19709\n",
            "Converting SMILES to graph: 19151/19709\n",
            "Converting SMILES to graph: 19152/19709\n",
            "Converting SMILES to graph: 19153/19709\n",
            "Converting SMILES to graph: 19154/19709\n",
            "Converting SMILES to graph: 19155/19709\n",
            "Converting SMILES to graph: 19156/19709\n",
            "Converting SMILES to graph: 19157/19709\n",
            "Converting SMILES to graph: 19158/19709\n",
            "Converting SMILES to graph: 19159/19709\n",
            "Converting SMILES to graph: 19160/19709\n",
            "Converting SMILES to graph: 19161/19709\n",
            "Converting SMILES to graph: 19162/19709\n",
            "Converting SMILES to graph: 19163/19709\n",
            "Converting SMILES to graph: 19164/19709\n",
            "Converting SMILES to graph: 19165/19709\n",
            "Converting SMILES to graph: 19166/19709\n",
            "Converting SMILES to graph: 19167/19709\n",
            "Converting SMILES to graph: 19168/19709\n",
            "Converting SMILES to graph: 19169/19709\n",
            "Converting SMILES to graph: 19170/19709\n",
            "Converting SMILES to graph: 19171/19709\n",
            "Converting SMILES to graph: 19172/19709\n",
            "Converting SMILES to graph: 19173/19709\n",
            "Converting SMILES to graph: 19174/19709\n",
            "Converting SMILES to graph: 19175/19709\n",
            "Converting SMILES to graph: 19176/19709\n",
            "Converting SMILES to graph: 19177/19709\n",
            "Converting SMILES to graph: 19178/19709\n",
            "Converting SMILES to graph: 19179/19709\n",
            "Converting SMILES to graph: 19180/19709\n",
            "Converting SMILES to graph: 19181/19709\n",
            "Converting SMILES to graph: 19182/19709\n",
            "Converting SMILES to graph: 19183/19709\n",
            "Converting SMILES to graph: 19184/19709\n",
            "Converting SMILES to graph: 19185/19709\n",
            "Converting SMILES to graph: 19186/19709\n",
            "Converting SMILES to graph: 19187/19709\n",
            "Converting SMILES to graph: 19188/19709\n",
            "Converting SMILES to graph: 19189/19709\n",
            "Converting SMILES to graph: 19190/19709\n",
            "Converting SMILES to graph: 19191/19709\n",
            "Converting SMILES to graph: 19192/19709\n",
            "Converting SMILES to graph: 19193/19709\n",
            "Converting SMILES to graph: 19194/19709\n",
            "Converting SMILES to graph: 19195/19709\n",
            "Converting SMILES to graph: 19196/19709\n",
            "Converting SMILES to graph: 19197/19709\n",
            "Converting SMILES to graph: 19198/19709\n",
            "Converting SMILES to graph: 19199/19709\n",
            "Converting SMILES to graph: 19200/19709\n",
            "Converting SMILES to graph: 19201/19709\n",
            "Converting SMILES to graph: 19202/19709\n",
            "Converting SMILES to graph: 19203/19709\n",
            "Converting SMILES to graph: 19204/19709\n",
            "Converting SMILES to graph: 19205/19709\n",
            "Converting SMILES to graph: 19206/19709\n",
            "Converting SMILES to graph: 19207/19709\n",
            "Converting SMILES to graph: 19208/19709\n",
            "Converting SMILES to graph: 19209/19709\n",
            "Converting SMILES to graph: 19210/19709\n",
            "Converting SMILES to graph: 19211/19709\n",
            "Converting SMILES to graph: 19212/19709\n",
            "Converting SMILES to graph: 19213/19709\n",
            "Converting SMILES to graph: 19214/19709\n",
            "Converting SMILES to graph: 19215/19709\n",
            "Converting SMILES to graph: 19216/19709\n",
            "Converting SMILES to graph: 19217/19709\n",
            "Converting SMILES to graph: 19218/19709\n",
            "Converting SMILES to graph: 19219/19709\n",
            "Converting SMILES to graph: 19220/19709\n",
            "Converting SMILES to graph: 19221/19709\n",
            "Converting SMILES to graph: 19222/19709\n",
            "Converting SMILES to graph: 19223/19709\n",
            "Converting SMILES to graph: 19224/19709\n",
            "Converting SMILES to graph: 19225/19709\n",
            "Converting SMILES to graph: 19226/19709\n",
            "Converting SMILES to graph: 19227/19709\n",
            "Converting SMILES to graph: 19228/19709\n",
            "Converting SMILES to graph: 19229/19709\n",
            "Converting SMILES to graph: 19230/19709\n",
            "Converting SMILES to graph: 19231/19709\n",
            "Converting SMILES to graph: 19232/19709\n",
            "Converting SMILES to graph: 19233/19709\n",
            "Converting SMILES to graph: 19234/19709\n",
            "Converting SMILES to graph: 19235/19709\n",
            "Converting SMILES to graph: 19236/19709\n",
            "Converting SMILES to graph: 19237/19709\n",
            "Converting SMILES to graph: 19238/19709\n",
            "Converting SMILES to graph: 19239/19709\n",
            "Converting SMILES to graph: 19240/19709\n",
            "Converting SMILES to graph: 19241/19709\n",
            "Converting SMILES to graph: 19242/19709\n",
            "Converting SMILES to graph: 19243/19709\n",
            "Converting SMILES to graph: 19244/19709\n",
            "Converting SMILES to graph: 19245/19709\n",
            "Converting SMILES to graph: 19246/19709\n",
            "Converting SMILES to graph: 19247/19709\n",
            "Converting SMILES to graph: 19248/19709\n",
            "Converting SMILES to graph: 19249/19709\n",
            "Converting SMILES to graph: 19250/19709\n",
            "Converting SMILES to graph: 19251/19709\n",
            "Converting SMILES to graph: 19252/19709\n",
            "Converting SMILES to graph: 19253/19709\n",
            "Converting SMILES to graph: 19254/19709\n",
            "Converting SMILES to graph: 19255/19709\n",
            "Converting SMILES to graph: 19256/19709\n",
            "Converting SMILES to graph: 19257/19709\n",
            "Converting SMILES to graph: 19258/19709\n",
            "Converting SMILES to graph: 19259/19709\n",
            "Converting SMILES to graph: 19260/19709\n",
            "Converting SMILES to graph: 19261/19709\n",
            "Converting SMILES to graph: 19262/19709\n",
            "Converting SMILES to graph: 19263/19709\n",
            "Converting SMILES to graph: 19264/19709\n",
            "Converting SMILES to graph: 19265/19709\n",
            "Converting SMILES to graph: 19266/19709\n",
            "Converting SMILES to graph: 19267/19709\n",
            "Converting SMILES to graph: 19268/19709\n",
            "Converting SMILES to graph: 19269/19709\n",
            "Converting SMILES to graph: 19270/19709\n",
            "Converting SMILES to graph: 19271/19709\n",
            "Converting SMILES to graph: 19272/19709\n",
            "Converting SMILES to graph: 19273/19709\n",
            "Converting SMILES to graph: 19274/19709\n",
            "Converting SMILES to graph: 19275/19709\n",
            "Converting SMILES to graph: 19276/19709\n",
            "Converting SMILES to graph: 19277/19709\n",
            "Converting SMILES to graph: 19278/19709\n",
            "Converting SMILES to graph: 19279/19709\n",
            "Converting SMILES to graph: 19280/19709\n",
            "Converting SMILES to graph: 19281/19709\n",
            "Converting SMILES to graph: 19282/19709\n",
            "Converting SMILES to graph: 19283/19709\n",
            "Converting SMILES to graph: 19284/19709\n",
            "Converting SMILES to graph: 19285/19709\n",
            "Converting SMILES to graph: 19286/19709\n",
            "Converting SMILES to graph: 19287/19709\n",
            "Converting SMILES to graph: 19288/19709\n",
            "Converting SMILES to graph: 19289/19709\n",
            "Converting SMILES to graph: 19290/19709\n",
            "Converting SMILES to graph: 19291/19709\n",
            "Converting SMILES to graph: 19292/19709\n",
            "Converting SMILES to graph: 19293/19709\n",
            "Converting SMILES to graph: 19294/19709\n",
            "Converting SMILES to graph: 19295/19709\n",
            "Converting SMILES to graph: 19296/19709\n",
            "Converting SMILES to graph: 19297/19709\n",
            "Converting SMILES to graph: 19298/19709\n",
            "Converting SMILES to graph: 19299/19709\n",
            "Converting SMILES to graph: 19300/19709\n",
            "Converting SMILES to graph: 19301/19709\n",
            "Converting SMILES to graph: 19302/19709\n",
            "Converting SMILES to graph: 19303/19709\n",
            "Converting SMILES to graph: 19304/19709\n",
            "Converting SMILES to graph: 19305/19709\n",
            "Converting SMILES to graph: 19306/19709\n",
            "Converting SMILES to graph: 19307/19709\n",
            "Converting SMILES to graph: 19308/19709\n",
            "Converting SMILES to graph: 19309/19709\n",
            "Converting SMILES to graph: 19310/19709\n",
            "Converting SMILES to graph: 19311/19709\n",
            "Converting SMILES to graph: 19312/19709\n",
            "Converting SMILES to graph: 19313/19709\n",
            "Converting SMILES to graph: 19314/19709\n",
            "Converting SMILES to graph: 19315/19709\n",
            "Converting SMILES to graph: 19316/19709\n",
            "Converting SMILES to graph: 19317/19709\n",
            "Converting SMILES to graph: 19318/19709\n",
            "Converting SMILES to graph: 19319/19709\n",
            "Converting SMILES to graph: 19320/19709\n",
            "Converting SMILES to graph: 19321/19709\n",
            "Converting SMILES to graph: 19322/19709\n",
            "Converting SMILES to graph: 19323/19709\n",
            "Converting SMILES to graph: 19324/19709\n",
            "Converting SMILES to graph: 19325/19709\n",
            "Converting SMILES to graph: 19326/19709\n",
            "Converting SMILES to graph: 19327/19709\n",
            "Converting SMILES to graph: 19328/19709\n",
            "Converting SMILES to graph: 19329/19709\n",
            "Converting SMILES to graph: 19330/19709\n",
            "Converting SMILES to graph: 19331/19709\n",
            "Converting SMILES to graph: 19332/19709\n",
            "Converting SMILES to graph: 19333/19709\n",
            "Converting SMILES to graph: 19334/19709\n",
            "Converting SMILES to graph: 19335/19709\n",
            "Converting SMILES to graph: 19336/19709\n",
            "Converting SMILES to graph: 19337/19709\n",
            "Converting SMILES to graph: 19338/19709\n",
            "Converting SMILES to graph: 19339/19709\n",
            "Converting SMILES to graph: 19340/19709\n",
            "Converting SMILES to graph: 19341/19709\n",
            "Converting SMILES to graph: 19342/19709\n",
            "Converting SMILES to graph: 19343/19709\n",
            "Converting SMILES to graph: 19344/19709\n",
            "Converting SMILES to graph: 19345/19709\n",
            "Converting SMILES to graph: 19346/19709\n",
            "Converting SMILES to graph: 19347/19709\n",
            "Converting SMILES to graph: 19348/19709\n",
            "Converting SMILES to graph: 19349/19709\n",
            "Converting SMILES to graph: 19350/19709\n",
            "Converting SMILES to graph: 19351/19709\n",
            "Converting SMILES to graph: 19352/19709\n",
            "Converting SMILES to graph: 19353/19709\n",
            "Converting SMILES to graph: 19354/19709\n",
            "Converting SMILES to graph: 19355/19709\n",
            "Converting SMILES to graph: 19356/19709\n",
            "Converting SMILES to graph: 19357/19709\n",
            "Converting SMILES to graph: 19358/19709\n",
            "Converting SMILES to graph: 19359/19709\n",
            "Converting SMILES to graph: 19360/19709\n",
            "Converting SMILES to graph: 19361/19709\n",
            "Converting SMILES to graph: 19362/19709\n",
            "Converting SMILES to graph: 19363/19709\n",
            "Converting SMILES to graph: 19364/19709\n",
            "Converting SMILES to graph: 19365/19709\n",
            "Converting SMILES to graph: 19366/19709\n",
            "Converting SMILES to graph: 19367/19709\n",
            "Converting SMILES to graph: 19368/19709\n",
            "Converting SMILES to graph: 19369/19709\n",
            "Converting SMILES to graph: 19370/19709\n",
            "Converting SMILES to graph: 19371/19709\n",
            "Converting SMILES to graph: 19372/19709\n",
            "Converting SMILES to graph: 19373/19709\n",
            "Converting SMILES to graph: 19374/19709\n",
            "Converting SMILES to graph: 19375/19709\n",
            "Converting SMILES to graph: 19376/19709\n",
            "Converting SMILES to graph: 19377/19709\n",
            "Converting SMILES to graph: 19378/19709\n",
            "Converting SMILES to graph: 19379/19709\n",
            "Converting SMILES to graph: 19380/19709\n",
            "Converting SMILES to graph: 19381/19709\n",
            "Converting SMILES to graph: 19382/19709\n",
            "Converting SMILES to graph: 19383/19709\n",
            "Converting SMILES to graph: 19384/19709\n",
            "Converting SMILES to graph: 19385/19709\n",
            "Converting SMILES to graph: 19386/19709\n",
            "Converting SMILES to graph: 19387/19709\n",
            "Converting SMILES to graph: 19388/19709\n",
            "Converting SMILES to graph: 19389/19709\n",
            "Converting SMILES to graph: 19390/19709\n",
            "Converting SMILES to graph: 19391/19709\n",
            "Converting SMILES to graph: 19392/19709\n",
            "Converting SMILES to graph: 19393/19709\n",
            "Converting SMILES to graph: 19394/19709\n",
            "Converting SMILES to graph: 19395/19709\n",
            "Converting SMILES to graph: 19396/19709\n",
            "Converting SMILES to graph: 19397/19709\n",
            "Converting SMILES to graph: 19398/19709\n",
            "Converting SMILES to graph: 19399/19709\n",
            "Converting SMILES to graph: 19400/19709\n",
            "Converting SMILES to graph: 19401/19709\n",
            "Converting SMILES to graph: 19402/19709\n",
            "Converting SMILES to graph: 19403/19709\n",
            "Converting SMILES to graph: 19404/19709\n",
            "Converting SMILES to graph: 19405/19709\n",
            "Converting SMILES to graph: 19406/19709\n",
            "Converting SMILES to graph: 19407/19709\n",
            "Converting SMILES to graph: 19408/19709\n",
            "Converting SMILES to graph: 19409/19709\n",
            "Converting SMILES to graph: 19410/19709\n",
            "Converting SMILES to graph: 19411/19709\n",
            "Converting SMILES to graph: 19412/19709\n",
            "Converting SMILES to graph: 19413/19709\n",
            "Converting SMILES to graph: 19414/19709\n",
            "Converting SMILES to graph: 19415/19709\n",
            "Converting SMILES to graph: 19416/19709\n",
            "Converting SMILES to graph: 19417/19709\n",
            "Converting SMILES to graph: 19418/19709\n",
            "Converting SMILES to graph: 19419/19709\n",
            "Converting SMILES to graph: 19420/19709\n",
            "Converting SMILES to graph: 19421/19709\n",
            "Converting SMILES to graph: 19422/19709\n",
            "Converting SMILES to graph: 19423/19709\n",
            "Converting SMILES to graph: 19424/19709\n",
            "Converting SMILES to graph: 19425/19709\n",
            "Converting SMILES to graph: 19426/19709\n",
            "Converting SMILES to graph: 19427/19709\n",
            "Converting SMILES to graph: 19428/19709\n",
            "Converting SMILES to graph: 19429/19709\n",
            "Converting SMILES to graph: 19430/19709\n",
            "Converting SMILES to graph: 19431/19709\n",
            "Converting SMILES to graph: 19432/19709\n",
            "Converting SMILES to graph: 19433/19709\n",
            "Converting SMILES to graph: 19434/19709\n",
            "Converting SMILES to graph: 19435/19709\n",
            "Converting SMILES to graph: 19436/19709\n",
            "Converting SMILES to graph: 19437/19709\n",
            "Converting SMILES to graph: 19438/19709\n",
            "Converting SMILES to graph: 19439/19709\n",
            "Converting SMILES to graph: 19440/19709\n",
            "Converting SMILES to graph: 19441/19709\n",
            "Converting SMILES to graph: 19442/19709\n",
            "Converting SMILES to graph: 19443/19709\n",
            "Converting SMILES to graph: 19444/19709\n",
            "Converting SMILES to graph: 19445/19709\n",
            "Converting SMILES to graph: 19446/19709\n",
            "Converting SMILES to graph: 19447/19709\n",
            "Converting SMILES to graph: 19448/19709\n",
            "Converting SMILES to graph: 19449/19709\n",
            "Converting SMILES to graph: 19450/19709\n",
            "Converting SMILES to graph: 19451/19709\n",
            "Converting SMILES to graph: 19452/19709\n",
            "Converting SMILES to graph: 19453/19709\n",
            "Converting SMILES to graph: 19454/19709\n",
            "Converting SMILES to graph: 19455/19709\n",
            "Converting SMILES to graph: 19456/19709\n",
            "Converting SMILES to graph: 19457/19709\n",
            "Converting SMILES to graph: 19458/19709\n",
            "Converting SMILES to graph: 19459/19709\n",
            "Converting SMILES to graph: 19460/19709\n",
            "Converting SMILES to graph: 19461/19709\n",
            "Converting SMILES to graph: 19462/19709\n",
            "Converting SMILES to graph: 19463/19709\n",
            "Converting SMILES to graph: 19464/19709\n",
            "Converting SMILES to graph: 19465/19709\n",
            "Converting SMILES to graph: 19466/19709\n",
            "Converting SMILES to graph: 19467/19709\n",
            "Converting SMILES to graph: 19468/19709\n",
            "Converting SMILES to graph: 19469/19709\n",
            "Converting SMILES to graph: 19470/19709\n",
            "Converting SMILES to graph: 19471/19709\n",
            "Converting SMILES to graph: 19472/19709\n",
            "Converting SMILES to graph: 19473/19709\n",
            "Converting SMILES to graph: 19474/19709\n",
            "Converting SMILES to graph: 19475/19709\n",
            "Converting SMILES to graph: 19476/19709\n",
            "Converting SMILES to graph: 19477/19709\n",
            "Converting SMILES to graph: 19478/19709\n",
            "Converting SMILES to graph: 19479/19709\n",
            "Converting SMILES to graph: 19480/19709\n",
            "Converting SMILES to graph: 19481/19709\n",
            "Converting SMILES to graph: 19482/19709\n",
            "Converting SMILES to graph: 19483/19709\n",
            "Converting SMILES to graph: 19484/19709\n",
            "Converting SMILES to graph: 19485/19709\n",
            "Converting SMILES to graph: 19486/19709\n",
            "Converting SMILES to graph: 19487/19709\n",
            "Converting SMILES to graph: 19488/19709\n",
            "Converting SMILES to graph: 19489/19709\n",
            "Converting SMILES to graph: 19490/19709\n",
            "Converting SMILES to graph: 19491/19709\n",
            "Converting SMILES to graph: 19492/19709\n",
            "Converting SMILES to graph: 19493/19709\n",
            "Converting SMILES to graph: 19494/19709\n",
            "Converting SMILES to graph: 19495/19709\n",
            "Converting SMILES to graph: 19496/19709\n",
            "Converting SMILES to graph: 19497/19709\n",
            "Converting SMILES to graph: 19498/19709\n",
            "Converting SMILES to graph: 19499/19709\n",
            "Converting SMILES to graph: 19500/19709\n",
            "Converting SMILES to graph: 19501/19709\n",
            "Converting SMILES to graph: 19502/19709\n",
            "Converting SMILES to graph: 19503/19709\n",
            "Converting SMILES to graph: 19504/19709\n",
            "Converting SMILES to graph: 19505/19709\n",
            "Converting SMILES to graph: 19506/19709\n",
            "Converting SMILES to graph: 19507/19709\n",
            "Converting SMILES to graph: 19508/19709\n",
            "Converting SMILES to graph: 19509/19709\n",
            "Converting SMILES to graph: 19510/19709\n",
            "Converting SMILES to graph: 19511/19709\n",
            "Converting SMILES to graph: 19512/19709\n",
            "Converting SMILES to graph: 19513/19709\n",
            "Converting SMILES to graph: 19514/19709\n",
            "Converting SMILES to graph: 19515/19709\n",
            "Converting SMILES to graph: 19516/19709\n",
            "Converting SMILES to graph: 19517/19709\n",
            "Converting SMILES to graph: 19518/19709\n",
            "Converting SMILES to graph: 19519/19709\n",
            "Converting SMILES to graph: 19520/19709\n",
            "Converting SMILES to graph: 19521/19709\n",
            "Converting SMILES to graph: 19522/19709\n",
            "Converting SMILES to graph: 19523/19709\n",
            "Converting SMILES to graph: 19524/19709\n",
            "Converting SMILES to graph: 19525/19709\n",
            "Converting SMILES to graph: 19526/19709\n",
            "Converting SMILES to graph: 19527/19709\n",
            "Converting SMILES to graph: 19528/19709\n",
            "Converting SMILES to graph: 19529/19709\n",
            "Converting SMILES to graph: 19530/19709\n",
            "Converting SMILES to graph: 19531/19709\n",
            "Converting SMILES to graph: 19532/19709\n",
            "Converting SMILES to graph: 19533/19709\n",
            "Converting SMILES to graph: 19534/19709\n",
            "Converting SMILES to graph: 19535/19709\n",
            "Converting SMILES to graph: 19536/19709\n",
            "Converting SMILES to graph: 19537/19709\n",
            "Converting SMILES to graph: 19538/19709\n",
            "Converting SMILES to graph: 19539/19709\n",
            "Converting SMILES to graph: 19540/19709\n",
            "Converting SMILES to graph: 19541/19709\n",
            "Converting SMILES to graph: 19542/19709\n",
            "Converting SMILES to graph: 19543/19709\n",
            "Converting SMILES to graph: 19544/19709\n",
            "Converting SMILES to graph: 19545/19709\n",
            "Converting SMILES to graph: 19546/19709\n",
            "Converting SMILES to graph: 19547/19709\n",
            "Converting SMILES to graph: 19548/19709\n",
            "Converting SMILES to graph: 19549/19709\n",
            "Converting SMILES to graph: 19550/19709\n",
            "Converting SMILES to graph: 19551/19709\n",
            "Converting SMILES to graph: 19552/19709\n",
            "Converting SMILES to graph: 19553/19709\n",
            "Converting SMILES to graph: 19554/19709\n",
            "Converting SMILES to graph: 19555/19709\n",
            "Converting SMILES to graph: 19556/19709\n",
            "Converting SMILES to graph: 19557/19709\n",
            "Converting SMILES to graph: 19558/19709\n",
            "Converting SMILES to graph: 19559/19709\n",
            "Converting SMILES to graph: 19560/19709\n",
            "Converting SMILES to graph: 19561/19709\n",
            "Converting SMILES to graph: 19562/19709\n",
            "Converting SMILES to graph: 19563/19709\n",
            "Converting SMILES to graph: 19564/19709\n",
            "Converting SMILES to graph: 19565/19709\n",
            "Converting SMILES to graph: 19566/19709\n",
            "Converting SMILES to graph: 19567/19709\n",
            "Converting SMILES to graph: 19568/19709\n",
            "Converting SMILES to graph: 19569/19709\n",
            "Converting SMILES to graph: 19570/19709\n",
            "Converting SMILES to graph: 19571/19709\n",
            "Converting SMILES to graph: 19572/19709\n",
            "Converting SMILES to graph: 19573/19709\n",
            "Converting SMILES to graph: 19574/19709\n",
            "Converting SMILES to graph: 19575/19709\n",
            "Converting SMILES to graph: 19576/19709\n",
            "Converting SMILES to graph: 19577/19709\n",
            "Converting SMILES to graph: 19578/19709\n",
            "Converting SMILES to graph: 19579/19709\n",
            "Converting SMILES to graph: 19580/19709\n",
            "Converting SMILES to graph: 19581/19709\n",
            "Converting SMILES to graph: 19582/19709\n",
            "Converting SMILES to graph: 19583/19709\n",
            "Converting SMILES to graph: 19584/19709\n",
            "Converting SMILES to graph: 19585/19709\n",
            "Converting SMILES to graph: 19586/19709\n",
            "Converting SMILES to graph: 19587/19709\n",
            "Converting SMILES to graph: 19588/19709\n",
            "Converting SMILES to graph: 19589/19709\n",
            "Converting SMILES to graph: 19590/19709\n",
            "Converting SMILES to graph: 19591/19709\n",
            "Converting SMILES to graph: 19592/19709\n",
            "Converting SMILES to graph: 19593/19709\n",
            "Converting SMILES to graph: 19594/19709\n",
            "Converting SMILES to graph: 19595/19709\n",
            "Converting SMILES to graph: 19596/19709\n",
            "Converting SMILES to graph: 19597/19709\n",
            "Converting SMILES to graph: 19598/19709\n",
            "Converting SMILES to graph: 19599/19709\n",
            "Converting SMILES to graph: 19600/19709\n",
            "Converting SMILES to graph: 19601/19709\n",
            "Converting SMILES to graph: 19602/19709\n",
            "Converting SMILES to graph: 19603/19709\n",
            "Converting SMILES to graph: 19604/19709\n",
            "Converting SMILES to graph: 19605/19709\n",
            "Converting SMILES to graph: 19606/19709\n",
            "Converting SMILES to graph: 19607/19709\n",
            "Converting SMILES to graph: 19608/19709\n",
            "Converting SMILES to graph: 19609/19709\n",
            "Converting SMILES to graph: 19610/19709\n",
            "Converting SMILES to graph: 19611/19709\n",
            "Converting SMILES to graph: 19612/19709\n",
            "Converting SMILES to graph: 19613/19709\n",
            "Converting SMILES to graph: 19614/19709\n",
            "Converting SMILES to graph: 19615/19709\n",
            "Converting SMILES to graph: 19616/19709\n",
            "Converting SMILES to graph: 19617/19709\n",
            "Converting SMILES to graph: 19618/19709\n",
            "Converting SMILES to graph: 19619/19709\n",
            "Converting SMILES to graph: 19620/19709\n",
            "Converting SMILES to graph: 19621/19709\n",
            "Converting SMILES to graph: 19622/19709\n",
            "Converting SMILES to graph: 19623/19709\n",
            "Converting SMILES to graph: 19624/19709\n",
            "Converting SMILES to graph: 19625/19709\n",
            "Converting SMILES to graph: 19626/19709\n",
            "Converting SMILES to graph: 19627/19709\n",
            "Converting SMILES to graph: 19628/19709\n",
            "Converting SMILES to graph: 19629/19709\n",
            "Converting SMILES to graph: 19630/19709\n",
            "Converting SMILES to graph: 19631/19709\n",
            "Converting SMILES to graph: 19632/19709\n",
            "Converting SMILES to graph: 19633/19709\n",
            "Converting SMILES to graph: 19634/19709\n",
            "Converting SMILES to graph: 19635/19709\n",
            "Converting SMILES to graph: 19636/19709\n",
            "Converting SMILES to graph: 19637/19709\n",
            "Converting SMILES to graph: 19638/19709\n",
            "Converting SMILES to graph: 19639/19709\n",
            "Converting SMILES to graph: 19640/19709\n",
            "Converting SMILES to graph: 19641/19709\n",
            "Converting SMILES to graph: 19642/19709\n",
            "Converting SMILES to graph: 19643/19709\n",
            "Converting SMILES to graph: 19644/19709\n",
            "Converting SMILES to graph: 19645/19709\n",
            "Converting SMILES to graph: 19646/19709\n",
            "Converting SMILES to graph: 19647/19709\n",
            "Converting SMILES to graph: 19648/19709\n",
            "Converting SMILES to graph: 19649/19709\n",
            "Converting SMILES to graph: 19650/19709\n",
            "Converting SMILES to graph: 19651/19709\n",
            "Converting SMILES to graph: 19652/19709\n",
            "Converting SMILES to graph: 19653/19709\n",
            "Converting SMILES to graph: 19654/19709\n",
            "Converting SMILES to graph: 19655/19709\n",
            "Converting SMILES to graph: 19656/19709\n",
            "Converting SMILES to graph: 19657/19709\n",
            "Converting SMILES to graph: 19658/19709\n",
            "Converting SMILES to graph: 19659/19709\n",
            "Converting SMILES to graph: 19660/19709\n",
            "Converting SMILES to graph: 19661/19709\n",
            "Converting SMILES to graph: 19662/19709\n",
            "Converting SMILES to graph: 19663/19709\n",
            "Converting SMILES to graph: 19664/19709\n",
            "Converting SMILES to graph: 19665/19709\n",
            "Converting SMILES to graph: 19666/19709\n",
            "Converting SMILES to graph: 19667/19709\n",
            "Converting SMILES to graph: 19668/19709\n",
            "Converting SMILES to graph: 19669/19709\n",
            "Converting SMILES to graph: 19670/19709\n",
            "Converting SMILES to graph: 19671/19709\n",
            "Converting SMILES to graph: 19672/19709\n",
            "Converting SMILES to graph: 19673/19709\n",
            "Converting SMILES to graph: 19674/19709\n",
            "Converting SMILES to graph: 19675/19709\n",
            "Converting SMILES to graph: 19676/19709\n",
            "Converting SMILES to graph: 19677/19709\n",
            "Converting SMILES to graph: 19678/19709\n",
            "Converting SMILES to graph: 19679/19709\n",
            "Converting SMILES to graph: 19680/19709\n",
            "Converting SMILES to graph: 19681/19709\n",
            "Converting SMILES to graph: 19682/19709\n",
            "Converting SMILES to graph: 19683/19709\n",
            "Converting SMILES to graph: 19684/19709\n",
            "Converting SMILES to graph: 19685/19709\n",
            "Converting SMILES to graph: 19686/19709\n",
            "Converting SMILES to graph: 19687/19709\n",
            "Converting SMILES to graph: 19688/19709\n",
            "Converting SMILES to graph: 19689/19709\n",
            "Converting SMILES to graph: 19690/19709\n",
            "Converting SMILES to graph: 19691/19709\n",
            "Converting SMILES to graph: 19692/19709\n",
            "Converting SMILES to graph: 19693/19709\n",
            "Converting SMILES to graph: 19694/19709\n",
            "Converting SMILES to graph: 19695/19709\n",
            "Converting SMILES to graph: 19696/19709\n",
            "Converting SMILES to graph: 19697/19709\n",
            "Converting SMILES to graph: 19698/19709\n",
            "Converting SMILES to graph: 19699/19709\n",
            "Converting SMILES to graph: 19700/19709\n",
            "Converting SMILES to graph: 19701/19709\n",
            "Converting SMILES to graph: 19702/19709\n",
            "Converting SMILES to graph: 19703/19709\n",
            "Converting SMILES to graph: 19704/19709\n",
            "Converting SMILES to graph: 19705/19709\n",
            "Converting SMILES to graph: 19706/19709\n",
            "Converting SMILES to graph: 19707/19709\n",
            "Converting SMILES to graph: 19708/19709\n",
            "Converting SMILES to graph: 19709/19709\n",
            "Graph construction done. Saving to file.\n",
            "data/processed/kiba_train.pt  and  data/processed/kiba_test.pt  have been created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training.py 0 1 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp191fRA2mUa",
        "outputId": "438e5f87-bd4a-4878-d705-0db2cec5b34b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train epoch: 154 [633020/25046 (79%)]\tLoss: 0.632504\n",
            "Train epoch: 154 [663040/25046 (82%)]\tLoss: 0.542150\n",
            "Train epoch: 154 [698940/25046 (84%)]\tLoss: 0.873960\n",
            "Train epoch: 154 [758880/25046 (87%)]\tLoss: 0.689996\n",
            "Train epoch: 154 [714700/25046 (89%)]\tLoss: 0.830941\n",
            "Train epoch: 154 [736560/25046 (92%)]\tLoss: 0.694505\n",
            "Train epoch: 154 [751840/25046 (95%)]\tLoss: 1.262341\n",
            "Train epoch: 154 [817000/25046 (97%)]\tLoss: 0.859942\n",
            "Train epoch: 154 [833040/25046 (100%)]\tLoss: 0.650608\n",
            "Make prediction for 5010 samples...\n",
            "0.8050461 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 155 [0/25046 (0%)]\tLoss: 0.702057\n",
            "Train epoch: 155 [20520/25046 (3%)]\tLoss: 0.589316\n",
            "Train epoch: 155 [39840/25046 (5%)]\tLoss: 0.256727\n",
            "Train epoch: 155 [60540/25046 (8%)]\tLoss: 0.380912\n",
            "Train epoch: 155 [81280/25046 (10%)]\tLoss: 0.889121\n",
            "Train epoch: 155 [102300/25046 (13%)]\tLoss: 1.095693\n",
            "Train epoch: 155 [124440/25046 (15%)]\tLoss: 0.793772\n",
            "Train epoch: 155 [141120/25046 (18%)]\tLoss: 0.505411\n",
            "Train epoch: 155 [164800/25046 (20%)]\tLoss: 1.324425\n",
            "Train epoch: 155 [189000/25046 (23%)]\tLoss: 0.894638\n",
            "Train epoch: 155 [204000/25046 (26%)]\tLoss: 1.276397\n",
            "Train epoch: 155 [219120/25046 (28%)]\tLoss: 0.721114\n",
            "Train epoch: 155 [234240/25046 (31%)]\tLoss: 0.326281\n",
            "Train epoch: 155 [261560/25046 (33%)]\tLoss: 1.229926\n",
            "Train epoch: 155 [298200/25046 (36%)]\tLoss: 0.898663\n",
            "Train epoch: 155 [305700/25046 (38%)]\tLoss: 0.377653\n",
            "Train epoch: 155 [323200/25046 (41%)]\tLoss: 0.977577\n",
            "Train epoch: 155 [336260/25046 (43%)]\tLoss: 0.992857\n",
            "Train epoch: 155 [360360/25046 (46%)]\tLoss: 1.001123\n",
            "Train epoch: 155 [383420/25046 (49%)]\tLoss: 0.725969\n",
            "Train epoch: 155 [441600/25046 (51%)]\tLoss: 1.045848\n",
            "Train epoch: 155 [460320/25046 (54%)]\tLoss: 0.522508\n",
            "Train epoch: 155 [447920/25046 (56%)]\tLoss: 0.774966\n",
            "Train epoch: 155 [466900/25046 (59%)]\tLoss: 0.431437\n",
            "Train epoch: 155 [487680/25046 (61%)]\tLoss: 1.133571\n",
            "Train epoch: 155 [547500/25046 (64%)]\tLoss: 0.785205\n",
            "Train epoch: 155 [558480/25046 (66%)]\tLoss: 0.324794\n",
            "Train epoch: 155 [536760/25046 (69%)]\tLoss: 0.387980\n",
            "Train epoch: 155 [597520/25046 (72%)]\tLoss: 1.205061\n",
            "Train epoch: 155 [571880/25046 (74%)]\tLoss: 0.335793\n",
            "Train epoch: 155 [604200/25046 (77%)]\tLoss: 0.705070\n",
            "Train epoch: 155 [636740/25046 (79%)]\tLoss: 1.118655\n",
            "Train epoch: 155 [683520/25046 (82%)]\tLoss: 1.150054\n",
            "Train epoch: 155 [679140/25046 (84%)]\tLoss: 0.506811\n",
            "Train epoch: 155 [687480/25046 (87%)]\tLoss: 1.911911\n",
            "Train epoch: 155 [759500/25046 (89%)]\tLoss: 1.219926\n",
            "Train epoch: 155 [703440/25046 (92%)]\tLoss: 0.600174\n",
            "Train epoch: 155 [788100/25046 (95%)]\tLoss: 0.251673\n",
            "Train epoch: 155 [802560/25046 (97%)]\tLoss: 1.087730\n",
            "Train epoch: 155 [779220/25046 (100%)]\tLoss: 1.370949\n",
            "Make prediction for 5010 samples...\n",
            "0.8017303 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 156 [0/25046 (0%)]\tLoss: 0.599236\n",
            "Train epoch: 156 [20640/25046 (3%)]\tLoss: 1.703517\n",
            "Train epoch: 156 [43720/25046 (5%)]\tLoss: 0.693738\n",
            "Train epoch: 156 [62100/25046 (8%)]\tLoss: 0.618070\n",
            "Train epoch: 156 [79920/25046 (10%)]\tLoss: 0.926343\n",
            "Train epoch: 156 [102700/25046 (13%)]\tLoss: 0.619423\n",
            "Train epoch: 156 [121680/25046 (15%)]\tLoss: 0.726974\n",
            "Train epoch: 156 [144060/25046 (18%)]\tLoss: 0.760482\n",
            "Train epoch: 156 [156160/25046 (20%)]\tLoss: 0.801553\n",
            "Train epoch: 156 [178380/25046 (23%)]\tLoss: 0.745021\n",
            "Train epoch: 156 [213000/25046 (26%)]\tLoss: 1.021200\n",
            "Train epoch: 156 [208780/25046 (28%)]\tLoss: 1.121118\n",
            "Train epoch: 156 [241440/25046 (31%)]\tLoss: 0.837707\n",
            "Train epoch: 156 [284960/25046 (33%)]\tLoss: 0.683754\n",
            "Train epoch: 156 [283920/25046 (36%)]\tLoss: 0.800495\n",
            "Train epoch: 156 [305100/25046 (38%)]\tLoss: 1.419357\n",
            "Train epoch: 156 [345920/25046 (41%)]\tLoss: 0.276505\n",
            "Train epoch: 156 [345780/25046 (43%)]\tLoss: 0.713485\n",
            "Train epoch: 156 [387000/25046 (46%)]\tLoss: 0.755111\n",
            "Train epoch: 156 [407740/25046 (49%)]\tLoss: 1.223499\n",
            "Train epoch: 156 [384400/25046 (51%)]\tLoss: 0.987431\n",
            "Train epoch: 156 [429660/25046 (54%)]\tLoss: 0.379603\n",
            "Train epoch: 156 [443960/25046 (56%)]\tLoss: 0.318748\n",
            "Train epoch: 156 [480700/25046 (59%)]\tLoss: 1.095164\n",
            "Train epoch: 156 [481440/25046 (61%)]\tLoss: 0.586601\n",
            "Train epoch: 156 [504500/25046 (64%)]\tLoss: 0.433871\n",
            "Train epoch: 156 [534560/25046 (66%)]\tLoss: 0.509298\n",
            "Train epoch: 156 [547560/25046 (69%)]\tLoss: 0.407018\n",
            "Train epoch: 156 [581840/25046 (72%)]\tLoss: 0.824988\n",
            "Train epoch: 156 [595660/25046 (74%)]\tLoss: 1.398880\n",
            "Train epoch: 156 [635400/25046 (77%)]\tLoss: 0.705053\n",
            "Train epoch: 156 [647900/25046 (79%)]\tLoss: 0.549996\n",
            "Train epoch: 156 [626560/25046 (82%)]\tLoss: 0.344604\n",
            "Train epoch: 156 [691020/25046 (84%)]\tLoss: 1.631825\n",
            "Train epoch: 156 [738480/25046 (87%)]\tLoss: 0.864933\n",
            "Train epoch: 156 [700000/25046 (89%)]\tLoss: 0.568502\n",
            "Train epoch: 156 [735120/25046 (92%)]\tLoss: 0.400574\n",
            "Train epoch: 156 [757760/25046 (95%)]\tLoss: 0.840558\n",
            "Train epoch: 156 [739480/25046 (97%)]\tLoss: 0.450470\n",
            "Train epoch: 156 [839280/25046 (100%)]\tLoss: 1.301147\n",
            "Make prediction for 5010 samples...\n",
            "0.809755 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 157 [0/25046 (0%)]\tLoss: 1.356370\n",
            "Train epoch: 157 [20240/25046 (3%)]\tLoss: 0.413269\n",
            "Train epoch: 157 [42200/25046 (5%)]\tLoss: 0.689252\n",
            "Train epoch: 157 [61680/25046 (8%)]\tLoss: 0.489182\n",
            "Train epoch: 157 [81760/25046 (10%)]\tLoss: 0.647825\n",
            "Train epoch: 157 [99600/25046 (13%)]\tLoss: 0.472772\n",
            "Train epoch: 157 [124440/25046 (15%)]\tLoss: 0.567137\n",
            "Train epoch: 157 [149240/25046 (18%)]\tLoss: 1.138121\n",
            "Train epoch: 157 [172160/25046 (20%)]\tLoss: 1.509238\n",
            "Train epoch: 157 [192960/25046 (23%)]\tLoss: 1.155570\n",
            "Train epoch: 157 [202600/25046 (26%)]\tLoss: 1.192018\n",
            "Train epoch: 157 [229680/25046 (28%)]\tLoss: 0.711822\n",
            "Train epoch: 157 [243360/25046 (31%)]\tLoss: 1.171667\n",
            "Train epoch: 157 [267280/25046 (33%)]\tLoss: 1.037942\n",
            "Train epoch: 157 [293160/25046 (36%)]\tLoss: 1.239699\n",
            "Train epoch: 157 [297900/25046 (38%)]\tLoss: 1.533994\n",
            "Train epoch: 157 [317440/25046 (41%)]\tLoss: 0.354985\n",
            "Train epoch: 157 [341020/25046 (43%)]\tLoss: 0.345822\n",
            "Train epoch: 157 [389520/25046 (46%)]\tLoss: 0.844448\n",
            "Train epoch: 157 [397480/25046 (49%)]\tLoss: 0.595801\n",
            "Train epoch: 157 [415600/25046 (51%)]\tLoss: 0.605730\n",
            "Train epoch: 157 [434280/25046 (54%)]\tLoss: 0.441338\n",
            "Train epoch: 157 [443520/25046 (56%)]\tLoss: 0.658616\n",
            "Train epoch: 157 [471500/25046 (59%)]\tLoss: 1.116650\n",
            "Train epoch: 157 [483360/25046 (61%)]\tLoss: 0.324971\n",
            "Train epoch: 157 [532000/25046 (64%)]\tLoss: 1.043706\n",
            "Train epoch: 157 [548080/25046 (66%)]\tLoss: 0.650956\n",
            "Train epoch: 157 [562680/25046 (69%)]\tLoss: 1.168595\n",
            "Train epoch: 157 [575680/25046 (72%)]\tLoss: 0.560726\n",
            "Train epoch: 157 [599140/25046 (74%)]\tLoss: 0.489930\n",
            "Train epoch: 157 [606000/25046 (77%)]\tLoss: 1.535197\n",
            "Train epoch: 157 [598920/25046 (79%)]\tLoss: 0.481750\n",
            "Train epoch: 157 [636800/25046 (82%)]\tLoss: 1.256312\n",
            "Train epoch: 157 [663960/25046 (84%)]\tLoss: 0.608212\n",
            "Train epoch: 157 [716040/25046 (87%)]\tLoss: 0.371246\n",
            "Train epoch: 157 [746900/25046 (89%)]\tLoss: 1.219716\n",
            "Train epoch: 157 [745200/25046 (92%)]\tLoss: 0.278682\n",
            "Train epoch: 157 [779220/25046 (95%)]\tLoss: 0.256566\n",
            "Train epoch: 157 [801800/25046 (97%)]\tLoss: 0.783167\n",
            "Train epoch: 157 [770640/25046 (100%)]\tLoss: 0.611586\n",
            "Make prediction for 5010 samples...\n",
            "0.80152357 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 158 [0/25046 (0%)]\tLoss: 1.795867\n",
            "Train epoch: 158 [20140/25046 (3%)]\tLoss: 0.678782\n",
            "Train epoch: 158 [43920/25046 (5%)]\tLoss: 0.397876\n",
            "Train epoch: 158 [62520/25046 (8%)]\tLoss: 0.978829\n",
            "Train epoch: 158 [79200/25046 (10%)]\tLoss: 0.490895\n",
            "Train epoch: 158 [99100/25046 (13%)]\tLoss: 0.442417\n",
            "Train epoch: 158 [118440/25046 (15%)]\tLoss: 0.612609\n",
            "Train epoch: 158 [146720/25046 (18%)]\tLoss: 0.938594\n",
            "Train epoch: 158 [160160/25046 (20%)]\tLoss: 0.733403\n",
            "Train epoch: 158 [182520/25046 (23%)]\tLoss: 0.650559\n",
            "Train epoch: 158 [196600/25046 (26%)]\tLoss: 0.827642\n",
            "Train epoch: 158 [229020/25046 (28%)]\tLoss: 1.778716\n",
            "Train epoch: 158 [255360/25046 (31%)]\tLoss: 1.353738\n",
            "Train epoch: 158 [268580/25046 (33%)]\tLoss: 1.826681\n",
            "Train epoch: 158 [290640/25046 (36%)]\tLoss: 0.476602\n",
            "Train epoch: 158 [313800/25046 (38%)]\tLoss: 0.737799\n",
            "Train epoch: 158 [343680/25046 (41%)]\tLoss: 1.647940\n",
            "Train epoch: 158 [386240/25046 (43%)]\tLoss: 0.958901\n",
            "Train epoch: 158 [375840/25046 (46%)]\tLoss: 0.970917\n",
            "Train epoch: 158 [389500/25046 (49%)]\tLoss: 1.181643\n",
            "Train epoch: 158 [410800/25046 (51%)]\tLoss: 0.550084\n",
            "Train epoch: 158 [427560/25046 (54%)]\tLoss: 1.529015\n",
            "Train epoch: 158 [467720/25046 (56%)]\tLoss: 0.578562\n",
            "Train epoch: 158 [480700/25046 (59%)]\tLoss: 0.164020\n",
            "Train epoch: 158 [497760/25046 (61%)]\tLoss: 0.369618\n",
            "Train epoch: 158 [477000/25046 (64%)]\tLoss: 0.868321\n",
            "Train epoch: 158 [534560/25046 (66%)]\tLoss: 0.594146\n",
            "Train epoch: 158 [534060/25046 (69%)]\tLoss: 0.387044\n",
            "Train epoch: 158 [594160/25046 (72%)]\tLoss: 0.491965\n",
            "Train epoch: 158 [581740/25046 (74%)]\tLoss: 0.525596\n",
            "Train epoch: 158 [651000/25046 (77%)]\tLoss: 0.828177\n",
            "Train epoch: 158 [623100/25046 (79%)]\tLoss: 0.794825\n",
            "Train epoch: 158 [664960/25046 (82%)]\tLoss: 0.359092\n",
            "Train epoch: 158 [669240/25046 (84%)]\tLoss: 0.309585\n",
            "Train epoch: 158 [671160/25046 (87%)]\tLoss: 0.910405\n",
            "Train epoch: 158 [674800/25046 (89%)]\tLoss: 0.768467\n",
            "Train epoch: 158 [726480/25046 (92%)]\tLoss: 1.165898\n",
            "Train epoch: 158 [758500/25046 (95%)]\tLoss: 0.419890\n",
            "Train epoch: 158 [781280/25046 (97%)]\tLoss: 0.917939\n",
            "Train epoch: 158 [764400/25046 (100%)]\tLoss: 0.557959\n",
            "Make prediction for 5010 samples...\n",
            "0.80318844 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 159 [0/25046 (0%)]\tLoss: 0.507213\n",
            "Train epoch: 159 [21160/25046 (3%)]\tLoss: 1.214135\n",
            "Train epoch: 159 [41400/25046 (5%)]\tLoss: 1.055073\n",
            "Train epoch: 159 [60600/25046 (8%)]\tLoss: 0.330300\n",
            "Train epoch: 159 [86480/25046 (10%)]\tLoss: 0.814897\n",
            "Train epoch: 159 [102600/25046 (13%)]\tLoss: 1.106725\n",
            "Train epoch: 159 [125160/25046 (15%)]\tLoss: 0.880619\n",
            "Train epoch: 159 [150220/25046 (18%)]\tLoss: 0.630403\n",
            "Train epoch: 159 [161440/25046 (20%)]\tLoss: 0.388884\n",
            "Train epoch: 159 [188460/25046 (23%)]\tLoss: 0.357754\n",
            "Train epoch: 159 [202200/25046 (26%)]\tLoss: 0.898623\n",
            "Train epoch: 159 [218680/25046 (28%)]\tLoss: 0.483484\n",
            "Train epoch: 159 [238320/25046 (31%)]\tLoss: 1.166723\n",
            "Train epoch: 159 [268580/25046 (33%)]\tLoss: 0.393823\n",
            "Train epoch: 159 [278040/25046 (36%)]\tLoss: 0.522887\n",
            "Train epoch: 159 [310200/25046 (38%)]\tLoss: 1.199231\n",
            "Train epoch: 159 [323200/25046 (41%)]\tLoss: 0.207815\n",
            "Train epoch: 159 [348840/25046 (43%)]\tLoss: 0.720643\n",
            "Train epoch: 159 [365040/25046 (46%)]\tLoss: 1.369840\n",
            "Train epoch: 159 [388360/25046 (49%)]\tLoss: 0.874498\n",
            "Train epoch: 159 [407200/25046 (51%)]\tLoss: 0.839221\n",
            "Train epoch: 159 [422100/25046 (54%)]\tLoss: 1.212499\n",
            "Train epoch: 159 [462000/25046 (56%)]\tLoss: 0.446666\n",
            "Train epoch: 159 [474720/25046 (59%)]\tLoss: 0.789371\n",
            "Train epoch: 159 [510720/25046 (61%)]\tLoss: 1.315530\n",
            "Train epoch: 159 [505500/25046 (64%)]\tLoss: 0.840432\n",
            "Train epoch: 159 [527800/25046 (66%)]\tLoss: 0.935611\n",
            "Train epoch: 159 [544860/25046 (69%)]\tLoss: 1.099441\n",
            "Train epoch: 159 [554400/25046 (72%)]\tLoss: 0.943240\n",
            "Train epoch: 159 [597400/25046 (74%)]\tLoss: 0.459348\n",
            "Train epoch: 159 [595800/25046 (77%)]\tLoss: 0.662963\n",
            "Train epoch: 159 [648520/25046 (79%)]\tLoss: 0.433797\n",
            "Train epoch: 159 [654080/25046 (82%)]\tLoss: 0.937364\n",
            "Train epoch: 159 [716760/25046 (84%)]\tLoss: 0.630493\n",
            "Train epoch: 159 [735760/25046 (87%)]\tLoss: 0.454365\n",
            "Train epoch: 159 [727300/25046 (89%)]\tLoss: 1.883536\n",
            "Train epoch: 159 [786960/25046 (92%)]\tLoss: 1.411092\n",
            "Train epoch: 159 [780700/25046 (95%)]\tLoss: 1.152717\n",
            "Train epoch: 159 [742520/25046 (97%)]\tLoss: 0.621607\n",
            "Train epoch: 159 [833820/25046 (100%)]\tLoss: 0.557773\n",
            "Make prediction for 5010 samples...\n",
            "0.8015627 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 160 [0/25046 (0%)]\tLoss: 0.493903\n",
            "Train epoch: 160 [20160/25046 (3%)]\tLoss: 0.413891\n",
            "Train epoch: 160 [42080/25046 (5%)]\tLoss: 0.423567\n",
            "Train epoch: 160 [65100/25046 (8%)]\tLoss: 0.236831\n",
            "Train epoch: 160 [77920/25046 (10%)]\tLoss: 0.874270\n",
            "Train epoch: 160 [101900/25046 (13%)]\tLoss: 0.487335\n",
            "Train epoch: 160 [120600/25046 (15%)]\tLoss: 2.128809\n",
            "Train epoch: 160 [139860/25046 (18%)]\tLoss: 0.823033\n",
            "Train epoch: 160 [166400/25046 (20%)]\tLoss: 1.413887\n",
            "Train epoch: 160 [190800/25046 (23%)]\tLoss: 0.774296\n",
            "Train epoch: 160 [211800/25046 (26%)]\tLoss: 0.693587\n",
            "Train epoch: 160 [226600/25046 (28%)]\tLoss: 1.070057\n",
            "Train epoch: 160 [240720/25046 (31%)]\tLoss: 0.584968\n",
            "Train epoch: 160 [266500/25046 (33%)]\tLoss: 0.501716\n",
            "Train epoch: 160 [287840/25046 (36%)]\tLoss: 1.190719\n",
            "Train epoch: 160 [296400/25046 (38%)]\tLoss: 0.806602\n",
            "Train epoch: 160 [341440/25046 (41%)]\tLoss: 0.827078\n",
            "Train epoch: 160 [355300/25046 (43%)]\tLoss: 0.985198\n",
            "Train epoch: 160 [384480/25046 (46%)]\tLoss: 0.727063\n",
            "Train epoch: 160 [375060/25046 (49%)]\tLoss: 0.529489\n",
            "Train epoch: 160 [407200/25046 (51%)]\tLoss: 0.562452\n",
            "Train epoch: 160 [404880/25046 (54%)]\tLoss: 0.969124\n",
            "Train epoch: 160 [434280/25046 (56%)]\tLoss: 0.673411\n",
            "Train epoch: 160 [475180/25046 (59%)]\tLoss: 0.764273\n",
            "Train epoch: 160 [467520/25046 (61%)]\tLoss: 0.900760\n",
            "Train epoch: 160 [510000/25046 (64%)]\tLoss: 0.728902\n",
            "Train epoch: 160 [574080/25046 (66%)]\tLoss: 0.639259\n",
            "Train epoch: 160 [529740/25046 (69%)]\tLoss: 0.541929\n",
            "Train epoch: 160 [588560/25046 (72%)]\tLoss: 0.781958\n",
            "Train epoch: 160 [624080/25046 (74%)]\tLoss: 0.824858\n",
            "Train epoch: 160 [614400/25046 (77%)]\tLoss: 0.477558\n",
            "Train epoch: 160 [644180/25046 (79%)]\tLoss: 1.464587\n",
            "Train epoch: 160 [640640/25046 (82%)]\tLoss: 0.599467\n",
            "Train epoch: 160 [636900/25046 (84%)]\tLoss: 0.510477\n",
            "Train epoch: 160 [703800/25046 (87%)]\tLoss: 0.883027\n",
            "Train epoch: 160 [697200/25046 (89%)]\tLoss: 0.888619\n",
            "Train epoch: 160 [752400/25046 (92%)]\tLoss: 0.970731\n",
            "Train epoch: 160 [728900/25046 (95%)]\tLoss: 0.505898\n",
            "Train epoch: 160 [779000/25046 (97%)]\tLoss: 1.451869\n",
            "Train epoch: 160 [783900/25046 (100%)]\tLoss: 0.972370\n",
            "Make prediction for 5010 samples...\n",
            "0.8019813 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 161 [0/25046 (0%)]\tLoss: 1.002959\n",
            "Train epoch: 161 [20420/25046 (3%)]\tLoss: 0.887253\n",
            "Train epoch: 161 [44480/25046 (5%)]\tLoss: 0.712528\n",
            "Train epoch: 161 [59760/25046 (8%)]\tLoss: 0.687096\n",
            "Train epoch: 161 [80720/25046 (10%)]\tLoss: 0.600750\n",
            "Train epoch: 161 [101400/25046 (13%)]\tLoss: 0.207591\n",
            "Train epoch: 161 [121560/25046 (15%)]\tLoss: 0.419116\n",
            "Train epoch: 161 [143780/25046 (18%)]\tLoss: 0.805573\n",
            "Train epoch: 161 [166400/25046 (20%)]\tLoss: 1.147258\n",
            "Train epoch: 161 [181080/25046 (23%)]\tLoss: 0.503697\n",
            "Train epoch: 161 [196600/25046 (26%)]\tLoss: 0.946813\n",
            "Train epoch: 161 [230340/25046 (28%)]\tLoss: 0.461869\n",
            "Train epoch: 161 [251520/25046 (31%)]\tLoss: 0.615418\n",
            "Train epoch: 161 [262860/25046 (33%)]\tLoss: 0.470642\n",
            "Train epoch: 161 [281680/25046 (36%)]\tLoss: 1.088813\n",
            "Train epoch: 161 [297600/25046 (38%)]\tLoss: 1.039543\n",
            "Train epoch: 161 [320640/25046 (41%)]\tLoss: 0.825055\n",
            "Train epoch: 161 [348500/25046 (43%)]\tLoss: 0.905684\n",
            "Train epoch: 161 [372960/25046 (46%)]\tLoss: 0.665786\n",
            "Train epoch: 161 [383420/25046 (49%)]\tLoss: 0.649489\n",
            "Train epoch: 161 [424000/25046 (51%)]\tLoss: 1.172493\n",
            "Train epoch: 161 [427980/25046 (54%)]\tLoss: 1.184310\n",
            "Train epoch: 161 [435600/25046 (56%)]\tLoss: 0.467595\n",
            "Train epoch: 161 [448960/25046 (59%)]\tLoss: 0.526447\n",
            "Train epoch: 161 [484800/25046 (61%)]\tLoss: 0.585552\n",
            "Train epoch: 161 [534500/25046 (64%)]\tLoss: 0.381635\n",
            "Train epoch: 161 [504400/25046 (66%)]\tLoss: 1.019936\n",
            "Train epoch: 161 [547020/25046 (69%)]\tLoss: 1.187351\n",
            "Train epoch: 161 [600320/25046 (72%)]\tLoss: 0.913875\n",
            "Train epoch: 161 [591020/25046 (74%)]\tLoss: 0.354808\n",
            "Train epoch: 161 [558000/25046 (77%)]\tLoss: 0.685694\n",
            "Train epoch: 161 [613180/25046 (79%)]\tLoss: 0.929967\n",
            "Train epoch: 161 [673920/25046 (82%)]\tLoss: 0.931194\n",
            "Train epoch: 161 [672540/25046 (84%)]\tLoss: 1.334148\n",
            "Train epoch: 161 [680000/25046 (87%)]\tLoss: 0.868695\n",
            "Train epoch: 161 [711900/25046 (89%)]\tLoss: 0.627190\n",
            "Train epoch: 161 [725760/25046 (92%)]\tLoss: 1.216184\n",
            "Train epoch: 161 [760720/25046 (95%)]\tLoss: 0.525965\n",
            "Train epoch: 161 [799520/25046 (97%)]\tLoss: 0.836392\n",
            "Train epoch: 161 [827580/25046 (100%)]\tLoss: 0.808527\n",
            "Make prediction for 5010 samples...\n",
            "0.801586 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 162 [0/25046 (0%)]\tLoss: 0.472960\n",
            "Train epoch: 162 [20020/25046 (3%)]\tLoss: 0.583564\n",
            "Train epoch: 162 [41600/25046 (5%)]\tLoss: 0.823677\n",
            "Train epoch: 162 [63300/25046 (8%)]\tLoss: 1.222799\n",
            "Train epoch: 162 [83520/25046 (10%)]\tLoss: 0.861746\n",
            "Train epoch: 162 [103900/25046 (13%)]\tLoss: 1.215351\n",
            "Train epoch: 162 [119040/25046 (15%)]\tLoss: 0.555242\n",
            "Train epoch: 162 [137060/25046 (18%)]\tLoss: 0.545751\n",
            "Train epoch: 162 [162400/25046 (20%)]\tLoss: 0.755082\n",
            "Train epoch: 162 [188280/25046 (23%)]\tLoss: 1.088965\n",
            "Train epoch: 162 [201600/25046 (26%)]\tLoss: 0.654274\n",
            "Train epoch: 162 [234080/25046 (28%)]\tLoss: 0.777402\n",
            "Train epoch: 162 [245280/25046 (31%)]\tLoss: 0.288453\n",
            "Train epoch: 162 [247000/25046 (33%)]\tLoss: 0.430612\n",
            "Train epoch: 162 [286160/25046 (36%)]\tLoss: 0.457542\n",
            "Train epoch: 162 [312900/25046 (38%)]\tLoss: 0.728440\n",
            "Train epoch: 162 [336320/25046 (41%)]\tLoss: 1.013797\n",
            "Train epoch: 162 [372640/25046 (43%)]\tLoss: 1.247970\n",
            "Train epoch: 162 [369720/25046 (46%)]\tLoss: 0.903589\n",
            "Train epoch: 162 [377340/25046 (49%)]\tLoss: 1.271466\n",
            "Train epoch: 162 [402800/25046 (51%)]\tLoss: 1.019404\n",
            "Train epoch: 162 [431760/25046 (54%)]\tLoss: 0.634057\n",
            "Train epoch: 162 [460680/25046 (56%)]\tLoss: 0.717186\n",
            "Train epoch: 162 [451260/25046 (59%)]\tLoss: 0.449471\n",
            "Train epoch: 162 [462240/25046 (61%)]\tLoss: 0.875386\n",
            "Train epoch: 162 [540500/25046 (64%)]\tLoss: 0.990640\n",
            "Train epoch: 162 [508560/25046 (66%)]\tLoss: 0.690792\n",
            "Train epoch: 162 [543780/25046 (69%)]\tLoss: 0.694709\n",
            "Train epoch: 162 [580720/25046 (72%)]\tLoss: 0.599208\n",
            "Train epoch: 162 [594500/25046 (74%)]\tLoss: 0.280560\n",
            "Train epoch: 162 [607200/25046 (77%)]\tLoss: 0.508681\n",
            "Train epoch: 162 [626820/25046 (79%)]\tLoss: 0.443178\n",
            "Train epoch: 162 [615680/25046 (82%)]\tLoss: 0.571361\n",
            "Train epoch: 162 [675840/25046 (84%)]\tLoss: 0.918317\n",
            "Train epoch: 162 [710600/25046 (87%)]\tLoss: 0.518352\n",
            "Train epoch: 162 [712600/25046 (89%)]\tLoss: 0.889416\n",
            "Train epoch: 162 [753120/25046 (92%)]\tLoss: 0.348603\n",
            "Train epoch: 162 [774040/25046 (95%)]\tLoss: 1.498684\n",
            "Train epoch: 162 [779760/25046 (97%)]\tLoss: 0.700623\n",
            "Train epoch: 162 [809640/25046 (100%)]\tLoss: 0.486479\n",
            "Make prediction for 5010 samples...\n",
            "0.80244356 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 163 [0/25046 (0%)]\tLoss: 0.299119\n",
            "Train epoch: 163 [20540/25046 (3%)]\tLoss: 0.804297\n",
            "Train epoch: 163 [37960/25046 (5%)]\tLoss: 0.333225\n",
            "Train epoch: 163 [59520/25046 (8%)]\tLoss: 0.550034\n",
            "Train epoch: 163 [79360/25046 (10%)]\tLoss: 1.091119\n",
            "Train epoch: 163 [101500/25046 (13%)]\tLoss: 0.323789\n",
            "Train epoch: 163 [126120/25046 (15%)]\tLoss: 0.615893\n",
            "Train epoch: 163 [141680/25046 (18%)]\tLoss: 1.048686\n",
            "Train epoch: 163 [166720/25046 (20%)]\tLoss: 0.805052\n",
            "Train epoch: 163 [192420/25046 (23%)]\tLoss: 0.610049\n",
            "Train epoch: 163 [190200/25046 (26%)]\tLoss: 0.459465\n",
            "Train epoch: 163 [221100/25046 (28%)]\tLoss: 0.322715\n",
            "Train epoch: 163 [235920/25046 (31%)]\tLoss: 0.537560\n",
            "Train epoch: 163 [258960/25046 (33%)]\tLoss: 0.495116\n",
            "Train epoch: 163 [283360/25046 (36%)]\tLoss: 0.629346\n",
            "Train epoch: 163 [310800/25046 (38%)]\tLoss: 1.355217\n",
            "Train epoch: 163 [335680/25046 (41%)]\tLoss: 0.670034\n",
            "Train epoch: 163 [339660/25046 (43%)]\tLoss: 0.832524\n",
            "Train epoch: 163 [369000/25046 (46%)]\tLoss: 0.910259\n",
            "Train epoch: 163 [410780/25046 (49%)]\tLoss: 0.800731\n",
            "Train epoch: 163 [422000/25046 (51%)]\tLoss: 0.833561\n",
            "Train epoch: 163 [433440/25046 (54%)]\tLoss: 0.546222\n",
            "Train epoch: 163 [436480/25046 (56%)]\tLoss: 0.386912\n",
            "Train epoch: 163 [485300/25046 (59%)]\tLoss: 1.085299\n",
            "Train epoch: 163 [515520/25046 (61%)]\tLoss: 0.855791\n",
            "Train epoch: 163 [521000/25046 (64%)]\tLoss: 0.497159\n",
            "Train epoch: 163 [510120/25046 (66%)]\tLoss: 0.626267\n",
            "Train epoch: 163 [511920/25046 (69%)]\tLoss: 0.621828\n",
            "Train epoch: 163 [571760/25046 (72%)]\tLoss: 0.926784\n",
            "Train epoch: 163 [604360/25046 (74%)]\tLoss: 0.920311\n",
            "Train epoch: 163 [631800/25046 (77%)]\tLoss: 0.608815\n",
            "Train epoch: 163 [642320/25046 (79%)]\tLoss: 0.663363\n",
            "Train epoch: 163 [660480/25046 (82%)]\tLoss: 0.657641\n",
            "Train epoch: 163 [670560/25046 (84%)]\tLoss: 1.316172\n",
            "Train epoch: 163 [718760/25046 (87%)]\tLoss: 1.178462\n",
            "Train epoch: 163 [697200/25046 (89%)]\tLoss: 0.731731\n",
            "Train epoch: 163 [761760/25046 (92%)]\tLoss: 0.887243\n",
            "Train epoch: 163 [768860/25046 (95%)]\tLoss: 0.737694\n",
            "Train epoch: 163 [794960/25046 (97%)]\tLoss: 0.459878\n",
            "Train epoch: 163 [790140/25046 (100%)]\tLoss: 0.654137\n",
            "Make prediction for 5010 samples...\n",
            "0.8041504 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 164 [0/25046 (0%)]\tLoss: 0.583589\n",
            "Train epoch: 164 [20080/25046 (3%)]\tLoss: 1.254998\n",
            "Train epoch: 164 [40520/25046 (5%)]\tLoss: 1.718428\n",
            "Train epoch: 164 [58800/25046 (8%)]\tLoss: 0.999960\n",
            "Train epoch: 164 [83760/25046 (10%)]\tLoss: 0.855542\n",
            "Train epoch: 164 [104500/25046 (13%)]\tLoss: 1.011542\n",
            "Train epoch: 164 [118800/25046 (15%)]\tLoss: 0.622198\n",
            "Train epoch: 164 [140140/25046 (18%)]\tLoss: 0.673226\n",
            "Train epoch: 164 [163200/25046 (20%)]\tLoss: 0.879819\n",
            "Train epoch: 164 [180900/25046 (23%)]\tLoss: 0.902138\n",
            "Train epoch: 164 [192200/25046 (26%)]\tLoss: 0.635155\n",
            "Train epoch: 164 [217580/25046 (28%)]\tLoss: 0.515450\n",
            "Train epoch: 164 [238320/25046 (31%)]\tLoss: 0.777089\n",
            "Train epoch: 164 [257920/25046 (33%)]\tLoss: 0.533648\n",
            "Train epoch: 164 [254240/25046 (36%)]\tLoss: 0.243357\n",
            "Train epoch: 164 [294300/25046 (38%)]\tLoss: 0.759899\n",
            "Train epoch: 164 [322560/25046 (41%)]\tLoss: 0.896608\n",
            "Train epoch: 164 [334900/25046 (43%)]\tLoss: 0.944347\n",
            "Train epoch: 164 [361800/25046 (46%)]\tLoss: 0.436596\n",
            "Train epoch: 164 [399000/25046 (49%)]\tLoss: 1.765810\n",
            "Train epoch: 164 [422800/25046 (51%)]\tLoss: 1.324446\n",
            "Train epoch: 164 [411600/25046 (54%)]\tLoss: 0.493234\n",
            "Train epoch: 164 [432080/25046 (56%)]\tLoss: 0.587290\n",
            "Train epoch: 164 [477940/25046 (59%)]\tLoss: 0.460566\n",
            "Train epoch: 164 [475200/25046 (61%)]\tLoss: 1.592725\n",
            "Train epoch: 164 [553500/25046 (64%)]\tLoss: 0.975299\n",
            "Train epoch: 164 [586560/25046 (66%)]\tLoss: 0.740899\n",
            "Train epoch: 164 [536220/25046 (69%)]\tLoss: 1.479561\n",
            "Train epoch: 164 [565040/25046 (72%)]\tLoss: 0.601081\n",
            "Train epoch: 164 [578260/25046 (74%)]\tLoss: 0.483391\n",
            "Train epoch: 164 [596400/25046 (77%)]\tLoss: 0.871207\n",
            "Train epoch: 164 [606980/25046 (79%)]\tLoss: 0.639070\n",
            "Train epoch: 164 [664960/25046 (82%)]\tLoss: 0.921475\n",
            "Train epoch: 164 [667920/25046 (84%)]\tLoss: 0.468545\n",
            "Train epoch: 164 [684760/25046 (87%)]\tLoss: 0.591395\n",
            "Train epoch: 164 [712600/25046 (89%)]\tLoss: 0.594728\n",
            "Train epoch: 164 [714960/25046 (92%)]\tLoss: 0.691400\n",
            "Train epoch: 164 [766640/25046 (95%)]\tLoss: 1.107241\n",
            "Train epoch: 164 [762280/25046 (97%)]\tLoss: 1.283100\n",
            "Train epoch: 164 [828360/25046 (100%)]\tLoss: 1.454314\n",
            "Make prediction for 5010 samples...\n",
            "0.8053143 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 165 [0/25046 (0%)]\tLoss: 0.468179\n",
            "Train epoch: 165 [22160/25046 (3%)]\tLoss: 0.774757\n",
            "Train epoch: 165 [41200/25046 (5%)]\tLoss: 0.599596\n",
            "Train epoch: 165 [64080/25046 (8%)]\tLoss: 0.938182\n",
            "Train epoch: 165 [83760/25046 (10%)]\tLoss: 0.430714\n",
            "Train epoch: 165 [101800/25046 (13%)]\tLoss: 0.421545\n",
            "Train epoch: 165 [126840/25046 (15%)]\tLoss: 1.091031\n",
            "Train epoch: 165 [148120/25046 (18%)]\tLoss: 1.315680\n",
            "Train epoch: 165 [153440/25046 (20%)]\tLoss: 0.237111\n",
            "Train epoch: 165 [192060/25046 (23%)]\tLoss: 1.125747\n",
            "Train epoch: 165 [213200/25046 (26%)]\tLoss: 0.871132\n",
            "Train epoch: 165 [231880/25046 (28%)]\tLoss: 0.531886\n",
            "Train epoch: 165 [246480/25046 (31%)]\tLoss: 0.497882\n",
            "Train epoch: 165 [278460/25046 (33%)]\tLoss: 0.578342\n",
            "Train epoch: 165 [281680/25046 (36%)]\tLoss: 0.900755\n",
            "Train epoch: 165 [308700/25046 (38%)]\tLoss: 0.325646\n",
            "Train epoch: 165 [328320/25046 (41%)]\tLoss: 0.741030\n",
            "Train epoch: 165 [354280/25046 (43%)]\tLoss: 0.938718\n",
            "Train epoch: 165 [357840/25046 (46%)]\tLoss: 0.242261\n",
            "Train epoch: 165 [397860/25046 (49%)]\tLoss: 0.470734\n",
            "Train epoch: 165 [421200/25046 (51%)]\tLoss: 0.559610\n",
            "Train epoch: 165 [448140/25046 (54%)]\tLoss: 0.936320\n",
            "Train epoch: 165 [473880/25046 (56%)]\tLoss: 0.712053\n",
            "Train epoch: 165 [486680/25046 (59%)]\tLoss: 0.444759\n",
            "Train epoch: 165 [480000/25046 (61%)]\tLoss: 1.090719\n",
            "Train epoch: 165 [488000/25046 (64%)]\tLoss: 0.422779\n",
            "Train epoch: 165 [562120/25046 (66%)]\tLoss: 0.349284\n",
            "Train epoch: 165 [531360/25046 (69%)]\tLoss: 0.310766\n",
            "Train epoch: 165 [579600/25046 (72%)]\tLoss: 1.414314\n",
            "Train epoch: 165 [611320/25046 (74%)]\tLoss: 0.789471\n",
            "Train epoch: 165 [583200/25046 (77%)]\tLoss: 0.411985\n",
            "Train epoch: 165 [648520/25046 (79%)]\tLoss: 0.270083\n",
            "Train epoch: 165 [669440/25046 (82%)]\tLoss: 1.302310\n",
            "Train epoch: 165 [646140/25046 (84%)]\tLoss: 0.919595\n",
            "Train epoch: 165 [671160/25046 (87%)]\tLoss: 1.122694\n",
            "Train epoch: 165 [716800/25046 (89%)]\tLoss: 0.321660\n",
            "Train epoch: 165 [768960/25046 (92%)]\tLoss: 2.035410\n",
            "Train epoch: 165 [748140/25046 (95%)]\tLoss: 0.602198\n",
            "Train epoch: 165 [795720/25046 (97%)]\tLoss: 0.386900\n",
            "Train epoch: 165 [779220/25046 (100%)]\tLoss: 0.426963\n",
            "Make prediction for 5010 samples...\n",
            "0.8033856 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 166 [0/25046 (0%)]\tLoss: 0.342775\n",
            "Train epoch: 166 [20420/25046 (3%)]\tLoss: 0.917752\n",
            "Train epoch: 166 [44160/25046 (5%)]\tLoss: 0.420280\n",
            "Train epoch: 166 [64140/25046 (8%)]\tLoss: 0.687028\n",
            "Train epoch: 166 [78000/25046 (10%)]\tLoss: 0.694453\n",
            "Train epoch: 166 [105400/25046 (13%)]\tLoss: 1.910676\n",
            "Train epoch: 166 [123000/25046 (15%)]\tLoss: 0.880204\n",
            "Train epoch: 166 [140140/25046 (18%)]\tLoss: 0.378039\n",
            "Train epoch: 166 [157120/25046 (20%)]\tLoss: 0.889958\n",
            "Train epoch: 166 [190980/25046 (23%)]\tLoss: 0.838646\n",
            "Train epoch: 166 [203200/25046 (26%)]\tLoss: 0.311015\n",
            "Train epoch: 166 [229900/25046 (28%)]\tLoss: 0.580969\n",
            "Train epoch: 166 [240240/25046 (31%)]\tLoss: 0.969450\n",
            "Train epoch: 166 [276380/25046 (33%)]\tLoss: 0.719644\n",
            "Train epoch: 166 [291200/25046 (36%)]\tLoss: 0.910485\n",
            "Train epoch: 166 [307800/25046 (38%)]\tLoss: 1.135925\n",
            "Train epoch: 166 [330560/25046 (41%)]\tLoss: 0.857129\n",
            "Train epoch: 166 [333540/25046 (43%)]\tLoss: 0.744069\n",
            "Train epoch: 166 [348120/25046 (46%)]\tLoss: 0.505192\n",
            "Train epoch: 166 [395200/25046 (49%)]\tLoss: 1.049575\n",
            "Train epoch: 166 [422800/25046 (51%)]\tLoss: 0.689497\n",
            "Train epoch: 166 [414120/25046 (54%)]\tLoss: 0.675999\n",
            "Train epoch: 166 [420200/25046 (56%)]\tLoss: 0.495543\n",
            "Train epoch: 166 [462300/25046 (59%)]\tLoss: 1.313098\n",
            "Train epoch: 166 [474240/25046 (61%)]\tLoss: 0.495249\n",
            "Train epoch: 166 [501000/25046 (64%)]\tLoss: 0.404228\n",
            "Train epoch: 166 [515840/25046 (66%)]\tLoss: 0.554682\n",
            "Train epoch: 166 [591840/25046 (69%)]\tLoss: 0.998741\n",
            "Train epoch: 166 [545440/25046 (72%)]\tLoss: 0.225891\n",
            "Train epoch: 166 [581740/25046 (74%)]\tLoss: 0.374569\n",
            "Train epoch: 166 [634800/25046 (77%)]\tLoss: 2.110932\n",
            "Train epoch: 166 [584660/25046 (79%)]\tLoss: 0.688470\n",
            "Train epoch: 166 [683520/25046 (82%)]\tLoss: 0.710721\n",
            "Train epoch: 166 [733260/25046 (84%)]\tLoss: 0.718277\n",
            "Train epoch: 166 [703120/25046 (87%)]\tLoss: 1.721430\n",
            "Train epoch: 166 [697900/25046 (89%)]\tLoss: 0.305588\n",
            "Train epoch: 166 [717840/25046 (92%)]\tLoss: 0.269638\n",
            "Train epoch: 166 [718540/25046 (95%)]\tLoss: 0.295201\n",
            "Train epoch: 166 [793440/25046 (97%)]\tLoss: 0.641755\n",
            "Train epoch: 166 [787020/25046 (100%)]\tLoss: 1.112848\n",
            "Make prediction for 5010 samples...\n",
            "0.80184424 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 167 [0/25046 (0%)]\tLoss: 0.594581\n",
            "Train epoch: 167 [20740/25046 (3%)]\tLoss: 0.802864\n",
            "Train epoch: 167 [41120/25046 (5%)]\tLoss: 0.762488\n",
            "Train epoch: 167 [61800/25046 (8%)]\tLoss: 1.298208\n",
            "Train epoch: 167 [83440/25046 (10%)]\tLoss: 0.620571\n",
            "Train epoch: 167 [102100/25046 (13%)]\tLoss: 0.506623\n",
            "Train epoch: 167 [120120/25046 (15%)]\tLoss: 0.458985\n",
            "Train epoch: 167 [146580/25046 (18%)]\tLoss: 0.620557\n",
            "Train epoch: 167 [173280/25046 (20%)]\tLoss: 1.239586\n",
            "Train epoch: 167 [189000/25046 (23%)]\tLoss: 0.465139\n",
            "Train epoch: 167 [198000/25046 (26%)]\tLoss: 0.539334\n",
            "Train epoch: 167 [233860/25046 (28%)]\tLoss: 0.310363\n",
            "Train epoch: 167 [242160/25046 (31%)]\tLoss: 0.376071\n",
            "Train epoch: 167 [271700/25046 (33%)]\tLoss: 0.678045\n",
            "Train epoch: 167 [284480/25046 (36%)]\tLoss: 0.716891\n",
            "Train epoch: 167 [320700/25046 (38%)]\tLoss: 1.231162\n",
            "Train epoch: 167 [344640/25046 (41%)]\tLoss: 1.116590\n",
            "Train epoch: 167 [358020/25046 (43%)]\tLoss: 1.163587\n",
            "Train epoch: 167 [376920/25046 (46%)]\tLoss: 0.722728\n",
            "Train epoch: 167 [387220/25046 (49%)]\tLoss: 1.256827\n",
            "Train epoch: 167 [416400/25046 (51%)]\tLoss: 1.783046\n",
            "Train epoch: 167 [430920/25046 (54%)]\tLoss: 0.250633\n",
            "Train epoch: 167 [457160/25046 (56%)]\tLoss: 0.500975\n",
            "Train epoch: 167 [480700/25046 (59%)]\tLoss: 1.473851\n",
            "Train epoch: 167 [509760/25046 (61%)]\tLoss: 0.408402\n",
            "Train epoch: 167 [530000/25046 (64%)]\tLoss: 0.646177\n",
            "Train epoch: 167 [512200/25046 (66%)]\tLoss: 0.260347\n",
            "Train epoch: 167 [525960/25046 (69%)]\tLoss: 0.490689\n",
            "Train epoch: 167 [566720/25046 (72%)]\tLoss: 1.334340\n",
            "Train epoch: 167 [577680/25046 (74%)]\tLoss: 1.402941\n",
            "Train epoch: 167 [632400/25046 (77%)]\tLoss: 0.942617\n",
            "Train epoch: 167 [650380/25046 (79%)]\tLoss: 0.766775\n",
            "Train epoch: 167 [650880/25046 (82%)]\tLoss: 0.395670\n",
            "Train epoch: 167 [656700/25046 (84%)]\tLoss: 0.819831\n",
            "Train epoch: 167 [689520/25046 (87%)]\tLoss: 0.873464\n",
            "Train epoch: 167 [753200/25046 (89%)]\tLoss: 0.978448\n",
            "Train epoch: 167 [770400/25046 (92%)]\tLoss: 0.791499\n",
            "Train epoch: 167 [769600/25046 (95%)]\tLoss: 0.430071\n",
            "Train epoch: 167 [739480/25046 (97%)]\tLoss: 1.270299\n",
            "Train epoch: 167 [762060/25046 (100%)]\tLoss: 0.542364\n",
            "Make prediction for 5010 samples...\n",
            "0.80184954 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 168 [0/25046 (0%)]\tLoss: 0.652293\n",
            "Train epoch: 168 [19420/25046 (3%)]\tLoss: 0.529174\n",
            "Train epoch: 168 [41720/25046 (5%)]\tLoss: 0.421943\n",
            "Train epoch: 168 [60720/25046 (8%)]\tLoss: 0.676458\n",
            "Train epoch: 168 [80960/25046 (10%)]\tLoss: 0.238477\n",
            "Train epoch: 168 [101400/25046 (13%)]\tLoss: 0.815412\n",
            "Train epoch: 168 [126000/25046 (15%)]\tLoss: 0.943337\n",
            "Train epoch: 168 [149800/25046 (18%)]\tLoss: 0.516692\n",
            "Train epoch: 168 [160640/25046 (20%)]\tLoss: 0.390823\n",
            "Train epoch: 168 [169920/25046 (23%)]\tLoss: 0.385769\n",
            "Train epoch: 168 [202800/25046 (26%)]\tLoss: 0.865871\n",
            "Train epoch: 168 [225720/25046 (28%)]\tLoss: 1.067133\n",
            "Train epoch: 168 [259440/25046 (31%)]\tLoss: 0.410092\n",
            "Train epoch: 168 [264420/25046 (33%)]\tLoss: 0.320467\n",
            "Train epoch: 168 [277480/25046 (36%)]\tLoss: 0.730879\n",
            "Train epoch: 168 [286200/25046 (38%)]\tLoss: 0.466517\n",
            "Train epoch: 168 [341120/25046 (41%)]\tLoss: 1.326844\n",
            "Train epoch: 168 [335580/25046 (43%)]\tLoss: 1.208294\n",
            "Train epoch: 168 [384480/25046 (46%)]\tLoss: 1.250351\n",
            "Train epoch: 168 [417620/25046 (49%)]\tLoss: 0.544336\n",
            "Train epoch: 168 [409600/25046 (51%)]\tLoss: 0.906259\n",
            "Train epoch: 168 [425040/25046 (54%)]\tLoss: 0.967253\n",
            "Train epoch: 168 [476960/25046 (56%)]\tLoss: 1.178658\n",
            "Train epoch: 168 [486680/25046 (59%)]\tLoss: 0.677192\n",
            "Train epoch: 168 [483360/25046 (61%)]\tLoss: 0.199961\n",
            "Train epoch: 168 [550500/25046 (64%)]\tLoss: 0.703222\n",
            "Train epoch: 168 [492440/25046 (66%)]\tLoss: 0.373582\n",
            "Train epoch: 168 [547560/25046 (69%)]\tLoss: 0.600162\n",
            "Train epoch: 168 [586320/25046 (72%)]\tLoss: 1.234601\n",
            "Train epoch: 168 [590440/25046 (74%)]\tLoss: 0.431466\n",
            "Train epoch: 168 [631800/25046 (77%)]\tLoss: 1.418589\n",
            "Train epoch: 168 [647280/25046 (79%)]\tLoss: 0.563256\n",
            "Train epoch: 168 [652800/25046 (82%)]\tLoss: 0.268729\n",
            "Train epoch: 168 [688380/25046 (84%)]\tLoss: 0.521225\n",
            "Train epoch: 168 [665720/25046 (87%)]\tLoss: 0.959201\n",
            "Train epoch: 168 [716800/25046 (89%)]\tLoss: 0.692283\n",
            "Train epoch: 168 [735840/25046 (92%)]\tLoss: 0.837119\n",
            "Train epoch: 168 [765900/25046 (95%)]\tLoss: 0.696121\n",
            "Train epoch: 168 [788880/25046 (97%)]\tLoss: 0.705539\n",
            "Train epoch: 168 [756600/25046 (100%)]\tLoss: 1.088922\n",
            "Make prediction for 5010 samples...\n",
            "0.802089 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 169 [0/25046 (0%)]\tLoss: 0.684139\n",
            "Train epoch: 169 [21400/25046 (3%)]\tLoss: 1.166836\n",
            "Train epoch: 169 [44200/25046 (5%)]\tLoss: 0.296651\n",
            "Train epoch: 169 [61020/25046 (8%)]\tLoss: 0.648476\n",
            "Train epoch: 169 [82320/25046 (10%)]\tLoss: 0.558093\n",
            "Train epoch: 169 [107200/25046 (13%)]\tLoss: 1.901816\n",
            "Train epoch: 169 [124800/25046 (15%)]\tLoss: 0.850270\n",
            "Train epoch: 169 [141680/25046 (18%)]\tLoss: 0.422271\n",
            "Train epoch: 169 [165600/25046 (20%)]\tLoss: 0.753764\n",
            "Train epoch: 169 [178200/25046 (23%)]\tLoss: 1.744396\n",
            "Train epoch: 169 [203800/25046 (26%)]\tLoss: 0.629875\n",
            "Train epoch: 169 [241560/25046 (28%)]\tLoss: 0.473138\n",
            "Train epoch: 169 [236640/25046 (31%)]\tLoss: 0.621260\n",
            "Train epoch: 169 [265460/25046 (33%)]\tLoss: 0.732100\n",
            "Train epoch: 169 [282240/25046 (36%)]\tLoss: 1.326637\n",
            "Train epoch: 169 [300900/25046 (38%)]\tLoss: 0.949400\n",
            "Train epoch: 169 [336960/25046 (41%)]\tLoss: 0.683043\n",
            "Train epoch: 169 [349180/25046 (43%)]\tLoss: 0.858808\n",
            "Train epoch: 169 [379080/25046 (46%)]\tLoss: 0.819634\n",
            "Train epoch: 169 [392920/25046 (49%)]\tLoss: 1.023778\n",
            "Train epoch: 169 [413200/25046 (51%)]\tLoss: 1.109150\n",
            "Train epoch: 169 [401100/25046 (54%)]\tLoss: 0.408875\n",
            "Train epoch: 169 [446600/25046 (56%)]\tLoss: 0.567025\n",
            "Train epoch: 169 [507840/25046 (59%)]\tLoss: 1.089363\n",
            "Train epoch: 169 [487200/25046 (61%)]\tLoss: 1.629253\n",
            "Train epoch: 169 [503000/25046 (64%)]\tLoss: 1.239921\n",
            "Train epoch: 169 [546520/25046 (66%)]\tLoss: 0.823185\n",
            "Train epoch: 169 [633960/25046 (69%)]\tLoss: 0.714446\n",
            "Train epoch: 169 [615440/25046 (72%)]\tLoss: 0.441800\n",
            "Train epoch: 169 [572460/25046 (74%)]\tLoss: 0.513366\n",
            "Train epoch: 169 [590400/25046 (77%)]\tLoss: 1.434998\n",
            "Train epoch: 169 [644180/25046 (79%)]\tLoss: 1.100172\n",
            "Train epoch: 169 [634240/25046 (82%)]\tLoss: 0.296458\n",
            "Train epoch: 169 [704880/25046 (84%)]\tLoss: 0.703328\n",
            "Train epoch: 169 [694280/25046 (87%)]\tLoss: 0.307335\n",
            "Train epoch: 169 [688800/25046 (89%)]\tLoss: 0.692041\n",
            "Train epoch: 169 [747360/25046 (92%)]\tLoss: 0.442294\n",
            "Train epoch: 169 [746660/25046 (95%)]\tLoss: 0.562648\n",
            "Train epoch: 169 [763800/25046 (97%)]\tLoss: 1.056867\n",
            "Train epoch: 169 [801060/25046 (100%)]\tLoss: 0.904554\n",
            "Make prediction for 5010 samples...\n",
            "0.8045171 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 170 [0/25046 (0%)]\tLoss: 0.848278\n",
            "Train epoch: 170 [19920/25046 (3%)]\tLoss: 0.366596\n",
            "Train epoch: 170 [40600/25046 (5%)]\tLoss: 1.139490\n",
            "Train epoch: 170 [63480/25046 (8%)]\tLoss: 0.828021\n",
            "Train epoch: 170 [78880/25046 (10%)]\tLoss: 0.540744\n",
            "Train epoch: 170 [105200/25046 (13%)]\tLoss: 0.570299\n",
            "Train epoch: 170 [124440/25046 (15%)]\tLoss: 0.551861\n",
            "Train epoch: 170 [143780/25046 (18%)]\tLoss: 1.670121\n",
            "Train epoch: 170 [168480/25046 (20%)]\tLoss: 1.011395\n",
            "Train epoch: 170 [182700/25046 (23%)]\tLoss: 0.990668\n",
            "Train epoch: 170 [205800/25046 (26%)]\tLoss: 0.389626\n",
            "Train epoch: 170 [230560/25046 (28%)]\tLoss: 1.479690\n",
            "Train epoch: 170 [252000/25046 (31%)]\tLoss: 0.348821\n",
            "Train epoch: 170 [270400/25046 (33%)]\tLoss: 0.754909\n",
            "Train epoch: 170 [280280/25046 (36%)]\tLoss: 0.701777\n",
            "Train epoch: 170 [311700/25046 (38%)]\tLoss: 0.682542\n",
            "Train epoch: 170 [336000/25046 (41%)]\tLoss: 0.391927\n",
            "Train epoch: 170 [336260/25046 (43%)]\tLoss: 0.837386\n",
            "Train epoch: 170 [362160/25046 (46%)]\tLoss: 1.002467\n",
            "Train epoch: 170 [402420/25046 (49%)]\tLoss: 0.229120\n",
            "Train epoch: 170 [400000/25046 (51%)]\tLoss: 0.963692\n",
            "Train epoch: 170 [433020/25046 (54%)]\tLoss: 0.999416\n",
            "Train epoch: 170 [454520/25046 (56%)]\tLoss: 1.017644\n",
            "Train epoch: 170 [478860/25046 (59%)]\tLoss: 0.695150\n",
            "Train epoch: 170 [506880/25046 (61%)]\tLoss: 0.225053\n",
            "Train epoch: 170 [494000/25046 (64%)]\tLoss: 0.508600\n",
            "Train epoch: 170 [516880/25046 (66%)]\tLoss: 1.571895\n",
            "Train epoch: 170 [527580/25046 (69%)]\tLoss: 1.137915\n",
            "Train epoch: 170 [543760/25046 (72%)]\tLoss: 0.770538\n",
            "Train epoch: 170 [617120/25046 (74%)]\tLoss: 0.841918\n",
            "Train epoch: 170 [622800/25046 (77%)]\tLoss: 1.300274\n",
            "Train epoch: 170 [611320/25046 (79%)]\tLoss: 0.978491\n",
            "Train epoch: 170 [663040/25046 (82%)]\tLoss: 0.434022\n",
            "Train epoch: 170 [668580/25046 (84%)]\tLoss: 0.480527\n",
            "Train epoch: 170 [663000/25046 (87%)]\tLoss: 0.672010\n",
            "Train epoch: 170 [737800/25046 (89%)]\tLoss: 1.144063\n",
            "Train epoch: 170 [728640/25046 (92%)]\tLoss: 0.780901\n",
            "Train epoch: 170 [762940/25046 (95%)]\tLoss: 1.162985\n",
            "Train epoch: 170 [817000/25046 (97%)]\tLoss: 0.988230\n",
            "Train epoch: 170 [776880/25046 (100%)]\tLoss: 1.424289\n",
            "Make prediction for 5010 samples...\n",
            "0.80151653 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 171 [0/25046 (0%)]\tLoss: 0.879749\n",
            "Train epoch: 171 [20000/25046 (3%)]\tLoss: 0.729239\n",
            "Train epoch: 171 [42280/25046 (5%)]\tLoss: 0.745276\n",
            "Train epoch: 171 [63720/25046 (8%)]\tLoss: 1.842378\n",
            "Train epoch: 171 [80080/25046 (10%)]\tLoss: 0.757945\n",
            "Train epoch: 171 [105900/25046 (13%)]\tLoss: 0.652389\n",
            "Train epoch: 171 [120600/25046 (15%)]\tLoss: 0.236800\n",
            "Train epoch: 171 [147840/25046 (18%)]\tLoss: 0.511202\n",
            "Train epoch: 171 [158400/25046 (20%)]\tLoss: 0.426245\n",
            "Train epoch: 171 [190620/25046 (23%)]\tLoss: 0.341353\n",
            "Train epoch: 171 [195200/25046 (26%)]\tLoss: 0.195952\n",
            "Train epoch: 171 [225280/25046 (28%)]\tLoss: 0.300455\n",
            "Train epoch: 171 [234480/25046 (31%)]\tLoss: 1.253730\n",
            "Train epoch: 171 [271700/25046 (33%)]\tLoss: 0.192110\n",
            "Train epoch: 171 [282240/25046 (36%)]\tLoss: 1.513689\n",
            "Train epoch: 171 [318300/25046 (38%)]\tLoss: 1.499836\n",
            "Train epoch: 171 [328640/25046 (41%)]\tLoss: 1.162555\n",
            "Train epoch: 171 [335240/25046 (43%)]\tLoss: 0.746858\n",
            "Train epoch: 171 [369000/25046 (46%)]\tLoss: 0.327693\n",
            "Train epoch: 171 [396340/25046 (49%)]\tLoss: 0.571319\n",
            "Train epoch: 171 [410400/25046 (51%)]\tLoss: 0.596367\n",
            "Train epoch: 171 [407400/25046 (54%)]\tLoss: 0.260266\n",
            "Train epoch: 171 [441760/25046 (56%)]\tLoss: 0.962539\n",
            "Train epoch: 171 [475640/25046 (59%)]\tLoss: 1.024993\n",
            "Train epoch: 171 [530880/25046 (61%)]\tLoss: 0.645330\n",
            "Train epoch: 171 [511000/25046 (64%)]\tLoss: 1.098660\n",
            "Train epoch: 171 [506480/25046 (66%)]\tLoss: 1.053302\n",
            "Train epoch: 171 [582120/25046 (69%)]\tLoss: 0.749309\n",
            "Train epoch: 171 [544320/25046 (72%)]\tLoss: 0.445329\n",
            "Train epoch: 171 [597400/25046 (74%)]\tLoss: 0.557401\n",
            "Train epoch: 171 [608400/25046 (77%)]\tLoss: 1.047471\n",
            "Train epoch: 171 [606360/25046 (79%)]\tLoss: 0.752867\n",
            "Train epoch: 171 [632960/25046 (82%)]\tLoss: 0.608019\n",
            "Train epoch: 171 [704880/25046 (84%)]\tLoss: 1.298817\n",
            "Train epoch: 171 [690200/25046 (87%)]\tLoss: 0.498655\n",
            "Train epoch: 171 [688100/25046 (89%)]\tLoss: 0.752494\n",
            "Train epoch: 171 [767520/25046 (92%)]\tLoss: 1.058727\n",
            "Train epoch: 171 [734080/25046 (95%)]\tLoss: 0.286730\n",
            "Train epoch: 171 [764560/25046 (97%)]\tLoss: 0.666747\n",
            "Train epoch: 171 [823680/25046 (100%)]\tLoss: 0.933704\n",
            "Make prediction for 5010 samples...\n",
            "0.8016023 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 172 [0/25046 (0%)]\tLoss: 0.607098\n",
            "Train epoch: 172 [20140/25046 (3%)]\tLoss: 0.645611\n",
            "Train epoch: 172 [39240/25046 (5%)]\tLoss: 0.236923\n",
            "Train epoch: 172 [63900/25046 (8%)]\tLoss: 0.821173\n",
            "Train epoch: 172 [81520/25046 (10%)]\tLoss: 0.380298\n",
            "Train epoch: 172 [101500/25046 (13%)]\tLoss: 1.115573\n",
            "Train epoch: 172 [123600/25046 (15%)]\tLoss: 0.698238\n",
            "Train epoch: 172 [143220/25046 (18%)]\tLoss: 1.009541\n",
            "Train epoch: 172 [169280/25046 (20%)]\tLoss: 0.394746\n",
            "Train epoch: 172 [192420/25046 (23%)]\tLoss: 0.837978\n",
            "Train epoch: 172 [200600/25046 (26%)]\tLoss: 1.471655\n",
            "Train epoch: 172 [228360/25046 (28%)]\tLoss: 0.572456\n",
            "Train epoch: 172 [232800/25046 (31%)]\tLoss: 0.978067\n",
            "Train epoch: 172 [263900/25046 (33%)]\tLoss: 1.164208\n",
            "Train epoch: 172 [303240/25046 (36%)]\tLoss: 0.602972\n",
            "Train epoch: 172 [305100/25046 (38%)]\tLoss: 1.080279\n",
            "Train epoch: 172 [320000/25046 (41%)]\tLoss: 1.316061\n",
            "Train epoch: 172 [345780/25046 (43%)]\tLoss: 0.928300\n",
            "Train epoch: 172 [355680/25046 (46%)]\tLoss: 1.100166\n",
            "Train epoch: 172 [404700/25046 (49%)]\tLoss: 0.371679\n",
            "Train epoch: 172 [442400/25046 (51%)]\tLoss: 0.514170\n",
            "Train epoch: 172 [423780/25046 (54%)]\tLoss: 1.528773\n",
            "Train epoch: 172 [455840/25046 (56%)]\tLoss: 0.491909\n",
            "Train epoch: 172 [471960/25046 (59%)]\tLoss: 0.407330\n",
            "Train epoch: 172 [526080/25046 (61%)]\tLoss: 1.610239\n",
            "Train epoch: 172 [512500/25046 (64%)]\tLoss: 0.586634\n",
            "Train epoch: 172 [512200/25046 (66%)]\tLoss: 1.069262\n",
            "Train epoch: 172 [545940/25046 (69%)]\tLoss: 1.119414\n",
            "Train epoch: 172 [566720/25046 (72%)]\tLoss: 0.751248\n",
            "Train epoch: 172 [581740/25046 (74%)]\tLoss: 0.865367\n",
            "Train epoch: 172 [609000/25046 (77%)]\tLoss: 0.666512\n",
            "Train epoch: 172 [657820/25046 (79%)]\tLoss: 1.107629\n",
            "Train epoch: 172 [666880/25046 (82%)]\tLoss: 0.715702\n",
            "Train epoch: 172 [687060/25046 (84%)]\tLoss: 0.620649\n",
            "Train epoch: 172 [665040/25046 (87%)]\tLoss: 0.715326\n",
            "Train epoch: 172 [678300/25046 (89%)]\tLoss: 0.695357\n",
            "Train epoch: 172 [727200/25046 (92%)]\tLoss: 0.678213\n",
            "Train epoch: 172 [731120/25046 (95%)]\tLoss: 0.574617\n",
            "Train epoch: 172 [807880/25046 (97%)]\tLoss: 0.837891\n",
            "Train epoch: 172 [833820/25046 (100%)]\tLoss: 0.633048\n",
            "Make prediction for 5010 samples...\n",
            "0.8034493 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 173 [0/25046 (0%)]\tLoss: 0.888133\n",
            "Train epoch: 173 [21280/25046 (3%)]\tLoss: 0.662196\n",
            "Train epoch: 173 [40520/25046 (5%)]\tLoss: 0.650323\n",
            "Train epoch: 173 [62700/25046 (8%)]\tLoss: 0.243544\n",
            "Train epoch: 173 [80800/25046 (10%)]\tLoss: 0.590579\n",
            "Train epoch: 173 [98700/25046 (13%)]\tLoss: 0.748930\n",
            "Train epoch: 173 [125280/25046 (15%)]\tLoss: 0.351209\n",
            "Train epoch: 173 [144620/25046 (18%)]\tLoss: 1.346705\n",
            "Train epoch: 173 [163680/25046 (20%)]\tLoss: 0.370354\n",
            "Train epoch: 173 [190440/25046 (23%)]\tLoss: 0.938038\n",
            "Train epoch: 173 [202000/25046 (26%)]\tLoss: 0.931026\n",
            "Train epoch: 173 [227700/25046 (28%)]\tLoss: 1.552211\n",
            "Train epoch: 173 [241920/25046 (31%)]\tLoss: 1.530766\n",
            "Train epoch: 173 [252200/25046 (33%)]\tLoss: 0.882351\n",
            "Train epoch: 173 [280000/25046 (36%)]\tLoss: 0.724834\n",
            "Train epoch: 173 [302400/25046 (38%)]\tLoss: 0.366021\n",
            "Train epoch: 173 [314240/25046 (41%)]\tLoss: 1.579219\n",
            "Train epoch: 173 [352240/25046 (43%)]\tLoss: 1.663996\n",
            "Train epoch: 173 [353880/25046 (46%)]\tLoss: 0.438306\n",
            "Train epoch: 173 [389120/25046 (49%)]\tLoss: 0.518946\n",
            "Train epoch: 173 [370800/25046 (51%)]\tLoss: 0.383642\n",
            "Train epoch: 173 [427140/25046 (54%)]\tLoss: 0.908291\n",
            "Train epoch: 173 [468160/25046 (56%)]\tLoss: 1.195085\n",
            "Train epoch: 173 [446660/25046 (59%)]\tLoss: 0.394141\n",
            "Train epoch: 173 [492960/25046 (61%)]\tLoss: 0.605946\n",
            "Train epoch: 173 [532500/25046 (64%)]\tLoss: 0.800301\n",
            "Train epoch: 173 [549640/25046 (66%)]\tLoss: 0.980399\n",
            "Train epoch: 173 [546480/25046 (69%)]\tLoss: 0.971319\n",
            "Train epoch: 173 [569520/25046 (72%)]\tLoss: 0.656473\n",
            "Train epoch: 173 [596820/25046 (74%)]\tLoss: 0.915852\n",
            "Train epoch: 173 [576000/25046 (77%)]\tLoss: 1.067741\n",
            "Train epoch: 173 [623100/25046 (79%)]\tLoss: 0.611235\n",
            "Train epoch: 173 [654080/25046 (82%)]\tLoss: 0.683430\n",
            "Train epoch: 173 [701580/25046 (84%)]\tLoss: 1.500528\n",
            "Train epoch: 173 [697000/25046 (87%)]\tLoss: 0.282762\n",
            "Train epoch: 173 [729400/25046 (89%)]\tLoss: 0.767227\n",
            "Train epoch: 173 [784800/25046 (92%)]\tLoss: 1.276336\n",
            "Train epoch: 173 [828060/25046 (95%)]\tLoss: 0.409104\n",
            "Train epoch: 173 [766080/25046 (97%)]\tLoss: 0.887796\n",
            "Train epoch: 173 [796380/25046 (100%)]\tLoss: 0.501777\n",
            "Make prediction for 5010 samples...\n",
            "0.80241513 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 174 [0/25046 (0%)]\tLoss: 0.934463\n",
            "Train epoch: 174 [19420/25046 (3%)]\tLoss: 1.842499\n",
            "Train epoch: 174 [39440/25046 (5%)]\tLoss: 1.238915\n",
            "Train epoch: 174 [61260/25046 (8%)]\tLoss: 1.168241\n",
            "Train epoch: 174 [80080/25046 (10%)]\tLoss: 0.836816\n",
            "Train epoch: 174 [101400/25046 (13%)]\tLoss: 0.878033\n",
            "Train epoch: 174 [122760/25046 (15%)]\tLoss: 0.823774\n",
            "Train epoch: 174 [138040/25046 (18%)]\tLoss: 0.841417\n",
            "Train epoch: 174 [174720/25046 (20%)]\tLoss: 0.403202\n",
            "Train epoch: 174 [195660/25046 (23%)]\tLoss: 0.837703\n",
            "Train epoch: 174 [195000/25046 (26%)]\tLoss: 0.887509\n",
            "Train epoch: 174 [219560/25046 (28%)]\tLoss: 0.275337\n",
            "Train epoch: 174 [232080/25046 (31%)]\tLoss: 0.526756\n",
            "Train epoch: 174 [276640/25046 (33%)]\tLoss: 1.282589\n",
            "Train epoch: 174 [286440/25046 (36%)]\tLoss: 1.369077\n",
            "Train epoch: 174 [310800/25046 (38%)]\tLoss: 0.454567\n",
            "Train epoch: 174 [320960/25046 (41%)]\tLoss: 0.658720\n",
            "Train epoch: 174 [339320/25046 (43%)]\tLoss: 1.069201\n",
            "Train epoch: 174 [377280/25046 (46%)]\tLoss: 0.750437\n",
            "Train epoch: 174 [387980/25046 (49%)]\tLoss: 0.371036\n",
            "Train epoch: 174 [434000/25046 (51%)]\tLoss: 0.863372\n",
            "Train epoch: 174 [462840/25046 (54%)]\tLoss: 1.272918\n",
            "Train epoch: 174 [484000/25046 (56%)]\tLoss: 1.368643\n",
            "Train epoch: 174 [455400/25046 (59%)]\tLoss: 0.743024\n",
            "Train epoch: 174 [501600/25046 (61%)]\tLoss: 0.678780\n",
            "Train epoch: 174 [539000/25046 (64%)]\tLoss: 0.670004\n",
            "Train epoch: 174 [541840/25046 (66%)]\tLoss: 1.688709\n",
            "Train epoch: 174 [592380/25046 (69%)]\tLoss: 0.870312\n",
            "Train epoch: 174 [576800/25046 (72%)]\tLoss: 0.578964\n",
            "Train epoch: 174 [612480/25046 (74%)]\tLoss: 1.195295\n",
            "Train epoch: 174 [649200/25046 (77%)]\tLoss: 1.227465\n",
            "Train epoch: 174 [634260/25046 (79%)]\tLoss: 0.288922\n",
            "Train epoch: 174 [629120/25046 (82%)]\tLoss: 0.647775\n",
            "Train epoch: 174 [672540/25046 (84%)]\tLoss: 0.800480\n",
            "Train epoch: 174 [735760/25046 (87%)]\tLoss: 0.573772\n",
            "Train epoch: 174 [724500/25046 (89%)]\tLoss: 0.384621\n",
            "Train epoch: 174 [721440/25046 (92%)]\tLoss: 0.596801\n",
            "Train epoch: 174 [763680/25046 (95%)]\tLoss: 0.948013\n",
            "Train epoch: 174 [769120/25046 (97%)]\tLoss: 0.889161\n",
            "Train epoch: 174 [860340/25046 (100%)]\tLoss: 1.249704\n",
            "Make prediction for 5010 samples...\n",
            "0.80155605 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 175 [0/25046 (0%)]\tLoss: 0.925463\n",
            "Train epoch: 175 [21200/25046 (3%)]\tLoss: 1.775293\n",
            "Train epoch: 175 [39520/25046 (5%)]\tLoss: 0.380948\n",
            "Train epoch: 175 [58920/25046 (8%)]\tLoss: 0.550865\n",
            "Train epoch: 175 [80560/25046 (10%)]\tLoss: 0.398382\n",
            "Train epoch: 175 [97700/25046 (13%)]\tLoss: 0.415163\n",
            "Train epoch: 175 [127440/25046 (15%)]\tLoss: 1.867314\n",
            "Train epoch: 175 [148120/25046 (18%)]\tLoss: 0.287019\n",
            "Train epoch: 175 [166080/25046 (20%)]\tLoss: 0.612250\n",
            "Train epoch: 175 [184680/25046 (23%)]\tLoss: 0.273248\n",
            "Train epoch: 175 [203200/25046 (26%)]\tLoss: 1.322414\n",
            "Train epoch: 175 [223740/25046 (28%)]\tLoss: 0.543170\n",
            "Train epoch: 175 [243840/25046 (31%)]\tLoss: 0.264679\n",
            "Train epoch: 175 [259740/25046 (33%)]\tLoss: 1.036109\n",
            "Train epoch: 175 [300160/25046 (36%)]\tLoss: 0.510636\n",
            "Train epoch: 175 [321300/25046 (38%)]\tLoss: 0.441336\n",
            "Train epoch: 175 [326400/25046 (41%)]\tLoss: 0.813483\n",
            "Train epoch: 175 [329460/25046 (43%)]\tLoss: 1.374308\n",
            "Train epoch: 175 [366840/25046 (46%)]\tLoss: 1.254224\n",
            "Train epoch: 175 [383420/25046 (49%)]\tLoss: 0.314646\n",
            "Train epoch: 175 [403200/25046 (51%)]\tLoss: 0.771599\n",
            "Train epoch: 175 [427980/25046 (54%)]\tLoss: 1.196110\n",
            "Train epoch: 175 [441320/25046 (56%)]\tLoss: 0.797913\n",
            "Train epoch: 175 [489440/25046 (59%)]\tLoss: 1.065841\n",
            "Train epoch: 175 [492000/25046 (61%)]\tLoss: 0.642796\n",
            "Train epoch: 175 [490500/25046 (64%)]\tLoss: 1.137052\n",
            "Train epoch: 175 [584480/25046 (66%)]\tLoss: 1.081865\n",
            "Train epoch: 175 [565920/25046 (69%)]\tLoss: 0.529566\n",
            "Train epoch: 175 [562240/25046 (72%)]\tLoss: 0.763098\n",
            "Train epoch: 175 [593340/25046 (74%)]\tLoss: 0.853153\n",
            "Train epoch: 175 [637200/25046 (77%)]\tLoss: 1.116027\n",
            "Train epoch: 175 [611940/25046 (79%)]\tLoss: 0.867396\n",
            "Train epoch: 175 [595840/25046 (82%)]\tLoss: 1.374164\n",
            "Train epoch: 175 [686400/25046 (84%)]\tLoss: 1.356503\n",
            "Train epoch: 175 [702440/25046 (87%)]\tLoss: 0.517161\n",
            "Train epoch: 175 [758800/25046 (89%)]\tLoss: 0.542814\n",
            "Train epoch: 175 [734400/25046 (92%)]\tLoss: 0.616738\n",
            "Train epoch: 175 [726680/25046 (95%)]\tLoss: 0.789956\n",
            "Train epoch: 175 [767600/25046 (97%)]\tLoss: 0.582887\n",
            "Train epoch: 175 [729300/25046 (100%)]\tLoss: 0.820745\n",
            "Make prediction for 5010 samples...\n",
            "0.8018009 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 176 [0/25046 (0%)]\tLoss: 0.533588\n",
            "Train epoch: 176 [20280/25046 (3%)]\tLoss: 0.209426\n",
            "Train epoch: 176 [41240/25046 (5%)]\tLoss: 1.838806\n",
            "Train epoch: 176 [61800/25046 (8%)]\tLoss: 1.122160\n",
            "Train epoch: 176 [83760/25046 (10%)]\tLoss: 0.473839\n",
            "Train epoch: 176 [99900/25046 (13%)]\tLoss: 0.407035\n",
            "Train epoch: 176 [118680/25046 (15%)]\tLoss: 0.780315\n",
            "Train epoch: 176 [138460/25046 (18%)]\tLoss: 1.241068\n",
            "Train epoch: 176 [170560/25046 (20%)]\tLoss: 0.723425\n",
            "Train epoch: 176 [183600/25046 (23%)]\tLoss: 1.020729\n",
            "Train epoch: 176 [207000/25046 (26%)]\tLoss: 0.933511\n",
            "Train epoch: 176 [225500/25046 (28%)]\tLoss: 0.603006\n",
            "Train epoch: 176 [250800/25046 (31%)]\tLoss: 1.102324\n",
            "Train epoch: 176 [275600/25046 (33%)]\tLoss: 0.316118\n",
            "Train epoch: 176 [300440/25046 (36%)]\tLoss: 1.311407\n",
            "Train epoch: 176 [312000/25046 (38%)]\tLoss: 0.351556\n",
            "Train epoch: 176 [336320/25046 (41%)]\tLoss: 1.286615\n",
            "Train epoch: 176 [347140/25046 (43%)]\tLoss: 1.198685\n",
            "Train epoch: 176 [375840/25046 (46%)]\tLoss: 1.363885\n",
            "Train epoch: 176 [391400/25046 (49%)]\tLoss: 1.121766\n",
            "Train epoch: 176 [402400/25046 (51%)]\tLoss: 1.228952\n",
            "Train epoch: 176 [442260/25046 (54%)]\tLoss: 0.744773\n",
            "Train epoch: 176 [450120/25046 (56%)]\tLoss: 0.626709\n",
            "Train epoch: 176 [471500/25046 (59%)]\tLoss: 0.928515\n",
            "Train epoch: 176 [485760/25046 (61%)]\tLoss: 0.421850\n",
            "Train epoch: 176 [503500/25046 (64%)]\tLoss: 0.399468\n",
            "Train epoch: 176 [533520/25046 (66%)]\tLoss: 0.899684\n",
            "Train epoch: 176 [571860/25046 (69%)]\tLoss: 0.248352\n",
            "Train epoch: 176 [577360/25046 (72%)]\tLoss: 0.871843\n",
            "Train epoch: 176 [575940/25046 (74%)]\tLoss: 0.344812\n",
            "Train epoch: 176 [602400/25046 (77%)]\tLoss: 0.561464\n",
            "Train epoch: 176 [590240/25046 (79%)]\tLoss: 0.950837\n",
            "Train epoch: 176 [618880/25046 (82%)]\tLoss: 0.324839\n",
            "Train epoch: 176 [669900/25046 (84%)]\tLoss: 1.585124\n",
            "Train epoch: 176 [664360/25046 (87%)]\tLoss: 1.149928\n",
            "Train epoch: 176 [702100/25046 (89%)]\tLoss: 0.973550\n",
            "Train epoch: 176 [783360/25046 (92%)]\tLoss: 0.923550\n",
            "Train epoch: 176 [742220/25046 (95%)]\tLoss: 0.586259\n",
            "Train epoch: 176 [789640/25046 (97%)]\tLoss: 0.358607\n",
            "Train epoch: 176 [770640/25046 (100%)]\tLoss: 0.313668\n",
            "Make prediction for 5010 samples...\n",
            "0.8023445 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 177 [0/25046 (0%)]\tLoss: 0.601363\n",
            "Train epoch: 177 [20440/25046 (3%)]\tLoss: 1.569687\n",
            "Train epoch: 177 [40640/25046 (5%)]\tLoss: 0.877558\n",
            "Train epoch: 177 [63720/25046 (8%)]\tLoss: 0.558647\n",
            "Train epoch: 177 [83520/25046 (10%)]\tLoss: 0.427015\n",
            "Train epoch: 177 [97500/25046 (13%)]\tLoss: 0.138408\n",
            "Train epoch: 177 [127560/25046 (15%)]\tLoss: 0.596805\n",
            "Train epoch: 177 [147560/25046 (18%)]\tLoss: 0.705446\n",
            "Train epoch: 177 [164960/25046 (20%)]\tLoss: 0.987320\n",
            "Train epoch: 177 [185580/25046 (23%)]\tLoss: 0.284466\n",
            "Train epoch: 177 [204200/25046 (26%)]\tLoss: 0.492687\n",
            "Train epoch: 177 [232540/25046 (28%)]\tLoss: 0.723184\n",
            "Train epoch: 177 [227760/25046 (31%)]\tLoss: 0.552860\n",
            "Train epoch: 177 [277160/25046 (33%)]\tLoss: 0.520163\n",
            "Train epoch: 177 [294560/25046 (36%)]\tLoss: 1.114543\n",
            "Train epoch: 177 [322500/25046 (38%)]\tLoss: 1.455205\n",
            "Train epoch: 177 [313280/25046 (41%)]\tLoss: 0.533422\n",
            "Train epoch: 177 [328100/25046 (43%)]\tLoss: 1.084672\n",
            "Train epoch: 177 [369360/25046 (46%)]\tLoss: 0.849923\n",
            "Train epoch: 177 [390260/25046 (49%)]\tLoss: 0.797988\n",
            "Train epoch: 177 [429600/25046 (51%)]\tLoss: 0.632612\n",
            "Train epoch: 177 [436800/25046 (54%)]\tLoss: 0.294151\n",
            "Train epoch: 177 [418000/25046 (56%)]\tLoss: 0.642255\n",
            "Train epoch: 177 [485300/25046 (59%)]\tLoss: 0.296735\n",
            "Train epoch: 177 [490080/25046 (61%)]\tLoss: 1.565774\n",
            "Train epoch: 177 [527000/25046 (64%)]\tLoss: 0.627320\n",
            "Train epoch: 177 [526760/25046 (66%)]\tLoss: 0.544672\n",
            "Train epoch: 177 [527040/25046 (69%)]\tLoss: 1.144562\n",
            "Train epoch: 177 [553280/25046 (72%)]\tLoss: 0.784536\n",
            "Train epoch: 177 [596240/25046 (74%)]\tLoss: 0.584700\n",
            "Train epoch: 177 [608400/25046 (77%)]\tLoss: 0.299931\n",
            "Train epoch: 177 [600780/25046 (79%)]\tLoss: 0.577899\n",
            "Train epoch: 177 [671360/25046 (82%)]\tLoss: 1.238159\n",
            "Train epoch: 177 [670560/25046 (84%)]\tLoss: 1.304226\n",
            "Train epoch: 177 [741200/25046 (87%)]\tLoss: 0.347475\n",
            "Train epoch: 177 [715400/25046 (89%)]\tLoss: 0.346442\n",
            "Train epoch: 177 [732240/25046 (92%)]\tLoss: 0.426950\n",
            "Train epoch: 177 [772560/25046 (95%)]\tLoss: 0.706183\n",
            "Train epoch: 177 [786600/25046 (97%)]\tLoss: 0.631887\n",
            "Train epoch: 177 [787020/25046 (100%)]\tLoss: 1.270381\n",
            "Make prediction for 5010 samples...\n",
            "0.8016015 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 178 [0/25046 (0%)]\tLoss: 0.460753\n",
            "Train epoch: 178 [20440/25046 (3%)]\tLoss: 0.645254\n",
            "Train epoch: 178 [43440/25046 (5%)]\tLoss: 1.086546\n",
            "Train epoch: 178 [59400/25046 (8%)]\tLoss: 0.372850\n",
            "Train epoch: 178 [82560/25046 (10%)]\tLoss: 0.770292\n",
            "Train epoch: 178 [97300/25046 (13%)]\tLoss: 1.088278\n",
            "Train epoch: 178 [122160/25046 (15%)]\tLoss: 0.499163\n",
            "Train epoch: 178 [145180/25046 (18%)]\tLoss: 0.638775\n",
            "Train epoch: 178 [149280/25046 (20%)]\tLoss: 0.965512\n",
            "Train epoch: 178 [186660/25046 (23%)]\tLoss: 0.512972\n",
            "Train epoch: 178 [206400/25046 (26%)]\tLoss: 0.699734\n",
            "Train epoch: 178 [225720/25046 (28%)]\tLoss: 1.425603\n",
            "Train epoch: 178 [241680/25046 (31%)]\tLoss: 0.881570\n",
            "Train epoch: 178 [259740/25046 (33%)]\tLoss: 0.348334\n",
            "Train epoch: 178 [286160/25046 (36%)]\tLoss: 0.779566\n",
            "Train epoch: 178 [294600/25046 (38%)]\tLoss: 0.705789\n",
            "Train epoch: 178 [323520/25046 (41%)]\tLoss: 0.667549\n",
            "Train epoch: 178 [349860/25046 (43%)]\tLoss: 0.631721\n",
            "Train epoch: 178 [381960/25046 (46%)]\tLoss: 0.693779\n",
            "Train epoch: 178 [390640/25046 (49%)]\tLoss: 0.537810\n",
            "Train epoch: 178 [412800/25046 (51%)]\tLoss: 0.605158\n",
            "Train epoch: 178 [431340/25046 (54%)]\tLoss: 2.028653\n",
            "Train epoch: 178 [458480/25046 (56%)]\tLoss: 1.838983\n",
            "Train epoch: 178 [474720/25046 (59%)]\tLoss: 1.607467\n",
            "Train epoch: 178 [507840/25046 (61%)]\tLoss: 0.971291\n",
            "Train epoch: 178 [529500/25046 (64%)]\tLoss: 0.993025\n",
            "Train epoch: 178 [510640/25046 (66%)]\tLoss: 0.680421\n",
            "Train epoch: 178 [548640/25046 (69%)]\tLoss: 0.809479\n",
            "Train epoch: 178 [609280/25046 (72%)]\tLoss: 0.386083\n",
            "Train epoch: 178 [607840/25046 (74%)]\tLoss: 0.781796\n",
            "Train epoch: 178 [573000/25046 (77%)]\tLoss: 0.637764\n",
            "Train epoch: 178 [695020/25046 (79%)]\tLoss: 0.999931\n",
            "Train epoch: 178 [670720/25046 (82%)]\tLoss: 0.927460\n",
            "Train epoch: 178 [665940/25046 (84%)]\tLoss: 0.688215\n",
            "Train epoch: 178 [713320/25046 (87%)]\tLoss: 0.981744\n",
            "Train epoch: 178 [744100/25046 (89%)]\tLoss: 1.293362\n",
            "Train epoch: 178 [717840/25046 (92%)]\tLoss: 1.284155\n",
            "Train epoch: 178 [765160/25046 (95%)]\tLoss: 1.044257\n",
            "Train epoch: 178 [780520/25046 (97%)]\tLoss: 1.550682\n",
            "Train epoch: 178 [736320/25046 (100%)]\tLoss: 0.515350\n",
            "Make prediction for 5010 samples...\n",
            "0.80347013 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 179 [0/25046 (0%)]\tLoss: 0.492176\n",
            "Train epoch: 179 [22180/25046 (3%)]\tLoss: 0.554500\n",
            "Train epoch: 179 [41120/25046 (5%)]\tLoss: 0.795874\n",
            "Train epoch: 179 [60480/25046 (8%)]\tLoss: 0.648739\n",
            "Train epoch: 179 [82960/25046 (10%)]\tLoss: 0.812972\n",
            "Train epoch: 179 [96500/25046 (13%)]\tLoss: 0.366855\n",
            "Train epoch: 179 [120840/25046 (15%)]\tLoss: 1.275167\n",
            "Train epoch: 179 [140560/25046 (18%)]\tLoss: 0.658881\n",
            "Train epoch: 179 [162240/25046 (20%)]\tLoss: 0.616053\n",
            "Train epoch: 179 [186480/25046 (23%)]\tLoss: 1.196190\n",
            "Train epoch: 179 [213800/25046 (26%)]\tLoss: 0.691956\n",
            "Train epoch: 179 [225500/25046 (28%)]\tLoss: 1.220131\n",
            "Train epoch: 179 [249840/25046 (31%)]\tLoss: 1.199959\n",
            "Train epoch: 179 [271180/25046 (33%)]\tLoss: 0.347554\n",
            "Train epoch: 179 [284200/25046 (36%)]\tLoss: 0.716149\n",
            "Train epoch: 179 [325800/25046 (38%)]\tLoss: 0.870778\n",
            "Train epoch: 179 [319360/25046 (41%)]\tLoss: 0.972747\n",
            "Train epoch: 179 [353600/25046 (43%)]\tLoss: 1.226027\n",
            "Train epoch: 179 [365760/25046 (46%)]\tLoss: 1.220314\n",
            "Train epoch: 179 [386080/25046 (49%)]\tLoss: 0.451119\n",
            "Train epoch: 179 [419600/25046 (51%)]\tLoss: 1.459077\n",
            "Train epoch: 179 [424620/25046 (54%)]\tLoss: 0.315875\n",
            "Train epoch: 179 [466840/25046 (56%)]\tLoss: 1.336870\n",
            "Train epoch: 179 [482540/25046 (59%)]\tLoss: 1.070274\n",
            "Train epoch: 179 [518880/25046 (61%)]\tLoss: 1.189194\n",
            "Train epoch: 179 [509000/25046 (64%)]\tLoss: 1.162058\n",
            "Train epoch: 179 [556920/25046 (66%)]\tLoss: 1.537227\n",
            "Train epoch: 179 [524340/25046 (69%)]\tLoss: 0.588470\n",
            "Train epoch: 179 [570080/25046 (72%)]\tLoss: 0.640770\n",
            "Train epoch: 179 [546360/25046 (74%)]\tLoss: 0.259752\n",
            "Train epoch: 179 [594600/25046 (77%)]\tLoss: 0.988457\n",
            "Train epoch: 179 [607600/25046 (79%)]\tLoss: 1.079426\n",
            "Train epoch: 179 [647040/25046 (82%)]\tLoss: 0.434532\n",
            "Train epoch: 179 [658680/25046 (84%)]\tLoss: 0.525582\n",
            "Train epoch: 179 [687480/25046 (87%)]\tLoss: 0.663103\n",
            "Train epoch: 179 [699300/25046 (89%)]\tLoss: 0.927244\n",
            "Train epoch: 179 [714240/25046 (92%)]\tLoss: 0.269071\n",
            "Train epoch: 179 [784400/25046 (95%)]\tLoss: 0.608628\n",
            "Train epoch: 179 [779000/25046 (97%)]\tLoss: 1.592472\n",
            "Train epoch: 179 [794820/25046 (100%)]\tLoss: 0.829018\n",
            "Make prediction for 5010 samples...\n",
            "0.80190784 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 180 [0/25046 (0%)]\tLoss: 0.953287\n",
            "Train epoch: 180 [21240/25046 (3%)]\tLoss: 0.808897\n",
            "Train epoch: 180 [40400/25046 (5%)]\tLoss: 1.284458\n",
            "Train epoch: 180 [58980/25046 (8%)]\tLoss: 1.074834\n",
            "Train epoch: 180 [83440/25046 (10%)]\tLoss: 1.127082\n",
            "Train epoch: 180 [101100/25046 (13%)]\tLoss: 0.356467\n",
            "Train epoch: 180 [122520/25046 (15%)]\tLoss: 0.690802\n",
            "Train epoch: 180 [155820/25046 (18%)]\tLoss: 1.178550\n",
            "Train epoch: 180 [161760/25046 (20%)]\tLoss: 0.821990\n",
            "Train epoch: 180 [185580/25046 (23%)]\tLoss: 0.740129\n",
            "Train epoch: 180 [213200/25046 (26%)]\tLoss: 1.297564\n",
            "Train epoch: 180 [231220/25046 (28%)]\tLoss: 0.918715\n",
            "Train epoch: 180 [242400/25046 (31%)]\tLoss: 1.704499\n",
            "Train epoch: 180 [257920/25046 (33%)]\tLoss: 1.436882\n",
            "Train epoch: 180 [267960/25046 (36%)]\tLoss: 0.641652\n",
            "Train epoch: 180 [305100/25046 (38%)]\tLoss: 0.807563\n",
            "Train epoch: 180 [323200/25046 (41%)]\tLoss: 0.717800\n",
            "Train epoch: 180 [323340/25046 (43%)]\tLoss: 0.403840\n",
            "Train epoch: 180 [377640/25046 (46%)]\tLoss: 1.059105\n",
            "Train epoch: 180 [392160/25046 (49%)]\tLoss: 0.717719\n",
            "Train epoch: 180 [432400/25046 (51%)]\tLoss: 1.072667\n",
            "Train epoch: 180 [420000/25046 (54%)]\tLoss: 0.847020\n",
            "Train epoch: 180 [438240/25046 (56%)]\tLoss: 0.404273\n",
            "Train epoch: 180 [516120/25046 (59%)]\tLoss: 0.389776\n",
            "Train epoch: 180 [471360/25046 (61%)]\tLoss: 1.155099\n",
            "Train epoch: 180 [513500/25046 (64%)]\tLoss: 0.448549\n",
            "Train epoch: 180 [544440/25046 (66%)]\tLoss: 0.526721\n",
            "Train epoch: 180 [553500/25046 (69%)]\tLoss: 0.666283\n",
            "Train epoch: 180 [562800/25046 (72%)]\tLoss: 0.600332\n",
            "Train epoch: 180 [568980/25046 (74%)]\tLoss: 0.864775\n",
            "Train epoch: 180 [586200/25046 (77%)]\tLoss: 0.450697\n",
            "Train epoch: 180 [627440/25046 (79%)]\tLoss: 1.219906\n",
            "Train epoch: 180 [647040/25046 (82%)]\tLoss: 0.655373\n",
            "Train epoch: 180 [701580/25046 (84%)]\tLoss: 1.603153\n",
            "Train epoch: 180 [729640/25046 (87%)]\tLoss: 0.603805\n",
            "Train epoch: 180 [713300/25046 (89%)]\tLoss: 1.458017\n",
            "Train epoch: 180 [716400/25046 (92%)]\tLoss: 0.397892\n",
            "Train epoch: 180 [757760/25046 (95%)]\tLoss: 0.469594\n",
            "Train epoch: 180 [779000/25046 (97%)]\tLoss: 1.163213\n",
            "Train epoch: 180 [801840/25046 (100%)]\tLoss: 0.958157\n",
            "Make prediction for 5010 samples...\n",
            "0.8044984 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 181 [0/25046 (0%)]\tLoss: 0.541870\n",
            "Train epoch: 181 [20700/25046 (3%)]\tLoss: 0.978436\n",
            "Train epoch: 181 [42720/25046 (5%)]\tLoss: 0.728194\n",
            "Train epoch: 181 [62580/25046 (8%)]\tLoss: 0.848057\n",
            "Train epoch: 181 [80000/25046 (10%)]\tLoss: 1.451594\n",
            "Train epoch: 181 [105900/25046 (13%)]\tLoss: 0.390553\n",
            "Train epoch: 181 [118440/25046 (15%)]\tLoss: 0.572150\n",
            "Train epoch: 181 [147840/25046 (18%)]\tLoss: 0.730258\n",
            "Train epoch: 181 [171040/25046 (20%)]\tLoss: 0.434704\n",
            "Train epoch: 181 [184860/25046 (23%)]\tLoss: 1.177679\n",
            "Train epoch: 181 [191200/25046 (26%)]\tLoss: 1.131703\n",
            "Train epoch: 181 [214720/25046 (28%)]\tLoss: 0.234033\n",
            "Train epoch: 181 [220080/25046 (31%)]\tLoss: 0.398867\n",
            "Train epoch: 181 [266760/25046 (33%)]\tLoss: 0.667540\n",
            "Train epoch: 181 [290080/25046 (36%)]\tLoss: 0.572727\n",
            "Train epoch: 181 [304200/25046 (38%)]\tLoss: 0.747760\n",
            "Train epoch: 181 [339200/25046 (41%)]\tLoss: 0.906659\n",
            "Train epoch: 181 [358020/25046 (43%)]\tLoss: 0.826303\n",
            "Train epoch: 181 [354600/25046 (46%)]\tLoss: 0.641467\n",
            "Train epoch: 181 [396340/25046 (49%)]\tLoss: 0.509726\n",
            "Train epoch: 181 [402400/25046 (51%)]\tLoss: 0.738167\n",
            "Train epoch: 181 [438060/25046 (54%)]\tLoss: 0.752298\n",
            "Train epoch: 181 [451440/25046 (56%)]\tLoss: 1.075672\n",
            "Train epoch: 181 [463220/25046 (59%)]\tLoss: 1.052486\n",
            "Train epoch: 181 [492480/25046 (61%)]\tLoss: 0.906397\n",
            "Train epoch: 181 [522000/25046 (64%)]\tLoss: 0.272506\n",
            "Train epoch: 181 [518440/25046 (66%)]\tLoss: 0.434876\n",
            "Train epoch: 181 [564840/25046 (69%)]\tLoss: 1.493591\n",
            "Train epoch: 181 [547120/25046 (72%)]\tLoss: 0.454676\n",
            "Train epoch: 181 [609000/25046 (74%)]\tLoss: 0.815315\n",
            "Train epoch: 181 [579000/25046 (77%)]\tLoss: 0.316506\n",
            "Train epoch: 181 [628060/25046 (79%)]\tLoss: 0.369505\n",
            "Train epoch: 181 [688640/25046 (82%)]\tLoss: 0.422226\n",
            "Train epoch: 181 [670560/25046 (84%)]\tLoss: 1.053099\n",
            "Train epoch: 181 [675240/25046 (87%)]\tLoss: 0.864310\n",
            "Train epoch: 181 [742000/25046 (89%)]\tLoss: 0.628262\n",
            "Train epoch: 181 [735840/25046 (92%)]\tLoss: 0.747981\n",
            "Train epoch: 181 [760720/25046 (95%)]\tLoss: 1.127990\n",
            "Train epoch: 181 [798000/25046 (97%)]\tLoss: 0.525658\n",
            "Train epoch: 181 [750360/25046 (100%)]\tLoss: 0.218690\n",
            "Make prediction for 5010 samples...\n",
            "0.8020043 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 182 [0/25046 (0%)]\tLoss: 0.534376\n",
            "Train epoch: 182 [19140/25046 (3%)]\tLoss: 1.546735\n",
            "Train epoch: 182 [39400/25046 (5%)]\tLoss: 1.593466\n",
            "Train epoch: 182 [58320/25046 (8%)]\tLoss: 0.848878\n",
            "Train epoch: 182 [78480/25046 (10%)]\tLoss: 0.465888\n",
            "Train epoch: 182 [100800/25046 (13%)]\tLoss: 0.611048\n",
            "Train epoch: 182 [126480/25046 (15%)]\tLoss: 0.307885\n",
            "Train epoch: 182 [136920/25046 (18%)]\tLoss: 0.396591\n",
            "Train epoch: 182 [160800/25046 (20%)]\tLoss: 0.824348\n",
            "Train epoch: 182 [187920/25046 (23%)]\tLoss: 0.654087\n",
            "Train epoch: 182 [209800/25046 (26%)]\tLoss: 0.392129\n",
            "Train epoch: 182 [234960/25046 (28%)]\tLoss: 1.384136\n",
            "Train epoch: 182 [244320/25046 (31%)]\tLoss: 0.437087\n",
            "Train epoch: 182 [258700/25046 (33%)]\tLoss: 0.962922\n",
            "Train epoch: 182 [289240/25046 (36%)]\tLoss: 1.115478\n",
            "Train epoch: 182 [318900/25046 (38%)]\tLoss: 0.900157\n",
            "Train epoch: 182 [322240/25046 (41%)]\tLoss: 0.454707\n",
            "Train epoch: 182 [334560/25046 (43%)]\tLoss: 0.485953\n",
            "Train epoch: 182 [368280/25046 (46%)]\tLoss: 1.629387\n",
            "Train epoch: 182 [392160/25046 (49%)]\tLoss: 1.251392\n",
            "Train epoch: 182 [428800/25046 (51%)]\tLoss: 0.761095\n",
            "Train epoch: 182 [417480/25046 (54%)]\tLoss: 1.508680\n",
            "Train epoch: 182 [485320/25046 (56%)]\tLoss: 0.978191\n",
            "Train epoch: 182 [483000/25046 (59%)]\tLoss: 0.579580\n",
            "Train epoch: 182 [513600/25046 (61%)]\tLoss: 0.959391\n",
            "Train epoch: 182 [511500/25046 (64%)]\tLoss: 1.060757\n",
            "Train epoch: 182 [513760/25046 (66%)]\tLoss: 0.384830\n",
            "Train epoch: 182 [568620/25046 (69%)]\tLoss: 0.675465\n",
            "Train epoch: 182 [572880/25046 (72%)]\tLoss: 1.681337\n",
            "Train epoch: 182 [584060/25046 (74%)]\tLoss: 0.669384\n",
            "Train epoch: 182 [587400/25046 (77%)]\tLoss: 1.012015\n",
            "Train epoch: 182 [628060/25046 (79%)]\tLoss: 0.924270\n",
            "Train epoch: 182 [632960/25046 (82%)]\tLoss: 1.083659\n",
            "Train epoch: 182 [678480/25046 (84%)]\tLoss: 1.128313\n",
            "Train epoch: 182 [707880/25046 (87%)]\tLoss: 0.798082\n",
            "Train epoch: 182 [746900/25046 (89%)]\tLoss: 0.895169\n",
            "Train epoch: 182 [683280/25046 (92%)]\tLoss: 0.635385\n",
            "Train epoch: 182 [758500/25046 (95%)]\tLoss: 0.718606\n",
            "Train epoch: 182 [782800/25046 (97%)]\tLoss: 1.874233\n",
            "Train epoch: 182 [839280/25046 (100%)]\tLoss: 0.832725\n",
            "Make prediction for 5010 samples...\n",
            "0.8033544 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 183 [0/25046 (0%)]\tLoss: 0.804250\n",
            "Train epoch: 183 [21700/25046 (3%)]\tLoss: 0.990274\n",
            "Train epoch: 183 [41680/25046 (5%)]\tLoss: 1.367743\n",
            "Train epoch: 183 [63900/25046 (8%)]\tLoss: 2.036876\n",
            "Train epoch: 183 [82800/25046 (10%)]\tLoss: 0.451467\n",
            "Train epoch: 183 [101000/25046 (13%)]\tLoss: 0.659259\n",
            "Train epoch: 183 [129960/25046 (15%)]\tLoss: 0.661815\n",
            "Train epoch: 183 [144620/25046 (18%)]\tLoss: 0.438690\n",
            "Train epoch: 183 [165120/25046 (20%)]\tLoss: 1.372045\n",
            "Train epoch: 183 [184140/25046 (23%)]\tLoss: 0.926732\n",
            "Train epoch: 183 [189600/25046 (26%)]\tLoss: 0.627061\n",
            "Train epoch: 183 [230120/25046 (28%)]\tLoss: 1.301313\n",
            "Train epoch: 183 [257760/25046 (31%)]\tLoss: 0.330748\n",
            "Train epoch: 183 [281840/25046 (33%)]\tLoss: 0.724769\n",
            "Train epoch: 183 [279160/25046 (36%)]\tLoss: 0.510641\n",
            "Train epoch: 183 [324300/25046 (38%)]\tLoss: 0.403884\n",
            "Train epoch: 183 [315200/25046 (41%)]\tLoss: 0.873164\n",
            "Train epoch: 183 [353940/25046 (43%)]\tLoss: 0.339574\n",
            "Train epoch: 183 [392760/25046 (46%)]\tLoss: 0.353628\n",
            "Train epoch: 183 [378860/25046 (49%)]\tLoss: 0.886544\n",
            "Train epoch: 183 [401600/25046 (51%)]\tLoss: 0.509191\n",
            "Train epoch: 183 [410760/25046 (54%)]\tLoss: 0.957689\n",
            "Train epoch: 183 [465520/25046 (56%)]\tLoss: 1.426730\n",
            "Train epoch: 183 [438380/25046 (59%)]\tLoss: 1.282865\n",
            "Train epoch: 183 [492480/25046 (61%)]\tLoss: 0.656940\n",
            "Train epoch: 183 [506500/25046 (64%)]\tLoss: 0.419169\n",
            "Train epoch: 183 [523640/25046 (66%)]\tLoss: 0.656712\n",
            "Train epoch: 183 [523800/25046 (69%)]\tLoss: 0.484278\n",
            "Train epoch: 183 [579600/25046 (72%)]\tLoss: 0.709990\n",
            "Train epoch: 183 [614800/25046 (74%)]\tLoss: 0.475049\n",
            "Train epoch: 183 [662400/25046 (77%)]\tLoss: 1.149180\n",
            "Train epoch: 183 [619380/25046 (79%)]\tLoss: 1.212155\n",
            "Train epoch: 183 [692480/25046 (82%)]\tLoss: 0.758351\n",
            "Train epoch: 183 [729960/25046 (84%)]\tLoss: 0.998323\n",
            "Train epoch: 183 [688840/25046 (87%)]\tLoss: 0.378394\n",
            "Train epoch: 183 [714000/25046 (89%)]\tLoss: 0.409075\n",
            "Train epoch: 183 [727920/25046 (92%)]\tLoss: 0.681496\n",
            "Train epoch: 183 [750360/25046 (95%)]\tLoss: 0.606673\n",
            "Train epoch: 183 [739480/25046 (97%)]\tLoss: 0.281058\n",
            "Train epoch: 183 [839280/25046 (100%)]\tLoss: 0.518646\n",
            "Make prediction for 5010 samples...\n",
            "0.8033379 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 184 [0/25046 (0%)]\tLoss: 0.488243\n",
            "Train epoch: 184 [20820/25046 (3%)]\tLoss: 0.266154\n",
            "Train epoch: 184 [40600/25046 (5%)]\tLoss: 0.351447\n",
            "Train epoch: 184 [58920/25046 (8%)]\tLoss: 0.654019\n",
            "Train epoch: 184 [79760/25046 (10%)]\tLoss: 1.146435\n",
            "Train epoch: 184 [101500/25046 (13%)]\tLoss: 0.505519\n",
            "Train epoch: 184 [120960/25046 (15%)]\tLoss: 1.421514\n",
            "Train epoch: 184 [145600/25046 (18%)]\tLoss: 0.926254\n",
            "Train epoch: 184 [155520/25046 (20%)]\tLoss: 1.271423\n",
            "Train epoch: 184 [191520/25046 (23%)]\tLoss: 1.092022\n",
            "Train epoch: 184 [199800/25046 (26%)]\tLoss: 0.546595\n",
            "Train epoch: 184 [233860/25046 (28%)]\tLoss: 0.509375\n",
            "Train epoch: 184 [239520/25046 (31%)]\tLoss: 0.420200\n",
            "Train epoch: 184 [267020/25046 (33%)]\tLoss: 0.878266\n",
            "Train epoch: 184 [274400/25046 (36%)]\tLoss: 0.903337\n",
            "Train epoch: 184 [315600/25046 (38%)]\tLoss: 0.279183\n",
            "Train epoch: 184 [325760/25046 (41%)]\tLoss: 0.665224\n",
            "Train epoch: 184 [367540/25046 (43%)]\tLoss: 1.727490\n",
            "Train epoch: 184 [349200/25046 (46%)]\tLoss: 0.898382\n",
            "Train epoch: 184 [427500/25046 (49%)]\tLoss: 1.580989\n",
            "Train epoch: 184 [417600/25046 (51%)]\tLoss: 0.233879\n",
            "Train epoch: 184 [455700/25046 (54%)]\tLoss: 0.222634\n",
            "Train epoch: 184 [452320/25046 (56%)]\tLoss: 0.511708\n",
            "Train epoch: 184 [486680/25046 (59%)]\tLoss: 1.459922\n",
            "Train epoch: 184 [521760/25046 (61%)]\tLoss: 0.685804\n",
            "Train epoch: 184 [509000/25046 (64%)]\tLoss: 0.780591\n",
            "Train epoch: 184 [537680/25046 (66%)]\tLoss: 1.565804\n",
            "Train epoch: 184 [563760/25046 (69%)]\tLoss: 1.112555\n",
            "Train epoch: 184 [542080/25046 (72%)]\tLoss: 1.171968\n",
            "Train epoch: 184 [586960/25046 (74%)]\tLoss: 0.900912\n",
            "Train epoch: 184 [588000/25046 (77%)]\tLoss: 0.476824\n",
            "Train epoch: 184 [666500/25046 (79%)]\tLoss: 0.856322\n",
            "Train epoch: 184 [668160/25046 (82%)]\tLoss: 0.754827\n",
            "Train epoch: 184 [691020/25046 (84%)]\tLoss: 0.447276\n",
            "Train epoch: 184 [687480/25046 (87%)]\tLoss: 0.855369\n",
            "Train epoch: 184 [718900/25046 (89%)]\tLoss: 0.470505\n",
            "Train epoch: 184 [743040/25046 (92%)]\tLoss: 1.237593\n",
            "Train epoch: 184 [801420/25046 (95%)]\tLoss: 0.720844\n",
            "Train epoch: 184 [769880/25046 (97%)]\tLoss: 1.785872\n",
            "Train epoch: 184 [742560/25046 (100%)]\tLoss: 0.273926\n",
            "Make prediction for 5010 samples...\n",
            "0.8084924 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 185 [0/25046 (0%)]\tLoss: 1.213379\n",
            "Train epoch: 185 [19220/25046 (3%)]\tLoss: 0.709811\n",
            "Train epoch: 185 [41520/25046 (5%)]\tLoss: 0.640103\n",
            "Train epoch: 185 [62040/25046 (8%)]\tLoss: 0.565090\n",
            "Train epoch: 185 [77440/25046 (10%)]\tLoss: 1.599757\n",
            "Train epoch: 185 [102900/25046 (13%)]\tLoss: 0.778487\n",
            "Train epoch: 185 [123360/25046 (15%)]\tLoss: 0.774768\n",
            "Train epoch: 185 [142240/25046 (18%)]\tLoss: 1.037978\n",
            "Train epoch: 185 [168480/25046 (20%)]\tLoss: 1.105013\n",
            "Train epoch: 185 [180360/25046 (23%)]\tLoss: 0.593197\n",
            "Train epoch: 185 [203000/25046 (26%)]\tLoss: 1.006640\n",
            "Train epoch: 185 [220880/25046 (28%)]\tLoss: 0.882101\n",
            "Train epoch: 185 [253680/25046 (31%)]\tLoss: 0.896775\n",
            "Train epoch: 185 [268580/25046 (33%)]\tLoss: 0.865747\n",
            "Train epoch: 185 [292040/25046 (36%)]\tLoss: 0.863837\n",
            "Train epoch: 185 [337200/25046 (38%)]\tLoss: 0.859543\n",
            "Train epoch: 185 [345600/25046 (41%)]\tLoss: 0.183426\n",
            "Train epoch: 185 [316200/25046 (43%)]\tLoss: 1.127670\n",
            "Train epoch: 185 [378360/25046 (46%)]\tLoss: 1.816900\n",
            "Train epoch: 185 [400140/25046 (49%)]\tLoss: 1.197860\n",
            "Train epoch: 185 [409600/25046 (51%)]\tLoss: 0.643004\n",
            "Train epoch: 185 [418320/25046 (54%)]\tLoss: 0.630740\n",
            "Train epoch: 185 [454960/25046 (56%)]\tLoss: 0.426255\n",
            "Train epoch: 185 [476560/25046 (59%)]\tLoss: 1.052346\n",
            "Train epoch: 185 [508800/25046 (61%)]\tLoss: 0.736925\n",
            "Train epoch: 185 [496500/25046 (64%)]\tLoss: 0.971730\n",
            "Train epoch: 185 [530920/25046 (66%)]\tLoss: 0.885257\n",
            "Train epoch: 185 [542700/25046 (69%)]\tLoss: 0.190800\n",
            "Train epoch: 185 [534800/25046 (72%)]\tLoss: 0.698094\n",
            "Train epoch: 185 [625240/25046 (74%)]\tLoss: 0.808724\n",
            "Train epoch: 185 [655200/25046 (77%)]\tLoss: 0.775375\n",
            "Train epoch: 185 [639220/25046 (79%)]\tLoss: 0.809334\n",
            "Train epoch: 185 [652800/25046 (82%)]\tLoss: 0.304247\n",
            "Train epoch: 185 [646140/25046 (84%)]\tLoss: 0.582354\n",
            "Train epoch: 185 [709240/25046 (87%)]\tLoss: 0.901790\n",
            "Train epoch: 185 [669200/25046 (89%)]\tLoss: 0.374728\n",
            "Train epoch: 185 [747360/25046 (92%)]\tLoss: 0.795557\n",
            "Train epoch: 185 [752580/25046 (95%)]\tLoss: 0.426181\n",
            "Train epoch: 185 [794960/25046 (97%)]\tLoss: 0.476598\n",
            "Train epoch: 185 [783900/25046 (100%)]\tLoss: 1.259493\n",
            "Make prediction for 5010 samples...\n",
            "0.8050687 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 186 [0/25046 (0%)]\tLoss: 1.283437\n",
            "Train epoch: 186 [19780/25046 (3%)]\tLoss: 0.979230\n",
            "Train epoch: 186 [42480/25046 (5%)]\tLoss: 1.606628\n",
            "Train epoch: 186 [64140/25046 (8%)]\tLoss: 0.531669\n",
            "Train epoch: 186 [83840/25046 (10%)]\tLoss: 0.440722\n",
            "Train epoch: 186 [101600/25046 (13%)]\tLoss: 0.725273\n",
            "Train epoch: 186 [127200/25046 (15%)]\tLoss: 0.575334\n",
            "Train epoch: 186 [146300/25046 (18%)]\tLoss: 0.978230\n",
            "Train epoch: 186 [171040/25046 (20%)]\tLoss: 0.519553\n",
            "Train epoch: 186 [183780/25046 (23%)]\tLoss: 0.768352\n",
            "Train epoch: 186 [195800/25046 (26%)]\tLoss: 0.642955\n",
            "Train epoch: 186 [223740/25046 (28%)]\tLoss: 1.050159\n",
            "Train epoch: 186 [254880/25046 (31%)]\tLoss: 1.224367\n",
            "Train epoch: 186 [268840/25046 (33%)]\tLoss: 1.021387\n",
            "Train epoch: 186 [278040/25046 (36%)]\tLoss: 0.787076\n",
            "Train epoch: 186 [316800/25046 (38%)]\tLoss: 0.965792\n",
            "Train epoch: 186 [313920/25046 (41%)]\tLoss: 0.377192\n",
            "Train epoch: 186 [357340/25046 (43%)]\tLoss: 1.072500\n",
            "Train epoch: 186 [367200/25046 (46%)]\tLoss: 0.594605\n",
            "Train epoch: 186 [387220/25046 (49%)]\tLoss: 1.830482\n",
            "Train epoch: 186 [424400/25046 (51%)]\tLoss: 0.866347\n",
            "Train epoch: 186 [439320/25046 (54%)]\tLoss: 1.322744\n",
            "Train epoch: 186 [441320/25046 (56%)]\tLoss: 0.319584\n",
            "Train epoch: 186 [476100/25046 (59%)]\tLoss: 0.505689\n",
            "Train epoch: 186 [491520/25046 (61%)]\tLoss: 0.352813\n",
            "Train epoch: 186 [541500/25046 (64%)]\tLoss: 1.191481\n",
            "Train epoch: 186 [536120/25046 (66%)]\tLoss: 1.337040\n",
            "Train epoch: 186 [564840/25046 (69%)]\tLoss: 1.010068\n",
            "Train epoch: 186 [597520/25046 (72%)]\tLoss: 1.277789\n",
            "Train epoch: 186 [582320/25046 (74%)]\tLoss: 0.882129\n",
            "Train epoch: 186 [648000/25046 (77%)]\tLoss: 0.317448\n",
            "Train epoch: 186 [631160/25046 (79%)]\tLoss: 1.051479\n",
            "Train epoch: 186 [656000/25046 (82%)]\tLoss: 1.072678\n",
            "Train epoch: 186 [738540/25046 (84%)]\tLoss: 1.241835\n",
            "Train epoch: 186 [710600/25046 (87%)]\tLoss: 0.283307\n",
            "Train epoch: 186 [691600/25046 (89%)]\tLoss: 0.477040\n",
            "Train epoch: 186 [767520/25046 (92%)]\tLoss: 1.163226\n",
            "Train epoch: 186 [777000/25046 (95%)]\tLoss: 0.691125\n",
            "Train epoch: 186 [761520/25046 (97%)]\tLoss: 0.584044\n",
            "Train epoch: 186 [780000/25046 (100%)]\tLoss: 0.639464\n",
            "Make prediction for 5010 samples...\n",
            "0.8140826 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 187 [0/25046 (0%)]\tLoss: 0.981625\n",
            "Train epoch: 187 [21580/25046 (3%)]\tLoss: 0.785648\n",
            "Train epoch: 187 [40040/25046 (5%)]\tLoss: 0.283822\n",
            "Train epoch: 187 [62100/25046 (8%)]\tLoss: 0.437105\n",
            "Train epoch: 187 [86800/25046 (10%)]\tLoss: 0.983089\n",
            "Train epoch: 187 [96900/25046 (13%)]\tLoss: 0.445834\n",
            "Train epoch: 187 [129720/25046 (15%)]\tLoss: 0.988137\n",
            "Train epoch: 187 [140420/25046 (18%)]\tLoss: 0.857363\n",
            "Train epoch: 187 [171520/25046 (20%)]\tLoss: 1.016783\n",
            "Train epoch: 187 [195840/25046 (23%)]\tLoss: 0.394342\n",
            "Train epoch: 187 [210800/25046 (26%)]\tLoss: 1.035350\n",
            "Train epoch: 187 [221980/25046 (28%)]\tLoss: 0.495446\n",
            "Train epoch: 187 [238080/25046 (31%)]\tLoss: 0.365684\n",
            "Train epoch: 187 [256100/25046 (33%)]\tLoss: 0.761440\n",
            "Train epoch: 187 [290920/25046 (36%)]\tLoss: 1.274600\n",
            "Train epoch: 187 [283200/25046 (38%)]\tLoss: 0.596235\n",
            "Train epoch: 187 [316160/25046 (41%)]\tLoss: 1.184527\n",
            "Train epoch: 187 [343740/25046 (43%)]\tLoss: 0.712323\n",
            "Train epoch: 187 [356760/25046 (46%)]\tLoss: 0.533565\n",
            "Train epoch: 187 [413820/25046 (49%)]\tLoss: 1.314369\n",
            "Train epoch: 187 [431600/25046 (51%)]\tLoss: 0.733352\n",
            "Train epoch: 187 [417480/25046 (54%)]\tLoss: 0.493517\n",
            "Train epoch: 187 [434280/25046 (56%)]\tLoss: 1.009908\n",
            "Train epoch: 187 [471960/25046 (59%)]\tLoss: 0.867026\n",
            "Train epoch: 187 [489120/25046 (61%)]\tLoss: 1.329656\n",
            "Train epoch: 187 [504500/25046 (64%)]\tLoss: 0.483083\n",
            "Train epoch: 187 [573040/25046 (66%)]\tLoss: 0.647384\n",
            "Train epoch: 187 [583740/25046 (69%)]\tLoss: 0.443576\n",
            "Train epoch: 187 [557200/25046 (72%)]\tLoss: 1.049802\n",
            "Train epoch: 187 [571300/25046 (74%)]\tLoss: 1.035112\n",
            "Train epoch: 187 [618000/25046 (77%)]\tLoss: 0.553416\n",
            "Train epoch: 187 [639840/25046 (79%)]\tLoss: 0.330161\n",
            "Train epoch: 187 [682880/25046 (82%)]\tLoss: 2.007099\n",
            "Train epoch: 187 [733920/25046 (84%)]\tLoss: 1.433143\n",
            "Train epoch: 187 [662320/25046 (87%)]\tLoss: 1.497705\n",
            "Train epoch: 187 [717500/25046 (89%)]\tLoss: 0.641566\n",
            "Train epoch: 187 [755280/25046 (92%)]\tLoss: 1.084382\n",
            "Train epoch: 187 [754060/25046 (95%)]\tLoss: 0.637524\n",
            "Train epoch: 187 [775200/25046 (97%)]\tLoss: 0.924130\n",
            "Train epoch: 187 [826020/25046 (100%)]\tLoss: 0.393713\n",
            "Make prediction for 5010 samples...\n",
            "0.80167216 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 188 [0/25046 (0%)]\tLoss: 0.812064\n",
            "Train epoch: 188 [21160/25046 (3%)]\tLoss: 0.375864\n",
            "Train epoch: 188 [42160/25046 (5%)]\tLoss: 1.117225\n",
            "Train epoch: 188 [59880/25046 (8%)]\tLoss: 0.800885\n",
            "Train epoch: 188 [80800/25046 (10%)]\tLoss: 0.502197\n",
            "Train epoch: 188 [102600/25046 (13%)]\tLoss: 1.116174\n",
            "Train epoch: 188 [124680/25046 (15%)]\tLoss: 0.733645\n",
            "Train epoch: 188 [146580/25046 (18%)]\tLoss: 0.594953\n",
            "Train epoch: 188 [169440/25046 (20%)]\tLoss: 1.407402\n",
            "Train epoch: 188 [197460/25046 (23%)]\tLoss: 0.809210\n",
            "Train epoch: 188 [208600/25046 (26%)]\tLoss: 0.457224\n",
            "Train epoch: 188 [226160/25046 (28%)]\tLoss: 2.308310\n",
            "Train epoch: 188 [248640/25046 (31%)]\tLoss: 0.850083\n",
            "Train epoch: 188 [259740/25046 (33%)]\tLoss: 0.759845\n",
            "Train epoch: 188 [311920/25046 (36%)]\tLoss: 0.735207\n",
            "Train epoch: 188 [303300/25046 (38%)]\tLoss: 0.932546\n",
            "Train epoch: 188 [330240/25046 (41%)]\tLoss: 0.397226\n",
            "Train epoch: 188 [348160/25046 (43%)]\tLoss: 0.491456\n",
            "Train epoch: 188 [393840/25046 (46%)]\tLoss: 0.611163\n",
            "Train epoch: 188 [370120/25046 (49%)]\tLoss: 0.859998\n",
            "Train epoch: 188 [393600/25046 (51%)]\tLoss: 0.654380\n",
            "Train epoch: 188 [424620/25046 (54%)]\tLoss: 0.945156\n",
            "Train epoch: 188 [460240/25046 (56%)]\tLoss: 0.890070\n",
            "Train epoch: 188 [459540/25046 (59%)]\tLoss: 0.342935\n",
            "Train epoch: 188 [516960/25046 (61%)]\tLoss: 0.485197\n",
            "Train epoch: 188 [500500/25046 (64%)]\tLoss: 0.610619\n",
            "Train epoch: 188 [530400/25046 (66%)]\tLoss: 2.418643\n",
            "Train epoch: 188 [550260/25046 (69%)]\tLoss: 1.106903\n",
            "Train epoch: 188 [579600/25046 (72%)]\tLoss: 0.952839\n",
            "Train epoch: 188 [588700/25046 (74%)]\tLoss: 0.729652\n",
            "Train epoch: 188 [612000/25046 (77%)]\tLoss: 0.703552\n",
            "Train epoch: 188 [653480/25046 (79%)]\tLoss: 0.856947\n",
            "Train epoch: 188 [716160/25046 (82%)]\tLoss: 0.833322\n",
            "Train epoch: 188 [636900/25046 (84%)]\tLoss: 0.636190\n",
            "Train epoch: 188 [688160/25046 (87%)]\tLoss: 0.653989\n",
            "Train epoch: 188 [744800/25046 (89%)]\tLoss: 1.558416\n",
            "Train epoch: 188 [729360/25046 (92%)]\tLoss: 0.765838\n",
            "Train epoch: 188 [758500/25046 (95%)]\tLoss: 0.689481\n",
            "Train epoch: 188 [762280/25046 (97%)]\tLoss: 1.386927\n",
            "Train epoch: 188 [820560/25046 (100%)]\tLoss: 1.365435\n",
            "Make prediction for 5010 samples...\n",
            "0.803498 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 189 [0/25046 (0%)]\tLoss: 1.073598\n",
            "Train epoch: 189 [21440/25046 (3%)]\tLoss: 0.859693\n",
            "Train epoch: 189 [41040/25046 (5%)]\tLoss: 0.824581\n",
            "Train epoch: 189 [61920/25046 (8%)]\tLoss: 0.602478\n",
            "Train epoch: 189 [81280/25046 (10%)]\tLoss: 1.616539\n",
            "Train epoch: 189 [100200/25046 (13%)]\tLoss: 1.221892\n",
            "Train epoch: 189 [118320/25046 (15%)]\tLoss: 0.875869\n",
            "Train epoch: 189 [143500/25046 (18%)]\tLoss: 0.427455\n",
            "Train epoch: 189 [164320/25046 (20%)]\tLoss: 1.114881\n",
            "Train epoch: 189 [182340/25046 (23%)]\tLoss: 0.328706\n",
            "Train epoch: 189 [209800/25046 (26%)]\tLoss: 0.932599\n",
            "Train epoch: 189 [224620/25046 (28%)]\tLoss: 0.316498\n",
            "Train epoch: 189 [246480/25046 (31%)]\tLoss: 0.308390\n",
            "Train epoch: 189 [271700/25046 (33%)]\tLoss: 0.326283\n",
            "Train epoch: 189 [287000/25046 (36%)]\tLoss: 1.116200\n",
            "Train epoch: 189 [306900/25046 (38%)]\tLoss: 1.126219\n",
            "Train epoch: 189 [314880/25046 (41%)]\tLoss: 0.407008\n",
            "Train epoch: 189 [360740/25046 (43%)]\tLoss: 0.826127\n",
            "Train epoch: 189 [370080/25046 (46%)]\tLoss: 0.510853\n",
            "Train epoch: 189 [411540/25046 (49%)]\tLoss: 0.598413\n",
            "Train epoch: 189 [421200/25046 (51%)]\tLoss: 0.838993\n",
            "Train epoch: 189 [429240/25046 (54%)]\tLoss: 1.055734\n",
            "Train epoch: 189 [434720/25046 (56%)]\tLoss: 0.971477\n",
            "Train epoch: 189 [490360/25046 (59%)]\tLoss: 1.199671\n",
            "Train epoch: 189 [496800/25046 (61%)]\tLoss: 0.362695\n",
            "Train epoch: 189 [540500/25046 (64%)]\tLoss: 0.627683\n",
            "Train epoch: 189 [513240/25046 (66%)]\tLoss: 0.418855\n",
            "Train epoch: 189 [589680/25046 (69%)]\tLoss: 1.074524\n",
            "Train epoch: 189 [570080/25046 (72%)]\tLoss: 1.358413\n",
            "Train epoch: 189 [564920/25046 (74%)]\tLoss: 0.733667\n",
            "Train epoch: 189 [615000/25046 (77%)]\tLoss: 0.740630\n",
            "Train epoch: 189 [669600/25046 (79%)]\tLoss: 0.766840\n",
            "Train epoch: 189 [633600/25046 (82%)]\tLoss: 1.111692\n",
            "Train epoch: 189 [664620/25046 (84%)]\tLoss: 0.450598\n",
            "Train epoch: 189 [717400/25046 (87%)]\tLoss: 0.614912\n",
            "Train epoch: 189 [712600/25046 (89%)]\tLoss: 1.471672\n",
            "Train epoch: 189 [753120/25046 (92%)]\tLoss: 0.564820\n",
            "Train epoch: 189 [735560/25046 (95%)]\tLoss: 1.163914\n",
            "Train epoch: 189 [766840/25046 (97%)]\tLoss: 0.683593\n",
            "Train epoch: 189 [831480/25046 (100%)]\tLoss: 1.045018\n",
            "Make prediction for 5010 samples...\n",
            "0.803847 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 190 [0/25046 (0%)]\tLoss: 1.610648\n",
            "Train epoch: 190 [20420/25046 (3%)]\tLoss: 1.450218\n",
            "Train epoch: 190 [41200/25046 (5%)]\tLoss: 1.485438\n",
            "Train epoch: 190 [65640/25046 (8%)]\tLoss: 1.190720\n",
            "Train epoch: 190 [81120/25046 (10%)]\tLoss: 0.540225\n",
            "Train epoch: 190 [104300/25046 (13%)]\tLoss: 0.848297\n",
            "Train epoch: 190 [121920/25046 (15%)]\tLoss: 0.884425\n",
            "Train epoch: 190 [136500/25046 (18%)]\tLoss: 0.882473\n",
            "Train epoch: 190 [166720/25046 (20%)]\tLoss: 0.491873\n",
            "Train epoch: 190 [183240/25046 (23%)]\tLoss: 0.958567\n",
            "Train epoch: 190 [226000/25046 (26%)]\tLoss: 0.384346\n",
            "Train epoch: 190 [225720/25046 (28%)]\tLoss: 0.710514\n",
            "Train epoch: 190 [253200/25046 (31%)]\tLoss: 1.267662\n",
            "Train epoch: 190 [265720/25046 (33%)]\tLoss: 0.347324\n",
            "Train epoch: 190 [296520/25046 (36%)]\tLoss: 0.645212\n",
            "Train epoch: 190 [308100/25046 (38%)]\tLoss: 1.100119\n",
            "Train epoch: 190 [310400/25046 (41%)]\tLoss: 0.504798\n",
            "Train epoch: 190 [335920/25046 (43%)]\tLoss: 1.038636\n",
            "Train epoch: 190 [381240/25046 (46%)]\tLoss: 1.348494\n",
            "Train epoch: 190 [369360/25046 (49%)]\tLoss: 0.875090\n",
            "Train epoch: 190 [409200/25046 (51%)]\tLoss: 0.420330\n",
            "Train epoch: 190 [430500/25046 (54%)]\tLoss: 0.905661\n",
            "Train epoch: 190 [439560/25046 (56%)]\tLoss: 0.544949\n",
            "Train epoch: 190 [455860/25046 (59%)]\tLoss: 0.702610\n",
            "Train epoch: 190 [484320/25046 (61%)]\tLoss: 1.033152\n",
            "Train epoch: 190 [499500/25046 (64%)]\tLoss: 0.849763\n",
            "Train epoch: 190 [517920/25046 (66%)]\tLoss: 0.773081\n",
            "Train epoch: 190 [568080/25046 (69%)]\tLoss: 0.610788\n",
            "Train epoch: 190 [547680/25046 (72%)]\tLoss: 0.357705\n",
            "Train epoch: 190 [613060/25046 (74%)]\tLoss: 1.041107\n",
            "Train epoch: 190 [641400/25046 (77%)]\tLoss: 1.981154\n",
            "Train epoch: 190 [626200/25046 (79%)]\tLoss: 1.210204\n",
            "Train epoch: 190 [654080/25046 (82%)]\tLoss: 0.856901\n",
            "Train epoch: 190 [653400/25046 (84%)]\tLoss: 1.133182\n",
            "Train epoch: 190 [698360/25046 (87%)]\tLoss: 0.732380\n",
            "Train epoch: 190 [715400/25046 (89%)]\tLoss: 1.002076\n",
            "Train epoch: 190 [774720/25046 (92%)]\tLoss: 1.013088\n",
            "Train epoch: 190 [776260/25046 (95%)]\tLoss: 0.516820\n",
            "Train epoch: 190 [757720/25046 (97%)]\tLoss: 0.292735\n",
            "Train epoch: 190 [774540/25046 (100%)]\tLoss: 0.500736\n",
            "Make prediction for 5010 samples...\n",
            "0.80151445 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 191 [0/25046 (0%)]\tLoss: 0.881418\n",
            "Train epoch: 191 [20700/25046 (3%)]\tLoss: 1.243991\n",
            "Train epoch: 191 [39240/25046 (5%)]\tLoss: 0.421522\n",
            "Train epoch: 191 [63720/25046 (8%)]\tLoss: 0.484692\n",
            "Train epoch: 191 [81120/25046 (10%)]\tLoss: 0.750919\n",
            "Train epoch: 191 [99200/25046 (13%)]\tLoss: 1.461165\n",
            "Train epoch: 191 [131760/25046 (15%)]\tLoss: 0.547023\n",
            "Train epoch: 191 [132580/25046 (18%)]\tLoss: 0.803223\n",
            "Train epoch: 191 [170880/25046 (20%)]\tLoss: 0.898590\n",
            "Train epoch: 191 [188820/25046 (23%)]\tLoss: 0.849139\n",
            "Train epoch: 191 [217200/25046 (26%)]\tLoss: 0.896952\n",
            "Train epoch: 191 [220440/25046 (28%)]\tLoss: 1.066821\n",
            "Train epoch: 191 [241440/25046 (31%)]\tLoss: 0.421431\n",
            "Train epoch: 191 [256100/25046 (33%)]\tLoss: 1.117240\n",
            "Train epoch: 191 [295960/25046 (36%)]\tLoss: 0.446607\n",
            "Train epoch: 191 [306600/25046 (38%)]\tLoss: 0.488597\n",
            "Train epoch: 191 [328960/25046 (41%)]\tLoss: 0.519987\n",
            "Train epoch: 191 [347140/25046 (43%)]\tLoss: 1.167631\n",
            "Train epoch: 191 [397800/25046 (46%)]\tLoss: 1.103277\n",
            "Train epoch: 191 [384940/25046 (49%)]\tLoss: 0.682695\n",
            "Train epoch: 191 [438800/25046 (51%)]\tLoss: 0.841736\n",
            "Train epoch: 191 [438480/25046 (54%)]\tLoss: 1.290739\n",
            "Train epoch: 191 [465520/25046 (56%)]\tLoss: 0.508252\n",
            "Train epoch: 191 [485760/25046 (59%)]\tLoss: 0.785761\n",
            "Train epoch: 191 [490560/25046 (61%)]\tLoss: 0.445193\n",
            "Train epoch: 191 [479000/25046 (64%)]\tLoss: 1.503875\n",
            "Train epoch: 191 [494000/25046 (66%)]\tLoss: 0.273300\n",
            "Train epoch: 191 [574560/25046 (69%)]\tLoss: 0.467771\n",
            "Train epoch: 191 [560560/25046 (72%)]\tLoss: 1.031097\n",
            "Train epoch: 191 [567240/25046 (74%)]\tLoss: 0.316101\n",
            "Train epoch: 191 [630000/25046 (77%)]\tLoss: 0.553533\n",
            "Train epoch: 191 [648520/25046 (79%)]\tLoss: 1.044893\n",
            "Train epoch: 191 [659200/25046 (82%)]\tLoss: 1.077235\n",
            "Train epoch: 191 [660000/25046 (84%)]\tLoss: 0.957459\n",
            "Train epoch: 191 [673200/25046 (87%)]\tLoss: 0.971480\n",
            "Train epoch: 191 [700700/25046 (89%)]\tLoss: 0.899552\n",
            "Train epoch: 191 [817920/25046 (92%)]\tLoss: 0.784455\n",
            "Train epoch: 191 [785140/25046 (95%)]\tLoss: 1.741414\n",
            "Train epoch: 191 [769880/25046 (97%)]\tLoss: 1.009671\n",
            "Train epoch: 191 [841620/25046 (100%)]\tLoss: 0.612744\n",
            "Make prediction for 5010 samples...\n",
            "0.8024098 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 192 [0/25046 (0%)]\tLoss: 0.336952\n",
            "Train epoch: 192 [20600/25046 (3%)]\tLoss: 0.684921\n",
            "Train epoch: 192 [40560/25046 (5%)]\tLoss: 0.550038\n",
            "Train epoch: 192 [63360/25046 (8%)]\tLoss: 0.638852\n",
            "Train epoch: 192 [82160/25046 (10%)]\tLoss: 0.434948\n",
            "Train epoch: 192 [95100/25046 (13%)]\tLoss: 0.276980\n",
            "Train epoch: 192 [113280/25046 (15%)]\tLoss: 0.803920\n",
            "Train epoch: 192 [143780/25046 (18%)]\tLoss: 1.237706\n",
            "Train epoch: 192 [164480/25046 (20%)]\tLoss: 0.716171\n",
            "Train epoch: 192 [182160/25046 (23%)]\tLoss: 0.762890\n",
            "Train epoch: 192 [199800/25046 (26%)]\tLoss: 0.514075\n",
            "Train epoch: 192 [233200/25046 (28%)]\tLoss: 0.953181\n",
            "Train epoch: 192 [234240/25046 (31%)]\tLoss: 1.306285\n",
            "Train epoch: 192 [286260/25046 (33%)]\tLoss: 0.457839\n",
            "Train epoch: 192 [295120/25046 (36%)]\tLoss: 0.682363\n",
            "Train epoch: 192 [325500/25046 (38%)]\tLoss: 0.369545\n",
            "Train epoch: 192 [339840/25046 (41%)]\tLoss: 1.269458\n",
            "Train epoch: 192 [354280/25046 (43%)]\tLoss: 1.014460\n",
            "Train epoch: 192 [372240/25046 (46%)]\tLoss: 1.382962\n",
            "Train epoch: 192 [390260/25046 (49%)]\tLoss: 1.413777\n",
            "Train epoch: 192 [401200/25046 (51%)]\tLoss: 0.636825\n",
            "Train epoch: 192 [433860/25046 (54%)]\tLoss: 0.446801\n",
            "Train epoch: 192 [434720/25046 (56%)]\tLoss: 0.935074\n",
            "Train epoch: 192 [479320/25046 (59%)]\tLoss: 0.649466\n",
            "Train epoch: 192 [501120/25046 (61%)]\tLoss: 0.892898\n",
            "Train epoch: 192 [512500/25046 (64%)]\tLoss: 1.123222\n",
            "Train epoch: 192 [522600/25046 (66%)]\tLoss: 1.177826\n",
            "Train epoch: 192 [547560/25046 (69%)]\tLoss: 0.372950\n",
            "Train epoch: 192 [577920/25046 (72%)]\tLoss: 0.777998\n",
            "Train epoch: 192 [606100/25046 (74%)]\tLoss: 0.217989\n",
            "Train epoch: 192 [595800/25046 (77%)]\tLoss: 1.896022\n",
            "Train epoch: 192 [641700/25046 (79%)]\tLoss: 0.392129\n",
            "Train epoch: 192 [673280/25046 (82%)]\tLoss: 1.473970\n",
            "Train epoch: 192 [694980/25046 (84%)]\tLoss: 1.050570\n",
            "Train epoch: 192 [699040/25046 (87%)]\tLoss: 1.204957\n",
            "Train epoch: 192 [728700/25046 (89%)]\tLoss: 0.716404\n",
            "Train epoch: 192 [721440/25046 (92%)]\tLoss: 0.984950\n",
            "Train epoch: 192 [754060/25046 (95%)]\tLoss: 0.368630\n",
            "Train epoch: 192 [815480/25046 (97%)]\tLoss: 0.464275\n",
            "Train epoch: 192 [805740/25046 (100%)]\tLoss: 0.327245\n",
            "Make prediction for 5010 samples...\n",
            "0.8019554 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 193 [0/25046 (0%)]\tLoss: 0.414023\n",
            "Train epoch: 193 [20740/25046 (3%)]\tLoss: 0.501327\n",
            "Train epoch: 193 [40640/25046 (5%)]\tLoss: 0.674823\n",
            "Train epoch: 193 [63660/25046 (8%)]\tLoss: 0.705736\n",
            "Train epoch: 193 [82720/25046 (10%)]\tLoss: 0.902107\n",
            "Train epoch: 193 [100800/25046 (13%)]\tLoss: 0.385840\n",
            "Train epoch: 193 [124560/25046 (15%)]\tLoss: 1.941527\n",
            "Train epoch: 193 [143500/25046 (18%)]\tLoss: 0.690364\n",
            "Train epoch: 193 [162880/25046 (20%)]\tLoss: 1.249663\n",
            "Train epoch: 193 [188640/25046 (23%)]\tLoss: 1.055942\n",
            "Train epoch: 193 [211400/25046 (26%)]\tLoss: 0.779239\n",
            "Train epoch: 193 [227040/25046 (28%)]\tLoss: 0.840810\n",
            "Train epoch: 193 [266160/25046 (31%)]\tLoss: 0.855151\n",
            "Train epoch: 193 [273520/25046 (33%)]\tLoss: 0.765397\n",
            "Train epoch: 193 [269920/25046 (36%)]\tLoss: 1.203160\n",
            "Train epoch: 193 [300600/25046 (38%)]\tLoss: 0.696457\n",
            "Train epoch: 193 [360320/25046 (41%)]\tLoss: 0.599187\n",
            "Train epoch: 193 [346800/25046 (43%)]\tLoss: 1.135688\n",
            "Train epoch: 193 [362880/25046 (46%)]\tLoss: 0.841764\n",
            "Train epoch: 193 [372400/25046 (49%)]\tLoss: 0.554909\n",
            "Train epoch: 193 [405600/25046 (51%)]\tLoss: 1.579930\n",
            "Train epoch: 193 [445620/25046 (54%)]\tLoss: 0.470894\n",
            "Train epoch: 193 [451440/25046 (56%)]\tLoss: 0.315124\n",
            "Train epoch: 193 [470580/25046 (59%)]\tLoss: 0.383698\n",
            "Train epoch: 193 [496320/25046 (61%)]\tLoss: 1.316345\n",
            "Train epoch: 193 [518500/25046 (64%)]\tLoss: 1.102963\n",
            "Train epoch: 193 [512200/25046 (66%)]\tLoss: 0.563343\n",
            "Train epoch: 193 [526500/25046 (69%)]\tLoss: 0.978973\n",
            "Train epoch: 193 [590240/25046 (72%)]\tLoss: 1.375280\n",
            "Train epoch: 193 [596240/25046 (74%)]\tLoss: 0.372076\n",
            "Train epoch: 193 [610200/25046 (77%)]\tLoss: 0.947356\n",
            "Train epoch: 193 [667120/25046 (79%)]\tLoss: 0.240316\n",
            "Train epoch: 193 [634240/25046 (82%)]\tLoss: 0.451479\n",
            "Train epoch: 193 [685080/25046 (84%)]\tLoss: 0.497952\n",
            "Train epoch: 193 [694280/25046 (87%)]\tLoss: 0.610454\n",
            "Train epoch: 193 [704200/25046 (89%)]\tLoss: 1.270675\n",
            "Train epoch: 193 [720720/25046 (92%)]\tLoss: 0.659549\n",
            "Train epoch: 193 [761460/25046 (95%)]\tLoss: 0.884716\n",
            "Train epoch: 193 [751640/25046 (97%)]\tLoss: 0.241739\n",
            "Train epoch: 193 [822900/25046 (100%)]\tLoss: 1.414039\n",
            "Make prediction for 5010 samples...\n",
            "0.8049293 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 194 [0/25046 (0%)]\tLoss: 0.739703\n",
            "Train epoch: 194 [19920/25046 (3%)]\tLoss: 0.942917\n",
            "Train epoch: 194 [40680/25046 (5%)]\tLoss: 0.955640\n",
            "Train epoch: 194 [65280/25046 (8%)]\tLoss: 0.350815\n",
            "Train epoch: 194 [83760/25046 (10%)]\tLoss: 0.573560\n",
            "Train epoch: 194 [107500/25046 (13%)]\tLoss: 1.865741\n",
            "Train epoch: 194 [127200/25046 (15%)]\tLoss: 0.381990\n",
            "Train epoch: 194 [139720/25046 (18%)]\tLoss: 0.415858\n",
            "Train epoch: 194 [163520/25046 (20%)]\tLoss: 0.734712\n",
            "Train epoch: 194 [183420/25046 (23%)]\tLoss: 0.379576\n",
            "Train epoch: 194 [214400/25046 (26%)]\tLoss: 1.157280\n",
            "Train epoch: 194 [215820/25046 (28%)]\tLoss: 0.223256\n",
            "Train epoch: 194 [246480/25046 (31%)]\tLoss: 1.031252\n",
            "Train epoch: 194 [260780/25046 (33%)]\tLoss: 0.775362\n",
            "Train epoch: 194 [285600/25046 (36%)]\tLoss: 1.011022\n",
            "Train epoch: 194 [291300/25046 (38%)]\tLoss: 0.826958\n",
            "Train epoch: 194 [336000/25046 (41%)]\tLoss: 0.509196\n",
            "Train epoch: 194 [336260/25046 (43%)]\tLoss: 0.305604\n",
            "Train epoch: 194 [379080/25046 (46%)]\tLoss: 1.510719\n",
            "Train epoch: 194 [381900/25046 (49%)]\tLoss: 0.767392\n",
            "Train epoch: 194 [399600/25046 (51%)]\tLoss: 0.402426\n",
            "Train epoch: 194 [410760/25046 (54%)]\tLoss: 0.504364\n",
            "Train epoch: 194 [436480/25046 (56%)]\tLoss: 0.775326\n",
            "Train epoch: 194 [500940/25046 (59%)]\tLoss: 0.799858\n",
            "Train epoch: 194 [529440/25046 (61%)]\tLoss: 0.839605\n",
            "Train epoch: 194 [538000/25046 (64%)]\tLoss: 0.620364\n",
            "Train epoch: 194 [553280/25046 (66%)]\tLoss: 0.494237\n",
            "Train epoch: 194 [544860/25046 (69%)]\tLoss: 0.803510\n",
            "Train epoch: 194 [558320/25046 (72%)]\tLoss: 0.739810\n",
            "Train epoch: 194 [594500/25046 (74%)]\tLoss: 0.384493\n",
            "Train epoch: 194 [608400/25046 (77%)]\tLoss: 0.677932\n",
            "Train epoch: 194 [636120/25046 (79%)]\tLoss: 1.379537\n",
            "Train epoch: 194 [645120/25046 (82%)]\tLoss: 0.516640\n",
            "Train epoch: 194 [721380/25046 (84%)]\tLoss: 0.631677\n",
            "Train epoch: 194 [688840/25046 (87%)]\tLoss: 0.529885\n",
            "Train epoch: 194 [718900/25046 (89%)]\tLoss: 0.946031\n",
            "Train epoch: 194 [786240/25046 (92%)]\tLoss: 0.683474\n",
            "Train epoch: 194 [785140/25046 (95%)]\tLoss: 1.015309\n",
            "Train epoch: 194 [785840/25046 (97%)]\tLoss: 1.162650\n",
            "Train epoch: 194 [779220/25046 (100%)]\tLoss: 0.657143\n",
            "Make prediction for 5010 samples...\n",
            "0.8015169 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 195 [0/25046 (0%)]\tLoss: 0.518227\n",
            "Train epoch: 195 [20880/25046 (3%)]\tLoss: 1.253666\n",
            "Train epoch: 195 [41960/25046 (5%)]\tLoss: 0.674719\n",
            "Train epoch: 195 [63660/25046 (8%)]\tLoss: 0.530943\n",
            "Train epoch: 195 [82400/25046 (10%)]\tLoss: 0.999564\n",
            "Train epoch: 195 [105600/25046 (13%)]\tLoss: 0.978707\n",
            "Train epoch: 195 [123360/25046 (15%)]\tLoss: 0.553254\n",
            "Train epoch: 195 [151620/25046 (18%)]\tLoss: 1.634322\n",
            "Train epoch: 195 [157920/25046 (20%)]\tLoss: 0.645369\n",
            "Train epoch: 195 [175320/25046 (23%)]\tLoss: 0.472891\n",
            "Train epoch: 195 [207000/25046 (26%)]\tLoss: 0.382848\n",
            "Train epoch: 195 [223960/25046 (28%)]\tLoss: 0.508755\n",
            "Train epoch: 195 [257040/25046 (31%)]\tLoss: 1.233891\n",
            "Train epoch: 195 [274820/25046 (33%)]\tLoss: 0.532625\n",
            "Train epoch: 195 [293160/25046 (36%)]\tLoss: 1.442154\n",
            "Train epoch: 195 [298800/25046 (38%)]\tLoss: 0.310414\n",
            "Train epoch: 195 [322240/25046 (41%)]\tLoss: 1.108215\n",
            "Train epoch: 195 [349520/25046 (43%)]\tLoss: 0.993093\n",
            "Train epoch: 195 [372240/25046 (46%)]\tLoss: 0.648539\n",
            "Train epoch: 195 [380000/25046 (49%)]\tLoss: 0.422136\n",
            "Train epoch: 195 [407200/25046 (51%)]\tLoss: 0.957742\n",
            "Train epoch: 195 [409920/25046 (54%)]\tLoss: 0.466212\n",
            "Train epoch: 195 [468160/25046 (56%)]\tLoss: 0.770620\n",
            "Train epoch: 195 [483920/25046 (59%)]\tLoss: 0.243073\n",
            "Train epoch: 195 [491040/25046 (61%)]\tLoss: 0.622442\n",
            "Train epoch: 195 [541500/25046 (64%)]\tLoss: 0.872727\n",
            "Train epoch: 195 [537680/25046 (66%)]\tLoss: 1.125921\n",
            "Train epoch: 195 [550260/25046 (69%)]\tLoss: 1.834352\n",
            "Train epoch: 195 [565040/25046 (72%)]\tLoss: 1.071126\n",
            "Train epoch: 195 [573040/25046 (74%)]\tLoss: 0.819245\n",
            "Train epoch: 195 [634800/25046 (77%)]\tLoss: 0.913346\n",
            "Train epoch: 195 [633020/25046 (79%)]\tLoss: 0.569060\n",
            "Train epoch: 195 [652160/25046 (82%)]\tLoss: 1.152840\n",
            "Train epoch: 195 [673860/25046 (84%)]\tLoss: 0.419089\n",
            "Train epoch: 195 [739160/25046 (87%)]\tLoss: 1.068016\n",
            "Train epoch: 195 [690200/25046 (89%)]\tLoss: 1.158092\n",
            "Train epoch: 195 [701280/25046 (92%)]\tLoss: 0.858423\n",
            "Train epoch: 195 [782920/25046 (95%)]\tLoss: 0.434798\n",
            "Train epoch: 195 [812440/25046 (97%)]\tLoss: 2.287976\n",
            "Train epoch: 195 [794820/25046 (100%)]\tLoss: 0.650353\n",
            "Make prediction for 5010 samples...\n",
            "0.80239654 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 196 [0/25046 (0%)]\tLoss: 0.599333\n",
            "Train epoch: 196 [21900/25046 (3%)]\tLoss: 1.628479\n",
            "Train epoch: 196 [42440/25046 (5%)]\tLoss: 0.173833\n",
            "Train epoch: 196 [58440/25046 (8%)]\tLoss: 2.285033\n",
            "Train epoch: 196 [86880/25046 (10%)]\tLoss: 1.345328\n",
            "Train epoch: 196 [100300/25046 (13%)]\tLoss: 0.672264\n",
            "Train epoch: 196 [117480/25046 (15%)]\tLoss: 0.406500\n",
            "Train epoch: 196 [149380/25046 (18%)]\tLoss: 1.305882\n",
            "Train epoch: 196 [159840/25046 (20%)]\tLoss: 0.878710\n",
            "Train epoch: 196 [185040/25046 (23%)]\tLoss: 0.963067\n",
            "Train epoch: 196 [198400/25046 (26%)]\tLoss: 0.520843\n",
            "Train epoch: 196 [235180/25046 (28%)]\tLoss: 0.626541\n",
            "Train epoch: 196 [250080/25046 (31%)]\tLoss: 0.454118\n",
            "Train epoch: 196 [263120/25046 (33%)]\tLoss: 0.447940\n",
            "Train epoch: 196 [268520/25046 (36%)]\tLoss: 0.500365\n",
            "Train epoch: 196 [309900/25046 (38%)]\tLoss: 1.644403\n",
            "Train epoch: 196 [326720/25046 (41%)]\tLoss: 0.786786\n",
            "Train epoch: 196 [330480/25046 (43%)]\tLoss: 0.222181\n",
            "Train epoch: 196 [383040/25046 (46%)]\tLoss: 0.792569\n",
            "Train epoch: 196 [384560/25046 (49%)]\tLoss: 1.528536\n",
            "Train epoch: 196 [418000/25046 (51%)]\tLoss: 0.879914\n",
            "Train epoch: 196 [428400/25046 (54%)]\tLoss: 0.554513\n",
            "Train epoch: 196 [482240/25046 (56%)]\tLoss: 1.214024\n",
            "Train epoch: 196 [477480/25046 (59%)]\tLoss: 0.426604\n",
            "Train epoch: 196 [502080/25046 (61%)]\tLoss: 0.611289\n",
            "Train epoch: 196 [519000/25046 (64%)]\tLoss: 0.921201\n",
            "Train epoch: 196 [509080/25046 (66%)]\tLoss: 1.133345\n",
            "Train epoch: 196 [542700/25046 (69%)]\tLoss: 1.729113\n",
            "Train epoch: 196 [572320/25046 (72%)]\tLoss: 1.713943\n",
            "Train epoch: 196 [571880/25046 (74%)]\tLoss: 0.396350\n",
            "Train epoch: 196 [640800/25046 (77%)]\tLoss: 0.280855\n",
            "Train epoch: 196 [664640/25046 (79%)]\tLoss: 2.339232\n",
            "Train epoch: 196 [664960/25046 (82%)]\tLoss: 0.393231\n",
            "Train epoch: 196 [639540/25046 (84%)]\tLoss: 0.727001\n",
            "Train epoch: 196 [711280/25046 (87%)]\tLoss: 0.261891\n",
            "Train epoch: 196 [751800/25046 (89%)]\tLoss: 0.335700\n",
            "Train epoch: 196 [752400/25046 (92%)]\tLoss: 0.969417\n",
            "Train epoch: 196 [782180/25046 (95%)]\tLoss: 1.007176\n",
            "Train epoch: 196 [763040/25046 (97%)]\tLoss: 0.700748\n",
            "Train epoch: 196 [756600/25046 (100%)]\tLoss: 0.653724\n",
            "Make prediction for 5010 samples...\n",
            "0.8019068 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 197 [0/25046 (0%)]\tLoss: 0.446307\n",
            "Train epoch: 197 [21020/25046 (3%)]\tLoss: 0.366075\n",
            "Train epoch: 197 [44440/25046 (5%)]\tLoss: 0.848104\n",
            "Train epoch: 197 [63780/25046 (8%)]\tLoss: 1.003666\n",
            "Train epoch: 197 [81200/25046 (10%)]\tLoss: 0.305837\n",
            "Train epoch: 197 [107000/25046 (13%)]\tLoss: 0.461167\n",
            "Train epoch: 197 [127200/25046 (15%)]\tLoss: 0.810989\n",
            "Train epoch: 197 [141540/25046 (18%)]\tLoss: 0.533912\n",
            "Train epoch: 197 [169120/25046 (20%)]\tLoss: 0.419187\n",
            "Train epoch: 197 [197280/25046 (23%)]\tLoss: 0.675620\n",
            "Train epoch: 197 [205000/25046 (26%)]\tLoss: 0.587711\n",
            "Train epoch: 197 [210980/25046 (28%)]\tLoss: 0.435021\n",
            "Train epoch: 197 [255600/25046 (31%)]\tLoss: 1.227173\n",
            "Train epoch: 197 [252980/25046 (33%)]\tLoss: 0.379009\n",
            "Train epoch: 197 [293440/25046 (36%)]\tLoss: 1.278260\n",
            "Train epoch: 197 [284400/25046 (38%)]\tLoss: 0.625672\n",
            "Train epoch: 197 [333440/25046 (41%)]\tLoss: 0.366111\n",
            "Train epoch: 197 [342040/25046 (43%)]\tLoss: 1.148379\n",
            "Train epoch: 197 [376920/25046 (46%)]\tLoss: 0.755665\n",
            "Train epoch: 197 [413440/25046 (49%)]\tLoss: 0.827666\n",
            "Train epoch: 197 [422400/25046 (51%)]\tLoss: 0.928487\n",
            "Train epoch: 197 [418740/25046 (54%)]\tLoss: 0.271036\n",
            "Train epoch: 197 [455840/25046 (56%)]\tLoss: 0.683952\n",
            "Train epoch: 197 [480700/25046 (59%)]\tLoss: 1.157784\n",
            "Train epoch: 197 [483360/25046 (61%)]\tLoss: 0.926521\n",
            "Train epoch: 197 [488500/25046 (64%)]\tLoss: 0.557510\n",
            "Train epoch: 197 [511160/25046 (66%)]\tLoss: 0.653096\n",
            "Train epoch: 197 [524880/25046 (69%)]\tLoss: 0.819411\n",
            "Train epoch: 197 [571200/25046 (72%)]\tLoss: 0.578343\n",
            "Train epoch: 197 [606100/25046 (74%)]\tLoss: 0.705333\n",
            "Train epoch: 197 [657000/25046 (77%)]\tLoss: 0.603555\n",
            "Train epoch: 197 [649760/25046 (79%)]\tLoss: 0.429132\n",
            "Train epoch: 197 [681600/25046 (82%)]\tLoss: 0.519065\n",
            "Train epoch: 197 [664620/25046 (84%)]\tLoss: 0.673035\n",
            "Train epoch: 197 [687480/25046 (87%)]\tLoss: 1.365475\n",
            "Train epoch: 197 [728000/25046 (89%)]\tLoss: 1.130225\n",
            "Train epoch: 197 [732240/25046 (92%)]\tLoss: 0.700799\n",
            "Train epoch: 197 [745180/25046 (95%)]\tLoss: 0.432058\n",
            "Train epoch: 197 [797240/25046 (97%)]\tLoss: 0.934851\n",
            "Train epoch: 197 [782340/25046 (100%)]\tLoss: 1.163338\n",
            "Make prediction for 5010 samples...\n",
            "0.8029897 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 198 [0/25046 (0%)]\tLoss: 0.900157\n",
            "Train epoch: 198 [19080/25046 (3%)]\tLoss: 0.484727\n",
            "Train epoch: 198 [41400/25046 (5%)]\tLoss: 0.690756\n",
            "Train epoch: 198 [59160/25046 (8%)]\tLoss: 0.611050\n",
            "Train epoch: 198 [82880/25046 (10%)]\tLoss: 0.380963\n",
            "Train epoch: 198 [104100/25046 (13%)]\tLoss: 0.687788\n",
            "Train epoch: 198 [119880/25046 (15%)]\tLoss: 0.238445\n",
            "Train epoch: 198 [144340/25046 (18%)]\tLoss: 1.219784\n",
            "Train epoch: 198 [168160/25046 (20%)]\tLoss: 0.890367\n",
            "Train epoch: 198 [180900/25046 (23%)]\tLoss: 0.757011\n",
            "Train epoch: 198 [203400/25046 (26%)]\tLoss: 0.312606\n",
            "Train epoch: 198 [225940/25046 (28%)]\tLoss: 0.246837\n",
            "Train epoch: 198 [247920/25046 (31%)]\tLoss: 1.046163\n",
            "Train epoch: 198 [268580/25046 (33%)]\tLoss: 0.780774\n",
            "Train epoch: 198 [278040/25046 (36%)]\tLoss: 0.533391\n",
            "Train epoch: 198 [307800/25046 (38%)]\tLoss: 0.528654\n",
            "Train epoch: 198 [319680/25046 (41%)]\tLoss: 1.240764\n",
            "Train epoch: 198 [354280/25046 (43%)]\tLoss: 0.517617\n",
            "Train epoch: 198 [392400/25046 (46%)]\tLoss: 1.241342\n",
            "Train epoch: 198 [411160/25046 (49%)]\tLoss: 0.798630\n",
            "Train epoch: 198 [423600/25046 (51%)]\tLoss: 1.121101\n",
            "Train epoch: 198 [449400/25046 (54%)]\tLoss: 1.128281\n",
            "Train epoch: 198 [432520/25046 (56%)]\tLoss: 0.813919\n",
            "Train epoch: 198 [461380/25046 (59%)]\tLoss: 0.701058\n",
            "Train epoch: 198 [523200/25046 (61%)]\tLoss: 0.469997\n",
            "Train epoch: 198 [525500/25046 (64%)]\tLoss: 0.545298\n",
            "Train epoch: 198 [544440/25046 (66%)]\tLoss: 0.464302\n",
            "Train epoch: 198 [559980/25046 (69%)]\tLoss: 1.759286\n",
            "Train epoch: 198 [614880/25046 (72%)]\tLoss: 1.289950\n",
            "Train epoch: 198 [590440/25046 (74%)]\tLoss: 1.113051\n",
            "Train epoch: 198 [624000/25046 (77%)]\tLoss: 0.916828\n",
            "Train epoch: 198 [673320/25046 (79%)]\tLoss: 1.108853\n",
            "Train epoch: 198 [680960/25046 (82%)]\tLoss: 1.741372\n",
            "Train epoch: 198 [659340/25046 (84%)]\tLoss: 0.404300\n",
            "Train epoch: 198 [710600/25046 (87%)]\tLoss: 0.543622\n",
            "Train epoch: 198 [705600/25046 (89%)]\tLoss: 1.496975\n",
            "Train epoch: 198 [735840/25046 (92%)]\tLoss: 0.492318\n",
            "Train epoch: 198 [764420/25046 (95%)]\tLoss: 0.715548\n",
            "Train epoch: 198 [769120/25046 (97%)]\tLoss: 0.474391\n",
            "Train epoch: 198 [843180/25046 (100%)]\tLoss: 0.344242\n",
            "Make prediction for 5010 samples...\n",
            "0.80161345 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 199 [0/25046 (0%)]\tLoss: 1.317300\n",
            "Train epoch: 199 [21220/25046 (3%)]\tLoss: 0.404394\n",
            "Train epoch: 199 [38360/25046 (5%)]\tLoss: 0.715260\n",
            "Train epoch: 199 [58440/25046 (8%)]\tLoss: 1.645404\n",
            "Train epoch: 199 [81520/25046 (10%)]\tLoss: 0.386212\n",
            "Train epoch: 199 [100900/25046 (13%)]\tLoss: 0.785291\n",
            "Train epoch: 199 [127920/25046 (15%)]\tLoss: 0.861172\n",
            "Train epoch: 199 [142380/25046 (18%)]\tLoss: 1.226245\n",
            "Train epoch: 199 [162240/25046 (20%)]\tLoss: 0.423315\n",
            "Train epoch: 199 [182520/25046 (23%)]\tLoss: 0.352247\n",
            "Train epoch: 199 [204200/25046 (26%)]\tLoss: 1.175050\n",
            "Train epoch: 199 [234080/25046 (28%)]\tLoss: 0.638482\n",
            "Train epoch: 199 [246240/25046 (31%)]\tLoss: 1.574085\n",
            "Train epoch: 199 [261040/25046 (33%)]\tLoss: 0.655688\n",
            "Train epoch: 199 [280000/25046 (36%)]\tLoss: 0.551484\n",
            "Train epoch: 199 [313500/25046 (38%)]\tLoss: 0.896867\n",
            "Train epoch: 199 [327680/25046 (41%)]\tLoss: 0.929043\n",
            "Train epoch: 199 [347480/25046 (43%)]\tLoss: 0.918590\n",
            "Train epoch: 199 [381960/25046 (46%)]\tLoss: 0.977973\n",
            "Train epoch: 199 [391400/25046 (49%)]\tLoss: 0.507560\n",
            "Train epoch: 199 [386400/25046 (51%)]\tLoss: 1.141527\n",
            "Train epoch: 199 [409920/25046 (54%)]\tLoss: 1.550412\n",
            "Train epoch: 199 [443080/25046 (56%)]\tLoss: 0.784694\n",
            "Train epoch: 199 [476100/25046 (59%)]\tLoss: 0.801289\n",
            "Train epoch: 199 [522240/25046 (61%)]\tLoss: 0.894523\n",
            "Train epoch: 199 [528500/25046 (64%)]\tLoss: 0.318466\n",
            "Train epoch: 199 [547560/25046 (66%)]\tLoss: 0.280998\n",
            "Train epoch: 199 [532440/25046 (69%)]\tLoss: 0.322979\n",
            "Train epoch: 199 [560560/25046 (72%)]\tLoss: 0.728563\n",
            "Train epoch: 199 [573620/25046 (74%)]\tLoss: 0.833037\n",
            "Train epoch: 199 [608400/25046 (77%)]\tLoss: 0.919601\n",
            "Train epoch: 199 [611320/25046 (79%)]\tLoss: 0.307636\n",
            "Train epoch: 199 [627200/25046 (82%)]\tLoss: 0.276742\n",
            "Train epoch: 199 [656700/25046 (84%)]\tLoss: 0.876619\n",
            "Train epoch: 199 [735080/25046 (87%)]\tLoss: 0.623890\n",
            "Train epoch: 199 [718900/25046 (89%)]\tLoss: 0.563868\n",
            "Train epoch: 199 [758160/25046 (92%)]\tLoss: 0.283451\n",
            "Train epoch: 199 [737040/25046 (95%)]\tLoss: 0.646860\n",
            "Train epoch: 199 [788120/25046 (97%)]\tLoss: 0.307694\n",
            "Train epoch: 199 [833820/25046 (100%)]\tLoss: 0.976567\n",
            "Make prediction for 5010 samples...\n",
            "0.8015921 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 200 [0/25046 (0%)]\tLoss: 0.232845\n",
            "Train epoch: 200 [19840/25046 (3%)]\tLoss: 0.632517\n",
            "Train epoch: 200 [40960/25046 (5%)]\tLoss: 1.487317\n",
            "Train epoch: 200 [61200/25046 (8%)]\tLoss: 0.865032\n",
            "Train epoch: 200 [80240/25046 (10%)]\tLoss: 0.900817\n",
            "Train epoch: 200 [99300/25046 (13%)]\tLoss: 1.587063\n",
            "Train epoch: 200 [123240/25046 (15%)]\tLoss: 0.769187\n",
            "Train epoch: 200 [143920/25046 (18%)]\tLoss: 0.156953\n",
            "Train epoch: 200 [172640/25046 (20%)]\tLoss: 1.224718\n",
            "Train epoch: 200 [201240/25046 (23%)]\tLoss: 0.480678\n",
            "Train epoch: 200 [212800/25046 (26%)]\tLoss: 0.322281\n",
            "Train epoch: 200 [224840/25046 (28%)]\tLoss: 0.960067\n",
            "Train epoch: 200 [250800/25046 (31%)]\tLoss: 0.723303\n",
            "Train epoch: 200 [265720/25046 (33%)]\tLoss: 0.455730\n",
            "Train epoch: 200 [295400/25046 (36%)]\tLoss: 0.709653\n",
            "Train epoch: 200 [322200/25046 (38%)]\tLoss: 1.145547\n",
            "Train epoch: 200 [340160/25046 (41%)]\tLoss: 0.577634\n",
            "Train epoch: 200 [358360/25046 (43%)]\tLoss: 1.431569\n",
            "Train epoch: 200 [374760/25046 (46%)]\tLoss: 0.724548\n",
            "Train epoch: 200 [384560/25046 (49%)]\tLoss: 0.925404\n",
            "Train epoch: 200 [387200/25046 (51%)]\tLoss: 1.754194\n",
            "Train epoch: 200 [435120/25046 (54%)]\tLoss: 1.254544\n",
            "Train epoch: 200 [443960/25046 (56%)]\tLoss: 0.871972\n",
            "Train epoch: 200 [470580/25046 (59%)]\tLoss: 0.817355\n",
            "Train epoch: 200 [500160/25046 (61%)]\tLoss: 0.940459\n",
            "Train epoch: 200 [514500/25046 (64%)]\tLoss: 2.057600\n",
            "Train epoch: 200 [521560/25046 (66%)]\tLoss: 0.589080\n",
            "Train epoch: 200 [556740/25046 (69%)]\tLoss: 0.411673\n",
            "Train epoch: 200 [560000/25046 (72%)]\tLoss: 0.662474\n",
            "Train epoch: 200 [584060/25046 (74%)]\tLoss: 0.581205\n",
            "Train epoch: 200 [624600/25046 (77%)]\tLoss: 0.853436\n",
            "Train epoch: 200 [611320/25046 (79%)]\tLoss: 0.807268\n",
            "Train epoch: 200 [662400/25046 (82%)]\tLoss: 0.376884\n",
            "Train epoch: 200 [667260/25046 (84%)]\tLoss: 0.405913\n",
            "Train epoch: 200 [713320/25046 (87%)]\tLoss: 0.928587\n",
            "Train epoch: 200 [718200/25046 (89%)]\tLoss: 0.423972\n",
            "Train epoch: 200 [720000/25046 (92%)]\tLoss: 0.640766\n",
            "Train epoch: 200 [751100/25046 (95%)]\tLoss: 0.363576\n",
            "Train epoch: 200 [785840/25046 (97%)]\tLoss: 0.578319\n",
            "Train epoch: 200 [806520/25046 (100%)]\tLoss: 1.126599\n",
            "Make prediction for 5010 samples...\n",
            "0.8015222 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 201 [0/25046 (0%)]\tLoss: 1.433313\n",
            "Train epoch: 201 [21260/25046 (3%)]\tLoss: 1.384313\n",
            "Train epoch: 201 [40520/25046 (5%)]\tLoss: 1.121192\n",
            "Train epoch: 201 [60960/25046 (8%)]\tLoss: 1.100586\n",
            "Train epoch: 201 [83200/25046 (10%)]\tLoss: 1.274410\n",
            "Train epoch: 201 [105500/25046 (13%)]\tLoss: 0.971070\n",
            "Train epoch: 201 [129600/25046 (15%)]\tLoss: 0.804921\n",
            "Train epoch: 201 [141680/25046 (18%)]\tLoss: 1.572427\n",
            "Train epoch: 201 [160160/25046 (20%)]\tLoss: 1.363851\n",
            "Train epoch: 201 [184320/25046 (23%)]\tLoss: 0.733497\n",
            "Train epoch: 201 [209800/25046 (26%)]\tLoss: 0.878678\n",
            "Train epoch: 201 [220000/25046 (28%)]\tLoss: 0.489651\n",
            "Train epoch: 201 [253440/25046 (31%)]\tLoss: 0.519439\n",
            "Train epoch: 201 [270140/25046 (33%)]\tLoss: 0.344466\n",
            "Train epoch: 201 [287560/25046 (36%)]\tLoss: 0.836277\n",
            "Train epoch: 201 [279600/25046 (38%)]\tLoss: 0.924268\n",
            "Train epoch: 201 [328000/25046 (41%)]\tLoss: 0.528166\n",
            "Train epoch: 201 [353600/25046 (43%)]\tLoss: 0.762597\n",
            "Train epoch: 201 [374040/25046 (46%)]\tLoss: 0.666999\n",
            "Train epoch: 201 [401660/25046 (49%)]\tLoss: 0.313732\n",
            "Train epoch: 201 [424400/25046 (51%)]\tLoss: 0.528355\n",
            "Train epoch: 201 [454440/25046 (54%)]\tLoss: 0.851194\n",
            "Train epoch: 201 [455840/25046 (56%)]\tLoss: 0.367417\n",
            "Train epoch: 201 [483920/25046 (59%)]\tLoss: 0.681314\n",
            "Train epoch: 201 [476640/25046 (61%)]\tLoss: 0.978986\n",
            "Train epoch: 201 [527500/25046 (64%)]\tLoss: 0.444199\n",
            "Train epoch: 201 [541840/25046 (66%)]\tLoss: 1.090327\n",
            "Train epoch: 201 [548100/25046 (69%)]\tLoss: 0.367797\n",
            "Train epoch: 201 [563920/25046 (72%)]\tLoss: 2.255384\n",
            "Train epoch: 201 [573040/25046 (74%)]\tLoss: 0.703563\n",
            "Train epoch: 201 [606600/25046 (77%)]\tLoss: 1.048247\n",
            "Train epoch: 201 [628060/25046 (79%)]\tLoss: 1.245176\n",
            "Train epoch: 201 [619520/25046 (82%)]\tLoss: 0.821730\n",
            "Train epoch: 201 [648780/25046 (84%)]\tLoss: 0.514675\n",
            "Train epoch: 201 [697000/25046 (87%)]\tLoss: 0.654360\n",
            "Train epoch: 201 [689500/25046 (89%)]\tLoss: 1.258860\n",
            "Train epoch: 201 [750240/25046 (92%)]\tLoss: 0.794653\n",
            "Train epoch: 201 [751100/25046 (95%)]\tLoss: 0.568969\n",
            "Train epoch: 201 [752400/25046 (97%)]\tLoss: 0.647699\n",
            "Train epoch: 201 [879060/25046 (100%)]\tLoss: 1.410833\n",
            "Make prediction for 5010 samples...\n",
            "0.80513835 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 202 [0/25046 (0%)]\tLoss: 0.588391\n",
            "Train epoch: 202 [20740/25046 (3%)]\tLoss: 0.658161\n",
            "Train epoch: 202 [39080/25046 (5%)]\tLoss: 0.590135\n",
            "Train epoch: 202 [67320/25046 (8%)]\tLoss: 0.856205\n",
            "Train epoch: 202 [86320/25046 (10%)]\tLoss: 1.254399\n",
            "Train epoch: 202 [98700/25046 (13%)]\tLoss: 0.952988\n",
            "Train epoch: 202 [124680/25046 (15%)]\tLoss: 1.030825\n",
            "Train epoch: 202 [141680/25046 (18%)]\tLoss: 0.291006\n",
            "Train epoch: 202 [165120/25046 (20%)]\tLoss: 1.073544\n",
            "Train epoch: 202 [179640/25046 (23%)]\tLoss: 0.955624\n",
            "Train epoch: 202 [200400/25046 (26%)]\tLoss: 0.965906\n",
            "Train epoch: 202 [233640/25046 (28%)]\tLoss: 0.496869\n",
            "Train epoch: 202 [257280/25046 (31%)]\tLoss: 0.869389\n",
            "Train epoch: 202 [246740/25046 (33%)]\tLoss: 1.480010\n",
            "Train epoch: 202 [296520/25046 (36%)]\tLoss: 0.696797\n",
            "Train epoch: 202 [316800/25046 (38%)]\tLoss: 0.330456\n",
            "Train epoch: 202 [334400/25046 (41%)]\tLoss: 0.674492\n",
            "Train epoch: 202 [346800/25046 (43%)]\tLoss: 1.115151\n",
            "Train epoch: 202 [391680/25046 (46%)]\tLoss: 0.848623\n",
            "Train epoch: 202 [395200/25046 (49%)]\tLoss: 0.818842\n",
            "Train epoch: 202 [388400/25046 (51%)]\tLoss: 0.929619\n",
            "Train epoch: 202 [418320/25046 (54%)]\tLoss: 0.612121\n",
            "Train epoch: 202 [438680/25046 (56%)]\tLoss: 1.064290\n",
            "Train epoch: 202 [472880/25046 (59%)]\tLoss: 0.417532\n",
            "Train epoch: 202 [497280/25046 (61%)]\tLoss: 0.926176\n",
            "Train epoch: 202 [505000/25046 (64%)]\tLoss: 1.215810\n",
            "Train epoch: 202 [527280/25046 (66%)]\tLoss: 0.292441\n",
            "Train epoch: 202 [598320/25046 (69%)]\tLoss: 0.731442\n",
            "Train epoch: 202 [560000/25046 (72%)]\tLoss: 0.417918\n",
            "Train epoch: 202 [577680/25046 (74%)]\tLoss: 0.464219\n",
            "Train epoch: 202 [633000/25046 (77%)]\tLoss: 0.760523\n",
            "Train epoch: 202 [660920/25046 (79%)]\tLoss: 1.032201\n",
            "Train epoch: 202 [650240/25046 (82%)]\tLoss: 1.951100\n",
            "Train epoch: 202 [661320/25046 (84%)]\tLoss: 0.483165\n",
            "Train epoch: 202 [724200/25046 (87%)]\tLoss: 1.789137\n",
            "Train epoch: 202 [733600/25046 (89%)]\tLoss: 1.474250\n",
            "Train epoch: 202 [749520/25046 (92%)]\tLoss: 1.756268\n",
            "Train epoch: 202 [771820/25046 (95%)]\tLoss: 0.478513\n",
            "Train epoch: 202 [782800/25046 (97%)]\tLoss: 0.411277\n",
            "Train epoch: 202 [772200/25046 (100%)]\tLoss: 0.677917\n",
            "Make prediction for 5010 samples...\n",
            "0.8015157 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 203 [0/25046 (0%)]\tLoss: 0.972391\n",
            "Train epoch: 203 [19920/25046 (3%)]\tLoss: 1.029258\n",
            "Train epoch: 203 [40320/25046 (5%)]\tLoss: 1.407417\n",
            "Train epoch: 203 [59940/25046 (8%)]\tLoss: 0.391168\n",
            "Train epoch: 203 [83600/25046 (10%)]\tLoss: 0.568429\n",
            "Train epoch: 203 [101200/25046 (13%)]\tLoss: 0.449842\n",
            "Train epoch: 203 [123000/25046 (15%)]\tLoss: 1.163920\n",
            "Train epoch: 203 [142940/25046 (18%)]\tLoss: 0.713130\n",
            "Train epoch: 203 [168000/25046 (20%)]\tLoss: 0.340248\n",
            "Train epoch: 203 [191340/25046 (23%)]\tLoss: 0.549886\n",
            "Train epoch: 203 [202200/25046 (26%)]\tLoss: 0.555328\n",
            "Train epoch: 203 [232760/25046 (28%)]\tLoss: 0.619800\n",
            "Train epoch: 203 [243360/25046 (31%)]\tLoss: 0.505914\n",
            "Train epoch: 203 [267540/25046 (33%)]\tLoss: 0.553593\n",
            "Train epoch: 203 [280000/25046 (36%)]\tLoss: 0.747767\n",
            "Train epoch: 203 [313800/25046 (38%)]\tLoss: 0.431754\n",
            "Train epoch: 203 [330560/25046 (41%)]\tLoss: 0.909810\n",
            "Train epoch: 203 [363460/25046 (43%)]\tLoss: 0.346480\n",
            "Train epoch: 203 [351360/25046 (46%)]\tLoss: 0.538714\n",
            "Train epoch: 203 [394820/25046 (49%)]\tLoss: 0.507412\n",
            "Train epoch: 203 [403200/25046 (51%)]\tLoss: 1.431103\n",
            "Train epoch: 203 [434280/25046 (54%)]\tLoss: 0.565887\n",
            "Train epoch: 203 [462440/25046 (56%)]\tLoss: 1.085530\n",
            "Train epoch: 203 [489900/25046 (59%)]\tLoss: 0.244924\n",
            "Train epoch: 203 [504960/25046 (61%)]\tLoss: 1.184847\n",
            "Train epoch: 203 [506500/25046 (64%)]\tLoss: 0.883884\n",
            "Train epoch: 203 [530400/25046 (66%)]\tLoss: 0.413523\n",
            "Train epoch: 203 [556740/25046 (69%)]\tLoss: 1.223568\n",
            "Train epoch: 203 [599200/25046 (72%)]\tLoss: 0.334301\n",
            "Train epoch: 203 [569560/25046 (74%)]\tLoss: 0.889723\n",
            "Train epoch: 203 [603600/25046 (77%)]\tLoss: 1.061272\n",
            "Train epoch: 203 [641080/25046 (79%)]\tLoss: 0.468035\n",
            "Train epoch: 203 [648320/25046 (82%)]\tLoss: 0.516929\n",
            "Train epoch: 203 [646140/25046 (84%)]\tLoss: 0.780675\n",
            "Train epoch: 203 [688840/25046 (87%)]\tLoss: 0.263295\n",
            "Train epoch: 203 [715400/25046 (89%)]\tLoss: 0.959247\n",
            "Train epoch: 203 [717120/25046 (92%)]\tLoss: 1.025285\n",
            "Train epoch: 203 [725200/25046 (95%)]\tLoss: 0.814328\n",
            "Train epoch: 203 [791160/25046 (97%)]\tLoss: 1.627971\n",
            "Train epoch: 203 [781560/25046 (100%)]\tLoss: 0.860468\n",
            "Make prediction for 5010 samples...\n",
            "0.8020699 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 204 [0/25046 (0%)]\tLoss: 0.551692\n",
            "Train epoch: 204 [20120/25046 (3%)]\tLoss: 0.848679\n",
            "Train epoch: 204 [43480/25046 (5%)]\tLoss: 0.609272\n",
            "Train epoch: 204 [65520/25046 (8%)]\tLoss: 1.012192\n",
            "Train epoch: 204 [86960/25046 (10%)]\tLoss: 2.350986\n",
            "Train epoch: 204 [102000/25046 (13%)]\tLoss: 1.554404\n",
            "Train epoch: 204 [126240/25046 (15%)]\tLoss: 0.533392\n",
            "Train epoch: 204 [136640/25046 (18%)]\tLoss: 0.470928\n",
            "Train epoch: 204 [166720/25046 (20%)]\tLoss: 0.183811\n",
            "Train epoch: 204 [179100/25046 (23%)]\tLoss: 1.041330\n",
            "Train epoch: 204 [200200/25046 (26%)]\tLoss: 0.685387\n",
            "Train epoch: 204 [229460/25046 (28%)]\tLoss: 0.682911\n",
            "Train epoch: 204 [246720/25046 (31%)]\tLoss: 0.661092\n",
            "Train epoch: 204 [264940/25046 (33%)]\tLoss: 1.274489\n",
            "Train epoch: 204 [289800/25046 (36%)]\tLoss: 0.890195\n",
            "Train epoch: 204 [312600/25046 (38%)]\tLoss: 1.009054\n",
            "Train epoch: 204 [317440/25046 (41%)]\tLoss: 1.304900\n",
            "Train epoch: 204 [365500/25046 (43%)]\tLoss: 0.788388\n",
            "Train epoch: 204 [376560/25046 (46%)]\tLoss: 1.205805\n",
            "Train epoch: 204 [398620/25046 (49%)]\tLoss: 0.497523\n",
            "Train epoch: 204 [407600/25046 (51%)]\tLoss: 0.804124\n",
            "Train epoch: 204 [461580/25046 (54%)]\tLoss: 0.979167\n",
            "Train epoch: 204 [447040/25046 (56%)]\tLoss: 0.601180\n",
            "Train epoch: 204 [473340/25046 (59%)]\tLoss: 0.510886\n",
            "Train epoch: 204 [478080/25046 (61%)]\tLoss: 0.505843\n",
            "Train epoch: 204 [498000/25046 (64%)]\tLoss: 0.724808\n",
            "Train epoch: 204 [521560/25046 (66%)]\tLoss: 0.987135\n",
            "Train epoch: 204 [561600/25046 (69%)]\tLoss: 1.661949\n",
            "Train epoch: 204 [572320/25046 (72%)]\tLoss: 1.210536\n",
            "Train epoch: 204 [570720/25046 (74%)]\tLoss: 0.605417\n",
            "Train epoch: 204 [653400/25046 (77%)]\tLoss: 0.920569\n",
            "Train epoch: 204 [626200/25046 (79%)]\tLoss: 0.279106\n",
            "Train epoch: 204 [647040/25046 (82%)]\tLoss: 0.538410\n",
            "Train epoch: 204 [677160/25046 (84%)]\tLoss: 0.529174\n",
            "Train epoch: 204 [677960/25046 (87%)]\tLoss: 0.621703\n",
            "Train epoch: 204 [726600/25046 (89%)]\tLoss: 0.641181\n",
            "Train epoch: 204 [722880/25046 (92%)]\tLoss: 0.396208\n",
            "Train epoch: 204 [755540/25046 (95%)]\tLoss: 0.649223\n",
            "Train epoch: 204 [776720/25046 (97%)]\tLoss: 0.888033\n",
            "Train epoch: 204 [803400/25046 (100%)]\tLoss: 0.907659\n",
            "Make prediction for 5010 samples...\n",
            "0.80170864 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 205 [0/25046 (0%)]\tLoss: 0.557479\n",
            "Train epoch: 205 [20300/25046 (3%)]\tLoss: 1.289826\n",
            "Train epoch: 205 [42160/25046 (5%)]\tLoss: 0.909277\n",
            "Train epoch: 205 [62220/25046 (8%)]\tLoss: 0.332751\n",
            "Train epoch: 205 [76960/25046 (10%)]\tLoss: 0.595593\n",
            "Train epoch: 205 [111500/25046 (13%)]\tLoss: 1.169129\n",
            "Train epoch: 205 [118920/25046 (15%)]\tLoss: 0.744785\n",
            "Train epoch: 205 [149940/25046 (18%)]\tLoss: 0.629052\n",
            "Train epoch: 205 [172800/25046 (20%)]\tLoss: 0.981810\n",
            "Train epoch: 205 [181440/25046 (23%)]\tLoss: 0.345769\n",
            "Train epoch: 205 [209000/25046 (26%)]\tLoss: 0.961003\n",
            "Train epoch: 205 [228360/25046 (28%)]\tLoss: 0.999372\n",
            "Train epoch: 205 [253920/25046 (31%)]\tLoss: 0.723003\n",
            "Train epoch: 205 [269360/25046 (33%)]\tLoss: 1.095267\n",
            "Train epoch: 205 [288680/25046 (36%)]\tLoss: 0.489197\n",
            "Train epoch: 205 [298200/25046 (38%)]\tLoss: 0.439153\n",
            "Train epoch: 205 [330560/25046 (41%)]\tLoss: 0.210523\n",
            "Train epoch: 205 [335240/25046 (43%)]\tLoss: 0.617505\n",
            "Train epoch: 205 [389880/25046 (46%)]\tLoss: 1.158426\n",
            "Train epoch: 205 [412300/25046 (49%)]\tLoss: 0.738150\n",
            "Train epoch: 205 [384800/25046 (51%)]\tLoss: 0.745876\n",
            "Train epoch: 205 [448560/25046 (54%)]\tLoss: 0.659672\n",
            "Train epoch: 205 [483120/25046 (56%)]\tLoss: 0.949731\n",
            "Train epoch: 205 [482540/25046 (59%)]\tLoss: 0.828894\n",
            "Train epoch: 205 [518400/25046 (61%)]\tLoss: 1.127876\n",
            "Train epoch: 205 [522000/25046 (64%)]\tLoss: 0.218303\n",
            "Train epoch: 205 [561080/25046 (66%)]\tLoss: 0.612932\n",
            "Train epoch: 205 [530820/25046 (69%)]\tLoss: 1.500037\n",
            "Train epoch: 205 [565600/25046 (72%)]\tLoss: 1.249802\n",
            "Train epoch: 205 [578260/25046 (74%)]\tLoss: 0.734918\n",
            "Train epoch: 205 [585000/25046 (77%)]\tLoss: 0.702826\n",
            "Train epoch: 205 [594580/25046 (79%)]\tLoss: 1.043103\n",
            "Train epoch: 205 [688640/25046 (82%)]\tLoss: 1.142079\n",
            "Train epoch: 205 [693000/25046 (84%)]\tLoss: 0.291354\n",
            "Train epoch: 205 [688840/25046 (87%)]\tLoss: 0.458548\n",
            "Train epoch: 205 [697900/25046 (89%)]\tLoss: 0.806324\n",
            "Train epoch: 205 [735840/25046 (92%)]\tLoss: 1.157799\n",
            "Train epoch: 205 [785140/25046 (95%)]\tLoss: 0.936375\n",
            "Train epoch: 205 [791160/25046 (97%)]\tLoss: 0.938617\n",
            "Train epoch: 205 [757380/25046 (100%)]\tLoss: 0.870529\n",
            "Make prediction for 5010 samples...\n",
            "0.8017596 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 206 [0/25046 (0%)]\tLoss: 0.339413\n",
            "Train epoch: 206 [21500/25046 (3%)]\tLoss: 0.979368\n",
            "Train epoch: 206 [38560/25046 (5%)]\tLoss: 0.414125\n",
            "Train epoch: 206 [61500/25046 (8%)]\tLoss: 1.268414\n",
            "Train epoch: 206 [80720/25046 (10%)]\tLoss: 0.567312\n",
            "Train epoch: 206 [105700/25046 (13%)]\tLoss: 0.677064\n",
            "Train epoch: 206 [119400/25046 (15%)]\tLoss: 0.881831\n",
            "Train epoch: 206 [139440/25046 (18%)]\tLoss: 0.780861\n",
            "Train epoch: 206 [169280/25046 (20%)]\tLoss: 1.275654\n",
            "Train epoch: 206 [177840/25046 (23%)]\tLoss: 0.879127\n",
            "Train epoch: 206 [206600/25046 (26%)]\tLoss: 0.652473\n",
            "Train epoch: 206 [233420/25046 (28%)]\tLoss: 0.728482\n",
            "Train epoch: 206 [251280/25046 (31%)]\tLoss: 0.315942\n",
            "Train epoch: 206 [262600/25046 (33%)]\tLoss: 0.605784\n",
            "Train epoch: 206 [306600/25046 (36%)]\tLoss: 0.598462\n",
            "Train epoch: 206 [315300/25046 (38%)]\tLoss: 0.912439\n",
            "Train epoch: 206 [325760/25046 (41%)]\tLoss: 0.480485\n",
            "Train epoch: 206 [350540/25046 (43%)]\tLoss: 0.264969\n",
            "Train epoch: 206 [379080/25046 (46%)]\tLoss: 0.310455\n",
            "Train epoch: 206 [376960/25046 (49%)]\tLoss: 1.223961\n",
            "Train epoch: 206 [422800/25046 (51%)]\tLoss: 1.569784\n",
            "Train epoch: 206 [405300/25046 (54%)]\tLoss: 1.335910\n",
            "Train epoch: 206 [464640/25046 (56%)]\tLoss: 0.272468\n",
            "Train epoch: 206 [453560/25046 (59%)]\tLoss: 0.716333\n",
            "Train epoch: 206 [537600/25046 (61%)]\tLoss: 0.657076\n",
            "Train epoch: 206 [506000/25046 (64%)]\tLoss: 0.592322\n",
            "Train epoch: 206 [534560/25046 (66%)]\tLoss: 0.225925\n",
            "Train epoch: 206 [537300/25046 (69%)]\tLoss: 0.800856\n",
            "Train epoch: 206 [584080/25046 (72%)]\tLoss: 0.619268\n",
            "Train epoch: 206 [588120/25046 (74%)]\tLoss: 0.929561\n",
            "Train epoch: 206 [615000/25046 (77%)]\tLoss: 0.588733\n",
            "Train epoch: 206 [645420/25046 (79%)]\tLoss: 1.222141\n",
            "Train epoch: 206 [627840/25046 (82%)]\tLoss: 0.672245\n",
            "Train epoch: 206 [689700/25046 (84%)]\tLoss: 0.682700\n",
            "Train epoch: 206 [679320/25046 (87%)]\tLoss: 0.460138\n",
            "Train epoch: 206 [718900/25046 (89%)]\tLoss: 1.078095\n",
            "Train epoch: 206 [750240/25046 (92%)]\tLoss: 0.390412\n",
            "Train epoch: 206 [758500/25046 (95%)]\tLoss: 0.941850\n",
            "Train epoch: 206 [791920/25046 (97%)]\tLoss: 0.655285\n",
            "Train epoch: 206 [836160/25046 (100%)]\tLoss: 0.370265\n",
            "Make prediction for 5010 samples...\n",
            "0.80455476 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 207 [0/25046 (0%)]\tLoss: 1.298135\n",
            "Train epoch: 207 [18560/25046 (3%)]\tLoss: 0.203242\n",
            "Train epoch: 207 [38880/25046 (5%)]\tLoss: 0.345218\n",
            "Train epoch: 207 [61560/25046 (8%)]\tLoss: 0.349412\n",
            "Train epoch: 207 [81760/25046 (10%)]\tLoss: 0.671919\n",
            "Train epoch: 207 [98000/25046 (13%)]\tLoss: 0.260852\n",
            "Train epoch: 207 [121800/25046 (15%)]\tLoss: 0.744619\n",
            "Train epoch: 207 [148260/25046 (18%)]\tLoss: 1.229626\n",
            "Train epoch: 207 [165440/25046 (20%)]\tLoss: 0.478655\n",
            "Train epoch: 207 [177120/25046 (23%)]\tLoss: 0.982836\n",
            "Train epoch: 207 [205400/25046 (26%)]\tLoss: 0.664686\n",
            "Train epoch: 207 [239800/25046 (28%)]\tLoss: 0.822841\n",
            "Train epoch: 207 [245760/25046 (31%)]\tLoss: 1.235424\n",
            "Train epoch: 207 [263380/25046 (33%)]\tLoss: 0.522866\n",
            "Train epoch: 207 [276920/25046 (36%)]\tLoss: 0.827499\n",
            "Train epoch: 207 [308100/25046 (38%)]\tLoss: 1.008906\n",
            "Train epoch: 207 [342720/25046 (41%)]\tLoss: 0.880250\n",
            "Train epoch: 207 [333880/25046 (43%)]\tLoss: 0.632814\n",
            "Train epoch: 207 [376200/25046 (46%)]\tLoss: 0.557981\n",
            "Train epoch: 207 [381900/25046 (49%)]\tLoss: 1.003663\n",
            "Train epoch: 207 [404400/25046 (51%)]\tLoss: 1.566829\n",
            "Train epoch: 207 [417060/25046 (54%)]\tLoss: 0.424265\n",
            "Train epoch: 207 [435160/25046 (56%)]\tLoss: 0.488098\n",
            "Train epoch: 207 [480700/25046 (59%)]\tLoss: 1.159937\n",
            "Train epoch: 207 [499200/25046 (61%)]\tLoss: 0.400366\n",
            "Train epoch: 207 [498500/25046 (64%)]\tLoss: 0.404592\n",
            "Train epoch: 207 [557960/25046 (66%)]\tLoss: 0.865635\n",
            "Train epoch: 207 [560520/25046 (69%)]\tLoss: 0.504632\n",
            "Train epoch: 207 [571200/25046 (72%)]\tLoss: 0.886940\n",
            "Train epoch: 207 [632780/25046 (74%)]\tLoss: 0.482488\n",
            "Train epoch: 207 [629400/25046 (77%)]\tLoss: 1.092717\n",
            "Train epoch: 207 [649760/25046 (79%)]\tLoss: 1.335430\n",
            "Train epoch: 207 [641280/25046 (82%)]\tLoss: 0.607579\n",
            "Train epoch: 207 [691680/25046 (84%)]\tLoss: 0.479478\n",
            "Train epoch: 207 [720800/25046 (87%)]\tLoss: 0.717228\n",
            "Train epoch: 207 [721700/25046 (89%)]\tLoss: 0.521266\n",
            "Train epoch: 207 [802800/25046 (92%)]\tLoss: 1.285481\n",
            "Train epoch: 207 [731860/25046 (95%)]\tLoss: 1.326162\n",
            "Train epoch: 207 [814720/25046 (97%)]\tLoss: 0.583061\n",
            "Train epoch: 207 [776100/25046 (100%)]\tLoss: 0.803134\n",
            "Make prediction for 5010 samples...\n",
            "0.8015864 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 208 [0/25046 (0%)]\tLoss: 0.805510\n",
            "Train epoch: 208 [20180/25046 (3%)]\tLoss: 0.559150\n",
            "Train epoch: 208 [40720/25046 (5%)]\tLoss: 1.356287\n",
            "Train epoch: 208 [63960/25046 (8%)]\tLoss: 0.516016\n",
            "Train epoch: 208 [76880/25046 (10%)]\tLoss: 1.137177\n",
            "Train epoch: 208 [109300/25046 (13%)]\tLoss: 0.399299\n",
            "Train epoch: 208 [123480/25046 (15%)]\tLoss: 0.864884\n",
            "Train epoch: 208 [148540/25046 (18%)]\tLoss: 0.946289\n",
            "Train epoch: 208 [165120/25046 (20%)]\tLoss: 0.632030\n",
            "Train epoch: 208 [185760/25046 (23%)]\tLoss: 1.127998\n",
            "Train epoch: 208 [206800/25046 (26%)]\tLoss: 0.459419\n",
            "Train epoch: 208 [218680/25046 (28%)]\tLoss: 0.478378\n",
            "Train epoch: 208 [236880/25046 (31%)]\tLoss: 1.466013\n",
            "Train epoch: 208 [264940/25046 (33%)]\tLoss: 1.620037\n",
            "Train epoch: 208 [276920/25046 (36%)]\tLoss: 1.116912\n",
            "Train epoch: 208 [318000/25046 (38%)]\tLoss: 1.703825\n",
            "Train epoch: 208 [332160/25046 (41%)]\tLoss: 0.199515\n",
            "Train epoch: 208 [320960/25046 (43%)]\tLoss: 0.584164\n",
            "Train epoch: 208 [356760/25046 (46%)]\tLoss: 0.672120\n",
            "Train epoch: 208 [377340/25046 (49%)]\tLoss: 1.084243\n",
            "Train epoch: 208 [406800/25046 (51%)]\tLoss: 0.956285\n",
            "Train epoch: 208 [443520/25046 (54%)]\tLoss: 1.012213\n",
            "Train epoch: 208 [437800/25046 (56%)]\tLoss: 1.111654\n",
            "Train epoch: 208 [482080/25046 (59%)]\tLoss: 0.676093\n",
            "Train epoch: 208 [503520/25046 (61%)]\tLoss: 0.724829\n",
            "Train epoch: 208 [515500/25046 (64%)]\tLoss: 0.388929\n",
            "Train epoch: 208 [529360/25046 (66%)]\tLoss: 1.259530\n",
            "Train epoch: 208 [538380/25046 (69%)]\tLoss: 1.499382\n",
            "Train epoch: 208 [540960/25046 (72%)]\tLoss: 0.882390\n",
            "Train epoch: 208 [589280/25046 (74%)]\tLoss: 1.287630\n",
            "Train epoch: 208 [631200/25046 (77%)]\tLoss: 0.323872\n",
            "Train epoch: 208 [621240/25046 (79%)]\tLoss: 0.960001\n",
            "Train epoch: 208 [685440/25046 (82%)]\tLoss: 1.013579\n",
            "Train epoch: 208 [677820/25046 (84%)]\tLoss: 0.467675\n",
            "Train epoch: 208 [711280/25046 (87%)]\tLoss: 0.768268\n",
            "Train epoch: 208 [719600/25046 (89%)]\tLoss: 1.210344\n",
            "Train epoch: 208 [776160/25046 (92%)]\tLoss: 0.958723\n",
            "Train epoch: 208 [780700/25046 (95%)]\tLoss: 0.589477\n",
            "Train epoch: 208 [818520/25046 (97%)]\tLoss: 0.845626\n",
            "Train epoch: 208 [807300/25046 (100%)]\tLoss: 0.525702\n",
            "Make prediction for 5010 samples...\n",
            "0.8015243 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 209 [0/25046 (0%)]\tLoss: 1.279978\n",
            "Train epoch: 209 [20700/25046 (3%)]\tLoss: 0.954983\n",
            "Train epoch: 209 [40960/25046 (5%)]\tLoss: 0.344295\n",
            "Train epoch: 209 [64980/25046 (8%)]\tLoss: 0.628280\n",
            "Train epoch: 209 [82080/25046 (10%)]\tLoss: 0.517020\n",
            "Train epoch: 209 [107200/25046 (13%)]\tLoss: 1.056816\n",
            "Train epoch: 209 [124920/25046 (15%)]\tLoss: 1.146079\n",
            "Train epoch: 209 [143500/25046 (18%)]\tLoss: 0.951922\n",
            "Train epoch: 209 [156000/25046 (20%)]\tLoss: 0.542006\n",
            "Train epoch: 209 [191880/25046 (23%)]\tLoss: 1.158654\n",
            "Train epoch: 209 [211200/25046 (26%)]\tLoss: 0.235705\n",
            "Train epoch: 209 [226820/25046 (28%)]\tLoss: 1.011017\n",
            "Train epoch: 209 [255360/25046 (31%)]\tLoss: 1.382553\n",
            "Train epoch: 209 [266500/25046 (33%)]\tLoss: 0.596656\n",
            "Train epoch: 209 [290640/25046 (36%)]\tLoss: 0.707999\n",
            "Train epoch: 209 [309000/25046 (38%)]\tLoss: 1.320718\n",
            "Train epoch: 209 [310400/25046 (41%)]\tLoss: 0.546741\n",
            "Train epoch: 209 [344760/25046 (43%)]\tLoss: 0.573465\n",
            "Train epoch: 209 [371880/25046 (46%)]\tLoss: 1.546749\n",
            "Train epoch: 209 [379620/25046 (49%)]\tLoss: 0.363292\n",
            "Train epoch: 209 [425200/25046 (51%)]\tLoss: 1.006444\n",
            "Train epoch: 209 [435540/25046 (54%)]\tLoss: 0.949428\n",
            "Train epoch: 209 [458040/25046 (56%)]\tLoss: 1.054458\n",
            "Train epoch: 209 [469200/25046 (59%)]\tLoss: 0.717875\n",
            "Train epoch: 209 [490080/25046 (61%)]\tLoss: 0.871800\n",
            "Train epoch: 209 [516500/25046 (64%)]\tLoss: 1.000682\n",
            "Train epoch: 209 [507520/25046 (66%)]\tLoss: 0.552047\n",
            "Train epoch: 209 [564300/25046 (69%)]\tLoss: 1.773428\n",
            "Train epoch: 209 [603680/25046 (72%)]\tLoss: 0.390829\n",
            "Train epoch: 209 [593920/25046 (74%)]\tLoss: 0.730716\n",
            "Train epoch: 209 [597000/25046 (77%)]\tLoss: 0.407080\n",
            "Train epoch: 209 [659060/25046 (79%)]\tLoss: 0.749584\n",
            "Train epoch: 209 [638720/25046 (82%)]\tLoss: 1.444602\n",
            "Train epoch: 209 [681780/25046 (84%)]\tLoss: 1.053738\n",
            "Train epoch: 209 [735080/25046 (87%)]\tLoss: 0.808970\n",
            "Train epoch: 209 [685300/25046 (89%)]\tLoss: 0.331129\n",
            "Train epoch: 209 [749520/25046 (92%)]\tLoss: 2.499854\n",
            "Train epoch: 209 [769600/25046 (95%)]\tLoss: 0.628277\n",
            "Train epoch: 209 [769880/25046 (97%)]\tLoss: 0.483222\n",
            "Train epoch: 209 [797940/25046 (100%)]\tLoss: 0.746438\n",
            "Make prediction for 5010 samples...\n",
            "0.8018465 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 210 [0/25046 (0%)]\tLoss: 0.941302\n",
            "Train epoch: 210 [20300/25046 (3%)]\tLoss: 0.576671\n",
            "Train epoch: 210 [40120/25046 (5%)]\tLoss: 0.379980\n",
            "Train epoch: 210 [61620/25046 (8%)]\tLoss: 0.671504\n",
            "Train epoch: 210 [75280/25046 (10%)]\tLoss: 1.218890\n",
            "Train epoch: 210 [100200/25046 (13%)]\tLoss: 0.267837\n",
            "Train epoch: 210 [117840/25046 (15%)]\tLoss: 0.645992\n",
            "Train epoch: 210 [147420/25046 (18%)]\tLoss: 0.852956\n",
            "Train epoch: 210 [167040/25046 (20%)]\tLoss: 0.348502\n",
            "Train epoch: 210 [187380/25046 (23%)]\tLoss: 0.638511\n",
            "Train epoch: 210 [200400/25046 (26%)]\tLoss: 0.681365\n",
            "Train epoch: 210 [229020/25046 (28%)]\tLoss: 0.717522\n",
            "Train epoch: 210 [251760/25046 (31%)]\tLoss: 0.495911\n",
            "Train epoch: 210 [275600/25046 (33%)]\tLoss: 2.028223\n",
            "Train epoch: 210 [295960/25046 (36%)]\tLoss: 0.807741\n",
            "Train epoch: 210 [321900/25046 (38%)]\tLoss: 0.380565\n",
            "Train epoch: 210 [333440/25046 (41%)]\tLoss: 1.058646\n",
            "Train epoch: 210 [345440/25046 (43%)]\tLoss: 0.745311\n",
            "Train epoch: 210 [370440/25046 (46%)]\tLoss: 0.588203\n",
            "Train epoch: 210 [391780/25046 (49%)]\tLoss: 1.174881\n",
            "Train epoch: 210 [417200/25046 (51%)]\tLoss: 1.260440\n",
            "Train epoch: 210 [449400/25046 (54%)]\tLoss: 1.242194\n",
            "Train epoch: 210 [451880/25046 (56%)]\tLoss: 0.527866\n",
            "Train epoch: 210 [506920/25046 (59%)]\tLoss: 0.619907\n",
            "Train epoch: 210 [493440/25046 (61%)]\tLoss: 1.055076\n",
            "Train epoch: 210 [529500/25046 (64%)]\tLoss: 1.174947\n",
            "Train epoch: 210 [540800/25046 (66%)]\tLoss: 0.891635\n",
            "Train epoch: 210 [538920/25046 (69%)]\tLoss: 0.752830\n",
            "Train epoch: 210 [570640/25046 (72%)]\tLoss: 0.499645\n",
            "Train epoch: 210 [611900/25046 (74%)]\tLoss: 0.434915\n",
            "Train epoch: 210 [613800/25046 (77%)]\tLoss: 0.410544\n",
            "Train epoch: 210 [663400/25046 (79%)]\tLoss: 1.358444\n",
            "Train epoch: 210 [640000/25046 (82%)]\tLoss: 0.925452\n",
            "Train epoch: 210 [670560/25046 (84%)]\tLoss: 0.665664\n",
            "Train epoch: 210 [690880/25046 (87%)]\tLoss: 0.581633\n",
            "Train epoch: 210 [690200/25046 (89%)]\tLoss: 0.681936\n",
            "Train epoch: 210 [699120/25046 (92%)]\tLoss: 0.738743\n",
            "Train epoch: 210 [754060/25046 (95%)]\tLoss: 1.410308\n",
            "Train epoch: 210 [803320/25046 (97%)]\tLoss: 0.672772\n",
            "Train epoch: 210 [776100/25046 (100%)]\tLoss: 0.525771\n",
            "Make prediction for 5010 samples...\n",
            "0.80175686 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 211 [0/25046 (0%)]\tLoss: 0.717517\n",
            "Train epoch: 211 [20620/25046 (3%)]\tLoss: 0.727394\n",
            "Train epoch: 211 [38960/25046 (5%)]\tLoss: 0.446931\n",
            "Train epoch: 211 [61500/25046 (8%)]\tLoss: 1.139637\n",
            "Train epoch: 211 [76320/25046 (10%)]\tLoss: 0.996112\n",
            "Train epoch: 211 [103400/25046 (13%)]\tLoss: 0.903320\n",
            "Train epoch: 211 [123960/25046 (15%)]\tLoss: 1.046518\n",
            "Train epoch: 211 [155120/25046 (18%)]\tLoss: 1.235793\n",
            "Train epoch: 211 [173280/25046 (20%)]\tLoss: 1.210002\n",
            "Train epoch: 211 [178020/25046 (23%)]\tLoss: 0.996385\n",
            "Train epoch: 211 [205200/25046 (26%)]\tLoss: 0.795102\n",
            "Train epoch: 211 [210540/25046 (28%)]\tLoss: 1.327441\n",
            "Train epoch: 211 [241920/25046 (31%)]\tLoss: 0.649612\n",
            "Train epoch: 211 [262340/25046 (33%)]\tLoss: 0.935821\n",
            "Train epoch: 211 [303800/25046 (36%)]\tLoss: 1.231185\n",
            "Train epoch: 211 [311100/25046 (38%)]\tLoss: 0.844465\n",
            "Train epoch: 211 [333760/25046 (41%)]\tLoss: 1.000527\n",
            "Train epoch: 211 [341020/25046 (43%)]\tLoss: 0.343338\n",
            "Train epoch: 211 [374400/25046 (46%)]\tLoss: 1.720325\n",
            "Train epoch: 211 [403560/25046 (49%)]\tLoss: 1.357505\n",
            "Train epoch: 211 [420000/25046 (51%)]\tLoss: 1.512696\n",
            "Train epoch: 211 [427560/25046 (54%)]\tLoss: 0.953334\n",
            "Train epoch: 211 [461560/25046 (56%)]\tLoss: 0.452720\n",
            "Train epoch: 211 [461380/25046 (59%)]\tLoss: 0.498943\n",
            "Train epoch: 211 [498720/25046 (61%)]\tLoss: 0.644243\n",
            "Train epoch: 211 [514000/25046 (64%)]\tLoss: 0.637038\n",
            "Train epoch: 211 [518960/25046 (66%)]\tLoss: 0.316616\n",
            "Train epoch: 211 [525960/25046 (69%)]\tLoss: 0.325897\n",
            "Train epoch: 211 [563920/25046 (72%)]\tLoss: 0.787266\n",
            "Train epoch: 211 [610740/25046 (74%)]\tLoss: 0.840159\n",
            "Train epoch: 211 [637200/25046 (77%)]\tLoss: 1.628188\n",
            "Train epoch: 211 [653480/25046 (79%)]\tLoss: 0.495087\n",
            "Train epoch: 211 [654720/25046 (82%)]\tLoss: 0.908637\n",
            "Train epoch: 211 [675180/25046 (84%)]\tLoss: 0.512004\n",
            "Train epoch: 211 [706520/25046 (87%)]\tLoss: 0.227387\n",
            "Train epoch: 211 [710500/25046 (89%)]\tLoss: 0.502051\n",
            "Train epoch: 211 [722160/25046 (92%)]\tLoss: 1.466457\n",
            "Train epoch: 211 [734820/25046 (95%)]\tLoss: 0.654389\n",
            "Train epoch: 211 [739480/25046 (97%)]\tLoss: 0.524593\n",
            "Train epoch: 211 [817440/25046 (100%)]\tLoss: 0.409066\n",
            "Make prediction for 5010 samples...\n",
            "0.80194736 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 212 [0/25046 (0%)]\tLoss: 0.958498\n",
            "Train epoch: 212 [20380/25046 (3%)]\tLoss: 0.831511\n",
            "Train epoch: 212 [39760/25046 (5%)]\tLoss: 1.060690\n",
            "Train epoch: 212 [58320/25046 (8%)]\tLoss: 0.539507\n",
            "Train epoch: 212 [80320/25046 (10%)]\tLoss: 0.550701\n",
            "Train epoch: 212 [98800/25046 (13%)]\tLoss: 0.609585\n",
            "Train epoch: 212 [117000/25046 (15%)]\tLoss: 0.660306\n",
            "Train epoch: 212 [146300/25046 (18%)]\tLoss: 0.193234\n",
            "Train epoch: 212 [171040/25046 (20%)]\tLoss: 0.635843\n",
            "Train epoch: 212 [180900/25046 (23%)]\tLoss: 0.696351\n",
            "Train epoch: 212 [204200/25046 (26%)]\tLoss: 1.810520\n",
            "Train epoch: 212 [214940/25046 (28%)]\tLoss: 0.542055\n",
            "Train epoch: 212 [241440/25046 (31%)]\tLoss: 0.623386\n",
            "Train epoch: 212 [263900/25046 (33%)]\tLoss: 0.518183\n",
            "Train epoch: 212 [277760/25046 (36%)]\tLoss: 0.768032\n",
            "Train epoch: 212 [292800/25046 (38%)]\tLoss: 0.382843\n",
            "Train epoch: 212 [333760/25046 (41%)]\tLoss: 0.456149\n",
            "Train epoch: 212 [341700/25046 (43%)]\tLoss: 0.796022\n",
            "Train epoch: 212 [384840/25046 (46%)]\tLoss: 1.098613\n",
            "Train epoch: 212 [386840/25046 (49%)]\tLoss: 0.690309\n",
            "Train epoch: 212 [415600/25046 (51%)]\tLoss: 0.285673\n",
            "Train epoch: 212 [412020/25046 (54%)]\tLoss: 0.835828\n",
            "Train epoch: 212 [430760/25046 (56%)]\tLoss: 0.219373\n",
            "Train epoch: 212 [467820/25046 (59%)]\tLoss: 1.229492\n",
            "Train epoch: 212 [482880/25046 (61%)]\tLoss: 0.499151\n",
            "Train epoch: 212 [521000/25046 (64%)]\tLoss: 0.663400\n",
            "Train epoch: 212 [547560/25046 (66%)]\tLoss: 0.905143\n",
            "Train epoch: 212 [544320/25046 (69%)]\tLoss: 0.433310\n",
            "Train epoch: 212 [535360/25046 (72%)]\tLoss: 0.791308\n",
            "Train epoch: 212 [599140/25046 (74%)]\tLoss: 0.896816\n",
            "Train epoch: 212 [631800/25046 (77%)]\tLoss: 0.728512\n",
            "Train epoch: 212 [671460/25046 (79%)]\tLoss: 1.138238\n",
            "Train epoch: 212 [644480/25046 (82%)]\tLoss: 0.903348\n",
            "Train epoch: 212 [677820/25046 (84%)]\tLoss: 0.207987\n",
            "Train epoch: 212 [677960/25046 (87%)]\tLoss: 0.814488\n",
            "Train epoch: 212 [716100/25046 (89%)]\tLoss: 0.736908\n",
            "Train epoch: 212 [711360/25046 (92%)]\tLoss: 0.406785\n",
            "Train epoch: 212 [766640/25046 (95%)]\tLoss: 1.052187\n",
            "Train epoch: 212 [768360/25046 (97%)]\tLoss: 1.440191\n",
            "Train epoch: 212 [789360/25046 (100%)]\tLoss: 0.329406\n",
            "Make prediction for 5010 samples...\n",
            "0.8061141 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 213 [0/25046 (0%)]\tLoss: 1.533305\n",
            "Train epoch: 213 [19920/25046 (3%)]\tLoss: 1.224245\n",
            "Train epoch: 213 [40000/25046 (5%)]\tLoss: 0.724583\n",
            "Train epoch: 213 [63300/25046 (8%)]\tLoss: 0.668134\n",
            "Train epoch: 213 [82880/25046 (10%)]\tLoss: 1.179230\n",
            "Train epoch: 213 [102000/25046 (13%)]\tLoss: 0.668531\n",
            "Train epoch: 213 [122160/25046 (15%)]\tLoss: 0.540070\n",
            "Train epoch: 213 [153440/25046 (18%)]\tLoss: 0.525564\n",
            "Train epoch: 213 [163040/25046 (20%)]\tLoss: 0.428607\n",
            "Train epoch: 213 [182700/25046 (23%)]\tLoss: 1.100240\n",
            "Train epoch: 213 [200000/25046 (26%)]\tLoss: 0.666183\n",
            "Train epoch: 213 [226600/25046 (28%)]\tLoss: 0.930099\n",
            "Train epoch: 213 [242160/25046 (31%)]\tLoss: 0.765141\n",
            "Train epoch: 213 [273000/25046 (33%)]\tLoss: 0.938292\n",
            "Train epoch: 213 [281960/25046 (36%)]\tLoss: 1.362450\n",
            "Train epoch: 213 [322200/25046 (38%)]\tLoss: 0.988753\n",
            "Train epoch: 213 [319360/25046 (41%)]\tLoss: 1.391100\n",
            "Train epoch: 213 [333880/25046 (43%)]\tLoss: 0.828182\n",
            "Train epoch: 213 [365760/25046 (46%)]\tLoss: 0.730762\n",
            "Train epoch: 213 [378860/25046 (49%)]\tLoss: 0.585756\n",
            "Train epoch: 213 [398400/25046 (51%)]\tLoss: 0.336576\n",
            "Train epoch: 213 [412440/25046 (54%)]\tLoss: 0.781418\n",
            "Train epoch: 213 [452760/25046 (56%)]\tLoss: 0.851630\n",
            "Train epoch: 213 [449880/25046 (59%)]\tLoss: 0.401182\n",
            "Train epoch: 213 [478080/25046 (61%)]\tLoss: 1.240428\n",
            "Train epoch: 213 [507500/25046 (64%)]\tLoss: 0.686604\n",
            "Train epoch: 213 [521560/25046 (66%)]\tLoss: 0.472553\n",
            "Train epoch: 213 [545400/25046 (69%)]\tLoss: 0.611014\n",
            "Train epoch: 213 [601440/25046 (72%)]\tLoss: 0.543784\n",
            "Train epoch: 213 [615380/25046 (74%)]\tLoss: 0.818876\n",
            "Train epoch: 213 [631800/25046 (77%)]\tLoss: 1.073798\n",
            "Train epoch: 213 [609460/25046 (79%)]\tLoss: 0.259255\n",
            "Train epoch: 213 [666880/25046 (82%)]\tLoss: 1.105223\n",
            "Train epoch: 213 [691680/25046 (84%)]\tLoss: 0.256244\n",
            "Train epoch: 213 [729640/25046 (87%)]\tLoss: 0.643354\n",
            "Train epoch: 213 [759500/25046 (89%)]\tLoss: 0.973604\n",
            "Train epoch: 213 [784080/25046 (92%)]\tLoss: 0.583437\n",
            "Train epoch: 213 [791800/25046 (95%)]\tLoss: 0.987046\n",
            "Train epoch: 213 [738720/25046 (97%)]\tLoss: 0.807672\n",
            "Train epoch: 213 [801060/25046 (100%)]\tLoss: 1.224505\n",
            "Make prediction for 5010 samples...\n",
            "0.8035222 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 214 [0/25046 (0%)]\tLoss: 0.332678\n",
            "Train epoch: 214 [21240/25046 (3%)]\tLoss: 0.557231\n",
            "Train epoch: 214 [39760/25046 (5%)]\tLoss: 0.668212\n",
            "Train epoch: 214 [61320/25046 (8%)]\tLoss: 0.817624\n",
            "Train epoch: 214 [77040/25046 (10%)]\tLoss: 1.951302\n",
            "Train epoch: 214 [106200/25046 (13%)]\tLoss: 0.291785\n",
            "Train epoch: 214 [124920/25046 (15%)]\tLoss: 0.734801\n",
            "Train epoch: 214 [148680/25046 (18%)]\tLoss: 0.915248\n",
            "Train epoch: 214 [169920/25046 (20%)]\tLoss: 1.029524\n",
            "Train epoch: 214 [194940/25046 (23%)]\tLoss: 1.042517\n",
            "Train epoch: 214 [215800/25046 (26%)]\tLoss: 0.350861\n",
            "Train epoch: 214 [227920/25046 (28%)]\tLoss: 1.049049\n",
            "Train epoch: 214 [240960/25046 (31%)]\tLoss: 1.165655\n",
            "Train epoch: 214 [245440/25046 (33%)]\tLoss: 0.528845\n",
            "Train epoch: 214 [295400/25046 (36%)]\tLoss: 1.815799\n",
            "Train epoch: 214 [308400/25046 (38%)]\tLoss: 0.955298\n",
            "Train epoch: 214 [345600/25046 (41%)]\tLoss: 0.533230\n",
            "Train epoch: 214 [336600/25046 (43%)]\tLoss: 0.307132\n",
            "Train epoch: 214 [372600/25046 (46%)]\tLoss: 0.524530\n",
            "Train epoch: 214 [398240/25046 (49%)]\tLoss: 1.062076\n",
            "Train epoch: 214 [433600/25046 (51%)]\tLoss: 0.805340\n",
            "Train epoch: 214 [427560/25046 (54%)]\tLoss: 1.010808\n",
            "Train epoch: 214 [452320/25046 (56%)]\tLoss: 0.551849\n",
            "Train epoch: 214 [460920/25046 (59%)]\tLoss: 0.755379\n",
            "Train epoch: 214 [488160/25046 (61%)]\tLoss: 0.609650\n",
            "Train epoch: 214 [514500/25046 (64%)]\tLoss: 1.275347\n",
            "Train epoch: 214 [531440/25046 (66%)]\tLoss: 1.067047\n",
            "Train epoch: 214 [552420/25046 (69%)]\tLoss: 0.913656\n",
            "Train epoch: 214 [575680/25046 (72%)]\tLoss: 0.778984\n",
            "Train epoch: 214 [600300/25046 (74%)]\tLoss: 0.475111\n",
            "Train epoch: 214 [619800/25046 (77%)]\tLoss: 1.087524\n",
            "Train epoch: 214 [590240/25046 (79%)]\tLoss: 0.656724\n",
            "Train epoch: 214 [641920/25046 (82%)]\tLoss: 0.618327\n",
            "Train epoch: 214 [706200/25046 (84%)]\tLoss: 0.191673\n",
            "Train epoch: 214 [724200/25046 (87%)]\tLoss: 1.969767\n",
            "Train epoch: 214 [676900/25046 (89%)]\tLoss: 0.451471\n",
            "Train epoch: 214 [676800/25046 (92%)]\tLoss: 0.823348\n",
            "Train epoch: 214 [766640/25046 (95%)]\tLoss: 0.306211\n",
            "Train epoch: 214 [814720/25046 (97%)]\tLoss: 1.902840\n",
            "Train epoch: 214 [752700/25046 (100%)]\tLoss: 0.551129\n",
            "Make prediction for 5010 samples...\n",
            "0.80814564 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 215 [0/25046 (0%)]\tLoss: 0.778710\n",
            "Train epoch: 215 [19800/25046 (3%)]\tLoss: 0.536190\n",
            "Train epoch: 215 [41320/25046 (5%)]\tLoss: 0.443628\n",
            "Train epoch: 215 [61620/25046 (8%)]\tLoss: 0.877004\n",
            "Train epoch: 215 [83680/25046 (10%)]\tLoss: 0.544654\n",
            "Train epoch: 215 [100000/25046 (13%)]\tLoss: 0.278071\n",
            "Train epoch: 215 [119880/25046 (15%)]\tLoss: 0.360382\n",
            "Train epoch: 215 [149800/25046 (18%)]\tLoss: 1.313539\n",
            "Train epoch: 215 [161120/25046 (20%)]\tLoss: 0.854645\n",
            "Train epoch: 215 [181080/25046 (23%)]\tLoss: 0.577458\n",
            "Train epoch: 215 [204000/25046 (26%)]\tLoss: 1.168543\n",
            "Train epoch: 215 [238920/25046 (28%)]\tLoss: 0.241091\n",
            "Train epoch: 215 [255840/25046 (31%)]\tLoss: 1.122050\n",
            "Train epoch: 215 [266240/25046 (33%)]\tLoss: 1.100422\n",
            "Train epoch: 215 [286160/25046 (36%)]\tLoss: 0.581605\n",
            "Train epoch: 215 [305400/25046 (38%)]\tLoss: 0.368846\n",
            "Train epoch: 215 [352320/25046 (41%)]\tLoss: 1.050237\n",
            "Train epoch: 215 [345100/25046 (43%)]\tLoss: 0.700539\n",
            "Train epoch: 215 [376200/25046 (46%)]\tLoss: 1.379135\n",
            "Train epoch: 215 [368980/25046 (49%)]\tLoss: 1.256402\n",
            "Train epoch: 215 [432000/25046 (51%)]\tLoss: 0.282132\n",
            "Train epoch: 215 [438480/25046 (54%)]\tLoss: 0.450679\n",
            "Train epoch: 215 [447920/25046 (56%)]\tLoss: 1.097563\n",
            "Train epoch: 215 [486220/25046 (59%)]\tLoss: 0.493832\n",
            "Train epoch: 215 [500640/25046 (61%)]\tLoss: 0.794917\n",
            "Train epoch: 215 [540000/25046 (64%)]\tLoss: 0.472628\n",
            "Train epoch: 215 [545480/25046 (66%)]\tLoss: 0.388963\n",
            "Train epoch: 215 [565380/25046 (69%)]\tLoss: 0.654407\n",
            "Train epoch: 215 [616000/25046 (72%)]\tLoss: 0.888426\n",
            "Train epoch: 215 [567240/25046 (74%)]\tLoss: 1.026134\n",
            "Train epoch: 215 [582000/25046 (77%)]\tLoss: 0.959992\n",
            "Train epoch: 215 [661540/25046 (79%)]\tLoss: 0.726643\n",
            "Train epoch: 215 [693760/25046 (82%)]\tLoss: 1.182552\n",
            "Train epoch: 215 [657360/25046 (84%)]\tLoss: 0.574178\n",
            "Train epoch: 215 [688160/25046 (87%)]\tLoss: 0.845975\n",
            "Train epoch: 215 [693700/25046 (89%)]\tLoss: 0.528968\n",
            "Train epoch: 215 [705600/25046 (92%)]\tLoss: 0.548077\n",
            "Train epoch: 215 [765160/25046 (95%)]\tLoss: 0.663392\n",
            "Train epoch: 215 [788120/25046 (97%)]\tLoss: 0.925701\n",
            "Train epoch: 215 [790140/25046 (100%)]\tLoss: 1.084273\n",
            "Make prediction for 5010 samples...\n",
            "0.80612886 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 216 [0/25046 (0%)]\tLoss: 1.517629\n",
            "Train epoch: 216 [19440/25046 (3%)]\tLoss: 0.576020\n",
            "Train epoch: 216 [43080/25046 (5%)]\tLoss: 0.552845\n",
            "Train epoch: 216 [62940/25046 (8%)]\tLoss: 0.870371\n",
            "Train epoch: 216 [84400/25046 (10%)]\tLoss: 1.123000\n",
            "Train epoch: 216 [109900/25046 (13%)]\tLoss: 0.742823\n",
            "Train epoch: 216 [129720/25046 (15%)]\tLoss: 0.803877\n",
            "Train epoch: 216 [139860/25046 (18%)]\tLoss: 0.427369\n",
            "Train epoch: 216 [156160/25046 (20%)]\tLoss: 1.301618\n",
            "Train epoch: 216 [176040/25046 (23%)]\tLoss: 0.297014\n",
            "Train epoch: 216 [203400/25046 (26%)]\tLoss: 0.343433\n",
            "Train epoch: 216 [240680/25046 (28%)]\tLoss: 1.912999\n",
            "Train epoch: 216 [235200/25046 (31%)]\tLoss: 1.003923\n",
            "Train epoch: 216 [270140/25046 (33%)]\tLoss: 0.347408\n",
            "Train epoch: 216 [276080/25046 (36%)]\tLoss: 0.760946\n",
            "Train epoch: 216 [306900/25046 (38%)]\tLoss: 0.986461\n",
            "Train epoch: 216 [335040/25046 (41%)]\tLoss: 0.711095\n",
            "Train epoch: 216 [337280/25046 (43%)]\tLoss: 0.544943\n",
            "Train epoch: 216 [373680/25046 (46%)]\tLoss: 0.552720\n",
            "Train epoch: 216 [375440/25046 (49%)]\tLoss: 0.345060\n",
            "Train epoch: 216 [402400/25046 (51%)]\tLoss: 0.632535\n",
            "Train epoch: 216 [420420/25046 (54%)]\tLoss: 0.497545\n",
            "Train epoch: 216 [462000/25046 (56%)]\tLoss: 1.246608\n",
            "Train epoch: 216 [478400/25046 (59%)]\tLoss: 1.530831\n",
            "Train epoch: 216 [493920/25046 (61%)]\tLoss: 1.628184\n",
            "Train epoch: 216 [498000/25046 (64%)]\tLoss: 0.854718\n",
            "Train epoch: 216 [560040/25046 (66%)]\tLoss: 0.779120\n",
            "Train epoch: 216 [536220/25046 (69%)]\tLoss: 1.309986\n",
            "Train epoch: 216 [596400/25046 (72%)]\tLoss: 0.703593\n",
            "Train epoch: 216 [586960/25046 (74%)]\tLoss: 1.079835\n",
            "Train epoch: 216 [641400/25046 (77%)]\tLoss: 0.580655\n",
            "Train epoch: 216 [622480/25046 (79%)]\tLoss: 0.728132\n",
            "Train epoch: 216 [689280/25046 (82%)]\tLoss: 1.016919\n",
            "Train epoch: 216 [724020/25046 (84%)]\tLoss: 0.416565\n",
            "Train epoch: 216 [712640/25046 (87%)]\tLoss: 0.223569\n",
            "Train epoch: 216 [754600/25046 (89%)]\tLoss: 1.325937\n",
            "Train epoch: 216 [746640/25046 (92%)]\tLoss: 0.823642\n",
            "Train epoch: 216 [732600/25046 (95%)]\tLoss: 0.777877\n",
            "Train epoch: 216 [833720/25046 (97%)]\tLoss: 0.890175\n",
            "Train epoch: 216 [842400/25046 (100%)]\tLoss: 0.293379\n",
            "Make prediction for 5010 samples...\n",
            "0.80241823 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 217 [0/25046 (0%)]\tLoss: 0.208640\n",
            "Train epoch: 217 [19120/25046 (3%)]\tLoss: 0.652437\n",
            "Train epoch: 217 [42280/25046 (5%)]\tLoss: 0.798653\n",
            "Train epoch: 217 [63780/25046 (8%)]\tLoss: 0.790186\n",
            "Train epoch: 217 [79120/25046 (10%)]\tLoss: 0.281521\n",
            "Train epoch: 217 [103100/25046 (13%)]\tLoss: 0.230727\n",
            "Train epoch: 217 [118200/25046 (15%)]\tLoss: 0.923036\n",
            "Train epoch: 217 [148260/25046 (18%)]\tLoss: 0.595409\n",
            "Train epoch: 217 [172000/25046 (20%)]\tLoss: 0.533008\n",
            "Train epoch: 217 [185760/25046 (23%)]\tLoss: 0.793626\n",
            "Train epoch: 217 [204600/25046 (26%)]\tLoss: 0.848293\n",
            "Train epoch: 217 [225060/25046 (28%)]\tLoss: 0.718752\n",
            "Train epoch: 217 [243360/25046 (31%)]\tLoss: 1.115039\n",
            "Train epoch: 217 [267280/25046 (33%)]\tLoss: 0.387026\n",
            "Train epoch: 217 [302400/25046 (36%)]\tLoss: 0.301037\n",
            "Train epoch: 217 [315000/25046 (38%)]\tLoss: 1.842250\n",
            "Train epoch: 217 [306880/25046 (41%)]\tLoss: 1.366370\n",
            "Train epoch: 217 [341020/25046 (43%)]\tLoss: 0.817793\n",
            "Train epoch: 217 [367920/25046 (46%)]\tLoss: 0.719151\n",
            "Train epoch: 217 [377340/25046 (49%)]\tLoss: 0.754757\n",
            "Train epoch: 217 [418000/25046 (51%)]\tLoss: 0.575801\n",
            "Train epoch: 217 [426720/25046 (54%)]\tLoss: 0.670357\n",
            "Train epoch: 217 [461560/25046 (56%)]\tLoss: 0.717744\n",
            "Train epoch: 217 [464140/25046 (59%)]\tLoss: 0.306490\n",
            "Train epoch: 217 [479520/25046 (61%)]\tLoss: 0.464418\n",
            "Train epoch: 217 [508500/25046 (64%)]\tLoss: 0.538795\n",
            "Train epoch: 217 [541840/25046 (66%)]\tLoss: 0.445883\n",
            "Train epoch: 217 [536760/25046 (69%)]\tLoss: 1.037871\n",
            "Train epoch: 217 [576800/25046 (72%)]\tLoss: 0.777439\n",
            "Train epoch: 217 [620600/25046 (74%)]\tLoss: 0.891589\n",
            "Train epoch: 217 [585600/25046 (77%)]\tLoss: 0.388761\n",
            "Train epoch: 217 [626200/25046 (79%)]\tLoss: 1.125103\n",
            "Train epoch: 217 [682880/25046 (82%)]\tLoss: 0.300583\n",
            "Train epoch: 217 [669900/25046 (84%)]\tLoss: 0.680690\n",
            "Train epoch: 217 [703120/25046 (87%)]\tLoss: 0.535260\n",
            "Train epoch: 217 [751100/25046 (89%)]\tLoss: 0.529851\n",
            "Train epoch: 217 [722880/25046 (92%)]\tLoss: 0.596965\n",
            "Train epoch: 217 [765900/25046 (95%)]\tLoss: 0.921771\n",
            "Train epoch: 217 [756200/25046 (97%)]\tLoss: 1.372548\n",
            "Train epoch: 217 [791700/25046 (100%)]\tLoss: 1.156442\n",
            "Make prediction for 5010 samples...\n",
            "0.81298035 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 218 [0/25046 (0%)]\tLoss: 0.810282\n",
            "Train epoch: 218 [20940/25046 (3%)]\tLoss: 0.566092\n",
            "Train epoch: 218 [43800/25046 (5%)]\tLoss: 1.124785\n",
            "Train epoch: 218 [61980/25046 (8%)]\tLoss: 1.083113\n",
            "Train epoch: 218 [82160/25046 (10%)]\tLoss: 0.964456\n",
            "Train epoch: 218 [109000/25046 (13%)]\tLoss: 0.870571\n",
            "Train epoch: 218 [126960/25046 (15%)]\tLoss: 0.632966\n",
            "Train epoch: 218 [147560/25046 (18%)]\tLoss: 1.022285\n",
            "Train epoch: 218 [162080/25046 (20%)]\tLoss: 0.664873\n",
            "Train epoch: 218 [183060/25046 (23%)]\tLoss: 0.833396\n",
            "Train epoch: 218 [195600/25046 (26%)]\tLoss: 0.603700\n",
            "Train epoch: 218 [216480/25046 (28%)]\tLoss: 0.293297\n",
            "Train epoch: 218 [237360/25046 (31%)]\tLoss: 0.432222\n",
            "Train epoch: 218 [250380/25046 (33%)]\tLoss: 0.341892\n",
            "Train epoch: 218 [293440/25046 (36%)]\tLoss: 0.865746\n",
            "Train epoch: 218 [304500/25046 (38%)]\tLoss: 0.404045\n",
            "Train epoch: 218 [333440/25046 (41%)]\tLoss: 0.342624\n",
            "Train epoch: 218 [352240/25046 (43%)]\tLoss: 1.363096\n",
            "Train epoch: 218 [359280/25046 (46%)]\tLoss: 0.487094\n",
            "Train epoch: 218 [384180/25046 (49%)]\tLoss: 0.720383\n",
            "Train epoch: 218 [390400/25046 (51%)]\tLoss: 1.134887\n",
            "Train epoch: 218 [430920/25046 (54%)]\tLoss: 0.694893\n",
            "Train epoch: 218 [435600/25046 (56%)]\tLoss: 0.689206\n",
            "Train epoch: 218 [463220/25046 (59%)]\tLoss: 1.677580\n",
            "Train epoch: 218 [509760/25046 (61%)]\tLoss: 1.474599\n",
            "Train epoch: 218 [497000/25046 (64%)]\tLoss: 0.310371\n",
            "Train epoch: 218 [532480/25046 (66%)]\tLoss: 0.678318\n",
            "Train epoch: 218 [552420/25046 (69%)]\tLoss: 0.840325\n",
            "Train epoch: 218 [557200/25046 (72%)]\tLoss: 1.230035\n",
            "Train epoch: 218 [566080/25046 (74%)]\tLoss: 0.528017\n",
            "Train epoch: 218 [637800/25046 (77%)]\tLoss: 0.901100\n",
            "Train epoch: 218 [679520/25046 (79%)]\tLoss: 0.772697\n",
            "Train epoch: 218 [620160/25046 (82%)]\tLoss: 0.335207\n",
            "Train epoch: 218 [696960/25046 (84%)]\tLoss: 0.917872\n",
            "Train epoch: 218 [675920/25046 (87%)]\tLoss: 1.159166\n",
            "Train epoch: 218 [723100/25046 (89%)]\tLoss: 1.366751\n",
            "Train epoch: 218 [742320/25046 (92%)]\tLoss: 1.033541\n",
            "Train epoch: 218 [711880/25046 (95%)]\tLoss: 0.535569\n",
            "Train epoch: 218 [763800/25046 (97%)]\tLoss: 0.576703\n",
            "Train epoch: 218 [806520/25046 (100%)]\tLoss: 0.790991\n",
            "Make prediction for 5010 samples...\n",
            "0.8018433 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 219 [0/25046 (0%)]\tLoss: 1.832745\n",
            "Train epoch: 219 [21280/25046 (3%)]\tLoss: 0.452989\n",
            "Train epoch: 219 [42560/25046 (5%)]\tLoss: 0.733008\n",
            "Train epoch: 219 [65040/25046 (8%)]\tLoss: 0.923979\n",
            "Train epoch: 219 [88960/25046 (10%)]\tLoss: 1.058171\n",
            "Train epoch: 219 [107400/25046 (13%)]\tLoss: 0.188136\n",
            "Train epoch: 219 [125160/25046 (15%)]\tLoss: 1.210207\n",
            "Train epoch: 219 [143360/25046 (18%)]\tLoss: 0.602149\n",
            "Train epoch: 219 [160800/25046 (20%)]\tLoss: 0.391726\n",
            "Train epoch: 219 [181800/25046 (23%)]\tLoss: 0.884185\n",
            "Train epoch: 219 [199600/25046 (26%)]\tLoss: 0.264971\n",
            "Train epoch: 219 [236940/25046 (28%)]\tLoss: 0.701587\n",
            "Train epoch: 219 [246000/25046 (31%)]\tLoss: 1.352914\n",
            "Train epoch: 219 [262860/25046 (33%)]\tLoss: 0.516642\n",
            "Train epoch: 219 [290640/25046 (36%)]\tLoss: 0.818988\n",
            "Train epoch: 219 [291900/25046 (38%)]\tLoss: 0.542740\n",
            "Train epoch: 219 [321600/25046 (41%)]\tLoss: 0.876414\n",
            "Train epoch: 219 [337960/25046 (43%)]\tLoss: 0.340719\n",
            "Train epoch: 219 [382680/25046 (46%)]\tLoss: 0.640059\n",
            "Train epoch: 219 [374300/25046 (49%)]\tLoss: 0.376497\n",
            "Train epoch: 219 [418000/25046 (51%)]\tLoss: 0.673329\n",
            "Train epoch: 219 [450660/25046 (54%)]\tLoss: 0.540978\n",
            "Train epoch: 219 [440880/25046 (56%)]\tLoss: 0.785822\n",
            "Train epoch: 219 [500480/25046 (59%)]\tLoss: 0.579342\n",
            "Train epoch: 219 [510240/25046 (61%)]\tLoss: 1.070968\n",
            "Train epoch: 219 [509000/25046 (64%)]\tLoss: 1.773677\n",
            "Train epoch: 219 [538200/25046 (66%)]\tLoss: 1.698175\n",
            "Train epoch: 219 [545940/25046 (69%)]\tLoss: 0.513240\n",
            "Train epoch: 219 [539840/25046 (72%)]\tLoss: 0.251297\n",
            "Train epoch: 219 [591020/25046 (74%)]\tLoss: 0.425837\n",
            "Train epoch: 219 [635400/25046 (77%)]\tLoss: 1.513883\n",
            "Train epoch: 219 [631160/25046 (79%)]\tLoss: 0.953752\n",
            "Train epoch: 219 [626560/25046 (82%)]\tLoss: 1.646575\n",
            "Train epoch: 219 [635580/25046 (84%)]\tLoss: 0.583848\n",
            "Train epoch: 219 [721480/25046 (87%)]\tLoss: 0.733858\n",
            "Train epoch: 219 [728700/25046 (89%)]\tLoss: 0.702196\n",
            "Train epoch: 219 [703440/25046 (92%)]\tLoss: 0.747466\n",
            "Train epoch: 219 [810300/25046 (95%)]\tLoss: 0.625934\n",
            "Train epoch: 219 [792680/25046 (97%)]\tLoss: 0.988075\n",
            "Train epoch: 219 [818220/25046 (100%)]\tLoss: 1.961308\n",
            "Make prediction for 5010 samples...\n",
            "0.80204904 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 220 [0/25046 (0%)]\tLoss: 0.316696\n",
            "Train epoch: 220 [20540/25046 (3%)]\tLoss: 1.036936\n",
            "Train epoch: 220 [36520/25046 (5%)]\tLoss: 0.609080\n",
            "Train epoch: 220 [60180/25046 (8%)]\tLoss: 0.628668\n",
            "Train epoch: 220 [78960/25046 (10%)]\tLoss: 1.242515\n",
            "Train epoch: 220 [98900/25046 (13%)]\tLoss: 0.553772\n",
            "Train epoch: 220 [126240/25046 (15%)]\tLoss: 0.797349\n",
            "Train epoch: 220 [129780/25046 (18%)]\tLoss: 0.191562\n",
            "Train epoch: 220 [156800/25046 (20%)]\tLoss: 0.393995\n",
            "Train epoch: 220 [189180/25046 (23%)]\tLoss: 1.217548\n",
            "Train epoch: 220 [207200/25046 (26%)]\tLoss: 0.899580\n",
            "Train epoch: 220 [222420/25046 (28%)]\tLoss: 0.832926\n",
            "Train epoch: 220 [240960/25046 (31%)]\tLoss: 0.845974\n",
            "Train epoch: 220 [270400/25046 (33%)]\tLoss: 0.674823\n",
            "Train epoch: 220 [299040/25046 (36%)]\tLoss: 0.400438\n",
            "Train epoch: 220 [317400/25046 (38%)]\tLoss: 1.206744\n",
            "Train epoch: 220 [319040/25046 (41%)]\tLoss: 1.731007\n",
            "Train epoch: 220 [372980/25046 (43%)]\tLoss: 0.801370\n",
            "Train epoch: 220 [366840/25046 (46%)]\tLoss: 0.759917\n",
            "Train epoch: 220 [405460/25046 (49%)]\tLoss: 1.364423\n",
            "Train epoch: 220 [408000/25046 (51%)]\tLoss: 0.496611\n",
            "Train epoch: 220 [416220/25046 (54%)]\tLoss: 1.497184\n",
            "Train epoch: 220 [465960/25046 (56%)]\tLoss: 0.815149\n",
            "Train epoch: 220 [470580/25046 (59%)]\tLoss: 0.449268\n",
            "Train epoch: 220 [521280/25046 (61%)]\tLoss: 0.645029\n",
            "Train epoch: 220 [535500/25046 (64%)]\tLoss: 0.553170\n",
            "Train epoch: 220 [530920/25046 (66%)]\tLoss: 0.458549\n",
            "Train epoch: 220 [559980/25046 (69%)]\tLoss: 1.508272\n",
            "Train epoch: 220 [595840/25046 (72%)]\tLoss: 0.967657\n",
            "Train epoch: 220 [595660/25046 (74%)]\tLoss: 0.741735\n",
            "Train epoch: 220 [597000/25046 (77%)]\tLoss: 0.365366\n",
            "Train epoch: 220 [646660/25046 (79%)]\tLoss: 0.705794\n",
            "Train epoch: 220 [643200/25046 (82%)]\tLoss: 0.627047\n",
            "Train epoch: 220 [667260/25046 (84%)]\tLoss: 0.688159\n",
            "Train epoch: 220 [678640/25046 (87%)]\tLoss: 1.195625\n",
            "Train epoch: 220 [723100/25046 (89%)]\tLoss: 1.101536\n",
            "Train epoch: 220 [691200/25046 (92%)]\tLoss: 0.345363\n",
            "Train epoch: 220 [766640/25046 (95%)]\tLoss: 0.674186\n",
            "Train epoch: 220 [758480/25046 (97%)]\tLoss: 1.409816\n",
            "Train epoch: 220 [822900/25046 (100%)]\tLoss: 0.865318\n",
            "Make prediction for 5010 samples...\n",
            "0.80198497 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 221 [0/25046 (0%)]\tLoss: 0.289186\n",
            "Train epoch: 221 [20980/25046 (3%)]\tLoss: 0.350681\n",
            "Train epoch: 221 [40080/25046 (5%)]\tLoss: 0.676868\n",
            "Train epoch: 221 [58440/25046 (8%)]\tLoss: 0.654743\n",
            "Train epoch: 221 [79760/25046 (10%)]\tLoss: 1.508704\n",
            "Train epoch: 221 [102300/25046 (13%)]\tLoss: 0.983873\n",
            "Train epoch: 221 [122160/25046 (15%)]\tLoss: 1.682851\n",
            "Train epoch: 221 [143500/25046 (18%)]\tLoss: 0.853127\n",
            "Train epoch: 221 [172640/25046 (20%)]\tLoss: 0.335325\n",
            "Train epoch: 221 [196020/25046 (23%)]\tLoss: 0.554040\n",
            "Train epoch: 221 [198800/25046 (26%)]\tLoss: 0.289133\n",
            "Train epoch: 221 [205920/25046 (28%)]\tLoss: 1.092290\n",
            "Train epoch: 221 [248880/25046 (31%)]\tLoss: 0.776600\n",
            "Train epoch: 221 [251680/25046 (33%)]\tLoss: 2.056950\n",
            "Train epoch: 221 [281960/25046 (36%)]\tLoss: 1.132635\n",
            "Train epoch: 221 [314100/25046 (38%)]\tLoss: 0.609055\n",
            "Train epoch: 221 [353920/25046 (41%)]\tLoss: 0.469711\n",
            "Train epoch: 221 [351900/25046 (43%)]\tLoss: 0.504973\n",
            "Train epoch: 221 [367920/25046 (46%)]\tLoss: 0.547394\n",
            "Train epoch: 221 [413820/25046 (49%)]\tLoss: 0.324445\n",
            "Train epoch: 221 [396000/25046 (51%)]\tLoss: 0.535561\n",
            "Train epoch: 221 [435120/25046 (54%)]\tLoss: 1.328950\n",
            "Train epoch: 221 [446600/25046 (56%)]\tLoss: 0.350125\n",
            "Train epoch: 221 [475640/25046 (59%)]\tLoss: 0.414229\n",
            "Train epoch: 221 [485760/25046 (61%)]\tLoss: 0.355544\n",
            "Train epoch: 221 [520000/25046 (64%)]\tLoss: 1.135867\n",
            "Train epoch: 221 [541320/25046 (66%)]\tLoss: 1.281912\n",
            "Train epoch: 221 [591840/25046 (69%)]\tLoss: 1.417064\n",
            "Train epoch: 221 [603120/25046 (72%)]\tLoss: 1.507066\n",
            "Train epoch: 221 [598560/25046 (74%)]\tLoss: 1.907394\n",
            "Train epoch: 221 [651000/25046 (77%)]\tLoss: 1.317650\n",
            "Train epoch: 221 [677040/25046 (79%)]\tLoss: 1.432537\n",
            "Train epoch: 221 [634240/25046 (82%)]\tLoss: 1.158498\n",
            "Train epoch: 221 [689700/25046 (84%)]\tLoss: 1.114095\n",
            "Train epoch: 221 [679320/25046 (87%)]\tLoss: 0.715404\n",
            "Train epoch: 221 [717500/25046 (89%)]\tLoss: 0.719118\n",
            "Train epoch: 221 [761040/25046 (92%)]\tLoss: 0.299650\n",
            "Train epoch: 221 [752580/25046 (95%)]\tLoss: 0.601737\n",
            "Train epoch: 221 [803320/25046 (97%)]\tLoss: 0.283310\n",
            "Train epoch: 221 [795600/25046 (100%)]\tLoss: 0.564633\n",
            "Make prediction for 5010 samples...\n",
            "0.80416054 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 222 [0/25046 (0%)]\tLoss: 0.866192\n",
            "Train epoch: 222 [21180/25046 (3%)]\tLoss: 0.419330\n",
            "Train epoch: 222 [42760/25046 (5%)]\tLoss: 1.360190\n",
            "Train epoch: 222 [63240/25046 (8%)]\tLoss: 1.186944\n",
            "Train epoch: 222 [82240/25046 (10%)]\tLoss: 0.454125\n",
            "Train epoch: 222 [104100/25046 (13%)]\tLoss: 0.516589\n",
            "Train epoch: 222 [125640/25046 (15%)]\tLoss: 0.961605\n",
            "Train epoch: 222 [140280/25046 (18%)]\tLoss: 0.277553\n",
            "Train epoch: 222 [163520/25046 (20%)]\tLoss: 0.921570\n",
            "Train epoch: 222 [176760/25046 (23%)]\tLoss: 1.085411\n",
            "Train epoch: 222 [208400/25046 (26%)]\tLoss: 0.551567\n",
            "Train epoch: 222 [220000/25046 (28%)]\tLoss: 1.829156\n",
            "Train epoch: 222 [256320/25046 (31%)]\tLoss: 2.340456\n",
            "Train epoch: 222 [269360/25046 (33%)]\tLoss: 1.164562\n",
            "Train epoch: 222 [284760/25046 (36%)]\tLoss: 1.359938\n",
            "Train epoch: 222 [303900/25046 (38%)]\tLoss: 1.781369\n",
            "Train epoch: 222 [317120/25046 (41%)]\tLoss: 0.667858\n",
            "Train epoch: 222 [351220/25046 (43%)]\tLoss: 0.849095\n",
            "Train epoch: 222 [367560/25046 (46%)]\tLoss: 0.976395\n",
            "Train epoch: 222 [372400/25046 (49%)]\tLoss: 0.588811\n",
            "Train epoch: 222 [412000/25046 (51%)]\tLoss: 0.535149\n",
            "Train epoch: 222 [448980/25046 (54%)]\tLoss: 0.676568\n",
            "Train epoch: 222 [431200/25046 (56%)]\tLoss: 0.396999\n",
            "Train epoch: 222 [500480/25046 (59%)]\tLoss: 1.075557\n",
            "Train epoch: 222 [493920/25046 (61%)]\tLoss: 0.582543\n",
            "Train epoch: 222 [494000/25046 (64%)]\tLoss: 1.268845\n",
            "Train epoch: 222 [492960/25046 (66%)]\tLoss: 0.635927\n",
            "Train epoch: 222 [534600/25046 (69%)]\tLoss: 0.665544\n",
            "Train epoch: 222 [553840/25046 (72%)]\tLoss: 0.291955\n",
            "Train epoch: 222 [581160/25046 (74%)]\tLoss: 0.499549\n",
            "Train epoch: 222 [636000/25046 (77%)]\tLoss: 0.927130\n",
            "Train epoch: 222 [682620/25046 (79%)]\tLoss: 0.431796\n",
            "Train epoch: 222 [652160/25046 (82%)]\tLoss: 0.290615\n",
            "Train epoch: 222 [673200/25046 (84%)]\tLoss: 0.763996\n",
            "Train epoch: 222 [676600/25046 (87%)]\tLoss: 0.418781\n",
            "Train epoch: 222 [711900/25046 (89%)]\tLoss: 0.761020\n",
            "Train epoch: 222 [817920/25046 (92%)]\tLoss: 0.720560\n",
            "Train epoch: 222 [761460/25046 (95%)]\tLoss: 0.717267\n",
            "Train epoch: 222 [735680/25046 (97%)]\tLoss: 0.337573\n",
            "Train epoch: 222 [779220/25046 (100%)]\tLoss: 0.274748\n",
            "Make prediction for 5010 samples...\n",
            "0.80153555 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 223 [0/25046 (0%)]\tLoss: 0.966079\n",
            "Train epoch: 223 [21180/25046 (3%)]\tLoss: 0.617326\n",
            "Train epoch: 223 [43400/25046 (5%)]\tLoss: 0.432450\n",
            "Train epoch: 223 [62340/25046 (8%)]\tLoss: 0.427625\n",
            "Train epoch: 223 [78960/25046 (10%)]\tLoss: 0.442221\n",
            "Train epoch: 223 [101000/25046 (13%)]\tLoss: 0.480318\n",
            "Train epoch: 223 [124680/25046 (15%)]\tLoss: 1.155496\n",
            "Train epoch: 223 [143220/25046 (18%)]\tLoss: 1.547082\n",
            "Train epoch: 223 [158720/25046 (20%)]\tLoss: 1.201911\n",
            "Train epoch: 223 [177660/25046 (23%)]\tLoss: 0.504470\n",
            "Train epoch: 223 [198600/25046 (26%)]\tLoss: 0.890205\n",
            "Train epoch: 223 [223080/25046 (28%)]\tLoss: 0.367975\n",
            "Train epoch: 223 [242400/25046 (31%)]\tLoss: 1.253095\n",
            "Train epoch: 223 [269100/25046 (33%)]\tLoss: 0.781962\n",
            "Train epoch: 223 [295680/25046 (36%)]\tLoss: 1.215445\n",
            "Train epoch: 223 [310800/25046 (38%)]\tLoss: 0.437154\n",
            "Train epoch: 223 [336960/25046 (41%)]\tLoss: 0.491650\n",
            "Train epoch: 223 [350880/25046 (43%)]\tLoss: 0.869434\n",
            "Train epoch: 223 [365400/25046 (46%)]\tLoss: 1.723841\n",
            "Train epoch: 223 [395200/25046 (49%)]\tLoss: 0.690648\n",
            "Train epoch: 223 [425200/25046 (51%)]\tLoss: 0.372905\n",
            "Train epoch: 223 [452340/25046 (54%)]\tLoss: 0.913871\n",
            "Train epoch: 223 [440000/25046 (56%)]\tLoss: 0.892549\n",
            "Train epoch: 223 [455400/25046 (59%)]\tLoss: 0.886486\n",
            "Train epoch: 223 [486240/25046 (61%)]\tLoss: 0.770277\n",
            "Train epoch: 223 [528000/25046 (64%)]\tLoss: 0.374870\n",
            "Train epoch: 223 [530920/25046 (66%)]\tLoss: 0.542120\n",
            "Train epoch: 223 [525960/25046 (69%)]\tLoss: 0.692917\n",
            "Train epoch: 223 [591360/25046 (72%)]\tLoss: 0.597557\n",
            "Train epoch: 223 [627560/25046 (74%)]\tLoss: 1.166183\n",
            "Train epoch: 223 [632400/25046 (77%)]\tLoss: 0.729252\n",
            "Train epoch: 223 [628680/25046 (79%)]\tLoss: 0.508606\n",
            "Train epoch: 223 [650240/25046 (82%)]\tLoss: 0.624664\n",
            "Train epoch: 223 [683100/25046 (84%)]\tLoss: 0.688694\n",
            "Train epoch: 223 [738480/25046 (87%)]\tLoss: 0.219358\n",
            "Train epoch: 223 [690900/25046 (89%)]\tLoss: 0.316666\n",
            "Train epoch: 223 [735840/25046 (92%)]\tLoss: 0.534928\n",
            "Train epoch: 223 [778480/25046 (95%)]\tLoss: 1.232156\n",
            "Train epoch: 223 [738720/25046 (97%)]\tLoss: 0.373369\n",
            "Train epoch: 223 [860340/25046 (100%)]\tLoss: 0.675184\n",
            "Make prediction for 5010 samples...\n",
            "0.8017573 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 224 [0/25046 (0%)]\tLoss: 0.567844\n",
            "Train epoch: 224 [19680/25046 (3%)]\tLoss: 1.145490\n",
            "Train epoch: 224 [41840/25046 (5%)]\tLoss: 0.367519\n",
            "Train epoch: 224 [62640/25046 (8%)]\tLoss: 1.354908\n",
            "Train epoch: 224 [81760/25046 (10%)]\tLoss: 0.314561\n",
            "Train epoch: 224 [102100/25046 (13%)]\tLoss: 0.430229\n",
            "Train epoch: 224 [120000/25046 (15%)]\tLoss: 1.121248\n",
            "Train epoch: 224 [150220/25046 (18%)]\tLoss: 1.260705\n",
            "Train epoch: 224 [155360/25046 (20%)]\tLoss: 0.881015\n",
            "Train epoch: 224 [175320/25046 (23%)]\tLoss: 0.750975\n",
            "Train epoch: 224 [202000/25046 (26%)]\tLoss: 0.713879\n",
            "Train epoch: 224 [224180/25046 (28%)]\tLoss: 0.307965\n",
            "Train epoch: 224 [243120/25046 (31%)]\tLoss: 0.250991\n",
            "Train epoch: 224 [263640/25046 (33%)]\tLoss: 0.830525\n",
            "Train epoch: 224 [298200/25046 (36%)]\tLoss: 0.955287\n",
            "Train epoch: 224 [316500/25046 (38%)]\tLoss: 1.128702\n",
            "Train epoch: 224 [314880/25046 (41%)]\tLoss: 0.718791\n",
            "Train epoch: 224 [373660/25046 (43%)]\tLoss: 0.861992\n",
            "Train epoch: 224 [388800/25046 (46%)]\tLoss: 1.178116\n",
            "Train epoch: 224 [411160/25046 (49%)]\tLoss: 1.429930\n",
            "Train epoch: 224 [410400/25046 (51%)]\tLoss: 0.843743\n",
            "Train epoch: 224 [433860/25046 (54%)]\tLoss: 0.664891\n",
            "Train epoch: 224 [441760/25046 (56%)]\tLoss: 1.213152\n",
            "Train epoch: 224 [474260/25046 (59%)]\tLoss: 0.711538\n",
            "Train epoch: 224 [496320/25046 (61%)]\tLoss: 0.624882\n",
            "Train epoch: 224 [517500/25046 (64%)]\tLoss: 1.020831\n",
            "Train epoch: 224 [534560/25046 (66%)]\tLoss: 0.557978\n",
            "Train epoch: 224 [564300/25046 (69%)]\tLoss: 0.842774\n",
            "Train epoch: 224 [560000/25046 (72%)]\tLoss: 0.853883\n",
            "Train epoch: 224 [614220/25046 (74%)]\tLoss: 0.597757\n",
            "Train epoch: 224 [670800/25046 (77%)]\tLoss: 0.592765\n",
            "Train epoch: 224 [628060/25046 (79%)]\tLoss: 0.396210\n",
            "Train epoch: 224 [638720/25046 (82%)]\tLoss: 0.584455\n",
            "Train epoch: 224 [665280/25046 (84%)]\tLoss: 1.789990\n",
            "Train epoch: 224 [713320/25046 (87%)]\tLoss: 0.996415\n",
            "Train epoch: 224 [700000/25046 (89%)]\tLoss: 0.799768\n",
            "Train epoch: 224 [720720/25046 (92%)]\tLoss: 0.307004\n",
            "Train epoch: 224 [733340/25046 (95%)]\tLoss: 1.833217\n",
            "Train epoch: 224 [816240/25046 (97%)]\tLoss: 0.682234\n",
            "Train epoch: 224 [790920/25046 (100%)]\tLoss: 0.661181\n",
            "Make prediction for 5010 samples...\n",
            "0.8015776 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 225 [0/25046 (0%)]\tLoss: 1.186884\n",
            "Train epoch: 225 [19820/25046 (3%)]\tLoss: 1.194313\n",
            "Train epoch: 225 [44240/25046 (5%)]\tLoss: 1.047591\n",
            "Train epoch: 225 [62100/25046 (8%)]\tLoss: 0.429653\n",
            "Train epoch: 225 [85760/25046 (10%)]\tLoss: 0.659458\n",
            "Train epoch: 225 [105300/25046 (13%)]\tLoss: 0.642668\n",
            "Train epoch: 225 [116640/25046 (15%)]\tLoss: 0.423986\n",
            "Train epoch: 225 [149100/25046 (18%)]\tLoss: 1.372140\n",
            "Train epoch: 225 [162240/25046 (20%)]\tLoss: 0.573224\n",
            "Train epoch: 225 [192060/25046 (23%)]\tLoss: 0.574672\n",
            "Train epoch: 225 [198200/25046 (26%)]\tLoss: 0.583247\n",
            "Train epoch: 225 [218460/25046 (28%)]\tLoss: 0.244789\n",
            "Train epoch: 225 [242880/25046 (31%)]\tLoss: 1.054868\n",
            "Train epoch: 225 [260260/25046 (33%)]\tLoss: 0.617763\n",
            "Train epoch: 225 [279160/25046 (36%)]\tLoss: 1.357571\n",
            "Train epoch: 225 [316200/25046 (38%)]\tLoss: 0.877482\n",
            "Train epoch: 225 [321280/25046 (41%)]\tLoss: 0.650154\n",
            "Train epoch: 225 [374000/25046 (43%)]\tLoss: 0.404036\n",
            "Train epoch: 225 [358200/25046 (46%)]\tLoss: 0.991814\n",
            "Train epoch: 225 [399760/25046 (49%)]\tLoss: 1.078787\n",
            "Train epoch: 225 [401600/25046 (51%)]\tLoss: 1.014734\n",
            "Train epoch: 225 [420000/25046 (54%)]\tLoss: 0.523372\n",
            "Train epoch: 225 [467280/25046 (56%)]\tLoss: 0.555493\n",
            "Train epoch: 225 [454480/25046 (59%)]\tLoss: 0.811789\n",
            "Train epoch: 225 [464160/25046 (61%)]\tLoss: 0.479672\n",
            "Train epoch: 225 [484500/25046 (64%)]\tLoss: 0.289023\n",
            "Train epoch: 225 [553280/25046 (66%)]\tLoss: 0.988812\n",
            "Train epoch: 225 [544860/25046 (69%)]\tLoss: 0.437250\n",
            "Train epoch: 225 [586320/25046 (72%)]\tLoss: 1.284791\n",
            "Train epoch: 225 [620020/25046 (74%)]\tLoss: 0.764664\n",
            "Train epoch: 225 [583800/25046 (77%)]\tLoss: 0.792762\n",
            "Train epoch: 225 [654100/25046 (79%)]\tLoss: 0.354173\n",
            "Train epoch: 225 [677120/25046 (82%)]\tLoss: 0.858590\n",
            "Train epoch: 225 [708180/25046 (84%)]\tLoss: 0.357763\n",
            "Train epoch: 225 [660960/25046 (87%)]\tLoss: 0.766194\n",
            "Train epoch: 225 [751100/25046 (89%)]\tLoss: 1.002685\n",
            "Train epoch: 225 [707760/25046 (92%)]\tLoss: 0.672028\n",
            "Train epoch: 225 [743700/25046 (95%)]\tLoss: 1.449693\n",
            "Train epoch: 225 [794200/25046 (97%)]\tLoss: 0.552360\n",
            "Train epoch: 225 [830700/25046 (100%)]\tLoss: 0.412012\n",
            "Make prediction for 5010 samples...\n",
            "0.801849 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 226 [0/25046 (0%)]\tLoss: 0.876632\n",
            "Train epoch: 226 [20060/25046 (3%)]\tLoss: 0.453430\n",
            "Train epoch: 226 [40680/25046 (5%)]\tLoss: 0.599129\n",
            "Train epoch: 226 [58680/25046 (8%)]\tLoss: 0.439143\n",
            "Train epoch: 226 [82800/25046 (10%)]\tLoss: 0.866582\n",
            "Train epoch: 226 [96900/25046 (13%)]\tLoss: 0.467717\n",
            "Train epoch: 226 [123720/25046 (15%)]\tLoss: 0.845135\n",
            "Train epoch: 226 [144620/25046 (18%)]\tLoss: 0.694235\n",
            "Train epoch: 226 [165920/25046 (20%)]\tLoss: 1.004894\n",
            "Train epoch: 226 [177480/25046 (23%)]\tLoss: 0.613229\n",
            "Train epoch: 226 [195000/25046 (26%)]\tLoss: 0.822575\n",
            "Train epoch: 226 [218240/25046 (28%)]\tLoss: 0.629374\n",
            "Train epoch: 226 [239760/25046 (31%)]\tLoss: 0.447417\n",
            "Train epoch: 226 [263640/25046 (33%)]\tLoss: 1.294289\n",
            "Train epoch: 226 [290920/25046 (36%)]\tLoss: 0.486217\n",
            "Train epoch: 226 [301200/25046 (38%)]\tLoss: 0.679840\n",
            "Train epoch: 226 [326400/25046 (41%)]\tLoss: 0.678147\n",
            "Train epoch: 226 [331160/25046 (43%)]\tLoss: 0.633132\n",
            "Train epoch: 226 [363960/25046 (46%)]\tLoss: 0.736771\n",
            "Train epoch: 226 [374680/25046 (49%)]\tLoss: 0.764018\n",
            "Train epoch: 226 [402000/25046 (51%)]\tLoss: 0.922938\n",
            "Train epoch: 226 [441000/25046 (54%)]\tLoss: 1.188632\n",
            "Train epoch: 226 [454080/25046 (56%)]\tLoss: 0.905549\n",
            "Train epoch: 226 [487140/25046 (59%)]\tLoss: 0.352344\n",
            "Train epoch: 226 [454080/25046 (61%)]\tLoss: 0.655941\n",
            "Train epoch: 226 [496000/25046 (64%)]\tLoss: 0.650725\n",
            "Train epoch: 226 [494520/25046 (66%)]\tLoss: 0.441640\n",
            "Train epoch: 226 [541080/25046 (69%)]\tLoss: 0.797969\n",
            "Train epoch: 226 [558880/25046 (72%)]\tLoss: 1.103058\n",
            "Train epoch: 226 [570720/25046 (74%)]\tLoss: 0.427501\n",
            "Train epoch: 226 [641400/25046 (77%)]\tLoss: 0.375054\n",
            "Train epoch: 226 [633640/25046 (79%)]\tLoss: 0.912392\n",
            "Train epoch: 226 [679040/25046 (82%)]\tLoss: 0.758387\n",
            "Train epoch: 226 [649440/25046 (84%)]\tLoss: 0.441663\n",
            "Train epoch: 226 [709920/25046 (87%)]\tLoss: 0.865432\n",
            "Train epoch: 226 [681800/25046 (89%)]\tLoss: 0.635738\n",
            "Train epoch: 226 [761040/25046 (92%)]\tLoss: 0.392743\n",
            "Train epoch: 226 [756280/25046 (95%)]\tLoss: 0.410981\n",
            "Train epoch: 226 [774440/25046 (97%)]\tLoss: 0.860764\n",
            "Train epoch: 226 [763620/25046 (100%)]\tLoss: 1.437182\n",
            "Make prediction for 5010 samples...\n",
            "0.8052527 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 227 [0/25046 (0%)]\tLoss: 1.215455\n",
            "Train epoch: 227 [20120/25046 (3%)]\tLoss: 1.096174\n",
            "Train epoch: 227 [39560/25046 (5%)]\tLoss: 0.299151\n",
            "Train epoch: 227 [59520/25046 (8%)]\tLoss: 0.720174\n",
            "Train epoch: 227 [82400/25046 (10%)]\tLoss: 1.265141\n",
            "Train epoch: 227 [99300/25046 (13%)]\tLoss: 0.824202\n",
            "Train epoch: 227 [126960/25046 (15%)]\tLoss: 0.430573\n",
            "Train epoch: 227 [143780/25046 (18%)]\tLoss: 0.829775\n",
            "Train epoch: 227 [163520/25046 (20%)]\tLoss: 0.971993\n",
            "Train epoch: 227 [170640/25046 (23%)]\tLoss: 0.144749\n",
            "Train epoch: 227 [190000/25046 (26%)]\tLoss: 0.268861\n",
            "Train epoch: 227 [226600/25046 (28%)]\tLoss: 0.839585\n",
            "Train epoch: 227 [250320/25046 (31%)]\tLoss: 0.769801\n",
            "Train epoch: 227 [274040/25046 (33%)]\tLoss: 0.693935\n",
            "Train epoch: 227 [272160/25046 (36%)]\tLoss: 1.049963\n",
            "Train epoch: 227 [294300/25046 (38%)]\tLoss: 1.510873\n",
            "Train epoch: 227 [328960/25046 (41%)]\tLoss: 0.562667\n",
            "Train epoch: 227 [349520/25046 (43%)]\tLoss: 0.959279\n",
            "Train epoch: 227 [361440/25046 (46%)]\tLoss: 1.377049\n",
            "Train epoch: 227 [372780/25046 (49%)]\tLoss: 0.660335\n",
            "Train epoch: 227 [414400/25046 (51%)]\tLoss: 0.671822\n",
            "Train epoch: 227 [450660/25046 (54%)]\tLoss: 0.542149\n",
            "Train epoch: 227 [450120/25046 (56%)]\tLoss: 0.333988\n",
            "Train epoch: 227 [457240/25046 (59%)]\tLoss: 0.839342\n",
            "Train epoch: 227 [499200/25046 (61%)]\tLoss: 0.652369\n",
            "Train epoch: 227 [500000/25046 (64%)]\tLoss: 0.249246\n",
            "Train epoch: 227 [539760/25046 (66%)]\tLoss: 1.118324\n",
            "Train epoch: 227 [540540/25046 (69%)]\tLoss: 0.940395\n",
            "Train epoch: 227 [569520/25046 (72%)]\tLoss: 0.796800\n",
            "Train epoch: 227 [599720/25046 (74%)]\tLoss: 1.035501\n",
            "Train epoch: 227 [619800/25046 (77%)]\tLoss: 0.563678\n",
            "Train epoch: 227 [618140/25046 (79%)]\tLoss: 0.543626\n",
            "Train epoch: 227 [625280/25046 (82%)]\tLoss: 0.425336\n",
            "Train epoch: 227 [701580/25046 (84%)]\tLoss: 0.657502\n",
            "Train epoch: 227 [705840/25046 (87%)]\tLoss: 0.503541\n",
            "Train epoch: 227 [703500/25046 (89%)]\tLoss: 0.512393\n",
            "Train epoch: 227 [763920/25046 (92%)]\tLoss: 0.923407\n",
            "Train epoch: 227 [759980/25046 (95%)]\tLoss: 0.529086\n",
            "Train epoch: 227 [793440/25046 (97%)]\tLoss: 0.748927\n",
            "Train epoch: 227 [836160/25046 (100%)]\tLoss: 0.300492\n",
            "Make prediction for 5010 samples...\n",
            "0.80728716 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 228 [0/25046 (0%)]\tLoss: 0.861863\n",
            "Train epoch: 228 [21560/25046 (3%)]\tLoss: 0.851542\n",
            "Train epoch: 228 [42240/25046 (5%)]\tLoss: 0.216531\n",
            "Train epoch: 228 [61440/25046 (8%)]\tLoss: 1.342587\n",
            "Train epoch: 228 [83760/25046 (10%)]\tLoss: 0.668242\n",
            "Train epoch: 228 [106900/25046 (13%)]\tLoss: 0.720620\n",
            "Train epoch: 228 [121800/25046 (15%)]\tLoss: 0.777772\n",
            "Train epoch: 228 [137200/25046 (18%)]\tLoss: 0.435919\n",
            "Train epoch: 228 [160320/25046 (20%)]\tLoss: 0.514660\n",
            "Train epoch: 228 [192060/25046 (23%)]\tLoss: 0.896230\n",
            "Train epoch: 228 [201400/25046 (26%)]\tLoss: 0.448733\n",
            "Train epoch: 228 [231220/25046 (28%)]\tLoss: 0.542096\n",
            "Train epoch: 228 [241680/25046 (31%)]\tLoss: 0.833666\n",
            "Train epoch: 228 [277940/25046 (33%)]\tLoss: 2.283546\n",
            "Train epoch: 228 [284200/25046 (36%)]\tLoss: 1.348140\n",
            "Train epoch: 228 [327900/25046 (38%)]\tLoss: 0.605526\n",
            "Train epoch: 228 [332480/25046 (41%)]\tLoss: 0.853853\n",
            "Train epoch: 228 [349860/25046 (43%)]\tLoss: 0.999057\n",
            "Train epoch: 228 [376560/25046 (46%)]\tLoss: 0.755504\n",
            "Train epoch: 228 [397860/25046 (49%)]\tLoss: 0.440041\n",
            "Train epoch: 228 [419600/25046 (51%)]\tLoss: 1.343451\n",
            "Train epoch: 228 [450240/25046 (54%)]\tLoss: 0.807991\n",
            "Train epoch: 228 [429440/25046 (56%)]\tLoss: 0.560544\n",
            "Train epoch: 228 [512900/25046 (59%)]\tLoss: 1.195839\n",
            "Train epoch: 228 [511200/25046 (61%)]\tLoss: 0.623115\n",
            "Train epoch: 228 [525000/25046 (64%)]\tLoss: 0.703191\n",
            "Train epoch: 228 [544960/25046 (66%)]\tLoss: 1.272071\n",
            "Train epoch: 228 [584820/25046 (69%)]\tLoss: 0.613458\n",
            "Train epoch: 228 [575120/25046 (72%)]\tLoss: 0.819353\n",
            "Train epoch: 228 [579420/25046 (74%)]\tLoss: 0.712229\n",
            "Train epoch: 228 [628800/25046 (77%)]\tLoss: 1.734682\n",
            "Train epoch: 228 [646040/25046 (79%)]\tLoss: 0.837429\n",
            "Train epoch: 228 [608000/25046 (82%)]\tLoss: 0.474023\n",
            "Train epoch: 228 [657360/25046 (84%)]\tLoss: 1.221838\n",
            "Train epoch: 228 [698360/25046 (87%)]\tLoss: 0.861511\n",
            "Train epoch: 228 [679000/25046 (89%)]\tLoss: 0.572828\n",
            "Train epoch: 228 [733680/25046 (92%)]\tLoss: 1.098293\n",
            "Train epoch: 228 [760720/25046 (95%)]\tLoss: 0.691910\n",
            "Train epoch: 228 [758480/25046 (97%)]\tLoss: 0.672174\n",
            "Train epoch: 228 [786240/25046 (100%)]\tLoss: 1.338015\n",
            "Make prediction for 5010 samples...\n",
            "0.80443853 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 229 [0/25046 (0%)]\tLoss: 0.858331\n",
            "Train epoch: 229 [19820/25046 (3%)]\tLoss: 0.590504\n",
            "Train epoch: 229 [38440/25046 (5%)]\tLoss: 0.413876\n",
            "Train epoch: 229 [61320/25046 (8%)]\tLoss: 0.553690\n",
            "Train epoch: 229 [82480/25046 (10%)]\tLoss: 0.700806\n",
            "Train epoch: 229 [102100/25046 (13%)]\tLoss: 0.772027\n",
            "Train epoch: 229 [125880/25046 (15%)]\tLoss: 0.741639\n",
            "Train epoch: 229 [146300/25046 (18%)]\tLoss: 0.380064\n",
            "Train epoch: 229 [169760/25046 (20%)]\tLoss: 0.886034\n",
            "Train epoch: 229 [189900/25046 (23%)]\tLoss: 1.072583\n",
            "Train epoch: 229 [201200/25046 (26%)]\tLoss: 0.394993\n",
            "Train epoch: 229 [231220/25046 (28%)]\tLoss: 0.635068\n",
            "Train epoch: 229 [240720/25046 (31%)]\tLoss: 0.899452\n",
            "Train epoch: 229 [261300/25046 (33%)]\tLoss: 0.549715\n",
            "Train epoch: 229 [292600/25046 (36%)]\tLoss: 0.505097\n",
            "Train epoch: 229 [291600/25046 (38%)]\tLoss: 0.484579\n",
            "Train epoch: 229 [325120/25046 (41%)]\tLoss: 1.061041\n",
            "Train epoch: 229 [353600/25046 (43%)]\tLoss: 1.127701\n",
            "Train epoch: 229 [356760/25046 (46%)]\tLoss: 0.432003\n",
            "Train epoch: 229 [381140/25046 (49%)]\tLoss: 0.891452\n",
            "Train epoch: 229 [403600/25046 (51%)]\tLoss: 1.762150\n",
            "Train epoch: 229 [431760/25046 (54%)]\tLoss: 0.350205\n",
            "Train epoch: 229 [421960/25046 (56%)]\tLoss: 0.360465\n",
            "Train epoch: 229 [447580/25046 (59%)]\tLoss: 0.867064\n",
            "Train epoch: 229 [477120/25046 (61%)]\tLoss: 0.617145\n",
            "Train epoch: 229 [500000/25046 (64%)]\tLoss: 0.488578\n",
            "Train epoch: 229 [549120/25046 (66%)]\tLoss: 0.238817\n",
            "Train epoch: 229 [567540/25046 (69%)]\tLoss: 0.610570\n",
            "Train epoch: 229 [571200/25046 (72%)]\tLoss: 1.065703\n",
            "Train epoch: 229 [610160/25046 (74%)]\tLoss: 0.491539\n",
            "Train epoch: 229 [607200/25046 (77%)]\tLoss: 1.489581\n",
            "Train epoch: 229 [704320/25046 (79%)]\tLoss: 0.961996\n",
            "Train epoch: 229 [661120/25046 (82%)]\tLoss: 0.724772\n",
            "Train epoch: 229 [683100/25046 (84%)]\tLoss: 0.655778\n",
            "Train epoch: 229 [703800/25046 (87%)]\tLoss: 1.477429\n",
            "Train epoch: 229 [718200/25046 (89%)]\tLoss: 1.164881\n",
            "Train epoch: 229 [758160/25046 (92%)]\tLoss: 0.639732\n",
            "Train epoch: 229 [797720/25046 (95%)]\tLoss: 1.496977\n",
            "Train epoch: 229 [764560/25046 (97%)]\tLoss: 1.265062\n",
            "Train epoch: 229 [788580/25046 (100%)]\tLoss: 0.760578\n",
            "Make prediction for 5010 samples...\n",
            "0.8016176 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 230 [0/25046 (0%)]\tLoss: 2.317859\n",
            "Train epoch: 230 [20220/25046 (3%)]\tLoss: 1.024829\n",
            "Train epoch: 230 [43160/25046 (5%)]\tLoss: 0.508957\n",
            "Train epoch: 230 [60180/25046 (8%)]\tLoss: 0.304911\n",
            "Train epoch: 230 [80720/25046 (10%)]\tLoss: 0.402706\n",
            "Train epoch: 230 [104500/25046 (13%)]\tLoss: 0.772205\n",
            "Train epoch: 230 [123720/25046 (15%)]\tLoss: 0.464277\n",
            "Train epoch: 230 [141540/25046 (18%)]\tLoss: 0.775223\n",
            "Train epoch: 230 [161600/25046 (20%)]\tLoss: 0.511476\n",
            "Train epoch: 230 [176220/25046 (23%)]\tLoss: 0.810669\n",
            "Train epoch: 230 [212200/25046 (26%)]\tLoss: 0.795009\n",
            "Train epoch: 230 [232980/25046 (28%)]\tLoss: 0.461852\n",
            "Train epoch: 230 [245280/25046 (31%)]\tLoss: 0.609184\n",
            "Train epoch: 230 [262860/25046 (33%)]\tLoss: 1.092028\n",
            "Train epoch: 230 [289520/25046 (36%)]\tLoss: 1.371526\n",
            "Train epoch: 230 [308100/25046 (38%)]\tLoss: 0.533350\n",
            "Train epoch: 230 [311360/25046 (41%)]\tLoss: 0.375550\n",
            "Train epoch: 230 [330480/25046 (43%)]\tLoss: 0.314671\n",
            "Train epoch: 230 [384120/25046 (46%)]\tLoss: 0.721067\n",
            "Train epoch: 230 [381900/25046 (49%)]\tLoss: 0.914373\n",
            "Train epoch: 230 [408800/25046 (51%)]\tLoss: 0.642697\n",
            "Train epoch: 230 [422940/25046 (54%)]\tLoss: 0.590656\n",
            "Train epoch: 230 [448800/25046 (56%)]\tLoss: 0.541645\n",
            "Train epoch: 230 [487140/25046 (59%)]\tLoss: 0.860986\n",
            "Train epoch: 230 [480000/25046 (61%)]\tLoss: 1.089561\n",
            "Train epoch: 230 [529500/25046 (64%)]\tLoss: 0.509652\n",
            "Train epoch: 230 [524160/25046 (66%)]\tLoss: 1.325839\n",
            "Train epoch: 230 [515700/25046 (69%)]\tLoss: 0.440581\n",
            "Train epoch: 230 [583520/25046 (72%)]\tLoss: 1.086762\n",
            "Train epoch: 230 [592180/25046 (74%)]\tLoss: 0.517156\n",
            "Train epoch: 230 [585000/25046 (77%)]\tLoss: 0.259919\n",
            "Train epoch: 230 [634260/25046 (79%)]\tLoss: 0.747003\n",
            "Train epoch: 230 [645120/25046 (82%)]\tLoss: 0.449983\n",
            "Train epoch: 230 [654720/25046 (84%)]\tLoss: 0.458611\n",
            "Train epoch: 230 [691560/25046 (87%)]\tLoss: 0.751952\n",
            "Train epoch: 230 [704200/25046 (89%)]\tLoss: 0.398320\n",
            "Train epoch: 230 [733680/25046 (92%)]\tLoss: 0.720838\n",
            "Train epoch: 230 [762940/25046 (95%)]\tLoss: 0.608647\n",
            "Train epoch: 230 [784320/25046 (97%)]\tLoss: 1.010615\n",
            "Train epoch: 230 [801840/25046 (100%)]\tLoss: 0.990594\n",
            "Make prediction for 5010 samples...\n",
            "0.8015191 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 231 [0/25046 (0%)]\tLoss: 0.567795\n",
            "Train epoch: 231 [20800/25046 (3%)]\tLoss: 0.585282\n",
            "Train epoch: 231 [41200/25046 (5%)]\tLoss: 0.948815\n",
            "Train epoch: 231 [59220/25046 (8%)]\tLoss: 0.641956\n",
            "Train epoch: 231 [80560/25046 (10%)]\tLoss: 0.794500\n",
            "Train epoch: 231 [101200/25046 (13%)]\tLoss: 1.194936\n",
            "Train epoch: 231 [119160/25046 (15%)]\tLoss: 0.256298\n",
            "Train epoch: 231 [145320/25046 (18%)]\tLoss: 0.578140\n",
            "Train epoch: 231 [172000/25046 (20%)]\tLoss: 0.834010\n",
            "Train epoch: 231 [186300/25046 (23%)]\tLoss: 1.376200\n",
            "Train epoch: 231 [204000/25046 (26%)]\tLoss: 0.791324\n",
            "Train epoch: 231 [238260/25046 (28%)]\tLoss: 0.911559\n",
            "Train epoch: 231 [254640/25046 (31%)]\tLoss: 0.606935\n",
            "Train epoch: 231 [279500/25046 (33%)]\tLoss: 0.542123\n",
            "Train epoch: 231 [279160/25046 (36%)]\tLoss: 0.398226\n",
            "Train epoch: 231 [302400/25046 (38%)]\tLoss: 1.206726\n",
            "Train epoch: 231 [318720/25046 (41%)]\tLoss: 0.308675\n",
            "Train epoch: 231 [355980/25046 (43%)]\tLoss: 0.483398\n",
            "Train epoch: 231 [382680/25046 (46%)]\tLoss: 0.891961\n",
            "Train epoch: 231 [410020/25046 (49%)]\tLoss: 1.789631\n",
            "Train epoch: 231 [391200/25046 (51%)]\tLoss: 0.445408\n",
            "Train epoch: 231 [444360/25046 (54%)]\tLoss: 1.097009\n",
            "Train epoch: 231 [437360/25046 (56%)]\tLoss: 0.831885\n",
            "Train epoch: 231 [481160/25046 (59%)]\tLoss: 0.671879\n",
            "Train epoch: 231 [467040/25046 (61%)]\tLoss: 1.289835\n",
            "Train epoch: 231 [500000/25046 (64%)]\tLoss: 0.715461\n",
            "Train epoch: 231 [563160/25046 (66%)]\tLoss: 0.381346\n",
            "Train epoch: 231 [550260/25046 (69%)]\tLoss: 1.205965\n",
            "Train epoch: 231 [600880/25046 (72%)]\tLoss: 0.460415\n",
            "Train epoch: 231 [585220/25046 (74%)]\tLoss: 1.091337\n",
            "Train epoch: 231 [627600/25046 (77%)]\tLoss: 1.309833\n",
            "Train epoch: 231 [638600/25046 (79%)]\tLoss: 0.713104\n",
            "Train epoch: 231 [697600/25046 (82%)]\tLoss: 0.990632\n",
            "Train epoch: 231 [700920/25046 (84%)]\tLoss: 0.670089\n",
            "Train epoch: 231 [688840/25046 (87%)]\tLoss: 0.315724\n",
            "Train epoch: 231 [693700/25046 (89%)]\tLoss: 1.129046\n",
            "Train epoch: 231 [763200/25046 (92%)]\tLoss: 0.370085\n",
            "Train epoch: 231 [788100/25046 (95%)]\tLoss: 1.184981\n",
            "Train epoch: 231 [794960/25046 (97%)]\tLoss: 0.581109\n",
            "Train epoch: 231 [777660/25046 (100%)]\tLoss: 0.747919\n",
            "Make prediction for 5010 samples...\n",
            "0.8018576 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 232 [0/25046 (0%)]\tLoss: 0.698176\n",
            "Train epoch: 232 [19760/25046 (3%)]\tLoss: 0.427009\n",
            "Train epoch: 232 [42160/25046 (5%)]\tLoss: 1.420029\n",
            "Train epoch: 232 [62460/25046 (8%)]\tLoss: 1.754158\n",
            "Train epoch: 232 [83440/25046 (10%)]\tLoss: 0.328869\n",
            "Train epoch: 232 [106600/25046 (13%)]\tLoss: 0.784363\n",
            "Train epoch: 232 [118800/25046 (15%)]\tLoss: 0.394893\n",
            "Train epoch: 232 [136080/25046 (18%)]\tLoss: 0.408357\n",
            "Train epoch: 232 [166720/25046 (20%)]\tLoss: 0.837656\n",
            "Train epoch: 232 [186840/25046 (23%)]\tLoss: 0.513975\n",
            "Train epoch: 232 [206000/25046 (26%)]\tLoss: 1.160285\n",
            "Train epoch: 232 [231660/25046 (28%)]\tLoss: 1.259142\n",
            "Train epoch: 232 [231840/25046 (31%)]\tLoss: 0.561966\n",
            "Train epoch: 232 [262340/25046 (33%)]\tLoss: 1.135710\n",
            "Train epoch: 232 [277760/25046 (36%)]\tLoss: 0.756589\n",
            "Train epoch: 232 [299400/25046 (38%)]\tLoss: 0.596624\n",
            "Train epoch: 232 [324480/25046 (41%)]\tLoss: 0.561906\n",
            "Train epoch: 232 [350200/25046 (43%)]\tLoss: 0.467745\n",
            "Train epoch: 232 [379080/25046 (46%)]\tLoss: 0.530988\n",
            "Train epoch: 232 [405840/25046 (49%)]\tLoss: 0.543147\n",
            "Train epoch: 232 [433600/25046 (51%)]\tLoss: 0.560252\n",
            "Train epoch: 232 [415800/25046 (54%)]\tLoss: 0.685678\n",
            "Train epoch: 232 [421080/25046 (56%)]\tLoss: 0.773244\n",
            "Train epoch: 232 [470120/25046 (59%)]\tLoss: 0.420362\n",
            "Train epoch: 232 [464640/25046 (61%)]\tLoss: 1.381118\n",
            "Train epoch: 232 [517500/25046 (64%)]\tLoss: 1.664976\n",
            "Train epoch: 232 [536640/25046 (66%)]\tLoss: 0.329063\n",
            "Train epoch: 232 [546480/25046 (69%)]\tLoss: 1.579468\n",
            "Train epoch: 232 [582400/25046 (72%)]\tLoss: 0.734264\n",
            "Train epoch: 232 [626980/25046 (74%)]\tLoss: 1.266119\n",
            "Train epoch: 232 [625200/25046 (77%)]\tLoss: 0.377167\n",
            "Train epoch: 232 [655340/25046 (79%)]\tLoss: 0.660147\n",
            "Train epoch: 232 [623360/25046 (82%)]\tLoss: 0.379098\n",
            "Train epoch: 232 [626340/25046 (84%)]\tLoss: 0.268631\n",
            "Train epoch: 232 [685440/25046 (87%)]\tLoss: 0.999830\n",
            "Train epoch: 232 [751100/25046 (89%)]\tLoss: 1.472757\n",
            "Train epoch: 232 [784080/25046 (92%)]\tLoss: 0.998058\n",
            "Train epoch: 232 [757020/25046 (95%)]\tLoss: 0.531532\n",
            "Train epoch: 232 [787360/25046 (97%)]\tLoss: 0.693625\n",
            "Train epoch: 232 [819000/25046 (100%)]\tLoss: 0.686598\n",
            "Make prediction for 5010 samples...\n",
            "0.8027962 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 233 [0/25046 (0%)]\tLoss: 0.343274\n",
            "Train epoch: 233 [20980/25046 (3%)]\tLoss: 1.330843\n",
            "Train epoch: 233 [39680/25046 (5%)]\tLoss: 0.702324\n",
            "Train epoch: 233 [61920/25046 (8%)]\tLoss: 0.534935\n",
            "Train epoch: 233 [85040/25046 (10%)]\tLoss: 0.364566\n",
            "Train epoch: 233 [105800/25046 (13%)]\tLoss: 1.048466\n",
            "Train epoch: 233 [127080/25046 (15%)]\tLoss: 0.543261\n",
            "Train epoch: 233 [150360/25046 (18%)]\tLoss: 0.377130\n",
            "Train epoch: 233 [166560/25046 (20%)]\tLoss: 0.540153\n",
            "Train epoch: 233 [180000/25046 (23%)]\tLoss: 0.918866\n",
            "Train epoch: 233 [198000/25046 (26%)]\tLoss: 0.316102\n",
            "Train epoch: 233 [213840/25046 (28%)]\tLoss: 0.505574\n",
            "Train epoch: 233 [237840/25046 (31%)]\tLoss: 0.959526\n",
            "Train epoch: 233 [266760/25046 (33%)]\tLoss: 0.804462\n",
            "Train epoch: 233 [284200/25046 (36%)]\tLoss: 0.266176\n",
            "Train epoch: 233 [314100/25046 (38%)]\tLoss: 0.696042\n",
            "Train epoch: 233 [309120/25046 (41%)]\tLoss: 0.793821\n",
            "Train epoch: 233 [356660/25046 (43%)]\tLoss: 0.516008\n",
            "Train epoch: 233 [374760/25046 (46%)]\tLoss: 0.605883\n",
            "Train epoch: 233 [387980/25046 (49%)]\tLoss: 1.568850\n",
            "Train epoch: 233 [376400/25046 (51%)]\tLoss: 0.321733\n",
            "Train epoch: 233 [452340/25046 (54%)]\tLoss: 1.023011\n",
            "Train epoch: 233 [451880/25046 (56%)]\tLoss: 0.529195\n",
            "Train epoch: 233 [494500/25046 (59%)]\tLoss: 0.848697\n",
            "Train epoch: 233 [488640/25046 (61%)]\tLoss: 1.815873\n",
            "Train epoch: 233 [529500/25046 (64%)]\tLoss: 0.528273\n",
            "Train epoch: 233 [500240/25046 (66%)]\tLoss: 1.137359\n",
            "Train epoch: 233 [548100/25046 (69%)]\tLoss: 1.033614\n",
            "Train epoch: 233 [561680/25046 (72%)]\tLoss: 0.299105\n",
            "Train epoch: 233 [630460/25046 (74%)]\tLoss: 0.321038\n",
            "Train epoch: 233 [610200/25046 (77%)]\tLoss: 0.745735\n",
            "Train epoch: 233 [633640/25046 (79%)]\tLoss: 0.316120\n",
            "Train epoch: 233 [657920/25046 (82%)]\tLoss: 0.654786\n",
            "Train epoch: 233 [673200/25046 (84%)]\tLoss: 0.961168\n",
            "Train epoch: 233 [690200/25046 (87%)]\tLoss: 0.573662\n",
            "Train epoch: 233 [704200/25046 (89%)]\tLoss: 0.636186\n",
            "Train epoch: 233 [709200/25046 (92%)]\tLoss: 0.341045\n",
            "Train epoch: 233 [757760/25046 (95%)]\tLoss: 0.843684\n",
            "Train epoch: 233 [794960/25046 (97%)]\tLoss: 1.735676\n",
            "Train epoch: 233 [775320/25046 (100%)]\tLoss: 1.084375\n",
            "Make prediction for 5010 samples...\n",
            "0.80154127 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 234 [0/25046 (0%)]\tLoss: 0.784882\n",
            "Train epoch: 234 [20780/25046 (3%)]\tLoss: 0.719591\n",
            "Train epoch: 234 [43400/25046 (5%)]\tLoss: 0.846847\n",
            "Train epoch: 234 [62460/25046 (8%)]\tLoss: 0.841761\n",
            "Train epoch: 234 [78880/25046 (10%)]\tLoss: 0.432048\n",
            "Train epoch: 234 [99100/25046 (13%)]\tLoss: 1.016118\n",
            "Train epoch: 234 [120000/25046 (15%)]\tLoss: 1.128726\n",
            "Train epoch: 234 [145600/25046 (18%)]\tLoss: 1.114618\n",
            "Train epoch: 234 [166240/25046 (20%)]\tLoss: 1.456526\n",
            "Train epoch: 234 [185220/25046 (23%)]\tLoss: 0.639775\n",
            "Train epoch: 234 [214200/25046 (26%)]\tLoss: 1.049260\n",
            "Train epoch: 234 [229240/25046 (28%)]\tLoss: 0.677300\n",
            "Train epoch: 234 [245520/25046 (31%)]\tLoss: 0.365668\n",
            "Train epoch: 234 [268580/25046 (33%)]\tLoss: 0.590171\n",
            "Train epoch: 234 [290640/25046 (36%)]\tLoss: 1.496997\n",
            "Train epoch: 234 [312000/25046 (38%)]\tLoss: 1.810196\n",
            "Train epoch: 234 [318080/25046 (41%)]\tLoss: 0.992249\n",
            "Train epoch: 234 [343400/25046 (43%)]\tLoss: 1.754598\n",
            "Train epoch: 234 [384480/25046 (46%)]\tLoss: 0.849312\n",
            "Train epoch: 234 [386460/25046 (49%)]\tLoss: 0.642979\n",
            "Train epoch: 234 [388400/25046 (51%)]\tLoss: 0.514081\n",
            "Train epoch: 234 [447720/25046 (54%)]\tLoss: 0.552357\n",
            "Train epoch: 234 [465520/25046 (56%)]\tLoss: 0.279507\n",
            "Train epoch: 234 [483460/25046 (59%)]\tLoss: 1.446142\n",
            "Train epoch: 234 [482400/25046 (61%)]\tLoss: 1.031045\n",
            "Train epoch: 234 [509500/25046 (64%)]\tLoss: 0.367586\n",
            "Train epoch: 234 [534040/25046 (66%)]\tLoss: 0.842918\n",
            "Train epoch: 234 [549720/25046 (69%)]\tLoss: 0.484897\n",
            "Train epoch: 234 [551040/25046 (72%)]\tLoss: 0.414939\n",
            "Train epoch: 234 [586380/25046 (74%)]\tLoss: 0.390304\n",
            "Train epoch: 234 [595200/25046 (77%)]\tLoss: 0.755224\n",
            "Train epoch: 234 [652860/25046 (79%)]\tLoss: 1.267095\n",
            "Train epoch: 234 [659840/25046 (82%)]\tLoss: 0.492218\n",
            "Train epoch: 234 [667260/25046 (84%)]\tLoss: 0.429524\n",
            "Train epoch: 234 [687480/25046 (87%)]\tLoss: 1.425600\n",
            "Train epoch: 234 [706300/25046 (89%)]\tLoss: 0.885590\n",
            "Train epoch: 234 [737280/25046 (92%)]\tLoss: 0.493216\n",
            "Train epoch: 234 [742960/25046 (95%)]\tLoss: 0.625073\n",
            "Train epoch: 234 [773680/25046 (97%)]\tLoss: 1.038888\n",
            "Train epoch: 234 [780780/25046 (100%)]\tLoss: 1.367748\n",
            "Make prediction for 5010 samples...\n",
            "0.8020595 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 235 [0/25046 (0%)]\tLoss: 1.919288\n",
            "Train epoch: 235 [21160/25046 (3%)]\tLoss: 0.495896\n",
            "Train epoch: 235 [42000/25046 (5%)]\tLoss: 0.952907\n",
            "Train epoch: 235 [59880/25046 (8%)]\tLoss: 0.753915\n",
            "Train epoch: 235 [81600/25046 (10%)]\tLoss: 1.171756\n",
            "Train epoch: 235 [107400/25046 (13%)]\tLoss: 0.720845\n",
            "Train epoch: 235 [123240/25046 (15%)]\tLoss: 1.749663\n",
            "Train epoch: 235 [139160/25046 (18%)]\tLoss: 0.951482\n",
            "Train epoch: 235 [175200/25046 (20%)]\tLoss: 0.595052\n",
            "Train epoch: 235 [183780/25046 (23%)]\tLoss: 0.535981\n",
            "Train epoch: 235 [204200/25046 (26%)]\tLoss: 0.882018\n",
            "Train epoch: 235 [231000/25046 (28%)]\tLoss: 0.730017\n",
            "Train epoch: 235 [244080/25046 (31%)]\tLoss: 0.761735\n",
            "Train epoch: 235 [264940/25046 (33%)]\tLoss: 0.852284\n",
            "Train epoch: 235 [285040/25046 (36%)]\tLoss: 0.615975\n",
            "Train epoch: 235 [300300/25046 (38%)]\tLoss: 0.941269\n",
            "Train epoch: 235 [318720/25046 (41%)]\tLoss: 0.366475\n",
            "Train epoch: 235 [359380/25046 (43%)]\tLoss: 0.679850\n",
            "Train epoch: 235 [383400/25046 (46%)]\tLoss: 1.066684\n",
            "Train epoch: 235 [389500/25046 (49%)]\tLoss: 0.825921\n",
            "Train epoch: 235 [412000/25046 (51%)]\tLoss: 1.319921\n",
            "Train epoch: 235 [431340/25046 (54%)]\tLoss: 0.594450\n",
            "Train epoch: 235 [454520/25046 (56%)]\tLoss: 1.092743\n",
            "Train epoch: 235 [479780/25046 (59%)]\tLoss: 0.748259\n",
            "Train epoch: 235 [481920/25046 (61%)]\tLoss: 0.278522\n",
            "Train epoch: 235 [512000/25046 (64%)]\tLoss: 0.806331\n",
            "Train epoch: 235 [559000/25046 (66%)]\tLoss: 0.521314\n",
            "Train epoch: 235 [531360/25046 (69%)]\tLoss: 0.521610\n",
            "Train epoch: 235 [586320/25046 (72%)]\tLoss: 1.298559\n",
            "Train epoch: 235 [567240/25046 (74%)]\tLoss: 0.430505\n",
            "Train epoch: 235 [614400/25046 (77%)]\tLoss: 0.652360\n",
            "Train epoch: 235 [630540/25046 (79%)]\tLoss: 1.094002\n",
            "Train epoch: 235 [696960/25046 (82%)]\tLoss: 0.660396\n",
            "Train epoch: 235 [687060/25046 (84%)]\tLoss: 0.797563\n",
            "Train epoch: 235 [714680/25046 (87%)]\tLoss: 1.809627\n",
            "Train epoch: 235 [716100/25046 (89%)]\tLoss: 0.357374\n",
            "Train epoch: 235 [748080/25046 (92%)]\tLoss: 1.092449\n",
            "Train epoch: 235 [779960/25046 (95%)]\tLoss: 0.893608\n",
            "Train epoch: 235 [795720/25046 (97%)]\tLoss: 0.524751\n",
            "Train epoch: 235 [811200/25046 (100%)]\tLoss: 0.316154\n",
            "Make prediction for 5010 samples...\n",
            "0.8043887 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 236 [0/25046 (0%)]\tLoss: 0.803127\n",
            "Train epoch: 236 [20680/25046 (3%)]\tLoss: 0.578610\n",
            "Train epoch: 236 [37480/25046 (5%)]\tLoss: 0.225671\n",
            "Train epoch: 236 [60780/25046 (8%)]\tLoss: 0.474416\n",
            "Train epoch: 236 [83280/25046 (10%)]\tLoss: 0.951681\n",
            "Train epoch: 236 [97200/25046 (13%)]\tLoss: 1.212087\n",
            "Train epoch: 236 [121560/25046 (15%)]\tLoss: 0.603406\n",
            "Train epoch: 236 [139160/25046 (18%)]\tLoss: 0.231046\n",
            "Train epoch: 236 [160320/25046 (20%)]\tLoss: 1.055895\n",
            "Train epoch: 236 [203220/25046 (23%)]\tLoss: 0.813209\n",
            "Train epoch: 236 [210400/25046 (26%)]\tLoss: 0.351107\n",
            "Train epoch: 236 [231880/25046 (28%)]\tLoss: 0.859600\n",
            "Train epoch: 236 [254640/25046 (31%)]\tLoss: 0.954471\n",
            "Train epoch: 236 [270400/25046 (33%)]\tLoss: 1.041717\n",
            "Train epoch: 236 [295960/25046 (36%)]\tLoss: 1.054204\n",
            "Train epoch: 236 [294900/25046 (38%)]\tLoss: 0.646708\n",
            "Train epoch: 236 [339200/25046 (41%)]\tLoss: 0.556832\n",
            "Train epoch: 236 [357000/25046 (43%)]\tLoss: 1.447096\n",
            "Train epoch: 236 [365760/25046 (46%)]\tLoss: 0.369742\n",
            "Train epoch: 236 [399760/25046 (49%)]\tLoss: 0.718074\n",
            "Train epoch: 236 [407200/25046 (51%)]\tLoss: 1.316862\n",
            "Train epoch: 236 [455280/25046 (54%)]\tLoss: 0.401100\n",
            "Train epoch: 236 [438680/25046 (56%)]\tLoss: 0.645655\n",
            "Train epoch: 236 [458160/25046 (59%)]\tLoss: 0.562271\n",
            "Train epoch: 236 [504960/25046 (61%)]\tLoss: 1.309458\n",
            "Train epoch: 236 [481000/25046 (64%)]\tLoss: 0.316013\n",
            "Train epoch: 236 [537680/25046 (66%)]\tLoss: 0.273944\n",
            "Train epoch: 236 [541080/25046 (69%)]\tLoss: 0.941471\n",
            "Train epoch: 236 [557760/25046 (72%)]\tLoss: 0.414158\n",
            "Train epoch: 236 [604940/25046 (74%)]\tLoss: 0.771829\n",
            "Train epoch: 236 [606000/25046 (77%)]\tLoss: 1.511397\n",
            "Train epoch: 236 [621860/25046 (79%)]\tLoss: 0.426824\n",
            "Train epoch: 236 [662400/25046 (82%)]\tLoss: 1.238593\n",
            "Train epoch: 236 [681780/25046 (84%)]\tLoss: 1.473207\n",
            "Train epoch: 236 [694960/25046 (87%)]\tLoss: 1.044586\n",
            "Train epoch: 236 [696500/25046 (89%)]\tLoss: 1.513697\n",
            "Train epoch: 236 [739440/25046 (92%)]\tLoss: 0.362198\n",
            "Train epoch: 236 [749620/25046 (95%)]\tLoss: 0.493708\n",
            "Train epoch: 236 [813960/25046 (97%)]\tLoss: 0.795610\n",
            "Train epoch: 236 [769080/25046 (100%)]\tLoss: 0.723914\n",
            "Make prediction for 5010 samples...\n",
            "0.80586326 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 237 [0/25046 (0%)]\tLoss: 0.690056\n",
            "Train epoch: 237 [20460/25046 (3%)]\tLoss: 1.021958\n",
            "Train epoch: 237 [37920/25046 (5%)]\tLoss: 0.849239\n",
            "Train epoch: 237 [61020/25046 (8%)]\tLoss: 1.395176\n",
            "Train epoch: 237 [80080/25046 (10%)]\tLoss: 0.951259\n",
            "Train epoch: 237 [100700/25046 (13%)]\tLoss: 0.558359\n",
            "Train epoch: 237 [124800/25046 (15%)]\tLoss: 0.689940\n",
            "Train epoch: 237 [146440/25046 (18%)]\tLoss: 1.190963\n",
            "Train epoch: 237 [159520/25046 (20%)]\tLoss: 1.106876\n",
            "Train epoch: 237 [193680/25046 (23%)]\tLoss: 0.366458\n",
            "Train epoch: 237 [202200/25046 (26%)]\tLoss: 0.594994\n",
            "Train epoch: 237 [213400/25046 (28%)]\tLoss: 0.566197\n",
            "Train epoch: 237 [245520/25046 (31%)]\tLoss: 0.463455\n",
            "Train epoch: 237 [265720/25046 (33%)]\tLoss: 0.496543\n",
            "Train epoch: 237 [281400/25046 (36%)]\tLoss: 1.451357\n",
            "Train epoch: 237 [320100/25046 (38%)]\tLoss: 1.578711\n",
            "Train epoch: 237 [332160/25046 (41%)]\tLoss: 0.315095\n",
            "Train epoch: 237 [352240/25046 (43%)]\tLoss: 0.979131\n",
            "Train epoch: 237 [370800/25046 (46%)]\tLoss: 0.876750\n",
            "Train epoch: 237 [370500/25046 (49%)]\tLoss: 0.661690\n",
            "Train epoch: 237 [397200/25046 (51%)]\tLoss: 0.646072\n",
            "Train epoch: 237 [428820/25046 (54%)]\tLoss: 1.081551\n",
            "Train epoch: 237 [440440/25046 (56%)]\tLoss: 0.892796\n",
            "Train epoch: 237 [516580/25046 (59%)]\tLoss: 0.435026\n",
            "Train epoch: 237 [515040/25046 (61%)]\tLoss: 1.532637\n",
            "Train epoch: 237 [509500/25046 (64%)]\tLoss: 1.773382\n",
            "Train epoch: 237 [541320/25046 (66%)]\tLoss: 0.542835\n",
            "Train epoch: 237 [557820/25046 (69%)]\tLoss: 1.025127\n",
            "Train epoch: 237 [552160/25046 (72%)]\tLoss: 0.965600\n",
            "Train epoch: 237 [593340/25046 (74%)]\tLoss: 1.407343\n",
            "Train epoch: 237 [588600/25046 (77%)]\tLoss: 0.499140\n",
            "Train epoch: 237 [657200/25046 (79%)]\tLoss: 1.171903\n",
            "Train epoch: 237 [634880/25046 (82%)]\tLoss: 0.155109\n",
            "Train epoch: 237 [668580/25046 (84%)]\tLoss: 0.632942\n",
            "Train epoch: 237 [674560/25046 (87%)]\tLoss: 0.214103\n",
            "Train epoch: 237 [745500/25046 (89%)]\tLoss: 1.072534\n",
            "Train epoch: 237 [776880/25046 (92%)]\tLoss: 0.564613\n",
            "Train epoch: 237 [823620/25046 (95%)]\tLoss: 0.706127\n",
            "Train epoch: 237 [792680/25046 (97%)]\tLoss: 0.982036\n",
            "Train epoch: 237 [834600/25046 (100%)]\tLoss: 0.691776\n",
            "Make prediction for 5010 samples...\n",
            "0.8017072 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 238 [0/25046 (0%)]\tLoss: 0.936877\n",
            "Train epoch: 238 [21120/25046 (3%)]\tLoss: 0.767257\n",
            "Train epoch: 238 [39640/25046 (5%)]\tLoss: 1.432019\n",
            "Train epoch: 238 [58080/25046 (8%)]\tLoss: 0.599881\n",
            "Train epoch: 238 [81920/25046 (10%)]\tLoss: 0.240697\n",
            "Train epoch: 238 [103300/25046 (13%)]\tLoss: 0.947722\n",
            "Train epoch: 238 [126120/25046 (15%)]\tLoss: 1.131364\n",
            "Train epoch: 238 [144480/25046 (18%)]\tLoss: 1.267104\n",
            "Train epoch: 238 [167040/25046 (20%)]\tLoss: 0.632106\n",
            "Train epoch: 238 [190620/25046 (23%)]\tLoss: 0.263703\n",
            "Train epoch: 238 [206000/25046 (26%)]\tLoss: 0.783942\n",
            "Train epoch: 238 [224840/25046 (28%)]\tLoss: 1.205050\n",
            "Train epoch: 238 [247680/25046 (31%)]\tLoss: 0.753780\n",
            "Train epoch: 238 [277680/25046 (33%)]\tLoss: 0.574064\n",
            "Train epoch: 238 [297920/25046 (36%)]\tLoss: 0.732328\n",
            "Train epoch: 238 [304200/25046 (38%)]\tLoss: 1.404807\n",
            "Train epoch: 238 [335040/25046 (41%)]\tLoss: 1.042796\n",
            "Train epoch: 238 [358360/25046 (43%)]\tLoss: 0.187752\n",
            "Train epoch: 238 [346680/25046 (46%)]\tLoss: 0.860571\n",
            "Train epoch: 238 [398620/25046 (49%)]\tLoss: 0.844010\n",
            "Train epoch: 238 [416800/25046 (51%)]\tLoss: 1.001803\n",
            "Train epoch: 238 [446040/25046 (54%)]\tLoss: 0.461919\n",
            "Train epoch: 238 [437360/25046 (56%)]\tLoss: 0.965120\n",
            "Train epoch: 238 [494960/25046 (59%)]\tLoss: 0.677146\n",
            "Train epoch: 238 [492000/25046 (61%)]\tLoss: 0.306639\n",
            "Train epoch: 238 [525000/25046 (64%)]\tLoss: 0.923432\n",
            "Train epoch: 238 [500760/25046 (66%)]\tLoss: 0.911318\n",
            "Train epoch: 238 [561060/25046 (69%)]\tLoss: 1.603229\n",
            "Train epoch: 238 [555520/25046 (72%)]\tLoss: 0.236351\n",
            "Train epoch: 238 [583480/25046 (74%)]\tLoss: 0.240334\n",
            "Train epoch: 238 [651000/25046 (77%)]\tLoss: 1.191492\n",
            "Train epoch: 238 [673940/25046 (79%)]\tLoss: 0.682880\n",
            "Train epoch: 238 [669440/25046 (82%)]\tLoss: 0.689148\n",
            "Train epoch: 238 [653400/25046 (84%)]\tLoss: 0.441135\n",
            "Train epoch: 238 [665720/25046 (87%)]\tLoss: 0.909613\n",
            "Train epoch: 238 [664300/25046 (89%)]\tLoss: 0.617444\n",
            "Train epoch: 238 [717120/25046 (92%)]\tLoss: 0.773866\n",
            "Train epoch: 238 [735560/25046 (95%)]\tLoss: 0.465280\n",
            "Train epoch: 238 [792680/25046 (97%)]\tLoss: 1.496880\n",
            "Train epoch: 238 [807300/25046 (100%)]\tLoss: 0.357451\n",
            "Make prediction for 5010 samples...\n",
            "0.80331504 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 239 [0/25046 (0%)]\tLoss: 1.054896\n",
            "Train epoch: 239 [20720/25046 (3%)]\tLoss: 1.076523\n",
            "Train epoch: 239 [41440/25046 (5%)]\tLoss: 1.231022\n",
            "Train epoch: 239 [58380/25046 (8%)]\tLoss: 0.324329\n",
            "Train epoch: 239 [79760/25046 (10%)]\tLoss: 1.007616\n",
            "Train epoch: 239 [97600/25046 (13%)]\tLoss: 1.218622\n",
            "Train epoch: 239 [129720/25046 (15%)]\tLoss: 0.901733\n",
            "Train epoch: 239 [139160/25046 (18%)]\tLoss: 0.790069\n",
            "Train epoch: 239 [165440/25046 (20%)]\tLoss: 0.641277\n",
            "Train epoch: 239 [172080/25046 (23%)]\tLoss: 0.641379\n",
            "Train epoch: 239 [216600/25046 (26%)]\tLoss: 1.226104\n",
            "Train epoch: 239 [227480/25046 (28%)]\tLoss: 0.950920\n",
            "Train epoch: 239 [263760/25046 (31%)]\tLoss: 0.426109\n",
            "Train epoch: 239 [275600/25046 (33%)]\tLoss: 0.938880\n",
            "Train epoch: 239 [293160/25046 (36%)]\tLoss: 2.326910\n",
            "Train epoch: 239 [326400/25046 (38%)]\tLoss: 1.149299\n",
            "Train epoch: 239 [325760/25046 (41%)]\tLoss: 0.642229\n",
            "Train epoch: 239 [358700/25046 (43%)]\tLoss: 0.604137\n",
            "Train epoch: 239 [388440/25046 (46%)]\tLoss: 0.738515\n",
            "Train epoch: 239 [400140/25046 (49%)]\tLoss: 0.880679\n",
            "Train epoch: 239 [402800/25046 (51%)]\tLoss: 0.830290\n",
            "Train epoch: 239 [426300/25046 (54%)]\tLoss: 0.288805\n",
            "Train epoch: 239 [429880/25046 (56%)]\tLoss: 0.908872\n",
            "Train epoch: 239 [474260/25046 (59%)]\tLoss: 1.622973\n",
            "Train epoch: 239 [488160/25046 (61%)]\tLoss: 0.708591\n",
            "Train epoch: 239 [514500/25046 (64%)]\tLoss: 1.387413\n",
            "Train epoch: 239 [514280/25046 (66%)]\tLoss: 0.262032\n",
            "Train epoch: 239 [538920/25046 (69%)]\tLoss: 1.296767\n",
            "Train epoch: 239 [566160/25046 (72%)]\tLoss: 0.584915\n",
            "Train epoch: 239 [611900/25046 (74%)]\tLoss: 0.554411\n",
            "Train epoch: 239 [617400/25046 (77%)]\tLoss: 0.230781\n",
            "Train epoch: 239 [608220/25046 (79%)]\tLoss: 0.423541\n",
            "Train epoch: 239 [699520/25046 (82%)]\tLoss: 1.078017\n",
            "Train epoch: 239 [700920/25046 (84%)]\tLoss: 1.061614\n",
            "Train epoch: 239 [710600/25046 (87%)]\tLoss: 0.832074\n",
            "Train epoch: 239 [673400/25046 (89%)]\tLoss: 0.445881\n",
            "Train epoch: 239 [731520/25046 (92%)]\tLoss: 0.693630\n",
            "Train epoch: 239 [725200/25046 (95%)]\tLoss: 0.681259\n",
            "Train epoch: 239 [778240/25046 (97%)]\tLoss: 1.384501\n",
            "Train epoch: 239 [801840/25046 (100%)]\tLoss: 0.757372\n",
            "Make prediction for 5010 samples...\n",
            "0.8018649 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 240 [0/25046 (0%)]\tLoss: 0.795011\n",
            "Train epoch: 240 [21240/25046 (3%)]\tLoss: 0.802778\n",
            "Train epoch: 240 [41560/25046 (5%)]\tLoss: 0.598012\n",
            "Train epoch: 240 [61380/25046 (8%)]\tLoss: 1.048105\n",
            "Train epoch: 240 [85840/25046 (10%)]\tLoss: 1.046526\n",
            "Train epoch: 240 [106300/25046 (13%)]\tLoss: 0.311702\n",
            "Train epoch: 240 [117840/25046 (15%)]\tLoss: 0.569743\n",
            "Train epoch: 240 [139020/25046 (18%)]\tLoss: 0.799305\n",
            "Train epoch: 240 [158880/25046 (20%)]\tLoss: 0.546248\n",
            "Train epoch: 240 [187020/25046 (23%)]\tLoss: 0.404942\n",
            "Train epoch: 240 [214600/25046 (26%)]\tLoss: 1.281455\n",
            "Train epoch: 240 [231220/25046 (28%)]\tLoss: 0.471311\n",
            "Train epoch: 240 [241440/25046 (31%)]\tLoss: 0.806805\n",
            "Train epoch: 240 [248300/25046 (33%)]\tLoss: 0.252504\n",
            "Train epoch: 240 [289520/25046 (36%)]\tLoss: 1.081115\n",
            "Train epoch: 240 [306600/25046 (38%)]\tLoss: 0.886319\n",
            "Train epoch: 240 [331520/25046 (41%)]\tLoss: 0.738580\n",
            "Train epoch: 240 [344080/25046 (43%)]\tLoss: 0.221305\n",
            "Train epoch: 240 [374040/25046 (46%)]\tLoss: 1.195750\n",
            "Train epoch: 240 [379240/25046 (49%)]\tLoss: 0.613892\n",
            "Train epoch: 240 [423200/25046 (51%)]\tLoss: 0.789502\n",
            "Train epoch: 240 [415380/25046 (54%)]\tLoss: 0.411054\n",
            "Train epoch: 240 [418000/25046 (56%)]\tLoss: 0.422267\n",
            "Train epoch: 240 [459080/25046 (59%)]\tLoss: 0.377618\n",
            "Train epoch: 240 [471840/25046 (61%)]\tLoss: 0.276865\n",
            "Train epoch: 240 [509500/25046 (64%)]\tLoss: 0.974321\n",
            "Train epoch: 240 [520520/25046 (66%)]\tLoss: 0.621100\n",
            "Train epoch: 240 [554040/25046 (69%)]\tLoss: 0.969556\n",
            "Train epoch: 240 [600320/25046 (72%)]\tLoss: 0.461079\n",
            "Train epoch: 240 [577680/25046 (74%)]\tLoss: 1.315211\n",
            "Train epoch: 240 [618600/25046 (77%)]\tLoss: 0.814564\n",
            "Train epoch: 240 [650380/25046 (79%)]\tLoss: 1.344320\n",
            "Train epoch: 240 [659840/25046 (82%)]\tLoss: 0.934296\n",
            "Train epoch: 240 [672540/25046 (84%)]\tLoss: 0.719965\n",
            "Train epoch: 240 [687480/25046 (87%)]\tLoss: 1.418991\n",
            "Train epoch: 240 [707700/25046 (89%)]\tLoss: 0.673292\n",
            "Train epoch: 240 [722880/25046 (92%)]\tLoss: 0.902826\n",
            "Train epoch: 240 [720760/25046 (95%)]\tLoss: 0.287812\n",
            "Train epoch: 240 [781280/25046 (97%)]\tLoss: 1.344908\n",
            "Train epoch: 240 [796380/25046 (100%)]\tLoss: 0.969497\n",
            "Make prediction for 5010 samples...\n",
            "0.80399424 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 241 [0/25046 (0%)]\tLoss: 0.371609\n",
            "Train epoch: 241 [20000/25046 (3%)]\tLoss: 0.779225\n",
            "Train epoch: 241 [41480/25046 (5%)]\tLoss: 0.489618\n",
            "Train epoch: 241 [63600/25046 (8%)]\tLoss: 0.547600\n",
            "Train epoch: 241 [79040/25046 (10%)]\tLoss: 1.042527\n",
            "Train epoch: 241 [98500/25046 (13%)]\tLoss: 0.374045\n",
            "Train epoch: 241 [127920/25046 (15%)]\tLoss: 0.422948\n",
            "Train epoch: 241 [139440/25046 (18%)]\tLoss: 0.516368\n",
            "Train epoch: 241 [165440/25046 (20%)]\tLoss: 1.247908\n",
            "Train epoch: 241 [192060/25046 (23%)]\tLoss: 1.548384\n",
            "Train epoch: 241 [206800/25046 (26%)]\tLoss: 1.263616\n",
            "Train epoch: 241 [235840/25046 (28%)]\tLoss: 0.419060\n",
            "Train epoch: 241 [240960/25046 (31%)]\tLoss: 0.888848\n",
            "Train epoch: 241 [263120/25046 (33%)]\tLoss: 1.058676\n",
            "Train epoch: 241 [294000/25046 (36%)]\tLoss: 0.660639\n",
            "Train epoch: 241 [308700/25046 (38%)]\tLoss: 1.402768\n",
            "Train epoch: 241 [328640/25046 (41%)]\tLoss: 0.278435\n",
            "Train epoch: 241 [347480/25046 (43%)]\tLoss: 0.610273\n",
            "Train epoch: 241 [364680/25046 (46%)]\tLoss: 0.403790\n",
            "Train epoch: 241 [396340/25046 (49%)]\tLoss: 0.997629\n",
            "Train epoch: 241 [414000/25046 (51%)]\tLoss: 0.402143\n",
            "Train epoch: 241 [423780/25046 (54%)]\tLoss: 0.604671\n",
            "Train epoch: 241 [443080/25046 (56%)]\tLoss: 0.769771\n",
            "Train epoch: 241 [510140/25046 (59%)]\tLoss: 1.727276\n",
            "Train epoch: 241 [483360/25046 (61%)]\tLoss: 0.928592\n",
            "Train epoch: 241 [501500/25046 (64%)]\tLoss: 0.759812\n",
            "Train epoch: 241 [560560/25046 (66%)]\tLoss: 1.109776\n",
            "Train epoch: 241 [539460/25046 (69%)]\tLoss: 1.144842\n",
            "Train epoch: 241 [543760/25046 (72%)]\tLoss: 0.383114\n",
            "Train epoch: 241 [600880/25046 (74%)]\tLoss: 2.182414\n",
            "Train epoch: 241 [637200/25046 (77%)]\tLoss: 0.945935\n",
            "Train epoch: 241 [606360/25046 (79%)]\tLoss: 0.244995\n",
            "Train epoch: 241 [656000/25046 (82%)]\tLoss: 0.690203\n",
            "Train epoch: 241 [670560/25046 (84%)]\tLoss: 0.743406\n",
            "Train epoch: 241 [736440/25046 (87%)]\tLoss: 1.243306\n",
            "Train epoch: 241 [711900/25046 (89%)]\tLoss: 0.933052\n",
            "Train epoch: 241 [735840/25046 (92%)]\tLoss: 1.164464\n",
            "Train epoch: 241 [736300/25046 (95%)]\tLoss: 0.402090\n",
            "Train epoch: 241 [817760/25046 (97%)]\tLoss: 1.261667\n",
            "Train epoch: 241 [802620/25046 (100%)]\tLoss: 0.318987\n",
            "Make prediction for 5010 samples...\n",
            "0.8062417 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 242 [0/25046 (0%)]\tLoss: 0.763715\n",
            "Train epoch: 242 [19760/25046 (3%)]\tLoss: 0.699490\n",
            "Train epoch: 242 [41040/25046 (5%)]\tLoss: 0.904281\n",
            "Train epoch: 242 [59220/25046 (8%)]\tLoss: 2.146415\n",
            "Train epoch: 242 [80480/25046 (10%)]\tLoss: 0.584567\n",
            "Train epoch: 242 [97500/25046 (13%)]\tLoss: 0.362470\n",
            "Train epoch: 242 [124800/25046 (15%)]\tLoss: 0.283908\n",
            "Train epoch: 242 [140420/25046 (18%)]\tLoss: 0.674274\n",
            "Train epoch: 242 [167520/25046 (20%)]\tLoss: 0.707709\n",
            "Train epoch: 242 [181980/25046 (23%)]\tLoss: 0.415071\n",
            "Train epoch: 242 [206000/25046 (26%)]\tLoss: 0.718002\n",
            "Train epoch: 242 [230120/25046 (28%)]\tLoss: 0.604517\n",
            "Train epoch: 242 [252960/25046 (31%)]\tLoss: 0.892139\n",
            "Train epoch: 242 [270400/25046 (33%)]\tLoss: 0.426715\n",
            "Train epoch: 242 [307720/25046 (36%)]\tLoss: 0.826349\n",
            "Train epoch: 242 [306000/25046 (38%)]\tLoss: 0.411236\n",
            "Train epoch: 242 [336960/25046 (41%)]\tLoss: 0.983314\n",
            "Train epoch: 242 [362780/25046 (43%)]\tLoss: 1.003688\n",
            "Train epoch: 242 [353160/25046 (46%)]\tLoss: 0.608321\n",
            "Train epoch: 242 [387980/25046 (49%)]\tLoss: 0.502070\n",
            "Train epoch: 242 [400000/25046 (51%)]\tLoss: 0.499400\n",
            "Train epoch: 242 [413280/25046 (54%)]\tLoss: 1.221832\n",
            "Train epoch: 242 [465520/25046 (56%)]\tLoss: 1.976506\n",
            "Train epoch: 242 [485300/25046 (59%)]\tLoss: 0.516083\n",
            "Train epoch: 242 [486240/25046 (61%)]\tLoss: 0.548598\n",
            "Train epoch: 242 [512500/25046 (64%)]\tLoss: 0.479202\n",
            "Train epoch: 242 [564720/25046 (66%)]\tLoss: 0.961800\n",
            "Train epoch: 242 [576180/25046 (69%)]\tLoss: 1.057084\n",
            "Train epoch: 242 [565040/25046 (72%)]\tLoss: 0.609527\n",
            "Train epoch: 242 [610740/25046 (74%)]\tLoss: 1.175953\n",
            "Train epoch: 242 [601200/25046 (77%)]\tLoss: 0.759949\n",
            "Train epoch: 242 [647900/25046 (79%)]\tLoss: 0.845313\n",
            "Train epoch: 242 [670080/25046 (82%)]\tLoss: 0.765728\n",
            "Train epoch: 242 [659340/25046 (84%)]\tLoss: 0.683162\n",
            "Train epoch: 242 [687480/25046 (87%)]\tLoss: 0.681859\n",
            "Train epoch: 242 [691600/25046 (89%)]\tLoss: 0.349374\n",
            "Train epoch: 242 [749520/25046 (92%)]\tLoss: 1.501381\n",
            "Train epoch: 242 [745180/25046 (95%)]\tLoss: 0.445148\n",
            "Train epoch: 242 [789640/25046 (97%)]\tLoss: 0.559055\n",
            "Train epoch: 242 [775320/25046 (100%)]\tLoss: 0.834778\n",
            "Make prediction for 5010 samples...\n",
            "0.80464065 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 243 [0/25046 (0%)]\tLoss: 0.644182\n",
            "Train epoch: 243 [19640/25046 (3%)]\tLoss: 1.008233\n",
            "Train epoch: 243 [38760/25046 (5%)]\tLoss: 1.469355\n",
            "Train epoch: 243 [61440/25046 (8%)]\tLoss: 0.752137\n",
            "Train epoch: 243 [79680/25046 (10%)]\tLoss: 1.315274\n",
            "Train epoch: 243 [105600/25046 (13%)]\tLoss: 0.587020\n",
            "Train epoch: 243 [123240/25046 (15%)]\tLoss: 1.998126\n",
            "Train epoch: 243 [145040/25046 (18%)]\tLoss: 1.552112\n",
            "Train epoch: 243 [168320/25046 (20%)]\tLoss: 0.757080\n",
            "Train epoch: 243 [185760/25046 (23%)]\tLoss: 0.593018\n",
            "Train epoch: 243 [205000/25046 (26%)]\tLoss: 1.396615\n",
            "Train epoch: 243 [213840/25046 (28%)]\tLoss: 0.953085\n",
            "Train epoch: 243 [248160/25046 (31%)]\tLoss: 0.410245\n",
            "Train epoch: 243 [266240/25046 (33%)]\tLoss: 0.528923\n",
            "Train epoch: 243 [302680/25046 (36%)]\tLoss: 0.943190\n",
            "Train epoch: 243 [301200/25046 (38%)]\tLoss: 0.284486\n",
            "Train epoch: 243 [317760/25046 (41%)]\tLoss: 0.213918\n",
            "Train epoch: 243 [342720/25046 (43%)]\tLoss: 0.813527\n",
            "Train epoch: 243 [383400/25046 (46%)]\tLoss: 0.427419\n",
            "Train epoch: 243 [383040/25046 (49%)]\tLoss: 0.888286\n",
            "Train epoch: 243 [393200/25046 (51%)]\tLoss: 0.367817\n",
            "Train epoch: 243 [421260/25046 (54%)]\tLoss: 0.907318\n",
            "Train epoch: 243 [438680/25046 (56%)]\tLoss: 1.427292\n",
            "Train epoch: 243 [457700/25046 (59%)]\tLoss: 0.807227\n",
            "Train epoch: 243 [461760/25046 (61%)]\tLoss: 1.079564\n",
            "Train epoch: 243 [513000/25046 (64%)]\tLoss: 0.494439\n",
            "Train epoch: 243 [524160/25046 (66%)]\tLoss: 0.227927\n",
            "Train epoch: 243 [554580/25046 (69%)]\tLoss: 0.516020\n",
            "Train epoch: 243 [568960/25046 (72%)]\tLoss: 0.508645\n",
            "Train epoch: 243 [613060/25046 (74%)]\tLoss: 0.214727\n",
            "Train epoch: 243 [615000/25046 (77%)]\tLoss: 0.796517\n",
            "Train epoch: 243 [638600/25046 (79%)]\tLoss: 0.820149\n",
            "Train epoch: 243 [662400/25046 (82%)]\tLoss: 0.785348\n",
            "Train epoch: 243 [685740/25046 (84%)]\tLoss: 1.394307\n",
            "Train epoch: 243 [713320/25046 (87%)]\tLoss: 0.671557\n",
            "Train epoch: 243 [716100/25046 (89%)]\tLoss: 0.765082\n",
            "Train epoch: 243 [709920/25046 (92%)]\tLoss: 0.563174\n",
            "Train epoch: 243 [785140/25046 (95%)]\tLoss: 0.324662\n",
            "Train epoch: 243 [782800/25046 (97%)]\tLoss: 1.288134\n",
            "Train epoch: 243 [846300/25046 (100%)]\tLoss: 0.691409\n",
            "Make prediction for 5010 samples...\n",
            "0.8030612 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 244 [0/25046 (0%)]\tLoss: 0.557618\n",
            "Train epoch: 244 [20020/25046 (3%)]\tLoss: 0.615636\n",
            "Train epoch: 244 [42760/25046 (5%)]\tLoss: 1.132925\n",
            "Train epoch: 244 [59040/25046 (8%)]\tLoss: 0.830109\n",
            "Train epoch: 244 [78640/25046 (10%)]\tLoss: 0.463077\n",
            "Train epoch: 244 [100900/25046 (13%)]\tLoss: 1.043396\n",
            "Train epoch: 244 [114240/25046 (15%)]\tLoss: 0.248560\n",
            "Train epoch: 244 [137760/25046 (18%)]\tLoss: 0.874648\n",
            "Train epoch: 244 [169280/25046 (20%)]\tLoss: 0.369098\n",
            "Train epoch: 244 [184320/25046 (23%)]\tLoss: 0.825250\n",
            "Train epoch: 244 [219800/25046 (26%)]\tLoss: 1.046448\n",
            "Train epoch: 244 [238920/25046 (28%)]\tLoss: 0.646310\n",
            "Train epoch: 244 [249120/25046 (31%)]\tLoss: 0.331985\n",
            "Train epoch: 244 [274040/25046 (33%)]\tLoss: 1.297063\n",
            "Train epoch: 244 [277200/25046 (36%)]\tLoss: 1.456753\n",
            "Train epoch: 244 [312300/25046 (38%)]\tLoss: 1.061365\n",
            "Train epoch: 244 [327360/25046 (41%)]\tLoss: 0.774945\n",
            "Train epoch: 244 [344760/25046 (43%)]\tLoss: 0.733359\n",
            "Train epoch: 244 [351360/25046 (46%)]\tLoss: 0.800893\n",
            "Train epoch: 244 [402040/25046 (49%)]\tLoss: 0.523628\n",
            "Train epoch: 244 [410800/25046 (51%)]\tLoss: 0.407039\n",
            "Train epoch: 244 [417480/25046 (54%)]\tLoss: 0.463897\n",
            "Train epoch: 244 [449680/25046 (56%)]\tLoss: 1.584656\n",
            "Train epoch: 244 [461840/25046 (59%)]\tLoss: 0.753146\n",
            "Train epoch: 244 [476640/25046 (61%)]\tLoss: 1.291307\n",
            "Train epoch: 244 [543500/25046 (64%)]\tLoss: 1.925888\n",
            "Train epoch: 244 [538720/25046 (66%)]\tLoss: 0.737581\n",
            "Train epoch: 244 [565920/25046 (69%)]\tLoss: 0.550702\n",
            "Train epoch: 244 [588000/25046 (72%)]\tLoss: 0.675013\n",
            "Train epoch: 244 [615960/25046 (74%)]\tLoss: 0.479368\n",
            "Train epoch: 244 [657000/25046 (77%)]\tLoss: 0.490906\n",
            "Train epoch: 244 [610080/25046 (79%)]\tLoss: 1.019202\n",
            "Train epoch: 244 [600320/25046 (82%)]\tLoss: 0.633357\n",
            "Train epoch: 244 [698940/25046 (84%)]\tLoss: 0.696410\n",
            "Train epoch: 244 [738480/25046 (87%)]\tLoss: 0.455126\n",
            "Train epoch: 244 [717500/25046 (89%)]\tLoss: 0.977930\n",
            "Train epoch: 244 [753120/25046 (92%)]\tLoss: 1.314297\n",
            "Train epoch: 244 [762940/25046 (95%)]\tLoss: 0.380046\n",
            "Train epoch: 244 [807120/25046 (97%)]\tLoss: 0.697503\n",
            "Train epoch: 244 [810420/25046 (100%)]\tLoss: 1.716882\n",
            "Make prediction for 5010 samples...\n",
            "0.80213416 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 245 [0/25046 (0%)]\tLoss: 0.516379\n",
            "Train epoch: 245 [20100/25046 (3%)]\tLoss: 0.672875\n",
            "Train epoch: 245 [41480/25046 (5%)]\tLoss: 0.988042\n",
            "Train epoch: 245 [62340/25046 (8%)]\tLoss: 0.355913\n",
            "Train epoch: 245 [79040/25046 (10%)]\tLoss: 0.810078\n",
            "Train epoch: 245 [98600/25046 (13%)]\tLoss: 0.553056\n",
            "Train epoch: 245 [123600/25046 (15%)]\tLoss: 1.111265\n",
            "Train epoch: 245 [141680/25046 (18%)]\tLoss: 0.560150\n",
            "Train epoch: 245 [164640/25046 (20%)]\tLoss: 1.262293\n",
            "Train epoch: 245 [179280/25046 (23%)]\tLoss: 0.996872\n",
            "Train epoch: 245 [213400/25046 (26%)]\tLoss: 1.555681\n",
            "Train epoch: 245 [223960/25046 (28%)]\tLoss: 0.825863\n",
            "Train epoch: 245 [253680/25046 (31%)]\tLoss: 0.828526\n",
            "Train epoch: 245 [266240/25046 (33%)]\tLoss: 0.576620\n",
            "Train epoch: 245 [279160/25046 (36%)]\tLoss: 0.605075\n",
            "Train epoch: 245 [308700/25046 (38%)]\tLoss: 0.988952\n",
            "Train epoch: 245 [340160/25046 (41%)]\tLoss: 0.683666\n",
            "Train epoch: 245 [362100/25046 (43%)]\tLoss: 0.747811\n",
            "Train epoch: 245 [379440/25046 (46%)]\tLoss: 1.145644\n",
            "Train epoch: 245 [392540/25046 (49%)]\tLoss: 0.289103\n",
            "Train epoch: 245 [422000/25046 (51%)]\tLoss: 1.533934\n",
            "Train epoch: 245 [447300/25046 (54%)]\tLoss: 2.498412\n",
            "Train epoch: 245 [447920/25046 (56%)]\tLoss: 0.357442\n",
            "Train epoch: 245 [491740/25046 (59%)]\tLoss: 0.592983\n",
            "Train epoch: 245 [471840/25046 (61%)]\tLoss: 1.141814\n",
            "Train epoch: 245 [520000/25046 (64%)]\tLoss: 0.651329\n",
            "Train epoch: 245 [501280/25046 (66%)]\tLoss: 0.541875\n",
            "Train epoch: 245 [537840/25046 (69%)]\tLoss: 0.853735\n",
            "Train epoch: 245 [580720/25046 (72%)]\tLoss: 0.357349\n",
            "Train epoch: 245 [585800/25046 (74%)]\tLoss: 1.553524\n",
            "Train epoch: 245 [604200/25046 (77%)]\tLoss: 1.220542\n",
            "Train epoch: 245 [643560/25046 (79%)]\tLoss: 0.918256\n",
            "Train epoch: 245 [695680/25046 (82%)]\tLoss: 1.294069\n",
            "Train epoch: 245 [687720/25046 (84%)]\tLoss: 1.358467\n",
            "Train epoch: 245 [718760/25046 (87%)]\tLoss: 1.488610\n",
            "Train epoch: 245 [646800/25046 (89%)]\tLoss: 0.860053\n",
            "Train epoch: 245 [717120/25046 (92%)]\tLoss: 0.713206\n",
            "Train epoch: 245 [807340/25046 (95%)]\tLoss: 1.063194\n",
            "Train epoch: 245 [817760/25046 (97%)]\tLoss: 0.765599\n",
            "Train epoch: 245 [755040/25046 (100%)]\tLoss: 0.403611\n",
            "Make prediction for 5010 samples...\n",
            "0.80177146 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 246 [0/25046 (0%)]\tLoss: 0.839518\n",
            "Train epoch: 246 [20380/25046 (3%)]\tLoss: 0.410412\n",
            "Train epoch: 246 [42320/25046 (5%)]\tLoss: 1.170928\n",
            "Train epoch: 246 [62040/25046 (8%)]\tLoss: 0.591592\n",
            "Train epoch: 246 [79120/25046 (10%)]\tLoss: 0.346274\n",
            "Train epoch: 246 [108300/25046 (13%)]\tLoss: 0.702111\n",
            "Train epoch: 246 [124080/25046 (15%)]\tLoss: 0.920517\n",
            "Train epoch: 246 [140840/25046 (18%)]\tLoss: 0.708746\n",
            "Train epoch: 246 [168480/25046 (20%)]\tLoss: 0.506403\n",
            "Train epoch: 246 [175680/25046 (23%)]\tLoss: 1.066545\n",
            "Train epoch: 246 [213000/25046 (26%)]\tLoss: 0.693513\n",
            "Train epoch: 246 [216260/25046 (28%)]\tLoss: 0.537064\n",
            "Train epoch: 246 [250320/25046 (31%)]\tLoss: 0.591394\n",
            "Train epoch: 246 [265980/25046 (33%)]\tLoss: 1.070882\n",
            "Train epoch: 246 [279160/25046 (36%)]\tLoss: 0.970674\n",
            "Train epoch: 246 [306000/25046 (38%)]\tLoss: 0.997747\n",
            "Train epoch: 246 [319040/25046 (41%)]\tLoss: 0.621858\n",
            "Train epoch: 246 [351560/25046 (43%)]\tLoss: 0.648688\n",
            "Train epoch: 246 [375120/25046 (46%)]\tLoss: 0.882850\n",
            "Train epoch: 246 [376200/25046 (49%)]\tLoss: 0.410529\n",
            "Train epoch: 246 [420800/25046 (51%)]\tLoss: 0.751775\n",
            "Train epoch: 246 [414120/25046 (54%)]\tLoss: 0.780888\n",
            "Train epoch: 246 [463760/25046 (56%)]\tLoss: 0.418766\n",
            "Train epoch: 246 [477020/25046 (59%)]\tLoss: 0.811543\n",
            "Train epoch: 246 [499680/25046 (61%)]\tLoss: 1.618599\n",
            "Train epoch: 246 [490500/25046 (64%)]\tLoss: 0.549860\n",
            "Train epoch: 246 [522080/25046 (66%)]\tLoss: 0.579705\n",
            "Train epoch: 246 [532440/25046 (69%)]\tLoss: 0.962793\n",
            "Train epoch: 246 [592480/25046 (72%)]\tLoss: 1.105074\n",
            "Train epoch: 246 [581160/25046 (74%)]\tLoss: 1.026938\n",
            "Train epoch: 246 [631800/25046 (77%)]\tLoss: 0.556327\n",
            "Train epoch: 246 [645420/25046 (79%)]\tLoss: 0.525419\n",
            "Train epoch: 246 [668800/25046 (82%)]\tLoss: 1.564949\n",
            "Train epoch: 246 [695640/25046 (84%)]\tLoss: 0.912786\n",
            "Train epoch: 246 [663000/25046 (87%)]\tLoss: 1.123300\n",
            "Train epoch: 246 [736400/25046 (89%)]\tLoss: 1.120350\n",
            "Train epoch: 246 [756720/25046 (92%)]\tLoss: 0.614823\n",
            "Train epoch: 246 [762200/25046 (95%)]\tLoss: 1.021247\n",
            "Train epoch: 246 [788880/25046 (97%)]\tLoss: 0.658994\n",
            "Train epoch: 246 [751920/25046 (100%)]\tLoss: 0.721150\n",
            "Make prediction for 5010 samples...\n",
            "0.80159396 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 247 [0/25046 (0%)]\tLoss: 0.614839\n",
            "Train epoch: 247 [19880/25046 (3%)]\tLoss: 0.757611\n",
            "Train epoch: 247 [41440/25046 (5%)]\tLoss: 1.023709\n",
            "Train epoch: 247 [59400/25046 (8%)]\tLoss: 0.666008\n",
            "Train epoch: 247 [79840/25046 (10%)]\tLoss: 0.917836\n",
            "Train epoch: 247 [107200/25046 (13%)]\tLoss: 0.536856\n",
            "Train epoch: 247 [131520/25046 (15%)]\tLoss: 0.696946\n",
            "Train epoch: 247 [143780/25046 (18%)]\tLoss: 0.601439\n",
            "Train epoch: 247 [154400/25046 (20%)]\tLoss: 0.885269\n",
            "Train epoch: 247 [184680/25046 (23%)]\tLoss: 1.560714\n",
            "Train epoch: 247 [209400/25046 (26%)]\tLoss: 1.067156\n",
            "Train epoch: 247 [223520/25046 (28%)]\tLoss: 0.346226\n",
            "Train epoch: 247 [231600/25046 (31%)]\tLoss: 0.297656\n",
            "Train epoch: 247 [275340/25046 (33%)]\tLoss: 0.340178\n",
            "Train epoch: 247 [288120/25046 (36%)]\tLoss: 0.605477\n",
            "Train epoch: 247 [294600/25046 (38%)]\tLoss: 1.321860\n",
            "Train epoch: 247 [322240/25046 (41%)]\tLoss: 1.170046\n",
            "Train epoch: 247 [352920/25046 (43%)]\tLoss: 0.586408\n",
            "Train epoch: 247 [354240/25046 (46%)]\tLoss: 0.532157\n",
            "Train epoch: 247 [397480/25046 (49%)]\tLoss: 0.646504\n",
            "Train epoch: 247 [414800/25046 (51%)]\tLoss: 0.231308\n",
            "Train epoch: 247 [445620/25046 (54%)]\tLoss: 0.626882\n",
            "Train epoch: 247 [465520/25046 (56%)]\tLoss: 0.721474\n",
            "Train epoch: 247 [468280/25046 (59%)]\tLoss: 0.833057\n",
            "Train epoch: 247 [494400/25046 (61%)]\tLoss: 0.941095\n",
            "Train epoch: 247 [533000/25046 (64%)]\tLoss: 0.524606\n",
            "Train epoch: 247 [529360/25046 (66%)]\tLoss: 0.351150\n",
            "Train epoch: 247 [572940/25046 (69%)]\tLoss: 1.229471\n",
            "Train epoch: 247 [581280/25046 (72%)]\tLoss: 0.722069\n",
            "Train epoch: 247 [613060/25046 (74%)]\tLoss: 0.940742\n",
            "Train epoch: 247 [621600/25046 (77%)]\tLoss: 1.600943\n",
            "Train epoch: 247 [625580/25046 (79%)]\tLoss: 1.034977\n",
            "Train epoch: 247 [675200/25046 (82%)]\tLoss: 0.484223\n",
            "Train epoch: 247 [648780/25046 (84%)]\tLoss: 0.592970\n",
            "Train epoch: 247 [673880/25046 (87%)]\tLoss: 1.027083\n",
            "Train epoch: 247 [705600/25046 (89%)]\tLoss: 0.207340\n",
            "Train epoch: 247 [711360/25046 (92%)]\tLoss: 0.650518\n",
            "Train epoch: 247 [782180/25046 (95%)]\tLoss: 0.445842\n",
            "Train epoch: 247 [801040/25046 (97%)]\tLoss: 0.839348\n",
            "Train epoch: 247 [826020/25046 (100%)]\tLoss: 0.269545\n",
            "Make prediction for 5010 samples...\n",
            "0.80159605 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 248 [0/25046 (0%)]\tLoss: 0.455173\n",
            "Train epoch: 248 [21020/25046 (3%)]\tLoss: 1.589555\n",
            "Train epoch: 248 [40880/25046 (5%)]\tLoss: 0.832056\n",
            "Train epoch: 248 [60840/25046 (8%)]\tLoss: 0.686052\n",
            "Train epoch: 248 [83520/25046 (10%)]\tLoss: 0.591302\n",
            "Train epoch: 248 [96000/25046 (13%)]\tLoss: 0.819970\n",
            "Train epoch: 248 [128520/25046 (15%)]\tLoss: 0.291072\n",
            "Train epoch: 248 [145880/25046 (18%)]\tLoss: 0.542466\n",
            "Train epoch: 248 [168480/25046 (20%)]\tLoss: 0.557948\n",
            "Train epoch: 248 [190800/25046 (23%)]\tLoss: 0.817538\n",
            "Train epoch: 248 [210000/25046 (26%)]\tLoss: 0.774587\n",
            "Train epoch: 248 [226160/25046 (28%)]\tLoss: 1.173282\n",
            "Train epoch: 248 [242640/25046 (31%)]\tLoss: 1.201083\n",
            "Train epoch: 248 [265460/25046 (33%)]\tLoss: 0.549941\n",
            "Train epoch: 248 [283360/25046 (36%)]\tLoss: 0.973835\n",
            "Train epoch: 248 [311700/25046 (38%)]\tLoss: 1.590150\n",
            "Train epoch: 248 [339520/25046 (41%)]\tLoss: 1.617790\n",
            "Train epoch: 248 [341020/25046 (43%)]\tLoss: 0.258783\n",
            "Train epoch: 248 [379440/25046 (46%)]\tLoss: 0.972026\n",
            "Train epoch: 248 [392540/25046 (49%)]\tLoss: 1.456744\n",
            "Train epoch: 248 [413200/25046 (51%)]\tLoss: 0.611022\n",
            "Train epoch: 248 [440580/25046 (54%)]\tLoss: 0.548260\n",
            "Train epoch: 248 [439560/25046 (56%)]\tLoss: 1.393459\n",
            "Train epoch: 248 [490360/25046 (59%)]\tLoss: 0.749112\n",
            "Train epoch: 248 [476160/25046 (61%)]\tLoss: 1.004787\n",
            "Train epoch: 248 [495500/25046 (64%)]\tLoss: 0.640258\n",
            "Train epoch: 248 [530920/25046 (66%)]\tLoss: 0.928812\n",
            "Train epoch: 248 [550260/25046 (69%)]\tLoss: 0.741044\n",
            "Train epoch: 248 [577360/25046 (72%)]\tLoss: 0.884480\n",
            "Train epoch: 248 [604940/25046 (74%)]\tLoss: 0.676901\n",
            "Train epoch: 248 [649800/25046 (77%)]\tLoss: 1.730278\n",
            "Train epoch: 248 [657200/25046 (79%)]\tLoss: 0.485902\n",
            "Train epoch: 248 [641920/25046 (82%)]\tLoss: 1.006589\n",
            "Train epoch: 248 [678480/25046 (84%)]\tLoss: 0.493482\n",
            "Train epoch: 248 [686800/25046 (87%)]\tLoss: 1.160348\n",
            "Train epoch: 248 [697200/25046 (89%)]\tLoss: 0.615462\n",
            "Train epoch: 248 [739440/25046 (92%)]\tLoss: 0.426083\n",
            "Train epoch: 248 [782180/25046 (95%)]\tLoss: 1.511654\n",
            "Train epoch: 248 [810920/25046 (97%)]\tLoss: 0.397499\n",
            "Train epoch: 248 [795600/25046 (100%)]\tLoss: 0.896096\n",
            "Make prediction for 5010 samples...\n",
            "0.80162174 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 249 [0/25046 (0%)]\tLoss: 0.641906\n",
            "Train epoch: 249 [20220/25046 (3%)]\tLoss: 0.748568\n",
            "Train epoch: 249 [41160/25046 (5%)]\tLoss: 0.729080\n",
            "Train epoch: 249 [64680/25046 (8%)]\tLoss: 1.394554\n",
            "Train epoch: 249 [76560/25046 (10%)]\tLoss: 0.227651\n",
            "Train epoch: 249 [103500/25046 (13%)]\tLoss: 1.654804\n",
            "Train epoch: 249 [125280/25046 (15%)]\tLoss: 1.145074\n",
            "Train epoch: 249 [146300/25046 (18%)]\tLoss: 0.680350\n",
            "Train epoch: 249 [167200/25046 (20%)]\tLoss: 1.587773\n",
            "Train epoch: 249 [187020/25046 (23%)]\tLoss: 0.406063\n",
            "Train epoch: 249 [195800/25046 (26%)]\tLoss: 0.877498\n",
            "Train epoch: 249 [218900/25046 (28%)]\tLoss: 0.264677\n",
            "Train epoch: 249 [252240/25046 (31%)]\tLoss: 0.664683\n",
            "Train epoch: 249 [257920/25046 (33%)]\tLoss: 0.806506\n",
            "Train epoch: 249 [277480/25046 (36%)]\tLoss: 0.800661\n",
            "Train epoch: 249 [317400/25046 (38%)]\tLoss: 0.456417\n",
            "Train epoch: 249 [306880/25046 (41%)]\tLoss: 0.560773\n",
            "Train epoch: 249 [362100/25046 (43%)]\tLoss: 0.813319\n",
            "Train epoch: 249 [383400/25046 (46%)]\tLoss: 0.838083\n",
            "Train epoch: 249 [392540/25046 (49%)]\tLoss: 1.022449\n",
            "Train epoch: 249 [408800/25046 (51%)]\tLoss: 0.719268\n",
            "Train epoch: 249 [429240/25046 (54%)]\tLoss: 1.047033\n",
            "Train epoch: 249 [483560/25046 (56%)]\tLoss: 1.994288\n",
            "Train epoch: 249 [457700/25046 (59%)]\tLoss: 0.256938\n",
            "Train epoch: 249 [490560/25046 (61%)]\tLoss: 0.936108\n",
            "Train epoch: 249 [523500/25046 (64%)]\tLoss: 0.535112\n",
            "Train epoch: 249 [535600/25046 (66%)]\tLoss: 0.551187\n",
            "Train epoch: 249 [541620/25046 (69%)]\tLoss: 0.297446\n",
            "Train epoch: 249 [581280/25046 (72%)]\tLoss: 0.244334\n",
            "Train epoch: 249 [581160/25046 (74%)]\tLoss: 0.344868\n",
            "Train epoch: 249 [622800/25046 (77%)]\tLoss: 1.131529\n",
            "Train epoch: 249 [623100/25046 (79%)]\tLoss: 0.579650\n",
            "Train epoch: 249 [648320/25046 (82%)]\tLoss: 0.555572\n",
            "Train epoch: 249 [661320/25046 (84%)]\tLoss: 0.962308\n",
            "Train epoch: 249 [711280/25046 (87%)]\tLoss: 0.509550\n",
            "Train epoch: 249 [692300/25046 (89%)]\tLoss: 0.271635\n",
            "Train epoch: 249 [745920/25046 (92%)]\tLoss: 0.803891\n",
            "Train epoch: 249 [764420/25046 (95%)]\tLoss: 1.004660\n",
            "Train epoch: 249 [791160/25046 (97%)]\tLoss: 1.136539\n",
            "Train epoch: 249 [790140/25046 (100%)]\tLoss: 1.553563\n",
            "Make prediction for 5010 samples...\n",
            "0.8015209 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 250 [0/25046 (0%)]\tLoss: 0.400616\n",
            "Train epoch: 250 [19180/25046 (3%)]\tLoss: 1.029545\n",
            "Train epoch: 250 [39760/25046 (5%)]\tLoss: 1.076768\n",
            "Train epoch: 250 [64620/25046 (8%)]\tLoss: 1.754635\n",
            "Train epoch: 250 [80320/25046 (10%)]\tLoss: 0.793501\n",
            "Train epoch: 250 [103400/25046 (13%)]\tLoss: 1.876812\n",
            "Train epoch: 250 [125160/25046 (15%)]\tLoss: 0.377865\n",
            "Train epoch: 250 [136920/25046 (18%)]\tLoss: 0.396967\n",
            "Train epoch: 250 [171200/25046 (20%)]\tLoss: 1.403267\n",
            "Train epoch: 250 [183600/25046 (23%)]\tLoss: 1.605152\n",
            "Train epoch: 250 [209200/25046 (26%)]\tLoss: 0.900324\n",
            "Train epoch: 250 [222420/25046 (28%)]\tLoss: 0.449958\n",
            "Train epoch: 250 [245760/25046 (31%)]\tLoss: 0.212801\n",
            "Train epoch: 250 [269880/25046 (33%)]\tLoss: 0.185812\n",
            "Train epoch: 250 [286720/25046 (36%)]\tLoss: 0.301836\n",
            "Train epoch: 250 [308400/25046 (38%)]\tLoss: 0.863439\n",
            "Train epoch: 250 [328960/25046 (41%)]\tLoss: 0.984666\n",
            "Train epoch: 250 [359720/25046 (43%)]\tLoss: 1.052904\n",
            "Train epoch: 250 [363600/25046 (46%)]\tLoss: 1.222720\n",
            "Train epoch: 250 [395960/25046 (49%)]\tLoss: 0.399813\n",
            "Train epoch: 250 [426000/25046 (51%)]\tLoss: 0.729304\n",
            "Train epoch: 250 [430080/25046 (54%)]\tLoss: 0.610406\n",
            "Train epoch: 250 [443080/25046 (56%)]\tLoss: 0.634490\n",
            "Train epoch: 250 [471960/25046 (59%)]\tLoss: 0.506929\n",
            "Train epoch: 250 [481920/25046 (61%)]\tLoss: 0.476852\n",
            "Train epoch: 250 [505500/25046 (64%)]\tLoss: 1.167855\n",
            "Train epoch: 250 [509600/25046 (66%)]\tLoss: 0.291697\n",
            "Train epoch: 250 [571320/25046 (69%)]\tLoss: 1.350487\n",
            "Train epoch: 250 [586880/25046 (72%)]\tLoss: 0.421606\n",
            "Train epoch: 250 [584060/25046 (74%)]\tLoss: 0.842167\n",
            "Train epoch: 250 [606000/25046 (77%)]\tLoss: 0.936941\n",
            "Train epoch: 250 [608220/25046 (79%)]\tLoss: 0.647195\n",
            "Train epoch: 250 [680320/25046 (82%)]\tLoss: 0.737440\n",
            "Train epoch: 250 [714780/25046 (84%)]\tLoss: 1.272941\n",
            "Train epoch: 250 [726920/25046 (87%)]\tLoss: 0.631497\n",
            "Train epoch: 250 [742700/25046 (89%)]\tLoss: 0.396254\n",
            "Train epoch: 250 [779760/25046 (92%)]\tLoss: 0.588243\n",
            "Train epoch: 250 [779220/25046 (95%)]\tLoss: 0.638787\n",
            "Train epoch: 250 [782040/25046 (97%)]\tLoss: 0.757008\n",
            "Train epoch: 250 [776880/25046 (100%)]\tLoss: 0.670189\n",
            "Make prediction for 5010 samples...\n",
            "0.8019386 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 251 [0/25046 (0%)]\tLoss: 0.506392\n",
            "Train epoch: 251 [20020/25046 (3%)]\tLoss: 0.412818\n",
            "Train epoch: 251 [39640/25046 (5%)]\tLoss: 0.521094\n",
            "Train epoch: 251 [61440/25046 (8%)]\tLoss: 0.552525\n",
            "Train epoch: 251 [81280/25046 (10%)]\tLoss: 1.243186\n",
            "Train epoch: 251 [101800/25046 (13%)]\tLoss: 0.721491\n",
            "Train epoch: 251 [123720/25046 (15%)]\tLoss: 0.658460\n",
            "Train epoch: 251 [129220/25046 (18%)]\tLoss: 0.181774\n",
            "Train epoch: 251 [171680/25046 (20%)]\tLoss: 1.043422\n",
            "Train epoch: 251 [196920/25046 (23%)]\tLoss: 0.775971\n",
            "Train epoch: 251 [201200/25046 (26%)]\tLoss: 0.816612\n",
            "Train epoch: 251 [212080/25046 (28%)]\tLoss: 0.501918\n",
            "Train epoch: 251 [251520/25046 (31%)]\tLoss: 1.057746\n",
            "Train epoch: 251 [264940/25046 (33%)]\tLoss: 0.204455\n",
            "Train epoch: 251 [299880/25046 (36%)]\tLoss: 1.828588\n",
            "Train epoch: 251 [321600/25046 (38%)]\tLoss: 0.805237\n",
            "Train epoch: 251 [329920/25046 (41%)]\tLoss: 0.926696\n",
            "Train epoch: 251 [347140/25046 (43%)]\tLoss: 0.957680\n",
            "Train epoch: 251 [375480/25046 (46%)]\tLoss: 0.685216\n",
            "Train epoch: 251 [411920/25046 (49%)]\tLoss: 1.544651\n",
            "Train epoch: 251 [415600/25046 (51%)]\tLoss: 1.132670\n",
            "Train epoch: 251 [422100/25046 (54%)]\tLoss: 0.344585\n",
            "Train epoch: 251 [454520/25046 (56%)]\tLoss: 1.320221\n",
            "Train epoch: 251 [458160/25046 (59%)]\tLoss: 1.060575\n",
            "Train epoch: 251 [487680/25046 (61%)]\tLoss: 0.957994\n",
            "Train epoch: 251 [481000/25046 (64%)]\tLoss: 1.040472\n",
            "Train epoch: 251 [581360/25046 (66%)]\tLoss: 0.678951\n",
            "Train epoch: 251 [573480/25046 (69%)]\tLoss: 0.638705\n",
            "Train epoch: 251 [576800/25046 (72%)]\tLoss: 0.454160\n",
            "Train epoch: 251 [610740/25046 (74%)]\tLoss: 1.018355\n",
            "Train epoch: 251 [637200/25046 (77%)]\tLoss: 1.062563\n",
            "Train epoch: 251 [582180/25046 (79%)]\tLoss: 0.544661\n",
            "Train epoch: 251 [639360/25046 (82%)]\tLoss: 1.489845\n",
            "Train epoch: 251 [669900/25046 (84%)]\tLoss: 0.668029\n",
            "Train epoch: 251 [692920/25046 (87%)]\tLoss: 0.258922\n",
            "Train epoch: 251 [691600/25046 (89%)]\tLoss: 0.551367\n",
            "Train epoch: 251 [689760/25046 (92%)]\tLoss: 0.465460\n",
            "Train epoch: 251 [759980/25046 (95%)]\tLoss: 1.051304\n",
            "Train epoch: 251 [753160/25046 (97%)]\tLoss: 0.630694\n",
            "Train epoch: 251 [783900/25046 (100%)]\tLoss: 1.012977\n",
            "Make prediction for 5010 samples...\n",
            "0.80460376 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 252 [0/25046 (0%)]\tLoss: 1.333427\n",
            "Train epoch: 252 [20680/25046 (3%)]\tLoss: 0.394484\n",
            "Train epoch: 252 [41280/25046 (5%)]\tLoss: 0.505542\n",
            "Train epoch: 252 [61620/25046 (8%)]\tLoss: 0.294787\n",
            "Train epoch: 252 [82400/25046 (10%)]\tLoss: 1.235726\n",
            "Train epoch: 252 [93900/25046 (13%)]\tLoss: 0.836540\n",
            "Train epoch: 252 [124920/25046 (15%)]\tLoss: 0.463888\n",
            "Train epoch: 252 [149940/25046 (18%)]\tLoss: 1.020076\n",
            "Train epoch: 252 [176640/25046 (20%)]\tLoss: 0.707675\n",
            "Train epoch: 252 [180360/25046 (23%)]\tLoss: 0.735226\n",
            "Train epoch: 252 [206200/25046 (26%)]\tLoss: 0.960265\n",
            "Train epoch: 252 [205700/25046 (28%)]\tLoss: 0.299350\n",
            "Train epoch: 252 [252480/25046 (31%)]\tLoss: 1.340331\n",
            "Train epoch: 252 [260780/25046 (33%)]\tLoss: 1.068776\n",
            "Train epoch: 252 [300160/25046 (36%)]\tLoss: 1.074043\n",
            "Train epoch: 252 [312600/25046 (38%)]\tLoss: 1.119329\n",
            "Train epoch: 252 [329920/25046 (41%)]\tLoss: 0.957702\n",
            "Train epoch: 252 [358020/25046 (43%)]\tLoss: 0.556163\n",
            "Train epoch: 252 [387000/25046 (46%)]\tLoss: 0.558500\n",
            "Train epoch: 252 [367840/25046 (49%)]\tLoss: 0.625178\n",
            "Train epoch: 252 [411200/25046 (51%)]\tLoss: 0.387720\n",
            "Train epoch: 252 [413280/25046 (54%)]\tLoss: 0.689944\n",
            "Train epoch: 252 [461120/25046 (56%)]\tLoss: 0.345936\n",
            "Train epoch: 252 [468280/25046 (59%)]\tLoss: 0.954762\n",
            "Train epoch: 252 [495840/25046 (61%)]\tLoss: 0.245334\n",
            "Train epoch: 252 [482000/25046 (64%)]\tLoss: 0.357408\n",
            "Train epoch: 252 [512200/25046 (66%)]\tLoss: 0.445714\n",
            "Train epoch: 252 [537300/25046 (69%)]\tLoss: 0.399428\n",
            "Train epoch: 252 [571200/25046 (72%)]\tLoss: 0.748384\n",
            "Train epoch: 252 [582900/25046 (74%)]\tLoss: 1.079558\n",
            "Train epoch: 252 [615000/25046 (77%)]\tLoss: 0.458948\n",
            "Train epoch: 252 [615040/25046 (79%)]\tLoss: 0.572457\n",
            "Train epoch: 252 [650240/25046 (82%)]\tLoss: 0.628538\n",
            "Train epoch: 252 [687060/25046 (84%)]\tLoss: 0.853616\n",
            "Train epoch: 252 [716040/25046 (87%)]\tLoss: 0.779667\n",
            "Train epoch: 252 [726600/25046 (89%)]\tLoss: 0.960691\n",
            "Train epoch: 252 [729360/25046 (92%)]\tLoss: 1.121611\n",
            "Train epoch: 252 [788100/25046 (95%)]\tLoss: 1.238407\n",
            "Train epoch: 252 [785840/25046 (97%)]\tLoss: 0.459017\n",
            "Train epoch: 252 [793260/25046 (100%)]\tLoss: 1.351909\n",
            "Make prediction for 5010 samples...\n",
            "0.802635 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 253 [0/25046 (0%)]\tLoss: 1.119844\n",
            "Train epoch: 253 [20300/25046 (3%)]\tLoss: 1.134009\n",
            "Train epoch: 253 [41520/25046 (5%)]\tLoss: 0.387535\n",
            "Train epoch: 253 [59460/25046 (8%)]\tLoss: 0.306328\n",
            "Train epoch: 253 [79120/25046 (10%)]\tLoss: 1.070447\n",
            "Train epoch: 253 [96700/25046 (13%)]\tLoss: 1.717391\n",
            "Train epoch: 253 [131760/25046 (15%)]\tLoss: 0.975361\n",
            "Train epoch: 253 [137340/25046 (18%)]\tLoss: 1.082424\n",
            "Train epoch: 253 [164000/25046 (20%)]\tLoss: 0.656680\n",
            "Train epoch: 253 [177660/25046 (23%)]\tLoss: 0.639695\n",
            "Train epoch: 253 [207000/25046 (26%)]\tLoss: 0.676001\n",
            "Train epoch: 253 [226600/25046 (28%)]\tLoss: 0.623073\n",
            "Train epoch: 253 [244560/25046 (31%)]\tLoss: 0.595744\n",
            "Train epoch: 253 [279500/25046 (33%)]\tLoss: 1.039696\n",
            "Train epoch: 253 [307440/25046 (36%)]\tLoss: 1.173636\n",
            "Train epoch: 253 [304200/25046 (38%)]\tLoss: 1.170965\n",
            "Train epoch: 253 [323520/25046 (41%)]\tLoss: 0.597021\n",
            "Train epoch: 253 [352240/25046 (43%)]\tLoss: 0.649030\n",
            "Train epoch: 253 [346680/25046 (46%)]\tLoss: 0.401566\n",
            "Train epoch: 253 [371640/25046 (49%)]\tLoss: 0.920107\n",
            "Train epoch: 253 [417200/25046 (51%)]\tLoss: 1.860258\n",
            "Train epoch: 253 [433020/25046 (54%)]\tLoss: 0.384451\n",
            "Train epoch: 253 [510400/25046 (56%)]\tLoss: 0.712260\n",
            "Train epoch: 253 [494500/25046 (59%)]\tLoss: 0.260728\n",
            "Train epoch: 253 [506400/25046 (61%)]\tLoss: 1.099761\n",
            "Train epoch: 253 [515000/25046 (64%)]\tLoss: 0.530517\n",
            "Train epoch: 253 [547560/25046 (66%)]\tLoss: 0.218308\n",
            "Train epoch: 253 [570780/25046 (69%)]\tLoss: 0.529626\n",
            "Train epoch: 253 [571200/25046 (72%)]\tLoss: 0.406414\n",
            "Train epoch: 253 [591020/25046 (74%)]\tLoss: 1.437287\n",
            "Train epoch: 253 [609600/25046 (77%)]\tLoss: 1.176709\n",
            "Train epoch: 253 [657200/25046 (79%)]\tLoss: 1.737720\n",
            "Train epoch: 253 [652160/25046 (82%)]\tLoss: 0.574006\n",
            "Train epoch: 253 [670560/25046 (84%)]\tLoss: 0.771145\n",
            "Train epoch: 253 [733720/25046 (87%)]\tLoss: 1.213780\n",
            "Train epoch: 253 [721700/25046 (89%)]\tLoss: 1.205921\n",
            "Train epoch: 253 [758160/25046 (92%)]\tLoss: 1.115801\n",
            "Train epoch: 253 [777000/25046 (95%)]\tLoss: 1.469284\n",
            "Train epoch: 253 [825360/25046 (97%)]\tLoss: 1.485106\n",
            "Train epoch: 253 [840060/25046 (100%)]\tLoss: 0.999599\n",
            "Make prediction for 5010 samples...\n",
            "0.8018084 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 254 [0/25046 (0%)]\tLoss: 0.498649\n",
            "Train epoch: 254 [21300/25046 (3%)]\tLoss: 1.807881\n",
            "Train epoch: 254 [37920/25046 (5%)]\tLoss: 0.553734\n",
            "Train epoch: 254 [58860/25046 (8%)]\tLoss: 1.232600\n",
            "Train epoch: 254 [81680/25046 (10%)]\tLoss: 0.286465\n",
            "Train epoch: 254 [104400/25046 (13%)]\tLoss: 0.658000\n",
            "Train epoch: 254 [122760/25046 (15%)]\tLoss: 0.833857\n",
            "Train epoch: 254 [142240/25046 (18%)]\tLoss: 0.686478\n",
            "Train epoch: 254 [163520/25046 (20%)]\tLoss: 1.160211\n",
            "Train epoch: 254 [185400/25046 (23%)]\tLoss: 0.587959\n",
            "Train epoch: 254 [198200/25046 (26%)]\tLoss: 0.875534\n",
            "Train epoch: 254 [222640/25046 (28%)]\tLoss: 1.252204\n",
            "Train epoch: 254 [243360/25046 (31%)]\tLoss: 0.388408\n",
            "Train epoch: 254 [245960/25046 (33%)]\tLoss: 0.961771\n",
            "Train epoch: 254 [294280/25046 (36%)]\tLoss: 0.365384\n",
            "Train epoch: 254 [307500/25046 (38%)]\tLoss: 0.727911\n",
            "Train epoch: 254 [341440/25046 (41%)]\tLoss: 0.241276\n",
            "Train epoch: 254 [371960/25046 (43%)]\tLoss: 0.684701\n",
            "Train epoch: 254 [358920/25046 (46%)]\tLoss: 0.528703\n",
            "Train epoch: 254 [389880/25046 (49%)]\tLoss: 0.954775\n",
            "Train epoch: 254 [405600/25046 (51%)]\tLoss: 0.366963\n",
            "Train epoch: 254 [451920/25046 (54%)]\tLoss: 1.038552\n",
            "Train epoch: 254 [433400/25046 (56%)]\tLoss: 0.594701\n",
            "Train epoch: 254 [438380/25046 (59%)]\tLoss: 0.706351\n",
            "Train epoch: 254 [480480/25046 (61%)]\tLoss: 1.451452\n",
            "Train epoch: 254 [506000/25046 (64%)]\tLoss: 0.925694\n",
            "Train epoch: 254 [559000/25046 (66%)]\tLoss: 0.881282\n",
            "Train epoch: 254 [572940/25046 (69%)]\tLoss: 1.111804\n",
            "Train epoch: 254 [595840/25046 (72%)]\tLoss: 1.149298\n",
            "Train epoch: 254 [548100/25046 (74%)]\tLoss: 0.319174\n",
            "Train epoch: 254 [597600/25046 (77%)]\tLoss: 0.704033\n",
            "Train epoch: 254 [636740/25046 (79%)]\tLoss: 0.573676\n",
            "Train epoch: 254 [657920/25046 (82%)]\tLoss: 0.850157\n",
            "Train epoch: 254 [666600/25046 (84%)]\tLoss: 0.787033\n",
            "Train epoch: 254 [686120/25046 (87%)]\tLoss: 0.451040\n",
            "Train epoch: 254 [674800/25046 (89%)]\tLoss: 0.667264\n",
            "Train epoch: 254 [762480/25046 (92%)]\tLoss: 0.531059\n",
            "Train epoch: 254 [754800/25046 (95%)]\tLoss: 0.713729\n",
            "Train epoch: 254 [725040/25046 (97%)]\tLoss: 1.072288\n",
            "Train epoch: 254 [807300/25046 (100%)]\tLoss: 0.686327\n",
            "Make prediction for 5010 samples...\n",
            "0.80171686 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 255 [0/25046 (0%)]\tLoss: 0.902629\n",
            "Train epoch: 255 [20500/25046 (3%)]\tLoss: 0.546509\n",
            "Train epoch: 255 [40480/25046 (5%)]\tLoss: 0.664773\n",
            "Train epoch: 255 [60720/25046 (8%)]\tLoss: 0.492375\n",
            "Train epoch: 255 [84240/25046 (10%)]\tLoss: 1.068745\n",
            "Train epoch: 255 [102400/25046 (13%)]\tLoss: 0.760450\n",
            "Train epoch: 255 [124320/25046 (15%)]\tLoss: 0.589633\n",
            "Train epoch: 255 [140420/25046 (18%)]\tLoss: 0.729553\n",
            "Train epoch: 255 [160960/25046 (20%)]\tLoss: 0.344669\n",
            "Train epoch: 255 [181620/25046 (23%)]\tLoss: 0.780874\n",
            "Train epoch: 255 [203800/25046 (26%)]\tLoss: 1.136368\n",
            "Train epoch: 255 [227040/25046 (28%)]\tLoss: 0.488475\n",
            "Train epoch: 255 [257760/25046 (31%)]\tLoss: 0.752062\n",
            "Train epoch: 255 [258700/25046 (33%)]\tLoss: 1.213154\n",
            "Train epoch: 255 [277760/25046 (36%)]\tLoss: 1.583946\n",
            "Train epoch: 255 [300300/25046 (38%)]\tLoss: 0.542475\n",
            "Train epoch: 255 [325760/25046 (41%)]\tLoss: 0.811086\n",
            "Train epoch: 255 [318240/25046 (43%)]\tLoss: 0.517931\n",
            "Train epoch: 255 [395280/25046 (46%)]\tLoss: 0.692639\n",
            "Train epoch: 255 [380760/25046 (49%)]\tLoss: 1.103982\n",
            "Train epoch: 255 [415600/25046 (51%)]\tLoss: 0.717015\n",
            "Train epoch: 255 [446040/25046 (54%)]\tLoss: 0.854250\n",
            "Train epoch: 255 [425920/25046 (56%)]\tLoss: 0.717425\n",
            "Train epoch: 255 [442060/25046 (59%)]\tLoss: 0.650026\n",
            "Train epoch: 255 [492000/25046 (61%)]\tLoss: 0.341282\n",
            "Train epoch: 255 [513500/25046 (64%)]\tLoss: 0.958942\n",
            "Train epoch: 255 [545480/25046 (66%)]\tLoss: 0.667297\n",
            "Train epoch: 255 [581580/25046 (69%)]\tLoss: 1.083200\n",
            "Train epoch: 255 [574000/25046 (72%)]\tLoss: 0.939394\n",
            "Train epoch: 255 [585220/25046 (74%)]\tLoss: 0.844611\n",
            "Train epoch: 255 [622800/25046 (77%)]\tLoss: 1.267239\n",
            "Train epoch: 255 [607600/25046 (79%)]\tLoss: 0.592374\n",
            "Train epoch: 255 [640000/25046 (82%)]\tLoss: 1.383104\n",
            "Train epoch: 255 [683760/25046 (84%)]\tLoss: 1.361839\n",
            "Train epoch: 255 [718080/25046 (87%)]\tLoss: 0.872527\n",
            "Train epoch: 255 [700000/25046 (89%)]\tLoss: 1.093277\n",
            "Train epoch: 255 [744480/25046 (92%)]\tLoss: 1.555061\n",
            "Train epoch: 255 [782180/25046 (95%)]\tLoss: 1.349696\n",
            "Train epoch: 255 [808640/25046 (97%)]\tLoss: 1.037480\n",
            "Train epoch: 255 [857220/25046 (100%)]\tLoss: 0.961460\n",
            "Make prediction for 5010 samples...\n",
            "0.80194795 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 256 [0/25046 (0%)]\tLoss: 0.708587\n",
            "Train epoch: 256 [21220/25046 (3%)]\tLoss: 0.817441\n",
            "Train epoch: 256 [41640/25046 (5%)]\tLoss: 1.021684\n",
            "Train epoch: 256 [64020/25046 (8%)]\tLoss: 0.594564\n",
            "Train epoch: 256 [82160/25046 (10%)]\tLoss: 0.799456\n",
            "Train epoch: 256 [104600/25046 (13%)]\tLoss: 1.023427\n",
            "Train epoch: 256 [126120/25046 (15%)]\tLoss: 0.387156\n",
            "Train epoch: 256 [145320/25046 (18%)]\tLoss: 0.748754\n",
            "Train epoch: 256 [162080/25046 (20%)]\tLoss: 0.871325\n",
            "Train epoch: 256 [193140/25046 (23%)]\tLoss: 0.788202\n",
            "Train epoch: 256 [203800/25046 (26%)]\tLoss: 1.421113\n",
            "Train epoch: 256 [220880/25046 (28%)]\tLoss: 0.211968\n",
            "Train epoch: 256 [256800/25046 (31%)]\tLoss: 1.479919\n",
            "Train epoch: 256 [262340/25046 (33%)]\tLoss: 0.767359\n",
            "Train epoch: 256 [267680/25046 (36%)]\tLoss: 0.842936\n",
            "Train epoch: 256 [302100/25046 (38%)]\tLoss: 0.699982\n",
            "Train epoch: 256 [337920/25046 (41%)]\tLoss: 0.362613\n",
            "Train epoch: 256 [351220/25046 (43%)]\tLoss: 0.387554\n",
            "Train epoch: 256 [379800/25046 (46%)]\tLoss: 0.652456\n",
            "Train epoch: 256 [395960/25046 (49%)]\tLoss: 1.149688\n",
            "Train epoch: 256 [417600/25046 (51%)]\tLoss: 1.351496\n",
            "Train epoch: 256 [436800/25046 (54%)]\tLoss: 1.580039\n",
            "Train epoch: 256 [465080/25046 (56%)]\tLoss: 1.711969\n",
            "Train epoch: 256 [446200/25046 (59%)]\tLoss: 0.914650\n",
            "Train epoch: 256 [519840/25046 (61%)]\tLoss: 0.719883\n",
            "Train epoch: 256 [523000/25046 (64%)]\tLoss: 1.029701\n",
            "Train epoch: 256 [554320/25046 (66%)]\tLoss: 0.532283\n",
            "Train epoch: 256 [517320/25046 (69%)]\tLoss: 0.594388\n",
            "Train epoch: 256 [574000/25046 (72%)]\tLoss: 0.332567\n",
            "Train epoch: 256 [603780/25046 (74%)]\tLoss: 1.240418\n",
            "Train epoch: 256 [626400/25046 (77%)]\tLoss: 0.970554\n",
            "Train epoch: 256 [574120/25046 (79%)]\tLoss: 0.602109\n",
            "Train epoch: 256 [636160/25046 (82%)]\tLoss: 0.928544\n",
            "Train epoch: 256 [672540/25046 (84%)]\tLoss: 1.528105\n",
            "Train epoch: 256 [708560/25046 (87%)]\tLoss: 0.558614\n",
            "Train epoch: 256 [728000/25046 (89%)]\tLoss: 1.198279\n",
            "Train epoch: 256 [766080/25046 (92%)]\tLoss: 1.454692\n",
            "Train epoch: 256 [796980/25046 (95%)]\tLoss: 0.731840\n",
            "Train epoch: 256 [746320/25046 (97%)]\tLoss: 0.272588\n",
            "Train epoch: 256 [828360/25046 (100%)]\tLoss: 1.278419\n",
            "Make prediction for 5010 samples...\n",
            "0.8048253 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 257 [0/25046 (0%)]\tLoss: 0.520097\n",
            "Train epoch: 257 [19020/25046 (3%)]\tLoss: 0.484872\n",
            "Train epoch: 257 [42160/25046 (5%)]\tLoss: 0.391916\n",
            "Train epoch: 257 [64140/25046 (8%)]\tLoss: 1.059610\n",
            "Train epoch: 257 [77920/25046 (10%)]\tLoss: 0.783782\n",
            "Train epoch: 257 [104600/25046 (13%)]\tLoss: 1.101571\n",
            "Train epoch: 257 [128040/25046 (15%)]\tLoss: 0.688329\n",
            "Train epoch: 257 [151060/25046 (18%)]\tLoss: 1.079647\n",
            "Train epoch: 257 [163040/25046 (20%)]\tLoss: 1.672266\n",
            "Train epoch: 257 [173880/25046 (23%)]\tLoss: 1.094048\n",
            "Train epoch: 257 [215600/25046 (26%)]\tLoss: 1.421280\n",
            "Train epoch: 257 [219560/25046 (28%)]\tLoss: 0.324050\n",
            "Train epoch: 257 [239760/25046 (31%)]\tLoss: 0.967067\n",
            "Train epoch: 257 [258960/25046 (33%)]\tLoss: 0.953721\n",
            "Train epoch: 257 [296800/25046 (36%)]\tLoss: 0.704883\n",
            "Train epoch: 257 [298200/25046 (38%)]\tLoss: 0.247219\n",
            "Train epoch: 257 [305600/25046 (41%)]\tLoss: 0.755101\n",
            "Train epoch: 257 [330140/25046 (43%)]\tLoss: 1.816682\n",
            "Train epoch: 257 [379080/25046 (46%)]\tLoss: 1.222106\n",
            "Train epoch: 257 [416480/25046 (49%)]\tLoss: 0.358623\n",
            "Train epoch: 257 [422000/25046 (51%)]\tLoss: 1.223387\n",
            "Train epoch: 257 [435960/25046 (54%)]\tLoss: 0.348492\n",
            "Train epoch: 257 [449240/25046 (56%)]\tLoss: 1.538594\n",
            "Train epoch: 257 [455860/25046 (59%)]\tLoss: 0.557986\n",
            "Train epoch: 257 [516960/25046 (61%)]\tLoss: 0.410935\n",
            "Train epoch: 257 [526500/25046 (64%)]\tLoss: 1.182163\n",
            "Train epoch: 257 [494000/25046 (66%)]\tLoss: 0.842883\n",
            "Train epoch: 257 [516780/25046 (69%)]\tLoss: 0.614726\n",
            "Train epoch: 257 [510720/25046 (72%)]\tLoss: 0.752173\n",
            "Train epoch: 257 [607260/25046 (74%)]\tLoss: 0.577348\n",
            "Train epoch: 257 [598800/25046 (77%)]\tLoss: 0.653118\n",
            "Train epoch: 257 [664020/25046 (79%)]\tLoss: 1.121138\n",
            "Train epoch: 257 [659840/25046 (82%)]\tLoss: 0.615115\n",
            "Train epoch: 257 [661320/25046 (84%)]\tLoss: 0.372725\n",
            "Train epoch: 257 [703800/25046 (87%)]\tLoss: 0.372645\n",
            "Train epoch: 257 [658000/25046 (89%)]\tLoss: 0.461660\n",
            "Train epoch: 257 [740880/25046 (92%)]\tLoss: 0.917068\n",
            "Train epoch: 257 [705960/25046 (95%)]\tLoss: 1.195780\n",
            "Train epoch: 257 [791920/25046 (97%)]\tLoss: 0.961768\n",
            "Train epoch: 257 [833040/25046 (100%)]\tLoss: 0.395094\n",
            "Make prediction for 5010 samples...\n",
            "0.8015577 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 258 [0/25046 (0%)]\tLoss: 0.949655\n",
            "Train epoch: 258 [19280/25046 (3%)]\tLoss: 1.006278\n",
            "Train epoch: 258 [41160/25046 (5%)]\tLoss: 0.456923\n",
            "Train epoch: 258 [64200/25046 (8%)]\tLoss: 1.464458\n",
            "Train epoch: 258 [81840/25046 (10%)]\tLoss: 1.700060\n",
            "Train epoch: 258 [103100/25046 (13%)]\tLoss: 0.734729\n",
            "Train epoch: 258 [117360/25046 (15%)]\tLoss: 1.265411\n",
            "Train epoch: 258 [151760/25046 (18%)]\tLoss: 0.306743\n",
            "Train epoch: 258 [160800/25046 (20%)]\tLoss: 1.046552\n",
            "Train epoch: 258 [183240/25046 (23%)]\tLoss: 1.496540\n",
            "Train epoch: 258 [215000/25046 (26%)]\tLoss: 0.429554\n",
            "Train epoch: 258 [229460/25046 (28%)]\tLoss: 0.545553\n",
            "Train epoch: 258 [249360/25046 (31%)]\tLoss: 0.798544\n",
            "Train epoch: 258 [255580/25046 (33%)]\tLoss: 2.046976\n",
            "Train epoch: 258 [285600/25046 (36%)]\tLoss: 0.589467\n",
            "Train epoch: 258 [310200/25046 (38%)]\tLoss: 0.868481\n",
            "Train epoch: 258 [344000/25046 (41%)]\tLoss: 0.716301\n",
            "Train epoch: 258 [345440/25046 (43%)]\tLoss: 0.502979\n",
            "Train epoch: 258 [365040/25046 (46%)]\tLoss: 0.720780\n",
            "Train epoch: 258 [403560/25046 (49%)]\tLoss: 0.538693\n",
            "Train epoch: 258 [398400/25046 (51%)]\tLoss: 0.505340\n",
            "Train epoch: 258 [435120/25046 (54%)]\tLoss: 0.709208\n",
            "Train epoch: 258 [436040/25046 (56%)]\tLoss: 1.511552\n",
            "Train epoch: 258 [494040/25046 (59%)]\tLoss: 0.768498\n",
            "Train epoch: 258 [515520/25046 (61%)]\tLoss: 0.954413\n",
            "Train epoch: 258 [518500/25046 (64%)]\tLoss: 1.660074\n",
            "Train epoch: 258 [528840/25046 (66%)]\tLoss: 0.328376\n",
            "Train epoch: 258 [549720/25046 (69%)]\tLoss: 1.507128\n",
            "Train epoch: 258 [578480/25046 (72%)]\tLoss: 0.651248\n",
            "Train epoch: 258 [610160/25046 (74%)]\tLoss: 0.305851\n",
            "Train epoch: 258 [605400/25046 (77%)]\tLoss: 0.498487\n",
            "Train epoch: 258 [621240/25046 (79%)]\tLoss: 0.298560\n",
            "Train epoch: 258 [671360/25046 (82%)]\tLoss: 1.970744\n",
            "Train epoch: 258 [630960/25046 (84%)]\tLoss: 0.707338\n",
            "Train epoch: 258 [707200/25046 (87%)]\tLoss: 0.260751\n",
            "Train epoch: 258 [726600/25046 (89%)]\tLoss: 1.266459\n",
            "Train epoch: 258 [738720/25046 (92%)]\tLoss: 1.592809\n",
            "Train epoch: 258 [790320/25046 (95%)]\tLoss: 0.856526\n",
            "Train epoch: 258 [794960/25046 (97%)]\tLoss: 1.182179\n",
            "Train epoch: 258 [821340/25046 (100%)]\tLoss: 0.339841\n",
            "Make prediction for 5010 samples...\n",
            "0.80151576 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 259 [0/25046 (0%)]\tLoss: 0.331021\n",
            "Train epoch: 259 [21680/25046 (3%)]\tLoss: 0.368134\n",
            "Train epoch: 259 [41120/25046 (5%)]\tLoss: 0.635197\n",
            "Train epoch: 259 [60240/25046 (8%)]\tLoss: 1.315977\n",
            "Train epoch: 259 [84960/25046 (10%)]\tLoss: 0.705146\n",
            "Train epoch: 259 [106700/25046 (13%)]\tLoss: 0.776319\n",
            "Train epoch: 259 [129840/25046 (15%)]\tLoss: 0.319880\n",
            "Train epoch: 259 [147280/25046 (18%)]\tLoss: 0.599216\n",
            "Train epoch: 259 [164320/25046 (20%)]\tLoss: 0.761994\n",
            "Train epoch: 259 [197460/25046 (23%)]\tLoss: 1.299542\n",
            "Train epoch: 259 [210000/25046 (26%)]\tLoss: 0.642182\n",
            "Train epoch: 259 [223960/25046 (28%)]\tLoss: 1.090595\n",
            "Train epoch: 259 [262320/25046 (31%)]\tLoss: 1.022935\n",
            "Train epoch: 259 [277680/25046 (33%)]\tLoss: 1.374044\n",
            "Train epoch: 259 [286160/25046 (36%)]\tLoss: 0.431471\n",
            "Train epoch: 259 [321300/25046 (38%)]\tLoss: 0.669715\n",
            "Train epoch: 259 [346880/25046 (41%)]\tLoss: 0.393270\n",
            "Train epoch: 259 [352240/25046 (43%)]\tLoss: 0.589536\n",
            "Train epoch: 259 [376560/25046 (46%)]\tLoss: 0.458493\n",
            "Train epoch: 259 [382660/25046 (49%)]\tLoss: 0.452184\n",
            "Train epoch: 259 [421600/25046 (51%)]\tLoss: 0.237163\n",
            "Train epoch: 259 [425040/25046 (54%)]\tLoss: 0.310225\n",
            "Train epoch: 259 [451000/25046 (56%)]\tLoss: 1.368149\n",
            "Train epoch: 259 [462300/25046 (59%)]\tLoss: 1.788667\n",
            "Train epoch: 259 [509760/25046 (61%)]\tLoss: 0.595051\n",
            "Train epoch: 259 [562500/25046 (64%)]\tLoss: 0.811709\n",
            "Train epoch: 259 [542880/25046 (66%)]\tLoss: 0.295495\n",
            "Train epoch: 259 [531360/25046 (69%)]\tLoss: 0.538340\n",
            "Train epoch: 259 [588560/25046 (72%)]\tLoss: 0.899425\n",
            "Train epoch: 259 [584060/25046 (74%)]\tLoss: 0.733722\n",
            "Train epoch: 259 [585000/25046 (77%)]\tLoss: 0.756623\n",
            "Train epoch: 259 [645420/25046 (79%)]\tLoss: 0.784588\n",
            "Train epoch: 259 [622080/25046 (82%)]\tLoss: 0.365001\n",
            "Train epoch: 259 [712140/25046 (84%)]\tLoss: 1.126886\n",
            "Train epoch: 259 [709920/25046 (87%)]\tLoss: 1.061926\n",
            "Train epoch: 259 [705600/25046 (89%)]\tLoss: 0.374567\n",
            "Train epoch: 259 [763920/25046 (92%)]\tLoss: 1.872941\n",
            "Train epoch: 259 [769600/25046 (95%)]\tLoss: 0.530971\n",
            "Train epoch: 259 [788120/25046 (97%)]\tLoss: 0.872362\n",
            "Train epoch: 259 [818220/25046 (100%)]\tLoss: 1.071287\n",
            "Make prediction for 5010 samples...\n",
            "0.8025088 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 260 [0/25046 (0%)]\tLoss: 0.784590\n",
            "Train epoch: 260 [20940/25046 (3%)]\tLoss: 0.476696\n",
            "Train epoch: 260 [39880/25046 (5%)]\tLoss: 1.579861\n",
            "Train epoch: 260 [60240/25046 (8%)]\tLoss: 1.283744\n",
            "Train epoch: 260 [80560/25046 (10%)]\tLoss: 0.663995\n",
            "Train epoch: 260 [102200/25046 (13%)]\tLoss: 0.905256\n",
            "Train epoch: 260 [110280/25046 (15%)]\tLoss: 0.971436\n",
            "Train epoch: 260 [141680/25046 (18%)]\tLoss: 0.496776\n",
            "Train epoch: 260 [155520/25046 (20%)]\tLoss: 0.511470\n",
            "Train epoch: 260 [185220/25046 (23%)]\tLoss: 0.822516\n",
            "Train epoch: 260 [204000/25046 (26%)]\tLoss: 0.474393\n",
            "Train epoch: 260 [229020/25046 (28%)]\tLoss: 0.349941\n",
            "Train epoch: 260 [258000/25046 (31%)]\tLoss: 1.755000\n",
            "Train epoch: 260 [272480/25046 (33%)]\tLoss: 0.394904\n",
            "Train epoch: 260 [297360/25046 (36%)]\tLoss: 0.279319\n",
            "Train epoch: 260 [288600/25046 (38%)]\tLoss: 0.493080\n",
            "Train epoch: 260 [326720/25046 (41%)]\tLoss: 0.277760\n",
            "Train epoch: 260 [320960/25046 (43%)]\tLoss: 1.226803\n",
            "Train epoch: 260 [365400/25046 (46%)]\tLoss: 0.567488\n",
            "Train epoch: 260 [378100/25046 (49%)]\tLoss: 0.520970\n",
            "Train epoch: 260 [410000/25046 (51%)]\tLoss: 0.753175\n",
            "Train epoch: 260 [436800/25046 (54%)]\tLoss: 1.258917\n",
            "Train epoch: 260 [454960/25046 (56%)]\tLoss: 1.663602\n",
            "Train epoch: 260 [440220/25046 (59%)]\tLoss: 1.157353\n",
            "Train epoch: 260 [476640/25046 (61%)]\tLoss: 0.725853\n",
            "Train epoch: 260 [528000/25046 (64%)]\tLoss: 1.033221\n",
            "Train epoch: 260 [527800/25046 (66%)]\tLoss: 0.883636\n",
            "Train epoch: 260 [569700/25046 (69%)]\tLoss: 1.342601\n",
            "Train epoch: 260 [558880/25046 (72%)]\tLoss: 0.923630\n",
            "Train epoch: 260 [592760/25046 (74%)]\tLoss: 0.570119\n",
            "Train epoch: 260 [598200/25046 (77%)]\tLoss: 1.095722\n",
            "Train epoch: 260 [615660/25046 (79%)]\tLoss: 1.087335\n",
            "Train epoch: 260 [650880/25046 (82%)]\tLoss: 1.009299\n",
            "Train epoch: 260 [703560/25046 (84%)]\tLoss: 0.562634\n",
            "Train epoch: 260 [697680/25046 (87%)]\tLoss: 1.516333\n",
            "Train epoch: 260 [671300/25046 (89%)]\tLoss: 1.043563\n",
            "Train epoch: 260 [735120/25046 (92%)]\tLoss: 1.240008\n",
            "Train epoch: 260 [760720/25046 (95%)]\tLoss: 0.557406\n",
            "Train epoch: 260 [829920/25046 (97%)]\tLoss: 0.636908\n",
            "Train epoch: 260 [795600/25046 (100%)]\tLoss: 1.174652\n",
            "Make prediction for 5010 samples...\n",
            "0.8017027 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 261 [0/25046 (0%)]\tLoss: 0.655458\n",
            "Train epoch: 261 [19040/25046 (3%)]\tLoss: 0.778129\n",
            "Train epoch: 261 [39360/25046 (5%)]\tLoss: 0.392904\n",
            "Train epoch: 261 [62880/25046 (8%)]\tLoss: 0.902766\n",
            "Train epoch: 261 [82400/25046 (10%)]\tLoss: 1.060831\n",
            "Train epoch: 261 [103000/25046 (13%)]\tLoss: 0.725290\n",
            "Train epoch: 261 [121560/25046 (15%)]\tLoss: 0.577840\n",
            "Train epoch: 261 [141400/25046 (18%)]\tLoss: 0.770343\n",
            "Train epoch: 261 [166080/25046 (20%)]\tLoss: 0.902564\n",
            "Train epoch: 261 [184680/25046 (23%)]\tLoss: 1.077984\n",
            "Train epoch: 261 [211800/25046 (26%)]\tLoss: 0.450891\n",
            "Train epoch: 261 [225280/25046 (28%)]\tLoss: 1.469733\n",
            "Train epoch: 261 [248400/25046 (31%)]\tLoss: 0.543557\n",
            "Train epoch: 261 [275860/25046 (33%)]\tLoss: 0.307871\n",
            "Train epoch: 261 [282520/25046 (36%)]\tLoss: 0.792441\n",
            "Train epoch: 261 [287100/25046 (38%)]\tLoss: 0.577228\n",
            "Train epoch: 261 [320000/25046 (41%)]\tLoss: 0.339789\n",
            "Train epoch: 261 [341360/25046 (43%)]\tLoss: 0.731894\n",
            "Train epoch: 261 [383040/25046 (46%)]\tLoss: 0.875677\n",
            "Train epoch: 261 [402800/25046 (49%)]\tLoss: 0.651938\n",
            "Train epoch: 261 [412800/25046 (51%)]\tLoss: 1.595075\n",
            "Train epoch: 261 [407820/25046 (54%)]\tLoss: 1.330190\n",
            "Train epoch: 261 [450120/25046 (56%)]\tLoss: 1.047264\n",
            "Train epoch: 261 [448500/25046 (59%)]\tLoss: 0.428771\n",
            "Train epoch: 261 [468960/25046 (61%)]\tLoss: 0.252618\n",
            "Train epoch: 261 [505500/25046 (64%)]\tLoss: 0.572676\n",
            "Train epoch: 261 [554320/25046 (66%)]\tLoss: 0.751182\n",
            "Train epoch: 261 [528120/25046 (69%)]\tLoss: 2.074413\n",
            "Train epoch: 261 [567840/25046 (72%)]\tLoss: 1.068197\n",
            "Train epoch: 261 [587540/25046 (74%)]\tLoss: 0.538095\n",
            "Train epoch: 261 [584400/25046 (77%)]\tLoss: 0.692188\n",
            "Train epoch: 261 [649140/25046 (79%)]\tLoss: 0.376554\n",
            "Train epoch: 261 [620800/25046 (82%)]\tLoss: 0.632570\n",
            "Train epoch: 261 [663300/25046 (84%)]\tLoss: 0.751324\n",
            "Train epoch: 261 [709240/25046 (87%)]\tLoss: 0.554365\n",
            "Train epoch: 261 [730100/25046 (89%)]\tLoss: 0.402676\n",
            "Train epoch: 261 [679680/25046 (92%)]\tLoss: 0.999785\n",
            "Train epoch: 261 [731120/25046 (95%)]\tLoss: 1.183830\n",
            "Train epoch: 261 [734160/25046 (97%)]\tLoss: 0.339593\n",
            "Train epoch: 261 [840060/25046 (100%)]\tLoss: 0.544726\n",
            "Make prediction for 5010 samples...\n",
            "0.8015333 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 262 [0/25046 (0%)]\tLoss: 1.582928\n",
            "Train epoch: 262 [20360/25046 (3%)]\tLoss: 1.104808\n",
            "Train epoch: 262 [41000/25046 (5%)]\tLoss: 0.574617\n",
            "Train epoch: 262 [58620/25046 (8%)]\tLoss: 0.470500\n",
            "Train epoch: 262 [78560/25046 (10%)]\tLoss: 1.174073\n",
            "Train epoch: 262 [97900/25046 (13%)]\tLoss: 0.683148\n",
            "Train epoch: 262 [125040/25046 (15%)]\tLoss: 0.652991\n",
            "Train epoch: 262 [138180/25046 (18%)]\tLoss: 0.972024\n",
            "Train epoch: 262 [170560/25046 (20%)]\tLoss: 0.812061\n",
            "Train epoch: 262 [178740/25046 (23%)]\tLoss: 0.671860\n",
            "Train epoch: 262 [204600/25046 (26%)]\tLoss: 0.869451\n",
            "Train epoch: 262 [217360/25046 (28%)]\tLoss: 1.328272\n",
            "Train epoch: 262 [247440/25046 (31%)]\tLoss: 0.356987\n",
            "Train epoch: 262 [280800/25046 (33%)]\tLoss: 0.491700\n",
            "Train epoch: 262 [280560/25046 (36%)]\tLoss: 1.120701\n",
            "Train epoch: 262 [296400/25046 (38%)]\tLoss: 0.734750\n",
            "Train epoch: 262 [320960/25046 (41%)]\tLoss: 1.424252\n",
            "Train epoch: 262 [340680/25046 (43%)]\tLoss: 0.746578\n",
            "Train epoch: 262 [372240/25046 (46%)]\tLoss: 0.479141\n",
            "Train epoch: 262 [388740/25046 (49%)]\tLoss: 1.078146\n",
            "Train epoch: 262 [412400/25046 (51%)]\tLoss: 0.343980\n",
            "Train epoch: 262 [433440/25046 (54%)]\tLoss: 0.938128\n",
            "Train epoch: 262 [447480/25046 (56%)]\tLoss: 0.589071\n",
            "Train epoch: 262 [469660/25046 (59%)]\tLoss: 0.301843\n",
            "Train epoch: 262 [505920/25046 (61%)]\tLoss: 0.326444\n",
            "Train epoch: 262 [496500/25046 (64%)]\tLoss: 0.702768\n",
            "Train epoch: 262 [521560/25046 (66%)]\tLoss: 1.075634\n",
            "Train epoch: 262 [544860/25046 (69%)]\tLoss: 0.569168\n",
            "Train epoch: 262 [539840/25046 (72%)]\tLoss: 0.644723\n",
            "Train epoch: 262 [636260/25046 (74%)]\tLoss: 0.748140\n",
            "Train epoch: 262 [607200/25046 (77%)]\tLoss: 0.587361\n",
            "Train epoch: 262 [599540/25046 (79%)]\tLoss: 1.349624\n",
            "Train epoch: 262 [650240/25046 (82%)]\tLoss: 1.101351\n",
            "Train epoch: 262 [665940/25046 (84%)]\tLoss: 0.669295\n",
            "Train epoch: 262 [680680/25046 (87%)]\tLoss: 0.901879\n",
            "Train epoch: 262 [705600/25046 (89%)]\tLoss: 1.128813\n",
            "Train epoch: 262 [728640/25046 (92%)]\tLoss: 0.540664\n",
            "Train epoch: 262 [768120/25046 (95%)]\tLoss: 0.545669\n",
            "Train epoch: 262 [769880/25046 (97%)]\tLoss: 1.600910\n",
            "Train epoch: 262 [796380/25046 (100%)]\tLoss: 0.565862\n",
            "Make prediction for 5010 samples...\n",
            "0.80454874 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 263 [0/25046 (0%)]\tLoss: 0.833314\n",
            "Train epoch: 263 [20440/25046 (3%)]\tLoss: 1.279966\n",
            "Train epoch: 263 [39160/25046 (5%)]\tLoss: 0.405585\n",
            "Train epoch: 263 [59760/25046 (8%)]\tLoss: 0.526704\n",
            "Train epoch: 263 [79520/25046 (10%)]\tLoss: 1.044085\n",
            "Train epoch: 263 [99200/25046 (13%)]\tLoss: 0.898508\n",
            "Train epoch: 263 [123600/25046 (15%)]\tLoss: 1.149472\n",
            "Train epoch: 263 [152460/25046 (18%)]\tLoss: 1.215605\n",
            "Train epoch: 263 [159520/25046 (20%)]\tLoss: 0.845345\n",
            "Train epoch: 263 [189900/25046 (23%)]\tLoss: 0.369651\n",
            "Train epoch: 263 [190400/25046 (26%)]\tLoss: 0.813435\n",
            "Train epoch: 263 [226160/25046 (28%)]\tLoss: 0.866829\n",
            "Train epoch: 263 [250560/25046 (31%)]\tLoss: 0.628924\n",
            "Train epoch: 263 [265460/25046 (33%)]\tLoss: 0.679379\n",
            "Train epoch: 263 [288120/25046 (36%)]\tLoss: 0.939021\n",
            "Train epoch: 263 [310500/25046 (38%)]\tLoss: 0.263618\n",
            "Train epoch: 263 [333440/25046 (41%)]\tLoss: 1.036161\n",
            "Train epoch: 263 [351220/25046 (43%)]\tLoss: 0.404826\n",
            "Train epoch: 263 [370800/25046 (46%)]\tLoss: 0.728472\n",
            "Train epoch: 263 [394060/25046 (49%)]\tLoss: 0.422832\n",
            "Train epoch: 263 [392800/25046 (51%)]\tLoss: 0.986668\n",
            "Train epoch: 263 [412440/25046 (54%)]\tLoss: 0.427906\n",
            "Train epoch: 263 [456720/25046 (56%)]\tLoss: 0.861658\n",
            "Train epoch: 263 [451260/25046 (59%)]\tLoss: 0.911209\n",
            "Train epoch: 263 [510240/25046 (61%)]\tLoss: 1.497191\n",
            "Train epoch: 263 [490500/25046 (64%)]\tLoss: 1.068914\n",
            "Train epoch: 263 [520000/25046 (66%)]\tLoss: 1.883471\n",
            "Train epoch: 263 [579420/25046 (69%)]\tLoss: 0.567405\n",
            "Train epoch: 263 [576800/25046 (72%)]\tLoss: 1.341364\n",
            "Train epoch: 263 [611900/25046 (74%)]\tLoss: 0.603985\n",
            "Train epoch: 263 [610200/25046 (77%)]\tLoss: 1.170363\n",
            "Train epoch: 263 [647900/25046 (79%)]\tLoss: 0.964494\n",
            "Train epoch: 263 [654720/25046 (82%)]\tLoss: 0.712372\n",
            "Train epoch: 263 [726660/25046 (84%)]\tLoss: 1.056747\n",
            "Train epoch: 263 [728280/25046 (87%)]\tLoss: 1.265020\n",
            "Train epoch: 263 [684600/25046 (89%)]\tLoss: 0.863043\n",
            "Train epoch: 263 [761040/25046 (92%)]\tLoss: 1.045705\n",
            "Train epoch: 263 [750360/25046 (95%)]\tLoss: 0.871677\n",
            "Train epoch: 263 [775200/25046 (97%)]\tLoss: 0.992001\n",
            "Train epoch: 263 [836940/25046 (100%)]\tLoss: 0.280335\n",
            "Make prediction for 5010 samples...\n",
            "0.80212873 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 264 [0/25046 (0%)]\tLoss: 0.522012\n",
            "Train epoch: 264 [22220/25046 (3%)]\tLoss: 0.300444\n",
            "Train epoch: 264 [40960/25046 (5%)]\tLoss: 0.988367\n",
            "Train epoch: 264 [60840/25046 (8%)]\tLoss: 0.777338\n",
            "Train epoch: 264 [85120/25046 (10%)]\tLoss: 0.327797\n",
            "Train epoch: 264 [99500/25046 (13%)]\tLoss: 0.562730\n",
            "Train epoch: 264 [122880/25046 (15%)]\tLoss: 0.702141\n",
            "Train epoch: 264 [148820/25046 (18%)]\tLoss: 1.345836\n",
            "Train epoch: 264 [162720/25046 (20%)]\tLoss: 0.966684\n",
            "Train epoch: 264 [180540/25046 (23%)]\tLoss: 0.405907\n",
            "Train epoch: 264 [205600/25046 (26%)]\tLoss: 0.882520\n",
            "Train epoch: 264 [223300/25046 (28%)]\tLoss: 0.519469\n",
            "Train epoch: 264 [249840/25046 (31%)]\tLoss: 0.465448\n",
            "Train epoch: 264 [272480/25046 (33%)]\tLoss: 1.163164\n",
            "Train epoch: 264 [290360/25046 (36%)]\tLoss: 1.021751\n",
            "Train epoch: 264 [321600/25046 (38%)]\tLoss: 0.751669\n",
            "Train epoch: 264 [321600/25046 (41%)]\tLoss: 0.596578\n",
            "Train epoch: 264 [357340/25046 (43%)]\tLoss: 0.749966\n",
            "Train epoch: 264 [370800/25046 (46%)]\tLoss: 0.852666\n",
            "Train epoch: 264 [372020/25046 (49%)]\tLoss: 0.376050\n",
            "Train epoch: 264 [406400/25046 (51%)]\tLoss: 0.534880\n",
            "Train epoch: 264 [433860/25046 (54%)]\tLoss: 0.334242\n",
            "Train epoch: 264 [462880/25046 (56%)]\tLoss: 0.533597\n",
            "Train epoch: 264 [455400/25046 (59%)]\tLoss: 0.703546\n",
            "Train epoch: 264 [497280/25046 (61%)]\tLoss: 1.032945\n",
            "Train epoch: 264 [535000/25046 (64%)]\tLoss: 0.816847\n",
            "Train epoch: 264 [532480/25046 (66%)]\tLoss: 0.658933\n",
            "Train epoch: 264 [527580/25046 (69%)]\tLoss: 0.842066\n",
            "Train epoch: 264 [594160/25046 (72%)]\tLoss: 1.075248\n",
            "Train epoch: 264 [587540/25046 (74%)]\tLoss: 0.466163\n",
            "Train epoch: 264 [610800/25046 (77%)]\tLoss: 0.776939\n",
            "Train epoch: 264 [626200/25046 (79%)]\tLoss: 0.655927\n",
            "Train epoch: 264 [702080/25046 (82%)]\tLoss: 0.757165\n",
            "Train epoch: 264 [674520/25046 (84%)]\tLoss: 1.186002\n",
            "Train epoch: 264 [692240/25046 (87%)]\tLoss: 0.719312\n",
            "Train epoch: 264 [711900/25046 (89%)]\tLoss: 0.859915\n",
            "Train epoch: 264 [767520/25046 (92%)]\tLoss: 0.298590\n",
            "Train epoch: 264 [791060/25046 (95%)]\tLoss: 0.824431\n",
            "Train epoch: 264 [791160/25046 (97%)]\tLoss: 0.777838\n",
            "Train epoch: 264 [815880/25046 (100%)]\tLoss: 0.696922\n",
            "Make prediction for 5010 samples...\n",
            "0.801938 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 265 [0/25046 (0%)]\tLoss: 0.685065\n",
            "Train epoch: 265 [20600/25046 (3%)]\tLoss: 0.329600\n",
            "Train epoch: 265 [40120/25046 (5%)]\tLoss: 0.597671\n",
            "Train epoch: 265 [62880/25046 (8%)]\tLoss: 0.472212\n",
            "Train epoch: 265 [80080/25046 (10%)]\tLoss: 1.594905\n",
            "Train epoch: 265 [103500/25046 (13%)]\tLoss: 0.376938\n",
            "Train epoch: 265 [132720/25046 (15%)]\tLoss: 1.158613\n",
            "Train epoch: 265 [136780/25046 (18%)]\tLoss: 0.273283\n",
            "Train epoch: 265 [173440/25046 (20%)]\tLoss: 1.650729\n",
            "Train epoch: 265 [186120/25046 (23%)]\tLoss: 0.646208\n",
            "Train epoch: 265 [197200/25046 (26%)]\tLoss: 0.327219\n",
            "Train epoch: 265 [229240/25046 (28%)]\tLoss: 0.910595\n",
            "Train epoch: 265 [248640/25046 (31%)]\tLoss: 1.007699\n",
            "Train epoch: 265 [263120/25046 (33%)]\tLoss: 0.767179\n",
            "Train epoch: 265 [278880/25046 (36%)]\tLoss: 0.519035\n",
            "Train epoch: 265 [298500/25046 (38%)]\tLoss: 0.767531\n",
            "Train epoch: 265 [330560/25046 (41%)]\tLoss: 0.345357\n",
            "Train epoch: 265 [360400/25046 (43%)]\tLoss: 0.418370\n",
            "Train epoch: 265 [369000/25046 (46%)]\tLoss: 0.360294\n",
            "Train epoch: 265 [418760/25046 (49%)]\tLoss: 0.703628\n",
            "Train epoch: 265 [410800/25046 (51%)]\tLoss: 0.864630\n",
            "Train epoch: 265 [445200/25046 (54%)]\tLoss: 0.542834\n",
            "Train epoch: 265 [455400/25046 (56%)]\tLoss: 0.405784\n",
            "Train epoch: 265 [454020/25046 (59%)]\tLoss: 1.130006\n",
            "Train epoch: 265 [456000/25046 (61%)]\tLoss: 0.384713\n",
            "Train epoch: 265 [508000/25046 (64%)]\tLoss: 0.679425\n",
            "Train epoch: 265 [540280/25046 (66%)]\tLoss: 1.200630\n",
            "Train epoch: 265 [516780/25046 (69%)]\tLoss: 0.318911\n",
            "Train epoch: 265 [562800/25046 (72%)]\tLoss: 1.237973\n",
            "Train epoch: 265 [591020/25046 (74%)]\tLoss: 0.518778\n",
            "Train epoch: 265 [621600/25046 (77%)]\tLoss: 1.500470\n",
            "Train epoch: 265 [664640/25046 (79%)]\tLoss: 1.780724\n",
            "Train epoch: 265 [677120/25046 (82%)]\tLoss: 0.594696\n",
            "Train epoch: 265 [667260/25046 (84%)]\tLoss: 1.487530\n",
            "Train epoch: 265 [670480/25046 (87%)]\tLoss: 0.478037\n",
            "Train epoch: 265 [699300/25046 (89%)]\tLoss: 0.649547\n",
            "Train epoch: 265 [760320/25046 (92%)]\tLoss: 0.282233\n",
            "Train epoch: 265 [728160/25046 (95%)]\tLoss: 1.705728\n",
            "Train epoch: 265 [785840/25046 (97%)]\tLoss: 0.971618\n",
            "Train epoch: 265 [818220/25046 (100%)]\tLoss: 0.707418\n",
            "Make prediction for 5010 samples...\n",
            "0.8029742 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 266 [0/25046 (0%)]\tLoss: 0.763211\n",
            "Train epoch: 266 [22260/25046 (3%)]\tLoss: 1.350429\n",
            "Train epoch: 266 [41880/25046 (5%)]\tLoss: 1.179466\n",
            "Train epoch: 266 [60720/25046 (8%)]\tLoss: 0.643258\n",
            "Train epoch: 266 [80880/25046 (10%)]\tLoss: 0.424828\n",
            "Train epoch: 266 [102100/25046 (13%)]\tLoss: 0.610184\n",
            "Train epoch: 266 [120960/25046 (15%)]\tLoss: 0.715546\n",
            "Train epoch: 266 [142240/25046 (18%)]\tLoss: 0.682913\n",
            "Train epoch: 266 [163200/25046 (20%)]\tLoss: 0.713447\n",
            "Train epoch: 266 [184500/25046 (23%)]\tLoss: 0.547133\n",
            "Train epoch: 266 [219400/25046 (26%)]\tLoss: 0.546138\n",
            "Train epoch: 266 [217800/25046 (28%)]\tLoss: 0.345062\n",
            "Train epoch: 266 [240240/25046 (31%)]\tLoss: 0.819753\n",
            "Train epoch: 266 [263380/25046 (33%)]\tLoss: 0.385228\n",
            "Train epoch: 266 [284480/25046 (36%)]\tLoss: 0.323153\n",
            "Train epoch: 266 [312900/25046 (38%)]\tLoss: 1.299714\n",
            "Train epoch: 266 [331840/25046 (41%)]\tLoss: 0.644500\n",
            "Train epoch: 266 [346120/25046 (43%)]\tLoss: 0.271030\n",
            "Train epoch: 266 [383040/25046 (46%)]\tLoss: 0.969716\n",
            "Train epoch: 266 [383420/25046 (49%)]\tLoss: 0.846885\n",
            "Train epoch: 266 [436000/25046 (51%)]\tLoss: 0.617239\n",
            "Train epoch: 266 [436800/25046 (54%)]\tLoss: 0.734473\n",
            "Train epoch: 266 [426360/25046 (56%)]\tLoss: 1.025430\n",
            "Train epoch: 266 [491280/25046 (59%)]\tLoss: 0.778813\n",
            "Train epoch: 266 [487680/25046 (61%)]\tLoss: 0.956146\n",
            "Train epoch: 266 [490000/25046 (64%)]\tLoss: 0.488129\n",
            "Train epoch: 266 [544960/25046 (66%)]\tLoss: 1.212620\n",
            "Train epoch: 266 [570240/25046 (69%)]\tLoss: 0.630839\n",
            "Train epoch: 266 [597520/25046 (72%)]\tLoss: 0.274262\n",
            "Train epoch: 266 [598560/25046 (74%)]\tLoss: 0.727870\n",
            "Train epoch: 266 [630000/25046 (77%)]\tLoss: 0.729315\n",
            "Train epoch: 266 [661540/25046 (79%)]\tLoss: 0.219376\n",
            "Train epoch: 266 [668160/25046 (82%)]\tLoss: 0.560395\n",
            "Train epoch: 266 [656040/25046 (84%)]\tLoss: 0.719719\n",
            "Train epoch: 266 [727600/25046 (87%)]\tLoss: 0.520876\n",
            "Train epoch: 266 [702100/25046 (89%)]\tLoss: 0.478561\n",
            "Train epoch: 266 [741600/25046 (92%)]\tLoss: 1.088883\n",
            "Train epoch: 266 [782920/25046 (95%)]\tLoss: 0.746637\n",
            "Train epoch: 266 [760000/25046 (97%)]\tLoss: 1.705256\n",
            "Train epoch: 266 [816660/25046 (100%)]\tLoss: 1.263644\n",
            "Make prediction for 5010 samples...\n",
            "0.80151796 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 267 [0/25046 (0%)]\tLoss: 0.689031\n",
            "Train epoch: 267 [20880/25046 (3%)]\tLoss: 0.825813\n",
            "Train epoch: 267 [41120/25046 (5%)]\tLoss: 1.035386\n",
            "Train epoch: 267 [64620/25046 (8%)]\tLoss: 0.856408\n",
            "Train epoch: 267 [81920/25046 (10%)]\tLoss: 0.342379\n",
            "Train epoch: 267 [101600/25046 (13%)]\tLoss: 0.460615\n",
            "Train epoch: 267 [121200/25046 (15%)]\tLoss: 0.284141\n",
            "Train epoch: 267 [149520/25046 (18%)]\tLoss: 1.342338\n",
            "Train epoch: 267 [156640/25046 (20%)]\tLoss: 0.409441\n",
            "Train epoch: 267 [188460/25046 (23%)]\tLoss: 0.941065\n",
            "Train epoch: 267 [201600/25046 (26%)]\tLoss: 1.081121\n",
            "Train epoch: 267 [225280/25046 (28%)]\tLoss: 0.464752\n",
            "Train epoch: 267 [241440/25046 (31%)]\tLoss: 1.173178\n",
            "Train epoch: 267 [269100/25046 (33%)]\tLoss: 0.743550\n",
            "Train epoch: 267 [301280/25046 (36%)]\tLoss: 0.930838\n",
            "Train epoch: 267 [315000/25046 (38%)]\tLoss: 2.159307\n",
            "Train epoch: 267 [313280/25046 (41%)]\tLoss: 0.641471\n",
            "Train epoch: 267 [353600/25046 (43%)]\tLoss: 0.721069\n",
            "Train epoch: 267 [364680/25046 (46%)]\tLoss: 1.317521\n",
            "Train epoch: 267 [375820/25046 (49%)]\tLoss: 0.414816\n",
            "Train epoch: 267 [388800/25046 (51%)]\tLoss: 0.436677\n",
            "Train epoch: 267 [441420/25046 (54%)]\tLoss: 0.630503\n",
            "Train epoch: 267 [480920/25046 (56%)]\tLoss: 0.222052\n",
            "Train epoch: 267 [463680/25046 (59%)]\tLoss: 0.552009\n",
            "Train epoch: 267 [491040/25046 (61%)]\tLoss: 0.763622\n",
            "Train epoch: 267 [521000/25046 (64%)]\tLoss: 0.954293\n",
            "Train epoch: 267 [526760/25046 (66%)]\tLoss: 0.382339\n",
            "Train epoch: 267 [564840/25046 (69%)]\tLoss: 0.381869\n",
            "Train epoch: 267 [562800/25046 (72%)]\tLoss: 0.814270\n",
            "Train epoch: 267 [621180/25046 (74%)]\tLoss: 0.959925\n",
            "Train epoch: 267 [630000/25046 (77%)]\tLoss: 0.332494\n",
            "Train epoch: 267 [627440/25046 (79%)]\tLoss: 1.338030\n",
            "Train epoch: 267 [654080/25046 (82%)]\tLoss: 0.804233\n",
            "Train epoch: 267 [691020/25046 (84%)]\tLoss: 0.397297\n",
            "Train epoch: 267 [701080/25046 (87%)]\tLoss: 0.677497\n",
            "Train epoch: 267 [757400/25046 (89%)]\tLoss: 0.535096\n",
            "Train epoch: 267 [717840/25046 (92%)]\tLoss: 1.251816\n",
            "Train epoch: 267 [735560/25046 (95%)]\tLoss: 0.809499\n",
            "Train epoch: 267 [750880/25046 (97%)]\tLoss: 1.180872\n",
            "Train epoch: 267 [802620/25046 (100%)]\tLoss: 0.632545\n",
            "Make prediction for 5010 samples...\n",
            "0.80211455 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 268 [0/25046 (0%)]\tLoss: 0.371107\n",
            "Train epoch: 268 [19940/25046 (3%)]\tLoss: 0.946022\n",
            "Train epoch: 268 [38760/25046 (5%)]\tLoss: 0.522237\n",
            "Train epoch: 268 [61200/25046 (8%)]\tLoss: 0.678219\n",
            "Train epoch: 268 [81440/25046 (10%)]\tLoss: 1.243766\n",
            "Train epoch: 268 [105700/25046 (13%)]\tLoss: 1.121588\n",
            "Train epoch: 268 [118560/25046 (15%)]\tLoss: 1.132756\n",
            "Train epoch: 268 [141680/25046 (18%)]\tLoss: 0.266069\n",
            "Train epoch: 268 [160480/25046 (20%)]\tLoss: 1.232281\n",
            "Train epoch: 268 [180000/25046 (23%)]\tLoss: 0.295503\n",
            "Train epoch: 268 [207000/25046 (26%)]\tLoss: 0.468362\n",
            "Train epoch: 268 [228140/25046 (28%)]\tLoss: 0.844438\n",
            "Train epoch: 268 [254640/25046 (31%)]\tLoss: 0.343049\n",
            "Train epoch: 268 [286260/25046 (33%)]\tLoss: 0.714227\n",
            "Train epoch: 268 [308280/25046 (36%)]\tLoss: 0.568920\n",
            "Train epoch: 268 [295200/25046 (38%)]\tLoss: 0.861017\n",
            "Train epoch: 268 [316480/25046 (41%)]\tLoss: 0.884304\n",
            "Train epoch: 268 [354280/25046 (43%)]\tLoss: 0.588243\n",
            "Train epoch: 268 [382320/25046 (46%)]\tLoss: 0.846745\n",
            "Train epoch: 268 [399380/25046 (49%)]\tLoss: 1.220307\n",
            "Train epoch: 268 [381200/25046 (51%)]\tLoss: 0.412520\n",
            "Train epoch: 268 [437640/25046 (54%)]\tLoss: 1.055567\n",
            "Train epoch: 268 [438240/25046 (56%)]\tLoss: 0.658345\n",
            "Train epoch: 268 [472880/25046 (59%)]\tLoss: 0.696043\n",
            "Train epoch: 268 [475680/25046 (61%)]\tLoss: 0.628589\n",
            "Train epoch: 268 [526500/25046 (64%)]\tLoss: 0.662732\n",
            "Train epoch: 268 [565240/25046 (66%)]\tLoss: 0.520901\n",
            "Train epoch: 268 [584820/25046 (69%)]\tLoss: 0.374226\n",
            "Train epoch: 268 [608720/25046 (72%)]\tLoss: 0.918769\n",
            "Train epoch: 268 [606680/25046 (74%)]\tLoss: 0.544924\n",
            "Train epoch: 268 [619200/25046 (77%)]\tLoss: 0.850792\n",
            "Train epoch: 268 [642320/25046 (79%)]\tLoss: 0.642281\n",
            "Train epoch: 268 [644480/25046 (82%)]\tLoss: 1.747101\n",
            "Train epoch: 268 [677820/25046 (84%)]\tLoss: 0.659113\n",
            "Train epoch: 268 [707880/25046 (87%)]\tLoss: 0.723217\n",
            "Train epoch: 268 [686700/25046 (89%)]\tLoss: 0.484280\n",
            "Train epoch: 268 [708480/25046 (92%)]\tLoss: 0.831606\n",
            "Train epoch: 268 [788840/25046 (95%)]\tLoss: 1.508937\n",
            "Train epoch: 268 [780520/25046 (97%)]\tLoss: 0.765150\n",
            "Train epoch: 268 [797940/25046 (100%)]\tLoss: 0.709614\n",
            "Make prediction for 5010 samples...\n",
            "0.8015546 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 269 [0/25046 (0%)]\tLoss: 0.586141\n",
            "Train epoch: 269 [19200/25046 (3%)]\tLoss: 1.463561\n",
            "Train epoch: 269 [43960/25046 (5%)]\tLoss: 0.401928\n",
            "Train epoch: 269 [58080/25046 (8%)]\tLoss: 1.157610\n",
            "Train epoch: 269 [81280/25046 (10%)]\tLoss: 0.175455\n",
            "Train epoch: 269 [105600/25046 (13%)]\tLoss: 0.603532\n",
            "Train epoch: 269 [126840/25046 (15%)]\tLoss: 0.985614\n",
            "Train epoch: 269 [154700/25046 (18%)]\tLoss: 0.380817\n",
            "Train epoch: 269 [157600/25046 (20%)]\tLoss: 0.922397\n",
            "Train epoch: 269 [192240/25046 (23%)]\tLoss: 1.474702\n",
            "Train epoch: 269 [206800/25046 (26%)]\tLoss: 1.247598\n",
            "Train epoch: 269 [230340/25046 (28%)]\tLoss: 0.286245\n",
            "Train epoch: 269 [255600/25046 (31%)]\tLoss: 1.541242\n",
            "Train epoch: 269 [261560/25046 (33%)]\tLoss: 1.497810\n",
            "Train epoch: 269 [290640/25046 (36%)]\tLoss: 0.871473\n",
            "Train epoch: 269 [311400/25046 (38%)]\tLoss: 1.156396\n",
            "Train epoch: 269 [331200/25046 (41%)]\tLoss: 1.120388\n",
            "Train epoch: 269 [355640/25046 (43%)]\tLoss: 0.377156\n",
            "Train epoch: 269 [356760/25046 (46%)]\tLoss: 0.340464\n",
            "Train epoch: 269 [391020/25046 (49%)]\tLoss: 0.516771\n",
            "Train epoch: 269 [411600/25046 (51%)]\tLoss: 0.441273\n",
            "Train epoch: 269 [449820/25046 (54%)]\tLoss: 1.637921\n",
            "Train epoch: 269 [432520/25046 (56%)]\tLoss: 0.490069\n",
            "Train epoch: 269 [452180/25046 (59%)]\tLoss: 0.753236\n",
            "Train epoch: 269 [511200/25046 (61%)]\tLoss: 1.282588\n",
            "Train epoch: 269 [490000/25046 (64%)]\tLoss: 0.401352\n",
            "Train epoch: 269 [564200/25046 (66%)]\tLoss: 0.765070\n",
            "Train epoch: 269 [531360/25046 (69%)]\tLoss: 0.792360\n",
            "Train epoch: 269 [574560/25046 (72%)]\tLoss: 0.618116\n",
            "Train epoch: 269 [564920/25046 (74%)]\tLoss: 0.603731\n",
            "Train epoch: 269 [666600/25046 (77%)]\tLoss: 0.832516\n",
            "Train epoch: 269 [623100/25046 (79%)]\tLoss: 0.961250\n",
            "Train epoch: 269 [676480/25046 (82%)]\tLoss: 1.240999\n",
            "Train epoch: 269 [696300/25046 (84%)]\tLoss: 1.281187\n",
            "Train epoch: 269 [709240/25046 (87%)]\tLoss: 1.159746\n",
            "Train epoch: 269 [719600/25046 (89%)]\tLoss: 0.659887\n",
            "Train epoch: 269 [738720/25046 (92%)]\tLoss: 0.474523\n",
            "Train epoch: 269 [780700/25046 (95%)]\tLoss: 0.526552\n",
            "Train epoch: 269 [776720/25046 (97%)]\tLoss: 0.863361\n",
            "Train epoch: 269 [800280/25046 (100%)]\tLoss: 0.765853\n",
            "Make prediction for 5010 samples...\n",
            "0.8024515 No improvement since epoch  21 ; best_mse,best_ci: 0.6790952 0.7042508132023102 GATNet davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 270 [0/25046 (0%)]\tLoss: 0.609888\n",
            "Train epoch: 270 [20720/25046 (3%)]\tLoss: 0.479898\n",
            "Train epoch: 270 [40680/25046 (5%)]\tLoss: 0.918145\n",
            "Train epoch: 270 [61380/25046 (8%)]\tLoss: 1.330436\n",
            "Train epoch: 270 [80720/25046 (10%)]\tLoss: 0.833262\n",
            "Train epoch: 270 [101500/25046 (13%)]\tLoss: 0.583645\n",
            "Train epoch: 270 [121200/25046 (15%)]\tLoss: 1.433766\n",
            "Train epoch: 270 [145600/25046 (18%)]\tLoss: 0.662982\n",
            "Train epoch: 270 [162880/25046 (20%)]\tLoss: 0.456641\n",
            "Train epoch: 270 [180540/25046 (23%)]\tLoss: 0.669054\n",
            "Train epoch: 270 [208200/25046 (26%)]\tLoss: 0.644784\n",
            "Train epoch: 270 [230340/25046 (28%)]\tLoss: 0.939887\n",
            "Train epoch: 270 [240960/25046 (31%)]\tLoss: 1.500778\n",
            "Train epoch: 270 [264420/25046 (33%)]\tLoss: 0.873473\n",
            "Train epoch: 270 [295960/25046 (36%)]\tLoss: 0.293064\n",
            "Train epoch: 270 [311100/25046 (38%)]\tLoss: 0.700252\n",
            "Train epoch: 270 [321600/25046 (41%)]\tLoss: 0.999682\n",
            "Train epoch: 270 [347480/25046 (43%)]\tLoss: 0.993392\n",
            "Train epoch: 270 [366120/25046 (46%)]\tLoss: 0.328922\n",
            "Train epoch: 270 [391020/25046 (49%)]\tLoss: 0.903047\n",
            "Train epoch: 270 [396800/25046 (51%)]\tLoss: 1.518099\n",
            "Train epoch: 270 [399420/25046 (54%)]\tLoss: 0.420291\n",
            "Train epoch: 270 [435160/25046 (56%)]\tLoss: 0.750056\n",
            "Train epoch: 270 [471960/25046 (59%)]\tLoss: 0.380484\n",
            "Train epoch: 270 [471840/25046 (61%)]\tLoss: 0.180694\n",
            "Train epoch: 270 [528500/25046 (64%)]\tLoss: 1.464070\n",
            "Train epoch: 270 [497640/25046 (66%)]\tLoss: 0.414216\n",
            "Train epoch: 270 [554580/25046 (69%)]\tLoss: 0.773060\n",
            "Train epoch: 270 [585760/25046 (72%)]\tLoss: 0.828971\n",
            "Train epoch: 270 [573040/25046 (74%)]\tLoss: 1.511516\n",
            "Train epoch: 270 [601800/25046 (77%)]\tLoss: 0.555999\n",
            "Train epoch: 270 [616280/25046 (79%)]\tLoss: 0.749894\n",
            "Train epoch: 270 [623360/25046 (82%)]\tLoss: 1.185852\n",
            "Train epoch: 270 [691680/25046 (84%)]\tLoss: 0.653299\n",
            "Train epoch: 270 [650080/25046 (87%)]\tLoss: 0.843779\n",
            "Train epoch: 270 [729400/25046 (89%)]\tLoss: 2.467882\n",
            "Train epoch: 270 [747360/25046 (92%)]\tLoss: 0.975908\n",
            "Train epoch: 270 [743700/25046 (95%)]\tLoss: 1.133984\n",
            "Train epoch: 270 [774440/25046 (97%)]\tLoss: 1.480019\n",
            "Train epoch: 270 [838500/25046 (100%)]\tLoss: 0.764181\n",
            "Make prediction for 5010 samples...\n",
            "\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python training.py 0 2 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_NkLgojhYXl",
        "outputId": "0a9401bf-979d-41ff-b17a-e83a06463be9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GATNet(\n",
            "  (gcn1): GATConv(78, 78, heads=10)\n",
            "  (gcn2): GATConv(780, 128, heads=1)\n",
            "  (fc_g1): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (embedding_xt): Embedding(26, 128)\n",
            "  (conv_xt1): Conv1d(1000, 32, kernel_size=(8,), stride=(1,))\n",
            "  (fc_xt1): Linear(in_features=3872, out_features=128, bias=True)\n",
            "  (fc1): Linear(in_features=128, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (gelu): GELU(approximate='none')\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            ")\n",
            "GAT_GAT(\n",
            "  (conv1): GATConv(78, 78, heads=10)\n",
            "  (conv2): GATConv(780, 780, heads=1)\n",
            "  (conv3): GATConv(780, 780, heads=1)\n",
            "  (fc_g1): Linear(in_features=1560, out_features=1500, bias=True)\n",
            "  (fc_g2): Linear(in_features=1500, out_features=128, bias=True)\n",
            "  (gelu): GELU(approximate='none')\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (embedding_xt): Embedding(26, 128)\n",
            "  (conv_xt_1): Conv1d(1000, 32, kernel_size=(8,), stride=(1,))\n",
            "  (fc1_xt): Linear(in_features=3872, out_features=128, bias=True)\n",
            "  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (out): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n",
            "cuda_name: cuda:0\n",
            "Learning rate:  0.0004\n",
            "Epochs:  500\n",
            "\n",
            "running on  GAT_GAT_davis\n",
            "Pre-processed data found: data/processed/davis_train.pt, loading ...\n",
            "Pre-processed data found: data/processed/davis_test.pt, loading ...\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "Training on 25046 samples...\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/scatter.py:93: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n",
            "Train epoch: 1 [0/25046 (0%)]\tLoss: 30.269455\n",
            "Train epoch: 1 [82260/25046 (10%)]\tLoss: 1.092066\n",
            "Train epoch: 1 [162800/25046 (20%)]\tLoss: 0.997573\n",
            "Train epoch: 1 [246960/25046 (31%)]\tLoss: 0.700720\n",
            "Train epoch: 1 [331520/25046 (41%)]\tLoss: 1.023367\n",
            "Train epoch: 1 [410900/25046 (51%)]\tLoss: 0.543688\n",
            "Train epoch: 1 [499320/25046 (61%)]\tLoss: 0.679480\n",
            "Train epoch: 1 [574840/25046 (71%)]\tLoss: 0.603277\n",
            "Train epoch: 1 [634560/25046 (82%)]\tLoss: 0.513067\n",
            "Train epoch: 1 [744480/25046 (92%)]\tLoss: 0.416885\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  1 ; best_mse,best_ci: 0.70061857 0.7109559130172559 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 2 [0/25046 (0%)]\tLoss: 0.556341\n",
            "Train epoch: 2 [81940/25046 (10%)]\tLoss: 0.692029\n",
            "Train epoch: 2 [167320/25046 (20%)]\tLoss: 0.481664\n",
            "Train epoch: 2 [243060/25046 (31%)]\tLoss: 0.551916\n",
            "Train epoch: 2 [328880/25046 (41%)]\tLoss: 0.640496\n",
            "Train epoch: 2 [408900/25046 (51%)]\tLoss: 0.605122\n",
            "Train epoch: 2 [493320/25046 (61%)]\tLoss: 0.453109\n",
            "Train epoch: 2 [599760/25046 (71%)]\tLoss: 0.319681\n",
            "Train epoch: 2 [665440/25046 (82%)]\tLoss: 0.526956\n",
            "Train epoch: 2 [730980/25046 (92%)]\tLoss: 0.708464\n",
            "Make prediction for 5010 samples...\n",
            "0.7342183 No improvement since epoch  1 ; best_mse,best_ci: 0.70061857 0.7109559130172559 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 3 [0/25046 (0%)]\tLoss: 1.013829\n",
            "Train epoch: 3 [83720/25046 (10%)]\tLoss: 0.595165\n",
            "Train epoch: 3 [162360/25046 (20%)]\tLoss: 0.477142\n",
            "Train epoch: 3 [245760/25046 (31%)]\tLoss: 0.280702\n",
            "Train epoch: 3 [328800/25046 (41%)]\tLoss: 0.355697\n",
            "Train epoch: 3 [405400/25046 (51%)]\tLoss: 0.571173\n",
            "Train epoch: 3 [495960/25046 (61%)]\tLoss: 0.625318\n",
            "Train epoch: 3 [577780/25046 (71%)]\tLoss: 0.300422\n",
            "Train epoch: 3 [662560/25046 (82%)]\tLoss: 0.424019\n",
            "Train epoch: 3 [724500/25046 (92%)]\tLoss: 0.434256\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  3 ; best_mse,best_ci: 0.5521771 0.7636065030455171 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 4 [0/25046 (0%)]\tLoss: 0.706630\n",
            "Train epoch: 4 [82500/25046 (10%)]\tLoss: 0.508500\n",
            "Train epoch: 4 [166520/25046 (20%)]\tLoss: 0.851884\n",
            "Train epoch: 4 [240240/25046 (31%)]\tLoss: 0.397848\n",
            "Train epoch: 4 [330000/25046 (41%)]\tLoss: 0.550617\n",
            "Train epoch: 4 [403200/25046 (51%)]\tLoss: 0.935886\n",
            "Train epoch: 4 [492240/25046 (61%)]\tLoss: 0.447068\n",
            "Train epoch: 4 [582820/25046 (71%)]\tLoss: 0.661410\n",
            "Train epoch: 4 [665440/25046 (82%)]\tLoss: 0.440316\n",
            "Train epoch: 4 [745380/25046 (92%)]\tLoss: 0.593656\n",
            "Make prediction for 5010 samples...\n",
            "0.5825568 No improvement since epoch  3 ; best_mse,best_ci: 0.5521771 0.7636065030455171 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 5 [0/25046 (0%)]\tLoss: 0.381362\n",
            "Train epoch: 5 [83440/25046 (10%)]\tLoss: 0.363627\n",
            "Train epoch: 5 [167520/25046 (20%)]\tLoss: 0.647182\n",
            "Train epoch: 5 [248640/25046 (31%)]\tLoss: 0.528942\n",
            "Train epoch: 5 [332000/25046 (41%)]\tLoss: 0.625303\n",
            "Train epoch: 5 [416600/25046 (51%)]\tLoss: 0.743575\n",
            "Train epoch: 5 [490680/25046 (61%)]\tLoss: 0.311556\n",
            "Train epoch: 5 [591500/25046 (71%)]\tLoss: 0.520352\n",
            "Train epoch: 5 [651680/25046 (82%)]\tLoss: 0.314779\n",
            "Train epoch: 5 [728640/25046 (92%)]\tLoss: 0.461332\n",
            "Make prediction for 5010 samples...\n",
            "0.5680718 No improvement since epoch  3 ; best_mse,best_ci: 0.5521771 0.7636065030455171 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 6 [0/25046 (0%)]\tLoss: 0.439674\n",
            "Train epoch: 6 [82920/25046 (10%)]\tLoss: 0.435995\n",
            "Train epoch: 6 [166120/25046 (20%)]\tLoss: 0.566024\n",
            "Train epoch: 6 [246840/25046 (31%)]\tLoss: 0.581160\n",
            "Train epoch: 6 [326960/25046 (41%)]\tLoss: 0.576708\n",
            "Train epoch: 6 [405400/25046 (51%)]\tLoss: 0.409268\n",
            "Train epoch: 6 [492840/25046 (61%)]\tLoss: 0.566868\n",
            "Train epoch: 6 [590800/25046 (71%)]\tLoss: 0.436937\n",
            "Train epoch: 6 [637920/25046 (82%)]\tLoss: 0.482841\n",
            "Train epoch: 6 [741420/25046 (92%)]\tLoss: 0.599360\n",
            "Make prediction for 5010 samples...\n",
            "0.63386387 No improvement since epoch  3 ; best_mse,best_ci: 0.5521771 0.7636065030455171 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 7 [0/25046 (0%)]\tLoss: 0.627417\n",
            "Train epoch: 7 [81120/25046 (10%)]\tLoss: 0.413742\n",
            "Train epoch: 7 [167120/25046 (20%)]\tLoss: 0.830257\n",
            "Train epoch: 7 [242640/25046 (31%)]\tLoss: 0.543412\n",
            "Train epoch: 7 [319120/25046 (41%)]\tLoss: 0.343099\n",
            "Train epoch: 7 [404300/25046 (51%)]\tLoss: 0.513358\n",
            "Train epoch: 7 [483600/25046 (61%)]\tLoss: 0.578436\n",
            "Train epoch: 7 [570080/25046 (71%)]\tLoss: 0.528563\n",
            "Train epoch: 7 [665120/25046 (82%)]\tLoss: 0.631849\n",
            "Train epoch: 7 [748080/25046 (92%)]\tLoss: 0.444879\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  7 ; best_mse,best_ci: 0.4702553 0.8131948057358119 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 8 [0/25046 (0%)]\tLoss: 0.373428\n",
            "Train epoch: 8 [82580/25046 (10%)]\tLoss: 0.436976\n",
            "Train epoch: 8 [164560/25046 (20%)]\tLoss: 0.304832\n",
            "Train epoch: 8 [244140/25046 (31%)]\tLoss: 0.422958\n",
            "Train epoch: 8 [325280/25046 (41%)]\tLoss: 0.304955\n",
            "Train epoch: 8 [420500/25046 (51%)]\tLoss: 0.583824\n",
            "Train epoch: 8 [496440/25046 (61%)]\tLoss: 0.459202\n",
            "Train epoch: 8 [570920/25046 (71%)]\tLoss: 0.445778\n",
            "Train epoch: 8 [650560/25046 (82%)]\tLoss: 0.493780\n",
            "Train epoch: 8 [719280/25046 (92%)]\tLoss: 0.468047\n",
            "Make prediction for 5010 samples...\n",
            "0.47600338 No improvement since epoch  7 ; best_mse,best_ci: 0.4702553 0.8131948057358119 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 9 [0/25046 (0%)]\tLoss: 0.337331\n",
            "Train epoch: 9 [82240/25046 (10%)]\tLoss: 0.581113\n",
            "Train epoch: 9 [161480/25046 (20%)]\tLoss: 0.401349\n",
            "Train epoch: 9 [251820/25046 (31%)]\tLoss: 0.336075\n",
            "Train epoch: 9 [332240/25046 (41%)]\tLoss: 0.495951\n",
            "Train epoch: 9 [408100/25046 (51%)]\tLoss: 0.728701\n",
            "Train epoch: 9 [483240/25046 (61%)]\tLoss: 0.488609\n",
            "Train epoch: 9 [571200/25046 (71%)]\tLoss: 0.467368\n",
            "Train epoch: 9 [659040/25046 (82%)]\tLoss: 0.450570\n",
            "Train epoch: 9 [736740/25046 (92%)]\tLoss: 0.576894\n",
            "Make prediction for 5010 samples...\n",
            "0.4967714 No improvement since epoch  7 ; best_mse,best_ci: 0.4702553 0.8131948057358119 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 10 [0/25046 (0%)]\tLoss: 0.298232\n",
            "Train epoch: 10 [85200/25046 (10%)]\tLoss: 0.606145\n",
            "Train epoch: 10 [162080/25046 (20%)]\tLoss: 0.475032\n",
            "Train epoch: 10 [243120/25046 (31%)]\tLoss: 0.395384\n",
            "Train epoch: 10 [338000/25046 (41%)]\tLoss: 0.261618\n",
            "Train epoch: 10 [405800/25046 (51%)]\tLoss: 0.525360\n",
            "Train epoch: 10 [481200/25046 (61%)]\tLoss: 0.386348\n",
            "Train epoch: 10 [583660/25046 (71%)]\tLoss: 0.456991\n",
            "Train epoch: 10 [653600/25046 (82%)]\tLoss: 0.334709\n",
            "Train epoch: 10 [731160/25046 (92%)]\tLoss: 0.322398\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  10 ; best_mse,best_ci: 0.42579007 0.822221852954154 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 11 [0/25046 (0%)]\tLoss: 0.365141\n",
            "Train epoch: 11 [83960/25046 (10%)]\tLoss: 0.281489\n",
            "Train epoch: 11 [163480/25046 (20%)]\tLoss: 0.238203\n",
            "Train epoch: 11 [243900/25046 (31%)]\tLoss: 0.453153\n",
            "Train epoch: 11 [331280/25046 (41%)]\tLoss: 0.365108\n",
            "Train epoch: 11 [403200/25046 (51%)]\tLoss: 0.298474\n",
            "Train epoch: 11 [475200/25046 (61%)]\tLoss: 0.463227\n",
            "Train epoch: 11 [595420/25046 (71%)]\tLoss: 0.445758\n",
            "Train epoch: 11 [638080/25046 (82%)]\tLoss: 0.398814\n",
            "Train epoch: 11 [743760/25046 (92%)]\tLoss: 0.461256\n",
            "Make prediction for 5010 samples...\n",
            "0.4410771 No improvement since epoch  10 ; best_mse,best_ci: 0.42579007 0.822221852954154 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 12 [0/25046 (0%)]\tLoss: 0.502214\n",
            "Train epoch: 12 [82840/25046 (10%)]\tLoss: 0.303214\n",
            "Train epoch: 12 [160760/25046 (20%)]\tLoss: 0.327561\n",
            "Train epoch: 12 [251220/25046 (31%)]\tLoss: 0.320629\n",
            "Train epoch: 12 [328960/25046 (41%)]\tLoss: 0.372564\n",
            "Train epoch: 12 [419200/25046 (51%)]\tLoss: 0.405766\n",
            "Train epoch: 12 [499080/25046 (61%)]\tLoss: 0.388157\n",
            "Train epoch: 12 [563920/25046 (71%)]\tLoss: 0.332529\n",
            "Train epoch: 12 [651680/25046 (82%)]\tLoss: 0.300012\n",
            "Train epoch: 12 [762660/25046 (92%)]\tLoss: 0.403132\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  12 ; best_mse,best_ci: 0.4068556 0.8194452718942058 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 13 [0/25046 (0%)]\tLoss: 0.369098\n",
            "Train epoch: 13 [83280/25046 (10%)]\tLoss: 0.294075\n",
            "Train epoch: 13 [162920/25046 (20%)]\tLoss: 0.348911\n",
            "Train epoch: 13 [244920/25046 (31%)]\tLoss: 0.278332\n",
            "Train epoch: 13 [329280/25046 (41%)]\tLoss: 0.410373\n",
            "Train epoch: 13 [394300/25046 (51%)]\tLoss: 0.235209\n",
            "Train epoch: 13 [500400/25046 (61%)]\tLoss: 0.349148\n",
            "Train epoch: 13 [569660/25046 (71%)]\tLoss: 0.277705\n",
            "Train epoch: 13 [662240/25046 (82%)]\tLoss: 0.261086\n",
            "Train epoch: 13 [754020/25046 (92%)]\tLoss: 0.402636\n",
            "Make prediction for 5010 samples...\n",
            "0.40956387 No improvement since epoch  12 ; best_mse,best_ci: 0.4068556 0.8194452718942058 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 14 [0/25046 (0%)]\tLoss: 0.320401\n",
            "Train epoch: 14 [81960/25046 (10%)]\tLoss: 0.224293\n",
            "Train epoch: 14 [160720/25046 (20%)]\tLoss: 0.422221\n",
            "Train epoch: 14 [245880/25046 (31%)]\tLoss: 0.216491\n",
            "Train epoch: 14 [334560/25046 (41%)]\tLoss: 0.385254\n",
            "Train epoch: 14 [409200/25046 (51%)]\tLoss: 0.605359\n",
            "Train epoch: 14 [501480/25046 (61%)]\tLoss: 0.399022\n",
            "Train epoch: 14 [571480/25046 (71%)]\tLoss: 0.409402\n",
            "Train epoch: 14 [684640/25046 (82%)]\tLoss: 0.418147\n",
            "Train epoch: 14 [726120/25046 (92%)]\tLoss: 0.448197\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  14 ; best_mse,best_ci: 0.36923137 0.8412516829562383 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 15 [0/25046 (0%)]\tLoss: 0.401663\n",
            "Train epoch: 15 [81860/25046 (10%)]\tLoss: 0.450785\n",
            "Train epoch: 15 [165480/25046 (20%)]\tLoss: 0.281941\n",
            "Train epoch: 15 [240840/25046 (31%)]\tLoss: 0.279741\n",
            "Train epoch: 15 [329040/25046 (41%)]\tLoss: 0.245724\n",
            "Train epoch: 15 [418500/25046 (51%)]\tLoss: 0.281244\n",
            "Train epoch: 15 [491280/25046 (61%)]\tLoss: 0.439083\n",
            "Train epoch: 15 [568820/25046 (71%)]\tLoss: 0.444343\n",
            "Train epoch: 15 [659680/25046 (82%)]\tLoss: 0.243613\n",
            "Train epoch: 15 [758340/25046 (92%)]\tLoss: 0.268745\n",
            "Make prediction for 5010 samples...\n",
            "0.39965862 No improvement since epoch  14 ; best_mse,best_ci: 0.36923137 0.8412516829562383 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 16 [0/25046 (0%)]\tLoss: 0.295137\n",
            "Train epoch: 16 [80080/25046 (10%)]\tLoss: 0.336159\n",
            "Train epoch: 16 [163800/25046 (20%)]\tLoss: 0.345033\n",
            "Train epoch: 16 [246540/25046 (31%)]\tLoss: 0.363212\n",
            "Train epoch: 16 [328240/25046 (41%)]\tLoss: 0.270965\n",
            "Train epoch: 16 [404800/25046 (51%)]\tLoss: 0.230352\n",
            "Train epoch: 16 [493560/25046 (61%)]\tLoss: 0.315859\n",
            "Train epoch: 16 [577640/25046 (71%)]\tLoss: 0.231762\n",
            "Train epoch: 16 [659040/25046 (82%)]\tLoss: 0.449257\n",
            "Train epoch: 16 [731340/25046 (92%)]\tLoss: 0.289845\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  16 ; best_mse,best_ci: 0.36014727 0.8397283500726633 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 17 [0/25046 (0%)]\tLoss: 0.363329\n",
            "Train epoch: 17 [82460/25046 (10%)]\tLoss: 0.279374\n",
            "Train epoch: 17 [164280/25046 (20%)]\tLoss: 0.231104\n",
            "Train epoch: 17 [251160/25046 (31%)]\tLoss: 0.283324\n",
            "Train epoch: 17 [327920/25046 (41%)]\tLoss: 0.314194\n",
            "Train epoch: 17 [408300/25046 (51%)]\tLoss: 0.235810\n",
            "Train epoch: 17 [484080/25046 (61%)]\tLoss: 0.257631\n",
            "Train epoch: 17 [569800/25046 (71%)]\tLoss: 0.345373\n",
            "Train epoch: 17 [642720/25046 (82%)]\tLoss: 0.267196\n",
            "Train epoch: 17 [744480/25046 (92%)]\tLoss: 0.291852\n",
            "Make prediction for 5010 samples...\n",
            "0.43499905 No improvement since epoch  16 ; best_mse,best_ci: 0.36014727 0.8397283500726633 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 18 [0/25046 (0%)]\tLoss: 0.490753\n",
            "Train epoch: 18 [83800/25046 (10%)]\tLoss: 0.240064\n",
            "Train epoch: 18 [164840/25046 (20%)]\tLoss: 0.230551\n",
            "Train epoch: 18 [245280/25046 (31%)]\tLoss: 0.338422\n",
            "Train epoch: 18 [321520/25046 (41%)]\tLoss: 0.258954\n",
            "Train epoch: 18 [399500/25046 (51%)]\tLoss: 0.201766\n",
            "Train epoch: 18 [496560/25046 (61%)]\tLoss: 0.380432\n",
            "Train epoch: 18 [567700/25046 (71%)]\tLoss: 0.247673\n",
            "Train epoch: 18 [664960/25046 (82%)]\tLoss: 0.259318\n",
            "Train epoch: 18 [734220/25046 (92%)]\tLoss: 0.348777\n",
            "Make prediction for 5010 samples...\n",
            "0.3754214 No improvement since epoch  16 ; best_mse,best_ci: 0.36014727 0.8397283500726633 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 19 [0/25046 (0%)]\tLoss: 0.228916\n",
            "Train epoch: 19 [80800/25046 (10%)]\tLoss: 0.263529\n",
            "Train epoch: 19 [166640/25046 (20%)]\tLoss: 0.264217\n",
            "Train epoch: 19 [245220/25046 (31%)]\tLoss: 0.246530\n",
            "Train epoch: 19 [327920/25046 (41%)]\tLoss: 0.492083\n",
            "Train epoch: 19 [412000/25046 (51%)]\tLoss: 0.458534\n",
            "Train epoch: 19 [495600/25046 (61%)]\tLoss: 0.404974\n",
            "Train epoch: 19 [582260/25046 (71%)]\tLoss: 0.309553\n",
            "Train epoch: 19 [687520/25046 (82%)]\tLoss: 0.266694\n",
            "Train epoch: 19 [739440/25046 (92%)]\tLoss: 0.229436\n",
            "Make prediction for 5010 samples...\n",
            "0.36418718 No improvement since epoch  16 ; best_mse,best_ci: 0.36014727 0.8397283500726633 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 20 [0/25046 (0%)]\tLoss: 0.237459\n",
            "Train epoch: 20 [82520/25046 (10%)]\tLoss: 0.196813\n",
            "Train epoch: 20 [164400/25046 (20%)]\tLoss: 0.367982\n",
            "Train epoch: 20 [247920/25046 (31%)]\tLoss: 0.302266\n",
            "Train epoch: 20 [329040/25046 (41%)]\tLoss: 0.139958\n",
            "Train epoch: 20 [404800/25046 (51%)]\tLoss: 0.290512\n",
            "Train epoch: 20 [480600/25046 (61%)]\tLoss: 0.178561\n",
            "Train epoch: 20 [578340/25046 (71%)]\tLoss: 0.224420\n",
            "Train epoch: 20 [643200/25046 (82%)]\tLoss: 0.266122\n",
            "Train epoch: 20 [724140/25046 (92%)]\tLoss: 0.353561\n",
            "Make prediction for 5010 samples...\n",
            "0.38427734 No improvement since epoch  16 ; best_mse,best_ci: 0.36014727 0.8397283500726633 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 21 [0/25046 (0%)]\tLoss: 0.202136\n",
            "Train epoch: 21 [82740/25046 (10%)]\tLoss: 0.220410\n",
            "Train epoch: 21 [161520/25046 (20%)]\tLoss: 0.228844\n",
            "Train epoch: 21 [244500/25046 (31%)]\tLoss: 0.278873\n",
            "Train epoch: 21 [323120/25046 (41%)]\tLoss: 0.218008\n",
            "Train epoch: 21 [408500/25046 (51%)]\tLoss: 0.225086\n",
            "Train epoch: 21 [488160/25046 (61%)]\tLoss: 0.228831\n",
            "Train epoch: 21 [559440/25046 (71%)]\tLoss: 0.197200\n",
            "Train epoch: 21 [664160/25046 (82%)]\tLoss: 0.219116\n",
            "Train epoch: 21 [735120/25046 (92%)]\tLoss: 0.233079\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  21 ; best_mse,best_ci: 0.3480037 0.8454103135754667 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 22 [0/25046 (0%)]\tLoss: 0.325984\n",
            "Train epoch: 22 [83160/25046 (10%)]\tLoss: 0.357070\n",
            "Train epoch: 22 [157920/25046 (20%)]\tLoss: 0.278730\n",
            "Train epoch: 22 [239100/25046 (31%)]\tLoss: 0.261239\n",
            "Train epoch: 22 [331600/25046 (41%)]\tLoss: 0.187574\n",
            "Train epoch: 22 [405400/25046 (51%)]\tLoss: 0.202424\n",
            "Train epoch: 22 [496320/25046 (61%)]\tLoss: 0.285307\n",
            "Train epoch: 22 [582820/25046 (71%)]\tLoss: 0.299318\n",
            "Train epoch: 22 [658880/25046 (82%)]\tLoss: 0.206915\n",
            "Train epoch: 22 [740700/25046 (92%)]\tLoss: 0.264905\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  22 ; best_mse,best_ci: 0.3438235 0.8267178022961565 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 23 [0/25046 (0%)]\tLoss: 0.330737\n",
            "Train epoch: 23 [81760/25046 (10%)]\tLoss: 0.175499\n",
            "Train epoch: 23 [157080/25046 (20%)]\tLoss: 0.207493\n",
            "Train epoch: 23 [251340/25046 (31%)]\tLoss: 0.264893\n",
            "Train epoch: 23 [328160/25046 (41%)]\tLoss: 0.265519\n",
            "Train epoch: 23 [409500/25046 (51%)]\tLoss: 0.151466\n",
            "Train epoch: 23 [486480/25046 (61%)]\tLoss: 0.191433\n",
            "Train epoch: 23 [556500/25046 (71%)]\tLoss: 0.245237\n",
            "Train epoch: 23 [650400/25046 (82%)]\tLoss: 0.175198\n",
            "Train epoch: 23 [712260/25046 (92%)]\tLoss: 0.146249\n",
            "Make prediction for 5010 samples...\n",
            "0.3448625 No improvement since epoch  22 ; best_mse,best_ci: 0.3438235 0.8267178022961565 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 24 [0/25046 (0%)]\tLoss: 0.173063\n",
            "Train epoch: 24 [82040/25046 (10%)]\tLoss: 0.375890\n",
            "Train epoch: 24 [158600/25046 (20%)]\tLoss: 0.161883\n",
            "Train epoch: 24 [248400/25046 (31%)]\tLoss: 0.224054\n",
            "Train epoch: 24 [328560/25046 (41%)]\tLoss: 0.257363\n",
            "Train epoch: 24 [402300/25046 (51%)]\tLoss: 0.290779\n",
            "Train epoch: 24 [509280/25046 (61%)]\tLoss: 0.239901\n",
            "Train epoch: 24 [555800/25046 (71%)]\tLoss: 0.260880\n",
            "Train epoch: 24 [668320/25046 (82%)]\tLoss: 0.247662\n",
            "Train epoch: 24 [723960/25046 (92%)]\tLoss: 0.302692\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  24 ; best_mse,best_ci: 0.34157935 0.8418208747987765 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 25 [0/25046 (0%)]\tLoss: 0.217893\n",
            "Train epoch: 25 [82000/25046 (10%)]\tLoss: 0.335933\n",
            "Train epoch: 25 [164640/25046 (20%)]\tLoss: 0.305732\n",
            "Train epoch: 25 [245760/25046 (31%)]\tLoss: 0.244695\n",
            "Train epoch: 25 [338000/25046 (41%)]\tLoss: 0.257804\n",
            "Train epoch: 25 [406200/25046 (51%)]\tLoss: 0.231537\n",
            "Train epoch: 25 [472680/25046 (61%)]\tLoss: 0.249088\n",
            "Train epoch: 25 [580860/25046 (71%)]\tLoss: 0.200635\n",
            "Train epoch: 25 [657760/25046 (82%)]\tLoss: 0.176216\n",
            "Train epoch: 25 [738360/25046 (92%)]\tLoss: 0.332639\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  25 ; best_mse,best_ci: 0.33755136 0.8494625030994268 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 26 [0/25046 (0%)]\tLoss: 0.225041\n",
            "Train epoch: 26 [81340/25046 (10%)]\tLoss: 0.212131\n",
            "Train epoch: 26 [162080/25046 (20%)]\tLoss: 0.162959\n",
            "Train epoch: 26 [242520/25046 (31%)]\tLoss: 0.280599\n",
            "Train epoch: 26 [341760/25046 (41%)]\tLoss: 0.262624\n",
            "Train epoch: 26 [409000/25046 (51%)]\tLoss: 0.336133\n",
            "Train epoch: 26 [491760/25046 (61%)]\tLoss: 0.300783\n",
            "Train epoch: 26 [575400/25046 (71%)]\tLoss: 0.260200\n",
            "Train epoch: 26 [674720/25046 (82%)]\tLoss: 0.339914\n",
            "Train epoch: 26 [738000/25046 (92%)]\tLoss: 0.222383\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  26 ; best_mse,best_ci: 0.33188614 0.8489666713786633 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 27 [0/25046 (0%)]\tLoss: 0.249347\n",
            "Train epoch: 27 [81860/25046 (10%)]\tLoss: 0.193218\n",
            "Train epoch: 27 [162760/25046 (20%)]\tLoss: 0.215093\n",
            "Train epoch: 27 [244200/25046 (31%)]\tLoss: 0.186268\n",
            "Train epoch: 27 [323360/25046 (41%)]\tLoss: 0.229297\n",
            "Train epoch: 27 [409700/25046 (51%)]\tLoss: 0.201059\n",
            "Train epoch: 27 [491160/25046 (61%)]\tLoss: 0.215810\n",
            "Train epoch: 27 [579740/25046 (71%)]\tLoss: 0.266705\n",
            "Train epoch: 27 [655840/25046 (82%)]\tLoss: 0.178259\n",
            "Train epoch: 27 [746820/25046 (92%)]\tLoss: 0.212067\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  27 ; best_mse,best_ci: 0.32799834 0.8534662198080599 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 28 [0/25046 (0%)]\tLoss: 0.250466\n",
            "Train epoch: 28 [82100/25046 (10%)]\tLoss: 0.233662\n",
            "Train epoch: 28 [164920/25046 (20%)]\tLoss: 0.170116\n",
            "Train epoch: 28 [242700/25046 (31%)]\tLoss: 0.120060\n",
            "Train epoch: 28 [329600/25046 (41%)]\tLoss: 0.463833\n",
            "Train epoch: 28 [415900/25046 (51%)]\tLoss: 0.321419\n",
            "Train epoch: 28 [489960/25046 (61%)]\tLoss: 0.169149\n",
            "Train epoch: 28 [578760/25046 (71%)]\tLoss: 0.122278\n",
            "Train epoch: 28 [655200/25046 (82%)]\tLoss: 0.263509\n",
            "Train epoch: 28 [728820/25046 (92%)]\tLoss: 0.268196\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  28 ; best_mse,best_ci: 0.30833122 0.8549353366517429 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 29 [0/25046 (0%)]\tLoss: 0.115377\n",
            "Train epoch: 29 [80560/25046 (10%)]\tLoss: 0.183668\n",
            "Train epoch: 29 [165720/25046 (20%)]\tLoss: 0.214510\n",
            "Train epoch: 29 [240000/25046 (31%)]\tLoss: 0.189833\n",
            "Train epoch: 29 [326640/25046 (41%)]\tLoss: 0.162312\n",
            "Train epoch: 29 [412800/25046 (51%)]\tLoss: 0.136982\n",
            "Train epoch: 29 [493440/25046 (61%)]\tLoss: 0.119508\n",
            "Train epoch: 29 [579320/25046 (71%)]\tLoss: 0.225273\n",
            "Train epoch: 29 [649440/25046 (82%)]\tLoss: 0.211964\n",
            "Train epoch: 29 [742320/25046 (92%)]\tLoss: 0.224674\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  29 ; best_mse,best_ci: 0.30814993 0.8635959661428488 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 30 [0/25046 (0%)]\tLoss: 0.178452\n",
            "Train epoch: 30 [83300/25046 (10%)]\tLoss: 0.240512\n",
            "Train epoch: 30 [159080/25046 (20%)]\tLoss: 0.163616\n",
            "Train epoch: 30 [244920/25046 (31%)]\tLoss: 0.136235\n",
            "Train epoch: 30 [331520/25046 (41%)]\tLoss: 0.134259\n",
            "Train epoch: 30 [419100/25046 (51%)]\tLoss: 0.114513\n",
            "Train epoch: 30 [487920/25046 (61%)]\tLoss: 0.161422\n",
            "Train epoch: 30 [575960/25046 (71%)]\tLoss: 0.254201\n",
            "Train epoch: 30 [645440/25046 (82%)]\tLoss: 0.110742\n",
            "Train epoch: 30 [726480/25046 (92%)]\tLoss: 0.227147\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  30 ; best_mse,best_ci: 0.306385 0.8543832213302441 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 31 [0/25046 (0%)]\tLoss: 0.184769\n",
            "Train epoch: 31 [81900/25046 (10%)]\tLoss: 0.242268\n",
            "Train epoch: 31 [164080/25046 (20%)]\tLoss: 0.259048\n",
            "Train epoch: 31 [244800/25046 (31%)]\tLoss: 0.182820\n",
            "Train epoch: 31 [330640/25046 (41%)]\tLoss: 0.169816\n",
            "Train epoch: 31 [409200/25046 (51%)]\tLoss: 0.220166\n",
            "Train epoch: 31 [498000/25046 (61%)]\tLoss: 0.245639\n",
            "Train epoch: 31 [582960/25046 (71%)]\tLoss: 0.216146\n",
            "Train epoch: 31 [638560/25046 (82%)]\tLoss: 0.205471\n",
            "Train epoch: 31 [744120/25046 (92%)]\tLoss: 0.184594\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  31 ; best_mse,best_ci: 0.30546913 0.8657871977551497 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 32 [0/25046 (0%)]\tLoss: 0.106687\n",
            "Train epoch: 32 [83600/25046 (10%)]\tLoss: 0.182725\n",
            "Train epoch: 32 [160640/25046 (20%)]\tLoss: 0.207816\n",
            "Train epoch: 32 [242940/25046 (31%)]\tLoss: 0.141640\n",
            "Train epoch: 32 [328640/25046 (41%)]\tLoss: 0.153495\n",
            "Train epoch: 32 [416500/25046 (51%)]\tLoss: 0.214881\n",
            "Train epoch: 32 [489840/25046 (61%)]\tLoss: 0.231324\n",
            "Train epoch: 32 [569940/25046 (71%)]\tLoss: 0.238118\n",
            "Train epoch: 32 [644640/25046 (82%)]\tLoss: 0.210760\n",
            "Train epoch: 32 [735840/25046 (92%)]\tLoss: 0.212487\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  32 ; best_mse,best_ci: 0.29866663 0.8699601481476263 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 33 [0/25046 (0%)]\tLoss: 0.165633\n",
            "Train epoch: 33 [80880/25046 (10%)]\tLoss: 0.243863\n",
            "Train epoch: 33 [166960/25046 (20%)]\tLoss: 0.156462\n",
            "Train epoch: 33 [241920/25046 (31%)]\tLoss: 0.177109\n",
            "Train epoch: 33 [319040/25046 (41%)]\tLoss: 0.245871\n",
            "Train epoch: 33 [415600/25046 (51%)]\tLoss: 0.187327\n",
            "Train epoch: 33 [498000/25046 (61%)]\tLoss: 0.125071\n",
            "Train epoch: 33 [569520/25046 (71%)]\tLoss: 0.192642\n",
            "Train epoch: 33 [668480/25046 (82%)]\tLoss: 0.181618\n",
            "Train epoch: 33 [722700/25046 (92%)]\tLoss: 0.226442\n",
            "Make prediction for 5010 samples...\n",
            "0.32977584 No improvement since epoch  32 ; best_mse,best_ci: 0.29866663 0.8699601481476263 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 34 [0/25046 (0%)]\tLoss: 0.222161\n",
            "Train epoch: 34 [82320/25046 (10%)]\tLoss: 0.294850\n",
            "Train epoch: 34 [163000/25046 (20%)]\tLoss: 0.214857\n",
            "Train epoch: 34 [245280/25046 (31%)]\tLoss: 0.217496\n",
            "Train epoch: 34 [325520/25046 (41%)]\tLoss: 0.167835\n",
            "Train epoch: 34 [408700/25046 (51%)]\tLoss: 0.124838\n",
            "Train epoch: 34 [493800/25046 (61%)]\tLoss: 0.201856\n",
            "Train epoch: 34 [582820/25046 (71%)]\tLoss: 0.146848\n",
            "Train epoch: 34 [662560/25046 (82%)]\tLoss: 0.199584\n",
            "Train epoch: 34 [742500/25046 (92%)]\tLoss: 0.194274\n",
            "Make prediction for 5010 samples...\n",
            "0.3161784 No improvement since epoch  32 ; best_mse,best_ci: 0.29866663 0.8699601481476263 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 35 [0/25046 (0%)]\tLoss: 0.239382\n",
            "Train epoch: 35 [80340/25046 (10%)]\tLoss: 0.121723\n",
            "Train epoch: 35 [165560/25046 (20%)]\tLoss: 0.252213\n",
            "Train epoch: 35 [242760/25046 (31%)]\tLoss: 0.161105\n",
            "Train epoch: 35 [327760/25046 (41%)]\tLoss: 0.127730\n",
            "Train epoch: 35 [398200/25046 (51%)]\tLoss: 0.244976\n",
            "Train epoch: 35 [498840/25046 (61%)]\tLoss: 0.182053\n",
            "Train epoch: 35 [559580/25046 (71%)]\tLoss: 0.122970\n",
            "Train epoch: 35 [647200/25046 (82%)]\tLoss: 0.147535\n",
            "Train epoch: 35 [743040/25046 (92%)]\tLoss: 0.224925\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  35 ; best_mse,best_ci: 0.29399058 0.8695753521017828 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 36 [0/25046 (0%)]\tLoss: 0.130061\n",
            "Train epoch: 36 [80720/25046 (10%)]\tLoss: 0.106424\n",
            "Train epoch: 36 [167280/25046 (20%)]\tLoss: 0.297297\n",
            "Train epoch: 36 [243780/25046 (31%)]\tLoss: 0.188911\n",
            "Train epoch: 36 [323360/25046 (41%)]\tLoss: 0.244374\n",
            "Train epoch: 36 [409800/25046 (51%)]\tLoss: 0.203979\n",
            "Train epoch: 36 [489360/25046 (61%)]\tLoss: 0.185222\n",
            "Train epoch: 36 [566020/25046 (71%)]\tLoss: 0.228610\n",
            "Train epoch: 36 [651520/25046 (82%)]\tLoss: 0.218271\n",
            "Train epoch: 36 [735480/25046 (92%)]\tLoss: 0.141185\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  36 ; best_mse,best_ci: 0.2906666 0.8640662213702169 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 37 [0/25046 (0%)]\tLoss: 0.147117\n",
            "Train epoch: 37 [84300/25046 (10%)]\tLoss: 0.143665\n",
            "Train epoch: 37 [167520/25046 (20%)]\tLoss: 0.138192\n",
            "Train epoch: 37 [243960/25046 (31%)]\tLoss: 0.136620\n",
            "Train epoch: 37 [328240/25046 (41%)]\tLoss: 0.150120\n",
            "Train epoch: 37 [401400/25046 (51%)]\tLoss: 0.160751\n",
            "Train epoch: 37 [486120/25046 (61%)]\tLoss: 0.125869\n",
            "Train epoch: 37 [582960/25046 (71%)]\tLoss: 0.229368\n",
            "Train epoch: 37 [665600/25046 (82%)]\tLoss: 0.222890\n",
            "Train epoch: 37 [750780/25046 (92%)]\tLoss: 0.129859\n",
            "Make prediction for 5010 samples...\n",
            "0.33832985 No improvement since epoch  36 ; best_mse,best_ci: 0.2906666 0.8640662213702169 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 38 [0/25046 (0%)]\tLoss: 0.247720\n",
            "Train epoch: 38 [84120/25046 (10%)]\tLoss: 0.161383\n",
            "Train epoch: 38 [170920/25046 (20%)]\tLoss: 0.173337\n",
            "Train epoch: 38 [247440/25046 (31%)]\tLoss: 0.124257\n",
            "Train epoch: 38 [324400/25046 (41%)]\tLoss: 0.133053\n",
            "Train epoch: 38 [413200/25046 (51%)]\tLoss: 0.155938\n",
            "Train epoch: 38 [501120/25046 (61%)]\tLoss: 0.158553\n",
            "Train epoch: 38 [579320/25046 (71%)]\tLoss: 0.082089\n",
            "Train epoch: 38 [651520/25046 (82%)]\tLoss: 0.134374\n",
            "Train epoch: 38 [735300/25046 (92%)]\tLoss: 0.123270\n",
            "Make prediction for 5010 samples...\n",
            "0.2990959 No improvement since epoch  36 ; best_mse,best_ci: 0.2906666 0.8640662213702169 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 39 [0/25046 (0%)]\tLoss: 0.253000\n",
            "Train epoch: 39 [82960/25046 (10%)]\tLoss: 0.165851\n",
            "Train epoch: 39 [164720/25046 (20%)]\tLoss: 0.134259\n",
            "Train epoch: 39 [252180/25046 (31%)]\tLoss: 0.177930\n",
            "Train epoch: 39 [322000/25046 (41%)]\tLoss: 0.127801\n",
            "Train epoch: 39 [404100/25046 (51%)]\tLoss: 0.103840\n",
            "Train epoch: 39 [496320/25046 (61%)]\tLoss: 0.140614\n",
            "Train epoch: 39 [569940/25046 (71%)]\tLoss: 0.125764\n",
            "Train epoch: 39 [667520/25046 (82%)]\tLoss: 0.215321\n",
            "Train epoch: 39 [781560/25046 (92%)]\tLoss: 0.237200\n",
            "Make prediction for 5010 samples...\n",
            "0.29099876 No improvement since epoch  36 ; best_mse,best_ci: 0.2906666 0.8640662213702169 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 40 [0/25046 (0%)]\tLoss: 0.102922\n",
            "Train epoch: 40 [83080/25046 (10%)]\tLoss: 0.166874\n",
            "Train epoch: 40 [171480/25046 (20%)]\tLoss: 0.181328\n",
            "Train epoch: 40 [238440/25046 (31%)]\tLoss: 0.143821\n",
            "Train epoch: 40 [320640/25046 (41%)]\tLoss: 0.110395\n",
            "Train epoch: 40 [422300/25046 (51%)]\tLoss: 0.118430\n",
            "Train epoch: 40 [501000/25046 (61%)]\tLoss: 0.240360\n",
            "Train epoch: 40 [588140/25046 (71%)]\tLoss: 0.139793\n",
            "Train epoch: 40 [647840/25046 (82%)]\tLoss: 0.137419\n",
            "Train epoch: 40 [724140/25046 (92%)]\tLoss: 0.192948\n",
            "Make prediction for 5010 samples...\n",
            "0.29950055 No improvement since epoch  36 ; best_mse,best_ci: 0.2906666 0.8640662213702169 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 41 [0/25046 (0%)]\tLoss: 0.134083\n",
            "Train epoch: 41 [82360/25046 (10%)]\tLoss: 0.143610\n",
            "Train epoch: 41 [163920/25046 (20%)]\tLoss: 0.214933\n",
            "Train epoch: 41 [250380/25046 (31%)]\tLoss: 0.136393\n",
            "Train epoch: 41 [325600/25046 (41%)]\tLoss: 0.120146\n",
            "Train epoch: 41 [410700/25046 (51%)]\tLoss: 0.180667\n",
            "Train epoch: 41 [493320/25046 (61%)]\tLoss: 0.131742\n",
            "Train epoch: 41 [583660/25046 (71%)]\tLoss: 0.162089\n",
            "Train epoch: 41 [647360/25046 (82%)]\tLoss: 0.240288\n",
            "Train epoch: 41 [727740/25046 (92%)]\tLoss: 0.202884\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  41 ; best_mse,best_ci: 0.28627437 0.859537191054721 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 42 [0/25046 (0%)]\tLoss: 0.115992\n",
            "Train epoch: 42 [80960/25046 (10%)]\tLoss: 0.072439\n",
            "Train epoch: 42 [163040/25046 (20%)]\tLoss: 0.140057\n",
            "Train epoch: 42 [252000/25046 (31%)]\tLoss: 0.286406\n",
            "Train epoch: 42 [337760/25046 (41%)]\tLoss: 0.114063\n",
            "Train epoch: 42 [414600/25046 (51%)]\tLoss: 0.124688\n",
            "Train epoch: 42 [505800/25046 (61%)]\tLoss: 0.203034\n",
            "Train epoch: 42 [559580/25046 (71%)]\tLoss: 0.129965\n",
            "Train epoch: 42 [630880/25046 (82%)]\tLoss: 0.140254\n",
            "Train epoch: 42 [722700/25046 (92%)]\tLoss: 0.181672\n",
            "Make prediction for 5010 samples...\n",
            "0.29958063 No improvement since epoch  41 ; best_mse,best_ci: 0.28627437 0.859537191054721 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 43 [0/25046 (0%)]\tLoss: 0.120376\n",
            "Train epoch: 43 [86440/25046 (10%)]\tLoss: 0.141366\n",
            "Train epoch: 43 [163000/25046 (20%)]\tLoss: 0.158419\n",
            "Train epoch: 43 [244980/25046 (31%)]\tLoss: 0.152055\n",
            "Train epoch: 43 [325840/25046 (41%)]\tLoss: 0.217862\n",
            "Train epoch: 43 [419600/25046 (51%)]\tLoss: 0.143999\n",
            "Train epoch: 43 [504120/25046 (61%)]\tLoss: 0.133068\n",
            "Train epoch: 43 [580720/25046 (71%)]\tLoss: 0.189204\n",
            "Train epoch: 43 [667680/25046 (82%)]\tLoss: 0.085286\n",
            "Train epoch: 43 [756540/25046 (92%)]\tLoss: 0.171717\n",
            "Make prediction for 5010 samples...\n",
            "0.29959953 No improvement since epoch  41 ; best_mse,best_ci: 0.28627437 0.859537191054721 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 44 [0/25046 (0%)]\tLoss: 0.114561\n",
            "Train epoch: 44 [82580/25046 (10%)]\tLoss: 0.196848\n",
            "Train epoch: 44 [168240/25046 (20%)]\tLoss: 0.145412\n",
            "Train epoch: 44 [235380/25046 (31%)]\tLoss: 0.127634\n",
            "Train epoch: 44 [324160/25046 (41%)]\tLoss: 0.089080\n",
            "Train epoch: 44 [404500/25046 (51%)]\tLoss: 0.197911\n",
            "Train epoch: 44 [490920/25046 (61%)]\tLoss: 0.174277\n",
            "Train epoch: 44 [588700/25046 (71%)]\tLoss: 0.170675\n",
            "Train epoch: 44 [651520/25046 (82%)]\tLoss: 0.198001\n",
            "Train epoch: 44 [746460/25046 (92%)]\tLoss: 0.119734\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  44 ; best_mse,best_ci: 0.28364155 0.8663344121916865 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 45 [0/25046 (0%)]\tLoss: 0.068632\n",
            "Train epoch: 45 [82160/25046 (10%)]\tLoss: 0.142511\n",
            "Train epoch: 45 [161400/25046 (20%)]\tLoss: 0.092534\n",
            "Train epoch: 45 [243540/25046 (31%)]\tLoss: 0.129202\n",
            "Train epoch: 45 [328960/25046 (41%)]\tLoss: 0.151491\n",
            "Train epoch: 45 [414600/25046 (51%)]\tLoss: 0.130518\n",
            "Train epoch: 45 [485760/25046 (61%)]\tLoss: 0.112135\n",
            "Train epoch: 45 [567700/25046 (71%)]\tLoss: 0.138517\n",
            "Train epoch: 45 [660000/25046 (82%)]\tLoss: 0.127401\n",
            "Train epoch: 45 [756540/25046 (92%)]\tLoss: 0.101106\n",
            "Make prediction for 5010 samples...\n",
            "0.2952837 No improvement since epoch  44 ; best_mse,best_ci: 0.28364155 0.8663344121916865 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 46 [0/25046 (0%)]\tLoss: 0.163135\n",
            "Train epoch: 46 [80900/25046 (10%)]\tLoss: 0.098138\n",
            "Train epoch: 46 [162600/25046 (20%)]\tLoss: 0.097922\n",
            "Train epoch: 46 [252960/25046 (31%)]\tLoss: 0.284679\n",
            "Train epoch: 46 [335280/25046 (41%)]\tLoss: 0.122668\n",
            "Train epoch: 46 [396400/25046 (51%)]\tLoss: 0.084387\n",
            "Train epoch: 46 [484080/25046 (61%)]\tLoss: 0.143158\n",
            "Train epoch: 46 [570640/25046 (71%)]\tLoss: 0.103903\n",
            "Train epoch: 46 [668160/25046 (82%)]\tLoss: 0.151492\n",
            "Train epoch: 46 [746640/25046 (92%)]\tLoss: 0.099507\n",
            "Make prediction for 5010 samples...\n",
            "0.30125505 No improvement since epoch  44 ; best_mse,best_ci: 0.28364155 0.8663344121916865 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 47 [0/25046 (0%)]\tLoss: 0.092074\n",
            "Train epoch: 47 [80400/25046 (10%)]\tLoss: 0.138363\n",
            "Train epoch: 47 [162320/25046 (20%)]\tLoss: 0.125419\n",
            "Train epoch: 47 [244080/25046 (31%)]\tLoss: 0.155882\n",
            "Train epoch: 47 [325440/25046 (41%)]\tLoss: 0.088624\n",
            "Train epoch: 47 [421000/25046 (51%)]\tLoss: 0.124840\n",
            "Train epoch: 47 [499680/25046 (61%)]\tLoss: 0.157928\n",
            "Train epoch: 47 [575680/25046 (71%)]\tLoss: 0.117910\n",
            "Train epoch: 47 [658880/25046 (82%)]\tLoss: 0.129530\n",
            "Train epoch: 47 [746100/25046 (92%)]\tLoss: 0.119906\n",
            "Make prediction for 5010 samples...\n",
            "0.2937109 No improvement since epoch  44 ; best_mse,best_ci: 0.28364155 0.8663344121916865 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 48 [0/25046 (0%)]\tLoss: 0.191229\n",
            "Train epoch: 48 [83860/25046 (10%)]\tLoss: 0.097960\n",
            "Train epoch: 48 [164360/25046 (20%)]\tLoss: 0.165112\n",
            "Train epoch: 48 [239880/25046 (31%)]\tLoss: 0.181049\n",
            "Train epoch: 48 [334320/25046 (41%)]\tLoss: 0.202944\n",
            "Train epoch: 48 [415600/25046 (51%)]\tLoss: 0.124317\n",
            "Train epoch: 48 [501480/25046 (61%)]\tLoss: 0.135856\n",
            "Train epoch: 48 [558320/25046 (71%)]\tLoss: 0.100697\n",
            "Train epoch: 48 [665920/25046 (82%)]\tLoss: 0.208551\n",
            "Train epoch: 48 [742680/25046 (92%)]\tLoss: 0.122683\n",
            "Make prediction for 5010 samples...\n",
            "0.29630336 No improvement since epoch  44 ; best_mse,best_ci: 0.28364155 0.8663344121916865 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 49 [0/25046 (0%)]\tLoss: 0.108168\n",
            "Train epoch: 49 [84480/25046 (10%)]\tLoss: 0.166785\n",
            "Train epoch: 49 [166520/25046 (20%)]\tLoss: 0.141029\n",
            "Train epoch: 49 [243600/25046 (31%)]\tLoss: 0.106037\n",
            "Train epoch: 49 [324000/25046 (41%)]\tLoss: 0.167731\n",
            "Train epoch: 49 [407700/25046 (51%)]\tLoss: 0.100769\n",
            "Train epoch: 49 [486720/25046 (61%)]\tLoss: 0.146640\n",
            "Train epoch: 49 [566020/25046 (71%)]\tLoss: 0.121201\n",
            "Train epoch: 49 [669280/25046 (82%)]\tLoss: 0.130100\n",
            "Train epoch: 49 [715500/25046 (92%)]\tLoss: 0.121303\n",
            "Make prediction for 5010 samples...\n",
            "0.2853658 No improvement since epoch  44 ; best_mse,best_ci: 0.28364155 0.8663344121916865 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 50 [0/25046 (0%)]\tLoss: 0.109536\n",
            "Train epoch: 50 [81480/25046 (10%)]\tLoss: 0.217354\n",
            "Train epoch: 50 [161120/25046 (20%)]\tLoss: 0.134040\n",
            "Train epoch: 50 [244080/25046 (31%)]\tLoss: 0.214468\n",
            "Train epoch: 50 [335440/25046 (41%)]\tLoss: 0.127119\n",
            "Train epoch: 50 [409500/25046 (51%)]\tLoss: 0.084373\n",
            "Train epoch: 50 [499560/25046 (61%)]\tLoss: 0.128957\n",
            "Train epoch: 50 [584500/25046 (71%)]\tLoss: 0.138976\n",
            "Train epoch: 50 [663200/25046 (82%)]\tLoss: 0.147223\n",
            "Train epoch: 50 [741780/25046 (92%)]\tLoss: 0.180160\n",
            "Make prediction for 5010 samples...\n",
            "0.29337254 No improvement since epoch  44 ; best_mse,best_ci: 0.28364155 0.8663344121916865 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 51 [0/25046 (0%)]\tLoss: 0.134152\n",
            "Train epoch: 51 [83080/25046 (10%)]\tLoss: 0.151239\n",
            "Train epoch: 51 [161040/25046 (20%)]\tLoss: 0.160554\n",
            "Train epoch: 51 [247020/25046 (31%)]\tLoss: 0.125159\n",
            "Train epoch: 51 [335840/25046 (41%)]\tLoss: 0.129311\n",
            "Train epoch: 51 [409900/25046 (51%)]\tLoss: 0.293862\n",
            "Train epoch: 51 [499680/25046 (61%)]\tLoss: 0.071184\n",
            "Train epoch: 51 [587860/25046 (71%)]\tLoss: 0.103169\n",
            "Train epoch: 51 [634560/25046 (82%)]\tLoss: 0.143957\n",
            "Train epoch: 51 [721800/25046 (92%)]\tLoss: 0.267271\n",
            "Make prediction for 5010 samples...\n",
            "0.2965319 No improvement since epoch  44 ; best_mse,best_ci: 0.28364155 0.8663344121916865 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 52 [0/25046 (0%)]\tLoss: 0.135029\n",
            "Train epoch: 52 [80600/25046 (10%)]\tLoss: 0.152319\n",
            "Train epoch: 52 [165840/25046 (20%)]\tLoss: 0.069781\n",
            "Train epoch: 52 [246720/25046 (31%)]\tLoss: 0.097670\n",
            "Train epoch: 52 [336240/25046 (41%)]\tLoss: 0.130553\n",
            "Train epoch: 52 [409800/25046 (51%)]\tLoss: 0.126091\n",
            "Train epoch: 52 [492960/25046 (61%)]\tLoss: 0.127529\n",
            "Train epoch: 52 [580720/25046 (71%)]\tLoss: 0.140249\n",
            "Train epoch: 52 [676960/25046 (82%)]\tLoss: 0.116520\n",
            "Train epoch: 52 [763200/25046 (92%)]\tLoss: 0.121184\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  52 ; best_mse,best_ci: 0.27441067 0.8698120495301812 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 53 [0/25046 (0%)]\tLoss: 0.118725\n",
            "Train epoch: 53 [82460/25046 (10%)]\tLoss: 0.141776\n",
            "Train epoch: 53 [160320/25046 (20%)]\tLoss: 0.209744\n",
            "Train epoch: 53 [252300/25046 (31%)]\tLoss: 0.083640\n",
            "Train epoch: 53 [328000/25046 (41%)]\tLoss: 0.175971\n",
            "Train epoch: 53 [413000/25046 (51%)]\tLoss: 0.138501\n",
            "Train epoch: 53 [503760/25046 (61%)]\tLoss: 0.170431\n",
            "Train epoch: 53 [573860/25046 (71%)]\tLoss: 0.106266\n",
            "Train epoch: 53 [638880/25046 (82%)]\tLoss: 0.140268\n",
            "Train epoch: 53 [743220/25046 (92%)]\tLoss: 0.060047\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  53 ; best_mse,best_ci: 0.26888612 0.8768687878411494 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 54 [0/25046 (0%)]\tLoss: 0.133160\n",
            "Train epoch: 54 [84680/25046 (10%)]\tLoss: 0.089295\n",
            "Train epoch: 54 [161120/25046 (20%)]\tLoss: 0.132346\n",
            "Train epoch: 54 [240780/25046 (31%)]\tLoss: 0.133851\n",
            "Train epoch: 54 [332640/25046 (41%)]\tLoss: 0.237380\n",
            "Train epoch: 54 [407800/25046 (51%)]\tLoss: 0.139591\n",
            "Train epoch: 54 [498960/25046 (61%)]\tLoss: 0.089402\n",
            "Train epoch: 54 [579320/25046 (71%)]\tLoss: 0.145578\n",
            "Train epoch: 54 [663680/25046 (82%)]\tLoss: 0.175809\n",
            "Train epoch: 54 [718560/25046 (92%)]\tLoss: 0.153573\n",
            "Make prediction for 5010 samples...\n",
            "0.27159557 No improvement since epoch  53 ; best_mse,best_ci: 0.26888612 0.8768687878411494 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 55 [0/25046 (0%)]\tLoss: 0.090390\n",
            "Train epoch: 55 [81540/25046 (10%)]\tLoss: 0.175412\n",
            "Train epoch: 55 [164840/25046 (20%)]\tLoss: 0.109116\n",
            "Train epoch: 55 [248280/25046 (31%)]\tLoss: 0.134987\n",
            "Train epoch: 55 [324480/25046 (41%)]\tLoss: 0.143333\n",
            "Train epoch: 55 [405400/25046 (51%)]\tLoss: 0.120941\n",
            "Train epoch: 55 [494040/25046 (61%)]\tLoss: 0.158430\n",
            "Train epoch: 55 [580860/25046 (71%)]\tLoss: 0.085522\n",
            "Train epoch: 55 [662880/25046 (82%)]\tLoss: 0.107223\n",
            "Train epoch: 55 [727740/25046 (92%)]\tLoss: 0.100435\n",
            "Make prediction for 5010 samples...\n",
            "0.273923 No improvement since epoch  53 ; best_mse,best_ci: 0.26888612 0.8768687878411494 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 56 [0/25046 (0%)]\tLoss: 0.097167\n",
            "Train epoch: 56 [80600/25046 (10%)]\tLoss: 0.086794\n",
            "Train epoch: 56 [163520/25046 (20%)]\tLoss: 0.096427\n",
            "Train epoch: 56 [244500/25046 (31%)]\tLoss: 0.114998\n",
            "Train epoch: 56 [329120/25046 (41%)]\tLoss: 0.109768\n",
            "Train epoch: 56 [404900/25046 (51%)]\tLoss: 0.099808\n",
            "Train epoch: 56 [480000/25046 (61%)]\tLoss: 0.149014\n",
            "Train epoch: 56 [578340/25046 (71%)]\tLoss: 0.134639\n",
            "Train epoch: 56 [658080/25046 (82%)]\tLoss: 0.103112\n",
            "Train epoch: 56 [716940/25046 (92%)]\tLoss: 0.132806\n",
            "Make prediction for 5010 samples...\n",
            "0.2731154 No improvement since epoch  53 ; best_mse,best_ci: 0.26888612 0.8768687878411494 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 57 [0/25046 (0%)]\tLoss: 0.099668\n",
            "Train epoch: 57 [81080/25046 (10%)]\tLoss: 0.158084\n",
            "Train epoch: 57 [160400/25046 (20%)]\tLoss: 0.178983\n",
            "Train epoch: 57 [249060/25046 (31%)]\tLoss: 0.118354\n",
            "Train epoch: 57 [333520/25046 (41%)]\tLoss: 0.114171\n",
            "Train epoch: 57 [397500/25046 (51%)]\tLoss: 0.150906\n",
            "Train epoch: 57 [490080/25046 (61%)]\tLoss: 0.170935\n",
            "Train epoch: 57 [566580/25046 (71%)]\tLoss: 0.154630\n",
            "Train epoch: 57 [653920/25046 (82%)]\tLoss: 0.140757\n",
            "Train epoch: 57 [743760/25046 (92%)]\tLoss: 0.117748\n",
            "Make prediction for 5010 samples...\n",
            "0.27675778 No improvement since epoch  53 ; best_mse,best_ci: 0.26888612 0.8768687878411494 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 58 [0/25046 (0%)]\tLoss: 0.096700\n",
            "Train epoch: 58 [80960/25046 (10%)]\tLoss: 0.075901\n",
            "Train epoch: 58 [163160/25046 (20%)]\tLoss: 0.200587\n",
            "Train epoch: 58 [250320/25046 (31%)]\tLoss: 0.097885\n",
            "Train epoch: 58 [320480/25046 (41%)]\tLoss: 0.112745\n",
            "Train epoch: 58 [415600/25046 (51%)]\tLoss: 0.085963\n",
            "Train epoch: 58 [487560/25046 (61%)]\tLoss: 0.168356\n",
            "Train epoch: 58 [572880/25046 (71%)]\tLoss: 0.120534\n",
            "Train epoch: 58 [645120/25046 (82%)]\tLoss: 0.124192\n",
            "Train epoch: 58 [737100/25046 (92%)]\tLoss: 0.168523\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 59 [0/25046 (0%)]\tLoss: 0.126038\n",
            "Train epoch: 59 [82740/25046 (10%)]\tLoss: 0.099855\n",
            "Train epoch: 59 [166800/25046 (20%)]\tLoss: 0.121451\n",
            "Train epoch: 59 [250680/25046 (31%)]\tLoss: 0.146998\n",
            "Train epoch: 59 [334000/25046 (41%)]\tLoss: 0.093194\n",
            "Train epoch: 59 [402400/25046 (51%)]\tLoss: 0.102895\n",
            "Train epoch: 59 [491880/25046 (61%)]\tLoss: 0.128694\n",
            "Train epoch: 59 [567980/25046 (71%)]\tLoss: 0.120804\n",
            "Train epoch: 59 [627840/25046 (82%)]\tLoss: 0.207949\n",
            "Train epoch: 59 [735120/25046 (92%)]\tLoss: 0.145732\n",
            "Make prediction for 5010 samples...\n",
            "0.29294583 No improvement since epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 60 [0/25046 (0%)]\tLoss: 0.112320\n",
            "Train epoch: 60 [82060/25046 (10%)]\tLoss: 0.136850\n",
            "Train epoch: 60 [164760/25046 (20%)]\tLoss: 0.132322\n",
            "Train epoch: 60 [254280/25046 (31%)]\tLoss: 0.214902\n",
            "Train epoch: 60 [323760/25046 (41%)]\tLoss: 0.143666\n",
            "Train epoch: 60 [405600/25046 (51%)]\tLoss: 0.176786\n",
            "Train epoch: 60 [492240/25046 (61%)]\tLoss: 0.191948\n",
            "Train epoch: 60 [579040/25046 (71%)]\tLoss: 0.224324\n",
            "Train epoch: 60 [648800/25046 (82%)]\tLoss: 0.131632\n",
            "Train epoch: 60 [736560/25046 (92%)]\tLoss: 0.125351\n",
            "Make prediction for 5010 samples...\n",
            "0.28932095 No improvement since epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 61 [0/25046 (0%)]\tLoss: 0.116421\n",
            "Train epoch: 61 [81140/25046 (10%)]\tLoss: 0.085119\n",
            "Train epoch: 61 [163920/25046 (20%)]\tLoss: 0.135010\n",
            "Train epoch: 61 [241440/25046 (31%)]\tLoss: 0.123909\n",
            "Train epoch: 61 [321600/25046 (41%)]\tLoss: 0.119608\n",
            "Train epoch: 61 [409600/25046 (51%)]\tLoss: 0.078440\n",
            "Train epoch: 61 [489720/25046 (61%)]\tLoss: 0.120148\n",
            "Train epoch: 61 [558740/25046 (71%)]\tLoss: 0.172786\n",
            "Train epoch: 61 [642560/25046 (82%)]\tLoss: 0.086048\n",
            "Train epoch: 61 [727920/25046 (92%)]\tLoss: 0.135107\n",
            "Make prediction for 5010 samples...\n",
            "0.27292973 No improvement since epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 62 [0/25046 (0%)]\tLoss: 0.141195\n",
            "Train epoch: 62 [82720/25046 (10%)]\tLoss: 0.119635\n",
            "Train epoch: 62 [165760/25046 (20%)]\tLoss: 0.087690\n",
            "Train epoch: 62 [240420/25046 (31%)]\tLoss: 0.081800\n",
            "Train epoch: 62 [328320/25046 (41%)]\tLoss: 0.102397\n",
            "Train epoch: 62 [401600/25046 (51%)]\tLoss: 0.092511\n",
            "Train epoch: 62 [493680/25046 (61%)]\tLoss: 0.135372\n",
            "Train epoch: 62 [588560/25046 (71%)]\tLoss: 0.085066\n",
            "Train epoch: 62 [651680/25046 (82%)]\tLoss: 0.121468\n",
            "Train epoch: 62 [741420/25046 (92%)]\tLoss: 0.163115\n",
            "Make prediction for 5010 samples...\n",
            "0.28948125 No improvement since epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 63 [0/25046 (0%)]\tLoss: 0.171070\n",
            "Train epoch: 63 [82460/25046 (10%)]\tLoss: 0.260324\n",
            "Train epoch: 63 [159760/25046 (20%)]\tLoss: 0.094328\n",
            "Train epoch: 63 [246600/25046 (31%)]\tLoss: 0.088392\n",
            "Train epoch: 63 [328560/25046 (41%)]\tLoss: 0.153228\n",
            "Train epoch: 63 [398400/25046 (51%)]\tLoss: 0.097757\n",
            "Train epoch: 63 [479760/25046 (61%)]\tLoss: 0.093800\n",
            "Train epoch: 63 [577780/25046 (71%)]\tLoss: 0.071332\n",
            "Train epoch: 63 [654560/25046 (82%)]\tLoss: 0.128698\n",
            "Train epoch: 63 [748440/25046 (92%)]\tLoss: 0.120914\n",
            "Make prediction for 5010 samples...\n",
            "0.28410226 No improvement since epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 64 [0/25046 (0%)]\tLoss: 0.226471\n",
            "Train epoch: 64 [80560/25046 (10%)]\tLoss: 0.090132\n",
            "Train epoch: 64 [164600/25046 (20%)]\tLoss: 0.114649\n",
            "Train epoch: 64 [243600/25046 (31%)]\tLoss: 0.083879\n",
            "Train epoch: 64 [328880/25046 (41%)]\tLoss: 0.212477\n",
            "Train epoch: 64 [411400/25046 (51%)]\tLoss: 0.079816\n",
            "Train epoch: 64 [489840/25046 (61%)]\tLoss: 0.097350\n",
            "Train epoch: 64 [566440/25046 (71%)]\tLoss: 0.217398\n",
            "Train epoch: 64 [647840/25046 (82%)]\tLoss: 0.066651\n",
            "Train epoch: 64 [745380/25046 (92%)]\tLoss: 0.124283\n",
            "Make prediction for 5010 samples...\n",
            "0.27821505 No improvement since epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 65 [0/25046 (0%)]\tLoss: 0.215343\n",
            "Train epoch: 65 [83320/25046 (10%)]\tLoss: 0.170739\n",
            "Train epoch: 65 [164280/25046 (20%)]\tLoss: 0.127706\n",
            "Train epoch: 65 [238920/25046 (31%)]\tLoss: 0.093861\n",
            "Train epoch: 65 [328480/25046 (41%)]\tLoss: 0.134947\n",
            "Train epoch: 65 [405200/25046 (51%)]\tLoss: 0.154049\n",
            "Train epoch: 65 [495360/25046 (61%)]\tLoss: 0.079361\n",
            "Train epoch: 65 [580300/25046 (71%)]\tLoss: 0.100726\n",
            "Train epoch: 65 [666080/25046 (82%)]\tLoss: 0.091058\n",
            "Train epoch: 65 [721800/25046 (92%)]\tLoss: 0.125277\n",
            "Make prediction for 5010 samples...\n",
            "0.29267326 No improvement since epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 66 [0/25046 (0%)]\tLoss: 0.109850\n",
            "Train epoch: 66 [80280/25046 (10%)]\tLoss: 0.142504\n",
            "Train epoch: 66 [162160/25046 (20%)]\tLoss: 0.099338\n",
            "Train epoch: 66 [256140/25046 (31%)]\tLoss: 0.107115\n",
            "Train epoch: 66 [330400/25046 (41%)]\tLoss: 0.089479\n",
            "Train epoch: 66 [407200/25046 (51%)]\tLoss: 0.088141\n",
            "Train epoch: 66 [496800/25046 (61%)]\tLoss: 0.104536\n",
            "Train epoch: 66 [580580/25046 (71%)]\tLoss: 0.092204\n",
            "Train epoch: 66 [662560/25046 (82%)]\tLoss: 0.106735\n",
            "Train epoch: 66 [746460/25046 (92%)]\tLoss: 0.084670\n",
            "Make prediction for 5010 samples...\n",
            "0.26813298 No improvement since epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 67 [0/25046 (0%)]\tLoss: 0.097644\n",
            "Train epoch: 67 [79260/25046 (10%)]\tLoss: 0.062536\n",
            "Train epoch: 67 [162280/25046 (20%)]\tLoss: 0.093442\n",
            "Train epoch: 67 [247080/25046 (31%)]\tLoss: 0.087313\n",
            "Train epoch: 67 [332160/25046 (41%)]\tLoss: 0.108852\n",
            "Train epoch: 67 [411300/25046 (51%)]\tLoss: 0.108921\n",
            "Train epoch: 67 [481320/25046 (61%)]\tLoss: 0.229955\n",
            "Train epoch: 67 [574140/25046 (71%)]\tLoss: 0.130169\n",
            "Train epoch: 67 [674880/25046 (82%)]\tLoss: 0.115884\n",
            "Train epoch: 67 [758520/25046 (92%)]\tLoss: 0.100698\n",
            "Make prediction for 5010 samples...\n",
            "0.27095538 No improvement since epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 68 [0/25046 (0%)]\tLoss: 0.094498\n",
            "Train epoch: 68 [82660/25046 (10%)]\tLoss: 0.104351\n",
            "Train epoch: 68 [163800/25046 (20%)]\tLoss: 0.063328\n",
            "Train epoch: 68 [241560/25046 (31%)]\tLoss: 0.077094\n",
            "Train epoch: 68 [326800/25046 (41%)]\tLoss: 0.098668\n",
            "Train epoch: 68 [403500/25046 (51%)]\tLoss: 0.156515\n",
            "Train epoch: 68 [492960/25046 (61%)]\tLoss: 0.115183\n",
            "Train epoch: 68 [567840/25046 (71%)]\tLoss: 0.168246\n",
            "Train epoch: 68 [656480/25046 (82%)]\tLoss: 0.190197\n",
            "Train epoch: 68 [734940/25046 (92%)]\tLoss: 0.129519\n",
            "Make prediction for 5010 samples...\n",
            "0.2824841 No improvement since epoch  58 ; best_mse,best_ci: 0.2662721 0.8778152712494331 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 69 [0/25046 (0%)]\tLoss: 0.106525\n",
            "Train epoch: 69 [83720/25046 (10%)]\tLoss: 0.153416\n",
            "Train epoch: 69 [158800/25046 (20%)]\tLoss: 0.079751\n",
            "Train epoch: 69 [242700/25046 (31%)]\tLoss: 0.139293\n",
            "Train epoch: 69 [328880/25046 (41%)]\tLoss: 0.112134\n",
            "Train epoch: 69 [411200/25046 (51%)]\tLoss: 0.071965\n",
            "Train epoch: 69 [491880/25046 (61%)]\tLoss: 0.178839\n",
            "Train epoch: 69 [580720/25046 (71%)]\tLoss: 0.114774\n",
            "Train epoch: 69 [644640/25046 (82%)]\tLoss: 0.218505\n",
            "Train epoch: 69 [752040/25046 (92%)]\tLoss: 0.083871\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 70 [0/25046 (0%)]\tLoss: 0.067668\n",
            "Train epoch: 70 [84500/25046 (10%)]\tLoss: 0.114745\n",
            "Train epoch: 70 [163480/25046 (20%)]\tLoss: 0.085165\n",
            "Train epoch: 70 [239160/25046 (31%)]\tLoss: 0.175817\n",
            "Train epoch: 70 [326000/25046 (41%)]\tLoss: 0.097527\n",
            "Train epoch: 70 [411100/25046 (51%)]\tLoss: 0.130788\n",
            "Train epoch: 70 [497520/25046 (61%)]\tLoss: 0.090470\n",
            "Train epoch: 70 [563780/25046 (71%)]\tLoss: 0.133473\n",
            "Train epoch: 70 [672640/25046 (82%)]\tLoss: 0.134256\n",
            "Train epoch: 70 [731340/25046 (92%)]\tLoss: 0.108218\n",
            "Make prediction for 5010 samples...\n",
            "0.27597564 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 71 [0/25046 (0%)]\tLoss: 0.193324\n",
            "Train epoch: 71 [83340/25046 (10%)]\tLoss: 0.389558\n",
            "Train epoch: 71 [166040/25046 (20%)]\tLoss: 0.186231\n",
            "Train epoch: 71 [249900/25046 (31%)]\tLoss: 0.057211\n",
            "Train epoch: 71 [326640/25046 (41%)]\tLoss: 0.130525\n",
            "Train epoch: 71 [414900/25046 (51%)]\tLoss: 0.197859\n",
            "Train epoch: 71 [484560/25046 (61%)]\tLoss: 0.061422\n",
            "Train epoch: 71 [575820/25046 (71%)]\tLoss: 0.154974\n",
            "Train epoch: 71 [671840/25046 (82%)]\tLoss: 0.154553\n",
            "Train epoch: 71 [730080/25046 (92%)]\tLoss: 0.189286\n",
            "Make prediction for 5010 samples...\n",
            "0.27192914 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 72 [0/25046 (0%)]\tLoss: 0.095223\n",
            "Train epoch: 72 [82900/25046 (10%)]\tLoss: 0.082557\n",
            "Train epoch: 72 [161680/25046 (20%)]\tLoss: 0.144975\n",
            "Train epoch: 72 [246840/25046 (31%)]\tLoss: 0.091989\n",
            "Train epoch: 72 [326320/25046 (41%)]\tLoss: 0.112483\n",
            "Train epoch: 72 [404200/25046 (51%)]\tLoss: 0.063353\n",
            "Train epoch: 72 [494760/25046 (61%)]\tLoss: 0.121614\n",
            "Train epoch: 72 [573020/25046 (71%)]\tLoss: 0.131460\n",
            "Train epoch: 72 [654560/25046 (82%)]\tLoss: 0.068289\n",
            "Train epoch: 72 [754920/25046 (92%)]\tLoss: 0.158739\n",
            "Make prediction for 5010 samples...\n",
            "0.26764458 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 73 [0/25046 (0%)]\tLoss: 0.083264\n",
            "Train epoch: 73 [82100/25046 (10%)]\tLoss: 0.070615\n",
            "Train epoch: 73 [165240/25046 (20%)]\tLoss: 0.076789\n",
            "Train epoch: 73 [240840/25046 (31%)]\tLoss: 0.112409\n",
            "Train epoch: 73 [318320/25046 (41%)]\tLoss: 0.068084\n",
            "Train epoch: 73 [409500/25046 (51%)]\tLoss: 0.131410\n",
            "Train epoch: 73 [495720/25046 (61%)]\tLoss: 0.118632\n",
            "Train epoch: 73 [543900/25046 (71%)]\tLoss: 0.073700\n",
            "Train epoch: 73 [660000/25046 (82%)]\tLoss: 0.079530\n",
            "Train epoch: 73 [737280/25046 (92%)]\tLoss: 0.136512\n",
            "Make prediction for 5010 samples...\n",
            "0.26311126 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 74 [0/25046 (0%)]\tLoss: 0.073423\n",
            "Train epoch: 74 [79700/25046 (10%)]\tLoss: 0.082626\n",
            "Train epoch: 74 [162640/25046 (20%)]\tLoss: 0.106435\n",
            "Train epoch: 74 [246960/25046 (31%)]\tLoss: 0.067784\n",
            "Train epoch: 74 [321520/25046 (41%)]\tLoss: 0.097568\n",
            "Train epoch: 74 [414600/25046 (51%)]\tLoss: 0.076387\n",
            "Train epoch: 74 [505920/25046 (61%)]\tLoss: 0.143511\n",
            "Train epoch: 74 [571060/25046 (71%)]\tLoss: 0.090380\n",
            "Train epoch: 74 [649600/25046 (82%)]\tLoss: 0.139050\n",
            "Train epoch: 74 [728820/25046 (92%)]\tLoss: 0.083269\n",
            "Make prediction for 5010 samples...\n",
            "0.27235028 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 75 [0/25046 (0%)]\tLoss: 0.105037\n",
            "Train epoch: 75 [82620/25046 (10%)]\tLoss: 0.109906\n",
            "Train epoch: 75 [163960/25046 (20%)]\tLoss: 0.177636\n",
            "Train epoch: 75 [244260/25046 (31%)]\tLoss: 0.131011\n",
            "Train epoch: 75 [323440/25046 (41%)]\tLoss: 0.204615\n",
            "Train epoch: 75 [405100/25046 (51%)]\tLoss: 0.136697\n",
            "Train epoch: 75 [505680/25046 (61%)]\tLoss: 0.136370\n",
            "Train epoch: 75 [567280/25046 (71%)]\tLoss: 0.132379\n",
            "Train epoch: 75 [646880/25046 (82%)]\tLoss: 0.160519\n",
            "Train epoch: 75 [735480/25046 (92%)]\tLoss: 0.111059\n",
            "Make prediction for 5010 samples...\n",
            "0.28161842 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 76 [0/25046 (0%)]\tLoss: 0.076603\n",
            "Train epoch: 76 [82880/25046 (10%)]\tLoss: 0.126046\n",
            "Train epoch: 76 [166560/25046 (20%)]\tLoss: 0.132652\n",
            "Train epoch: 76 [243060/25046 (31%)]\tLoss: 0.093194\n",
            "Train epoch: 76 [328800/25046 (41%)]\tLoss: 0.141290\n",
            "Train epoch: 76 [412100/25046 (51%)]\tLoss: 0.126129\n",
            "Train epoch: 76 [488880/25046 (61%)]\tLoss: 0.184845\n",
            "Train epoch: 76 [540540/25046 (71%)]\tLoss: 0.155987\n",
            "Train epoch: 76 [655520/25046 (82%)]\tLoss: 0.122489\n",
            "Train epoch: 76 [747360/25046 (92%)]\tLoss: 0.120869\n",
            "Make prediction for 5010 samples...\n",
            "0.27334726 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 77 [0/25046 (0%)]\tLoss: 0.172320\n",
            "Train epoch: 77 [81020/25046 (10%)]\tLoss: 0.091885\n",
            "Train epoch: 77 [162360/25046 (20%)]\tLoss: 0.085505\n",
            "Train epoch: 77 [239700/25046 (31%)]\tLoss: 0.095338\n",
            "Train epoch: 77 [333920/25046 (41%)]\tLoss: 0.109529\n",
            "Train epoch: 77 [427300/25046 (51%)]\tLoss: 0.163116\n",
            "Train epoch: 77 [480840/25046 (61%)]\tLoss: 0.073084\n",
            "Train epoch: 77 [569100/25046 (71%)]\tLoss: 0.113578\n",
            "Train epoch: 77 [634400/25046 (82%)]\tLoss: 0.146461\n",
            "Train epoch: 77 [715320/25046 (92%)]\tLoss: 0.078578\n",
            "Make prediction for 5010 samples...\n",
            "0.27320227 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 78 [0/25046 (0%)]\tLoss: 0.191343\n",
            "Train epoch: 78 [81580/25046 (10%)]\tLoss: 0.076133\n",
            "Train epoch: 78 [162920/25046 (20%)]\tLoss: 0.150231\n",
            "Train epoch: 78 [247800/25046 (31%)]\tLoss: 0.119830\n",
            "Train epoch: 78 [327600/25046 (41%)]\tLoss: 0.179537\n",
            "Train epoch: 78 [410600/25046 (51%)]\tLoss: 0.073975\n",
            "Train epoch: 78 [491160/25046 (61%)]\tLoss: 0.121806\n",
            "Train epoch: 78 [562380/25046 (71%)]\tLoss: 0.089644\n",
            "Train epoch: 78 [663040/25046 (82%)]\tLoss: 0.167379\n",
            "Train epoch: 78 [737820/25046 (92%)]\tLoss: 0.103336\n",
            "Make prediction for 5010 samples...\n",
            "0.28295344 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 79 [0/25046 (0%)]\tLoss: 0.077326\n",
            "Train epoch: 79 [83700/25046 (10%)]\tLoss: 0.187063\n",
            "Train epoch: 79 [167960/25046 (20%)]\tLoss: 0.124519\n",
            "Train epoch: 79 [246420/25046 (31%)]\tLoss: 0.182777\n",
            "Train epoch: 79 [325920/25046 (41%)]\tLoss: 0.092986\n",
            "Train epoch: 79 [405000/25046 (51%)]\tLoss: 0.104882\n",
            "Train epoch: 79 [487080/25046 (61%)]\tLoss: 0.237594\n",
            "Train epoch: 79 [569940/25046 (71%)]\tLoss: 0.087716\n",
            "Train epoch: 79 [667840/25046 (82%)]\tLoss: 0.127800\n",
            "Train epoch: 79 [730440/25046 (92%)]\tLoss: 0.176317\n",
            "Make prediction for 5010 samples...\n",
            "0.2743197 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 80 [0/25046 (0%)]\tLoss: 0.074513\n",
            "Train epoch: 80 [82880/25046 (10%)]\tLoss: 0.159529\n",
            "Train epoch: 80 [169720/25046 (20%)]\tLoss: 0.084503\n",
            "Train epoch: 80 [241800/25046 (31%)]\tLoss: 0.080692\n",
            "Train epoch: 80 [326880/25046 (41%)]\tLoss: 0.100434\n",
            "Train epoch: 80 [408700/25046 (51%)]\tLoss: 0.105380\n",
            "Train epoch: 80 [510240/25046 (61%)]\tLoss: 0.087555\n",
            "Train epoch: 80 [572600/25046 (71%)]\tLoss: 0.147432\n",
            "Train epoch: 80 [652960/25046 (82%)]\tLoss: 0.144619\n",
            "Train epoch: 80 [747000/25046 (92%)]\tLoss: 0.193663\n",
            "Make prediction for 5010 samples...\n",
            "0.30090484 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 81 [0/25046 (0%)]\tLoss: 0.122822\n",
            "Train epoch: 81 [84060/25046 (10%)]\tLoss: 0.092564\n",
            "Train epoch: 81 [167240/25046 (20%)]\tLoss: 0.111283\n",
            "Train epoch: 81 [252060/25046 (31%)]\tLoss: 0.143320\n",
            "Train epoch: 81 [337680/25046 (41%)]\tLoss: 0.059959\n",
            "Train epoch: 81 [395500/25046 (51%)]\tLoss: 0.069586\n",
            "Train epoch: 81 [491040/25046 (61%)]\tLoss: 0.100807\n",
            "Train epoch: 81 [579460/25046 (71%)]\tLoss: 0.076447\n",
            "Train epoch: 81 [645120/25046 (82%)]\tLoss: 0.110048\n",
            "Train epoch: 81 [754020/25046 (92%)]\tLoss: 0.117775\n",
            "Make prediction for 5010 samples...\n",
            "0.26951078 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 82 [0/25046 (0%)]\tLoss: 0.086905\n",
            "Train epoch: 82 [80280/25046 (10%)]\tLoss: 0.144020\n",
            "Train epoch: 82 [162640/25046 (20%)]\tLoss: 0.105766\n",
            "Train epoch: 82 [239700/25046 (31%)]\tLoss: 0.179632\n",
            "Train epoch: 82 [327120/25046 (41%)]\tLoss: 0.101724\n",
            "Train epoch: 82 [406300/25046 (51%)]\tLoss: 0.108591\n",
            "Train epoch: 82 [504600/25046 (61%)]\tLoss: 0.113869\n",
            "Train epoch: 82 [564480/25046 (71%)]\tLoss: 0.153135\n",
            "Train epoch: 82 [653120/25046 (82%)]\tLoss: 0.086694\n",
            "Train epoch: 82 [733680/25046 (92%)]\tLoss: 0.124749\n",
            "Make prediction for 5010 samples...\n",
            "0.2616635 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 83 [0/25046 (0%)]\tLoss: 0.071842\n",
            "Train epoch: 83 [82240/25046 (10%)]\tLoss: 0.086486\n",
            "Train epoch: 83 [160200/25046 (20%)]\tLoss: 0.079642\n",
            "Train epoch: 83 [242280/25046 (31%)]\tLoss: 0.068684\n",
            "Train epoch: 83 [330080/25046 (41%)]\tLoss: 0.143915\n",
            "Train epoch: 83 [414900/25046 (51%)]\tLoss: 0.094890\n",
            "Train epoch: 83 [503880/25046 (61%)]\tLoss: 0.098204\n",
            "Train epoch: 83 [587720/25046 (71%)]\tLoss: 0.098880\n",
            "Train epoch: 83 [647040/25046 (82%)]\tLoss: 0.124143\n",
            "Train epoch: 83 [744480/25046 (92%)]\tLoss: 0.074634\n",
            "Make prediction for 5010 samples...\n",
            "0.26486754 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 84 [0/25046 (0%)]\tLoss: 0.103696\n",
            "Train epoch: 84 [79760/25046 (10%)]\tLoss: 0.055763\n",
            "Train epoch: 84 [171160/25046 (20%)]\tLoss: 0.076167\n",
            "Train epoch: 84 [250260/25046 (31%)]\tLoss: 0.098498\n",
            "Train epoch: 84 [327680/25046 (41%)]\tLoss: 0.115738\n",
            "Train epoch: 84 [412300/25046 (51%)]\tLoss: 0.105142\n",
            "Train epoch: 84 [498480/25046 (61%)]\tLoss: 0.112889\n",
            "Train epoch: 84 [568260/25046 (71%)]\tLoss: 0.150190\n",
            "Train epoch: 84 [655520/25046 (82%)]\tLoss: 0.083891\n",
            "Train epoch: 84 [739980/25046 (92%)]\tLoss: 0.125459\n",
            "Make prediction for 5010 samples...\n",
            "0.27996227 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 85 [0/25046 (0%)]\tLoss: 0.085837\n",
            "Train epoch: 85 [83000/25046 (10%)]\tLoss: 0.092742\n",
            "Train epoch: 85 [160840/25046 (20%)]\tLoss: 0.066888\n",
            "Train epoch: 85 [245760/25046 (31%)]\tLoss: 0.055123\n",
            "Train epoch: 85 [326880/25046 (41%)]\tLoss: 0.080441\n",
            "Train epoch: 85 [423700/25046 (51%)]\tLoss: 0.083951\n",
            "Train epoch: 85 [492240/25046 (61%)]\tLoss: 0.095147\n",
            "Train epoch: 85 [580020/25046 (71%)]\tLoss: 0.086635\n",
            "Train epoch: 85 [664960/25046 (82%)]\tLoss: 0.113379\n",
            "Train epoch: 85 [766800/25046 (92%)]\tLoss: 0.197786\n",
            "Make prediction for 5010 samples...\n",
            "0.28203243 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 86 [0/25046 (0%)]\tLoss: 0.113820\n",
            "Train epoch: 86 [82500/25046 (10%)]\tLoss: 0.102927\n",
            "Train epoch: 86 [164840/25046 (20%)]\tLoss: 0.086871\n",
            "Train epoch: 86 [249420/25046 (31%)]\tLoss: 0.068377\n",
            "Train epoch: 86 [333840/25046 (41%)]\tLoss: 0.099096\n",
            "Train epoch: 86 [415600/25046 (51%)]\tLoss: 0.072584\n",
            "Train epoch: 86 [479040/25046 (61%)]\tLoss: 0.078090\n",
            "Train epoch: 86 [583100/25046 (71%)]\tLoss: 0.076552\n",
            "Train epoch: 86 [659680/25046 (82%)]\tLoss: 0.133575\n",
            "Train epoch: 86 [750960/25046 (92%)]\tLoss: 0.152736\n",
            "Make prediction for 5010 samples...\n",
            "0.294491 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 87 [0/25046 (0%)]\tLoss: 0.085179\n",
            "Train epoch: 87 [83120/25046 (10%)]\tLoss: 0.091128\n",
            "Train epoch: 87 [162600/25046 (20%)]\tLoss: 0.140555\n",
            "Train epoch: 87 [247260/25046 (31%)]\tLoss: 0.085026\n",
            "Train epoch: 87 [323840/25046 (41%)]\tLoss: 0.123802\n",
            "Train epoch: 87 [412100/25046 (51%)]\tLoss: 0.267527\n",
            "Train epoch: 87 [501960/25046 (61%)]\tLoss: 0.131684\n",
            "Train epoch: 87 [577920/25046 (71%)]\tLoss: 0.165508\n",
            "Train epoch: 87 [656800/25046 (82%)]\tLoss: 0.092993\n",
            "Train epoch: 87 [742320/25046 (92%)]\tLoss: 0.140555\n",
            "Make prediction for 5010 samples...\n",
            "0.26892498 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 88 [0/25046 (0%)]\tLoss: 0.046731\n",
            "Train epoch: 88 [82980/25046 (10%)]\tLoss: 0.099844\n",
            "Train epoch: 88 [166800/25046 (20%)]\tLoss: 0.090818\n",
            "Train epoch: 88 [244200/25046 (31%)]\tLoss: 0.080586\n",
            "Train epoch: 88 [320720/25046 (41%)]\tLoss: 0.094177\n",
            "Train epoch: 88 [417600/25046 (51%)]\tLoss: 0.126074\n",
            "Train epoch: 88 [490920/25046 (61%)]\tLoss: 0.100834\n",
            "Train epoch: 88 [576380/25046 (71%)]\tLoss: 0.134238\n",
            "Train epoch: 88 [665120/25046 (82%)]\tLoss: 0.096106\n",
            "Train epoch: 88 [727560/25046 (92%)]\tLoss: 0.129153\n",
            "Make prediction for 5010 samples...\n",
            "0.27411687 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 89 [0/25046 (0%)]\tLoss: 0.110491\n",
            "Train epoch: 89 [82400/25046 (10%)]\tLoss: 0.132454\n",
            "Train epoch: 89 [166040/25046 (20%)]\tLoss: 0.078244\n",
            "Train epoch: 89 [245640/25046 (31%)]\tLoss: 0.119427\n",
            "Train epoch: 89 [334320/25046 (41%)]\tLoss: 0.076746\n",
            "Train epoch: 89 [408800/25046 (51%)]\tLoss: 0.073577\n",
            "Train epoch: 89 [494040/25046 (61%)]\tLoss: 0.124004\n",
            "Train epoch: 89 [573020/25046 (71%)]\tLoss: 0.090488\n",
            "Train epoch: 89 [661920/25046 (82%)]\tLoss: 0.077155\n",
            "Train epoch: 89 [751500/25046 (92%)]\tLoss: 0.080914\n",
            "Make prediction for 5010 samples...\n",
            "0.2595803 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 90 [0/25046 (0%)]\tLoss: 0.082686\n",
            "Train epoch: 90 [80280/25046 (10%)]\tLoss: 0.153419\n",
            "Train epoch: 90 [165720/25046 (20%)]\tLoss: 0.147911\n",
            "Train epoch: 90 [249900/25046 (31%)]\tLoss: 0.131040\n",
            "Train epoch: 90 [323280/25046 (41%)]\tLoss: 0.082800\n",
            "Train epoch: 90 [397500/25046 (51%)]\tLoss: 0.112795\n",
            "Train epoch: 90 [482040/25046 (61%)]\tLoss: 0.126226\n",
            "Train epoch: 90 [565460/25046 (71%)]\tLoss: 0.105961\n",
            "Train epoch: 90 [667680/25046 (82%)]\tLoss: 0.061720\n",
            "Train epoch: 90 [745920/25046 (92%)]\tLoss: 0.098679\n",
            "Make prediction for 5010 samples...\n",
            "0.26533058 No improvement since epoch  69 ; best_mse,best_ci: 0.25896978 0.8747299344368799 GAT_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 91 [0/25046 (0%)]\tLoss: 0.068069\n",
            "Train epoch: 91 [82040/25046 (10%)]\tLoss: 0.105494\n",
            "Train epoch: 91 [171400/25046 (20%)]\tLoss: 0.082598\n",
            "Train epoch: 91 [248760/25046 (31%)]\tLoss: 0.057520\n",
            "Train epoch: 91 [322480/25046 (41%)]\tLoss: 0.077281\n",
            "Train epoch: 91 [414400/25046 (51%)]\tLoss: 0.141100\n",
            "Train epoch: 91 [491400/25046 (61%)]\tLoss: 0.132823\n",
            "Train epoch: 91 [563360/25046 (71%)]\tLoss: 0.224968\n",
            "Train epoch: 91 [658720/25046 (82%)]\tLoss: 0.159393\n",
            "Train epoch: 91 [753300/25046 (92%)]\tLoss: 0.074222\n",
            "Make prediction for 5010 samples...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphDTA-new/training.py\", line 93, in <module>\n",
            "    torch.save(model.state_dict(), model_file_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 440, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 315, in _open_zipfile_writer\n",
            "    return container(name_or_buffer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 288, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileWriter(str(name)))\n",
            "RuntimeError: File model_GAT_GAT_davis.model cannot be opened.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DbTx4r7DqzrX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "outputId": "2e83405a-0b8c-46f7-f596-bdb14f2229bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GATNet(\n",
            "  (gcn1): GATConv(78, 78, heads=10)\n",
            "  (gcn2): GATConv(780, 128, heads=1)\n",
            "  (fc_g1): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (embedding_xt): Embedding(26, 128)\n",
            "  (conv_xt1): Conv1d(1000, 32, kernel_size=(8,), stride=(1,))\n",
            "  (fc_xt1): Linear(in_features=3872, out_features=128, bias=True)\n",
            "  (fc1): Linear(in_features=128, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (gelu): GELU(approximate='none')\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
            ")\n",
            "GAT_GAT(\n",
            "  (conv1): GATConv(78, 78, heads=10)\n",
            "  (conv2): GATConv(780, 780, heads=1)\n",
            "  (conv3): GATConv(780, 780, heads=1)\n",
            "  (fc_g1): Linear(in_features=1560, out_features=1500, bias=True)\n",
            "  (fc_g2): Linear(in_features=1500, out_features=128, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (embedding_xt): Embedding(26, 128)\n",
            "  (conv_xt_1): Conv1d(1000, 32, kernel_size=(8,), stride=(1,))\n",
            "  (fc1_xt): Linear(in_features=3872, out_features=128, bias=True)\n",
            "  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (out): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8185da26a983>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGATNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat_gcn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGAT_GATNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mginconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGINConvNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GAT_GATNet' from 'models.gat_gcn' (/content/drive/MyDrive/GraphDTA-new/models/gat_gcn.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "from random import shuffle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from models.gat import GATNet\n",
        "from models.gat_gcn import GAT_GATNet\n",
        "from models.gcn import GCNNet\n",
        "from models.ginconv import GINConvNet\n",
        "from utils import *\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dEmAFv7_0jxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create data.**py**"
      ],
      "metadata": {
        "id": "sRHRI1bUz94t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bJN2dLKR8CGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Nf4J2xrJ61o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}